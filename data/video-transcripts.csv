video_id,datetime,title,transcript
ISFmkrwJpcg,2025-06-09T05:00:30.000000,LlamaExtract Tutorial: Convert PDF & Images into JSON,"Good morning everyone. How's it going today? Welcome back to the channel. Today I wanted to show you Lama Extract, which is a new tool by Lama Index. And what it allows you to do is to extract structured information from an unstructured file. So for example, has it ever happened to you that you have a bunch of PDFs or images with resumes from employees or invoices and you want to take all of that information and put it into your database so that you can actually use it? Well, this can be quite cumbersome and a lot of work if you do not have a tool that does this automatically. So that is what Lama Extract can do for you. It is kind of a more automated way of doing what you can also do with unstructured, for example. So let me show you how it works. Essentially, it is very, very straightforward. All you have to do is define a schema of the information that you want to be extracted. Then you're going to send your document, it can be your PDF, with one or multiple pages, or an image, etc. And you will get, as a result, the JSON object with all of the data extracted from that file. And we're going to be covering everything that you need to know about how to use this in a very detailed notebook. And I'm also going to be showing you very quickly how to use the graphical user interface that they have available as well. And everything that I show right here, you can actually do it for free on their free tier. So this should be enough to cover anything for any personal project that you may have, or even maybe a small company. So let's get right into it. Alright, so to get started, all you have to do is click right here and get started. You will be prompted to create your new account, and then you will go right here to Llama Cloud. They have a very generous free tier, so you don't really need to add your credit card. You're going to go right here to parse, extract, or index. These are the tools that they have available. And the one that we're going to be using is extraction. As you can see, I have already created one extraction agent. They call them agents, so essentially this is just an extractor tool. And I have, as you can see, just created one right here, and you can create a new one just by going right here. When you create one, the UI will prompt you to select the extraction mode. You have the possibility to select between fast, balanced, multi-modal, and premium, depending on how powerful you need the extraction to be. Also, you have these more advanced features, such as you want to extract per page or per document. We're going to be seeing more on that in a second. And here, very importantly, you have the actual schema that you're going to be working with. So in this particular example, I'm going to be extracting resumes. So I'm going to be uploading a resume right here, and I'm going to be extracting the email, the name, and the skills of the person. So let me show you what this would look like. So I'm using a resume dataset that I downloaded from the internet, here with a bunch of different resumes. I'm going to take one of these ones right here, and I'm going to upload it right here. This works better with PDFs, however, they do support images. So I'm going to click on Run Extraction, and this is going to queue the process. And, as you can see, this is going to be pretty useful if you want to extract a single document. But if you really want to create a pipeline to extract, for example, a list of invoices that you have, or maybe automatically extract the results from the resumes that you're getting for your company, you probably want to do this with code. So we're going to see how to do this with code in just a moment. But let me just show you, here is the resume that I just extracted. And, as you can see, I have the extraction results right here that I can just export. However, the real useful thing and powerful thing right here is to do this with code. So let's take a look at the notebook on how to do this. So what we're going to be doing right now, actually, before starting, I deleted the previous agent that I had created right here, so that we can actually start from scratch. And the first thing that you're going to want to do is install Llamacloud Services. This is the SDK that we're going to be using in order to actually connect to the Llamacloud API. And then you're going to need a Llamacloud API key. So you're going to have to name it Llamacloud API key, like this, so that your SDK can detect it automatically. And then after that, you're going to go right here to API keys, generate new API key, you can name mine temp, hit on create, and then just copy this, and we're going to say that if there is no Llamacloud API key detected in our environment variables, we're going to define it right here, and there we go. And now we can start actually creating the extractor agent. So, the first thing that you're going to want to do is from Llamacloud Services, you're going to import LlamaExtract, and we're going to be using Pydantic to define the schema that we're going to be extracting from our PDFs or our unstructured files. So first of all, you initialize your extractor doing equal LlamaExtract that you imported from Llamacloud Services, and then you define your schema using Pydantic, like this right here. If you're not familiar with Pydantic, it is a data validation library for Python that allows you essentially to create these schemas that then you can just call in your applications to be sure that your application is respecting them. And that's what we're doing right here. So the way this works is that you import the base model from Pydantic, and then you inherit from that class, and then create your own class, and just add different properties that you're going to want this schema to have. So the first one that we're going to be using is the name, then the email, and the skills. The name is a string, the email is also a string, and the skills is a list of strings. And very importantly right here, you're going to have to add a field with a description right here. And this is extremely important, because this is what is going to tell your large language model, or your AI model, what information is going to be in this particular field. So remember to make it very specific. In this particular example, these are very straightforward things, but if you want it to be more specific, or you want your language model to perform some additional operation in between while filling this schema, this is the place to add those. Then you're going to want to just create the agent, saying agent equals extractor dot create agent. You're going to have to give it a name, and then you pass as a second argument the schema. And in this case, it is the resume that we have right here. And what I'm going to do is I'm going to be extracting this schema from one of these resumes that I have downloaded from a dataset. If you want the full dataset of all the fake resumes, it's in the description. But it's very straightforward. What is going to be happening is that I uploaded them right here under a data directory in my Colab notebook. I'm going to be calling it on resume1.pdf. So I'm going to do it with resume1.pdf, and we're just going to hit enter. And as you can see, this is going to start off the process. So it created my agent and it extracted my data. Now I can take a look at the data just by taking a look at the result right here. So as you can see, the resulting element is actually quite big. But if I just want to take a look at the data, I can do result.data. And now I can see that the name is Macy Williams email, and then the scales, there was no email in this particular one. So there you go. That is how you do this. And very interestingly is that you can go right here to extractions, and as you can see, my resume parser was just created. So I can take a look in my UI what is actually going on with my pipeline that I am doing. So I can see the extraction results right here as well. So you can see the file that I uploaded, and you can see the extracted data. And at the same time, you're going to be able to use this in your own pipelines for data extraction if that is what you want to do. And if you're working with this in a pipeline, you probably want to be able to manage the agents. So that is to delete them, create them, or also get the agents to reuse them once you have created them. And it's also possible to do this naturally in the UI. So you go right here to the UI extraction, and here you have all the agents that you have already created. But it is also quite useful to be able to do that programmatically so that you can create them and maybe even dispose of them on the spot while you're creating your pipeline. And that's very straightforward. All you're going to have to do is you're going to import LamaExtract like you did before. And from here, you can just initialize an extractor and call the ListAgents method right here. And as you can see, if I just hit an Enter right here, you can see that I have my agent that I had just created before named ResumeParser and the ID that is associated to it. Now, if what I want to do is to delete it, I can just run extractor.deleteAgent and all I'm going to have to do is to pass the ID of this particular agent that I want to delete. Or something else that I can do is I can just get an agent that I have already created and reuse it. Just by doing extractor.getAgent and then just pass in either the name or you can also pass in the ID and right here, this one right here, would take the actual ID of my agent. And in this example, what I'm going to do is I'm just going to delete it. So I'm going to run this right here. It's going to get my agent then delete it. And then if we come right here and reload, you can see that the agent is gone. Now, something very useful that the SDK can allow you to do is to extract data from multiple files at the same time. So you don't have to go one after another or manually load one after another in the UI. And in order to do that, it's very straightforward. I have actually recreated the agent that I had made before off camera. So I'm just going to run getAgent to be able to reuse it. So I'm going to set this agent to getAgentResumeParser and then I'm going to have to go to agent.qExtraction. And this one right here is going to take as input a list of all the locations of the files that you're going to be extracting. In this example, I'm going to be extracting two different resumes right here. I believe it is this one and this one right here. And it's very straightforward. All that it's going to do is it is going to queue that process in a process queue in the cloud. That is why this has to be awaited. And you will also be able to check the status of these processes in the queue to see when they have finished. So right now you can see that it has already queued the extraction. And now we can actually just check the job status right there. So for each one of the jobs that I have created, I can just check the status in getting the getExtraction job then passing the job.id, which I got from right here. And then just accessing the status part right there. And essentially you can see that both of them have already succeeded. So what I can do is just go right here. And for each one of them, I can just run getExtraction run for job, which essentially will return to me the value of the extraction after the job has been finished. After we have identified that the status of the process is a success. And then I can just go to results.data for each one of these results. And as you can see, I have the extracted data from my resumes. And now quite useful too, you can also update the schema of your agent that you have already created. So if your agent is already created what I'm going to do is actually just get the agent again. So I'm going to say getAgentResumeParser. And I'm going to update the schema. In this sense, I'm going to recreate a new pedantic model. And in this case, I'm going to add the location and education fields. And all I'm going to have to do is say agent.dataSchema and then just pass in my new schema right here. And I'm going to have to hit agent.save so that it actually gets updated in the cloud. So I'm going to hit enter right here. And after that, I'm going to be able to just reparse another file right here. I'm going to be parsing the resume number 2. And let's take a look at the data that it returned to us. And as you can see, we have Yamamoto, we have that this resume had no email, we have the skills, you have the location, and then you have the education as well. So there you go. That is how to create, update, and delete agents and how to run them in a batch. Alright, so now let's talk about some more custom configurations. For example, let's suppose that you have a single file with hundreds of different resumes in it or a single file with hundreds of different invoices. What you're going to want to do is probably not do what we have been doing before because that would extract you a single JSON file for the entire file of all of your resumes. So what you're going to want to do is instead you're going to want to set the setting for extraction by page. And there are some other custom configurations that are quite useful. But first of all, let me show you that you can actually initialize a Llama extract by project ID and by organization ID that can allow you to have more controlled environments. So when you go to Llama Cloud, what you can do is go right here and either create a new organization or a new project right here and have your different files associated to that particular project or organization. And also something that you can do is you can import this API error types from Llama Cloud Core.APIError so that way you're going to be able to have a much more resilient error handling logic like you see right here. So in this example, I am just getting the agent that I have already created. If it exists, I am going to delete it and then if there was an error, I'm just going to return the error right here. And the reason why I'm going to be deleting it is because I'm going to be creating a new agent with this more sophisticated configuration that you see right here. So in order to import this, you're going to have to import extract config from Llama Cloud like this. Now Llama Cloud naturally comes inside the Llama Cloud services so you do not have to install it separately. And now what we can do is just start using it. So I'm going to initialize extract config equals extract config like this. And here are a bunch of different configurations that you can set. The first one is the extraction mode. It can be either fast, balanced, multi-model or premium depending on how complicated your files are. Usually fast is more than enough. If you have a little bit of a doubt, you can use balanced. Multi-model is really if you have a lot of tables or images or lots. But in general, balanced or even fast should be enough for pretty much any use case. Secondly, you have the system prompt. So in this case, since it is a resume, I'm going to say this is a resume for the company Acme. And then the extraction target. This is a very important setting because this is the one that will allow you to actually extract one JSON object per page instead of per the entire document. So in this example, what I'm going to do is I'm actually going to be using this file right here with 8 resumes and I'm going to be extracting it right here with a single call and it is going to return an array of 8 different objects, one for each resume. Also, use reasoning. This one is in beta for now, but you can set it to true if for some reason you really need a much more sophisticated way of extraction. Maybe the agent is supposed to perform some calculation or perform some more sophisticated reasoning. I cannot think of any cases in which this would be necessary unless it is a very, very complex file with, say for example, a table and then you probably also have a plot and you have to extract some data correlating the table and the plot and things like that. Maybe for those scenarios you want to use reasoning. But for most case scenarios, you probably just want to go ahead without that part. And it is also possible to cite the sources. So when you hit this one to true, this is going to actually return to you a parameter with the sources with the actual exact text that it used to populate the field inside of your schema. So I'm going to be creating the agent like this. So agent, we're going to do extract.createAgent. I'm going to pass in as before my resume parser name, then the data schema, the resume that we had previously defined, and then the configuration which is this extract config object that we have just initialized. And I'm going to be passing in the mergedResumes.pdf. If I remember correctly, it is merged.pdf, not mergedResumes. So merged.pdf and let's hit enter. Remember that I am recreating the agent because I just deleted it right here. So there you go. And then let's take a look at the result. And there we go. So now we can actually just go to printing this part right here. So I'm going to be using PrettyPrint for this. So let's hit enter. And as you can see, I have eight different objects right here, not a single one. So I have the education for the first one, then the scales, the name, the education, name, scales for the second one, and the same for each one of the eight. Now just to show you what would happen if instead of perPage, I pass in perDoc. Let me just execute this. And there you go. Now if I print this one right here, you can see that I get a single JSON file, which is probably not what I want because I actually want the eight different ones. So just be sure to select perDoc or perPage depending on your specific use case. And then let's just take a very quick look at the pricing. Lamaindex has historically been very generous with their free tier, so there is really no reason to not test them out. Their free tier is essentially the equivalent of a $10 per month subscription, but for free. So you get 10,000 credits for free every single month. Every 1,000 credits is equivalent to $1. And you can get the starter or the pro enterprise if you really need enterprise grade parsing, but this is more than enough. With 1,000 credits, you actually get about 1,000 pages on their balanced extraction. So let me show you right here. Then to extract pricing, you can see that the balanced mode costs you 10 credits per page, which would be 1,000 pages per month on their free scheme. And very importantly, these credits can actually be used across their different products. So they can be used in extract, in parse, and in index. And in terms of privacy, well, Lamaindex ensures you that they do not use your data to train any models and the data is kept private. And also, if you're interested in it, they also allow you to host all of your models and all of your data processing and data storage in Europe. It's just a little bit more expensive, 50% more expensive to be precise. But it is possible to sign up in Europe and have everything in Europe instead of in North America. And in order to do that, all that you have to do is go to, instead of cloud.lamaindex.ai, you go to cloud.eu.lamaindex.ai. And that way, your data and all of the processes are never going to lead the European Union. In case that is useful to you, or important, you're probably a company in the European Union and you do not want your data leaving the European Union. And there you go. That has been a complete overview of how to extract structured information from a lot of unstructured files, such as PDFs or images. And it is very useful to actually implement your own pipeline. Maybe you want to extract all of your PDFs, all of your resumes, invoices and put them inside a database. And you can definitely do that very accurately with this tool right here. So thank you very much for watching. It has been a great pleasure being here with you. And I will see you next time. Music Music Music Music Music"
q3lcSwdLAEs,2025-06-05T09:01:24.000000,Vibe Coding For Engineers (make it ACTUALLY work),"Good morning, everyone. How's it going today? Welcome back to the channel. In today's video, we're going to be covering how to prompt your AI coding assistants, such as Trey, Cursor, Copilot, Windsurf, whatever you're using. And we're going to be seeing how to prompt them to actually create useful and secure applications that are robust and that do not acquire infinite technical debt that will make you want to pull your eyes out. So what we're going to be covering today is how these AI coding tools work, so how Cursor works, what is actually happening behind the scenes, and how you can think about this tool so that you can better use it. We're going to talk about what makes a good prompt. I'm going to show you actually some examples of pretty long prompts that are very, very useful to start actually a thread or a conversation with your assistant. We're going to be learning how to see conversations as threads of tokens, essentially, so that we use them in the way that they're actually working behind the scenes. And we're going to be covering a very quick demo of how to actually create one of these prompts and execute it. So without any further ado, let's actually get right into the video. All right, so now let's talk a little bit about how language models work. And this is especially important because this will give you an intuition of how to use these AI tools that we're working with and that you're most certainly going to be working with if you are not already. We have already talked about this a little bit, and we talked about how language models work when creating AI applications, but this intuition is also very useful to have it when you are using these AI applications, okay? So in this example, we have just a very quick diagram of how language models work, and this is a way to think about it, the best way to think about it, I would say, when using these tools. You have to think about a language model or these AI coding tools as essentially just a text-to-text machine, all right? So essentially what's going to happen is that you're going to send some text to it that is going to be your prompt. This text can include just a question, it can include a task, a very detailed instruction of a task, or it can contain just a short prompt and then a very long piece of code that it has to complete, etc. And then as the completion, you will have the most likely continuation to whatever you sent right here, okay? Now, how does this actually work? To give you a little bit of an idea of what is actually going on behind the scenes, the language model is actually not outputting a single token every single time that it receives an input. Actually, the output looks more similar to a distribution. So the final layer of your language model will generate a distribution of the most likely tokens that come after whatever input you give to it. So for example, let's suppose that you give to your language model the input, why did the chicken cross the, okay? It's a cut-off sentence, it's not even a question. Now, the language model is going to return a distribution of the most likely continuation to whatever you sent right here. So it can say that road maybe has a 20% probability of being the most likely continuation right here, then river, 10%, house, 5%, banana, planet, etc. And you'll have all the way to all the words in its dictionary, and all of the probabilities right here will total a 100% probability, okay? So that is actually what is going on right here. You're generating a distribution of the most likely tokens, and this one has a 20% probability of being chosen as the next continuation right here. Now, there are different ways to organize this distribution and to make it more or less spiked. Usually, it is the most likely continuation has a significantly higher probability of being chosen than the rest, but that's not always the case. And there are ways to tweak this, but usually you have to worry about it. It's already done by default. And also something to keep in mind about this is that this is mostly true or more visible with older models. Newer models are actually fine-tuned to follow a conversational system, conversational manner, in which if you send something like a cut-off sentence, instead of actually completing the sentence, they will continue the conversation saying, hey, I guess your message got cut off. Can you complete whatever you were sending? But in the end, what they're doing is just completing the sequence of tokens with the most likely continuation. And that's true not only when you're talking to JGPT, to Anthropics Cloud, to whichever assistant. It's true also for coding assistants that use these language models behind the scenes. Everything that is happening in the language model is going like this. And the input can be a very long piece of code, and the continuation will be the most likely continuation according to whatever you requested from that piece of code. So there you go. That is a way to think about language models and to think about code. And they will be generating the most likely continuation. All right. So let's talk about how to create a good prompt. And it's not as straightforward as it sounds. It's actually more of an art than a science. But right here, I'm going to show you some tips, tricks, some advice to, in general, help you create better prompts, not only for your AI coding assistants like Cursor, Trey, Copilot, but also for pretty much any other AI assistant, such as JGPT, Cloud, etc. And the first thing that you have to consider is that you have to shift the way you think about prompting or about querying to solve a problem. We have, for a very long time, been used to actually using Google to figure out solutions to our problems. So, for example, in Google, say you wanted to enter some data into your database, you would search for something like how to enter data in SQL. And this is already quite a good query for Google, but this is probably not the best for an AI. So an AI would probably take something better, like write the SQL query to enter this data to my SQL database. And then you can send to it something like my data is the username, the username is whatever, and then the email is whatever. And then the table name is this right here. As you can see, this is already becoming more of an actual instruction that you would give to someone who's actually building this, a human, rather than just learning how to do it and then trying to figure out how to put everything together. Because if you send something like this to your language model, be it on Cursor or in Copilot, whatever, it is just going to respond to you with a very simple query, and then you're going to have to update it by hand, and you will have lost time. You will have wasted time by waiting for the system to generate the response and then tweaking the response. Whereas if you had sent something very precise from the start, you probably would have something much closer to what you actually needed. So just a very quick example, but a good way to think about this in general is to think about it as though you were talking to a human that is very, very good at overly making assumptions about everything that you say. But it's also very good at executing things. So let's suppose that you go to, an example that I really like is let's suppose that you go to a travel agency. And in the travel agency, you arrive and you want to travel to China. So you tell your travel agent, organize a trip to China for me. Now, a human will most likely come right here and be like, okay, yeah, sure. Let's organize a trip to China for you. So where is your origin? Where are you going to live from? So you're going to live from San Francisco, maybe. What is your budget? When do you want to go and when do you want to come back? What cities would you like to visit, et cetera? So these are all of the questions that the travel agent is going to ask back at you. That is not how a language model is going to work. A language model is actually going to make assumptions about all of this, because they will be the most likely things to come after it starts writing the recommendation for a China trip for you. So it will give you the most likely continuation for the origin. It will give you the most likely continuation for the budget, the most likely continuation for dates, et cetera. So what you want to do, I mean, depending on how fine tuned it is. But in general, a good thing to assume is that it will make assumptions about everything. So you have to be very clear about everything that you want it to do. So actually, if this was a language model instead of an actual history, human, you would send all of this from the start. OK, that's a good way to think about it. So all of the instruction that is very precise has to go right there from the start, everything from you. OK. And now I understand that it is not very straightforward to do. It's not something that's very straightforward to do when you're trying to create something, especially in software. Sometimes you don't really have a very clear idea from the start of exactly where everything is going. So if you're talking to an assistant, maybe you're trying to figure things out at the same time as you're talking to your AI. And we're going to get there in just a moment, how to actually figure all of these things out and how to start a new thread with whatever you found out. But something to keep in mind about this is that a good rule of thumb when creating this prompt is to add, is to consider this three pillars of a good prompt. You can consider that you have to have a very clear instruction, as we mentioned, a very clear context. So where you're coming from, what do you want, what you want to do, what you travel for, etc. And very clear examples also of what you want. This can be examples of exactly what you want the language model to generate, the format that you want the output to be, etc. I'm going to show you some examples in just a moment, but just consider these three things. You have to have instructions, very clear instructions, very clear context and very clear examples. OK, and you may see that this is already becoming quite long. And that is true. A very good prompt is a very long prompt. So actually, let me show you an example of a prompt that I built just a few days ago for precisely for YouTube. So let me show you that. All right. So as you may know, I do YouTube videos. So I actually needed the other day a tool that would allow me to concatenate all of the sequences of short clips that I record to put them all together into a single video for YouTube. And usually I do this manually on CapCut, go there real quick. But what happens is that I'm trying to make more videos, so I'm trying to make this a little bit more automatic. And since I don't do a lot of post-processing, I felt that I could just write a very quick script to concatenate the whole thing and generate a few things that I need every single time that I create a video. And I figured that I could make a script that would look something like this. So actually, the script has a few methods, as you can see, it has a concatenate video, generate timestamps, generate the transcript, generate the description, and then a few helper functions and then generate the SEO keywords. And it's quite a long, quite a long class right here. It is 432 lines right here. And the entry point is over 75 lines. So in total, about 500 lines of code. And I ended up coding the whole thing in about an hour. And the reason for that is that I used AI coding tools and I was very precise in exactly what I wanted to get. Okay. And actually the instructions that I used are right here. So this right here is the prompt that I sent to my language model. So that it could understand exactly what I wanted to get. And I sent this one to cursor, if I remember correctly, or maybe at the time I was using Trey. But in the end, it is a language model that is doing all the work behind the scenes and it's working through my AI coding assistant. So the instructions look something like this. So there is a very clear overview of what my tool, the entire thing that I am trying to build actually is. So this tool concatenates multiple MP3 files. So this tool concatenates multiple MP4 videos from a directory. It generates timestamps, creates transcripts, etc. I specify the configuration and the output of the organization, how the output is going to be organized, sorry, and the actual operations. So I have one, two, five, five operations. And every single operation, as you will see, is actually very well defined. So for each operation, I described a very clear objective, the requirements that I needed it to have, the steps that I needed it to take exactly. And for example, for the second step right here, the objective was to create a JSON file with the chapter information of each video segment in my video. And I wanted it to be exported to JSON, but I wanted it to be in a very specific format so that I would be able to parse it afterwards. And so in order to do that, I just gave it a very clear example of how it had to parse the whole thing. And that's how it goes. It's very straightforward. So this part right here is what I mentioned before when we came to examples. It's not only examples about what technology you're using or what the final code should look like. It's also examples about the schemas and the structure that you expect to get. So this is just one example right here, just an extra information right here, more information right here. And here's another example, as you can see. So this part right here is create a VTT transcript using OpenAI's Whisper API. And the steps are very clearly defined. And something that happens sometimes is that the language models actually use previous versions of the SDKs that you're trying to use or the libraries that you're trying to use. So a good rule of thumb to do when you're prompting your AI assistant to create something with a very specific version of a library or even if it's just the latest version of a library or a framework, a good thing to do is to send your language model an example of exactly how the code looks like of what you're trying to build. And what I did in order to get here was very straightforward. I just went to OpenAI Whisper API, I looked for the documentation and I copied the example right here with the latest implementation of the API, of the SDK. And there you go. Then you have more details right here. So as you can see, it's kind of programming in natural English language. And that's actually what we are doing. We are programming the language model, telling the language model what to do. And that is why it is very important to keep all of these things in mind. So you have, as you see, we have a very clear instruction. You have a very clear context and you have very clear examples of exactly everything that you need. The examples are particularly important because your language models are not trained on everything, especially not new material. So if there was new material that came out in the past few weeks or in the past few months, the latest language models probably don't even have it because they are pre training material and that before that new material came out. So a good thing to do is to send them an example of the new SDKs or the new documentation that you're trying to use so that they can actually absorb that on the spot. Language models are actually very good at absorbing information from your context, even if it was not in their training material. OK, so just keep that in mind. So, for example, if you're creating a script with a LangChain, LamaIndex, whatever, a good thing to do is to go to documentation of whichever library you're trying to use, copy an example of the implementation that you're trying to do, paste it into the context of your language model instruction and then ask for it whatever you want it to actually do. All right. So there you go. So now let's actually take a look at how I actually made this prompt because it's a pretty long prompt and it can take quite a bit of time to actually get here. So let's take a look at that. All right, so we are going to see now how to create a prompt that looks something like this, which is a very specific and very clear prompt. Remember that we mentioned before that the larger the prompt, usually the better because it will have more context to actually perform the correct calculations to give you a correct completion. So a very long prompt is actually exactly what you want to create. But how do you get there? As you can see, the prompt that I have right here is actually pretty long and it takes quite a bit of time to actually get to this part right here. In itself, it's actually kind of programming it in English. So how do I get to actually creating a prompt that is this structured? As you can see, it is quite well structured. And the reason for it is that it was actually a language model which wrote the final draft for me. It was not myself. And that's what I want to show you right now, how to use a language model to actually get to this place right here before you can actually start building with your AI assistant. So when you start the process, I would usually start with an assistant that is already within my code base. And to do this, I go to cursor, for example, I come right here. And in this example, I already have a code base that is open. But most likely then, I mean, you will most likely be in either of two scenarios. So you're starting a project from scratch or you're starting a project which is actually a feature of an existing code base. if your situation is situation number one, you're starting a project from scratch, I would actually encourage you to start the conversation, not with your AI editor, but instead with the chat GPT voice mode or your AI assistant of your choice, because that way you're able to actually just talk to it and describe your project and it can reply to you in voice and you can continue the conversation and it will be just like you're brainstorming your ideas about the project that you're trying to build. And something that is important is that whenever you're doing this, always tell your AI assistant that you're in the planning stage, okay? So you're brainstorming, you're figuring out how to implement different features so that it can also give you advice or suggestions about how to implement whatever you're trying to implement. And then by the end, after you have been talking to your assistant for a good 20 minutes or whatever, after that, you ask your assistant, okay, so now we have a very clear idea, you and me, of everything that my feature or my application should have, now help me write a prompt that will be used in a new AI assistant to create this application or this feature that we have been talking about. Describe it in a very precise and detailed way so that the AI knows exactly how to implement it. Describe the context and also give examples of whatever we have been talking about. So that's what I would expect you to do. So for example, let me show you. If you go right here, let's say that you are already working in a code base that already exists. If it is a code base that already exists, instead of using your preferred AI assistant such as chatGPT voice mode, I would actually encourage you to go straight into your ID coding assistant because it will have automatically all the context of the existing code base. So right here, I'm working with an MCP client. So let's suppose that I want to implement a new feature. So I will ask it to implement this new feature. I am trying to implement a new feature to this MCP client that will be able to not only generate the completion from the language model, but that will also stream the completion as it is being generated. For context, this application is an MCP client, which means that it works with the model context protocol by Anthropic. And essentially what it means is that it is able to connect to multiple tools that are hosted in this thing called the MCP server. As you can see, there are some methods that already connect to this MCP server and that get the tools. All I want you to do right now is to actually just take the tools that were generated, execute them if there are any in the language model response. And then after that, when the language model actually finishes using the tool, you will have to stream the generation token by token with a generator that I will expose via my API. And there you go. So as you can see, I mean, I described pretty much everything that I wanted from my project and actually getting a dictation tool, something like Super Whisper, Willow or Open Super Whisper for that matter. It's also quite useful because you can talk about what you want and you can be a little bit more detailed and go around whatever you're trying to build. And as you can see, it took me not too long to actually write a super long paragraph. And I can actually continue this by saying, help me plan this feature and make sure that everything that I want to implement is actually correct and cogent with whatever there is in my current implementation. I want to make sure that everything works correctly. Please ask me questions if I forgot to mention something, if you feel like something needs a little bit more detail and let me know if there are some other libraries that I should implement in order to actually implement the feature that I am trying to build. And there you go. So this is my entire prompt. I'm gonna send it. And now Cursor is going to start actually thinking about the whole thing. And it's going to consider the process that I already have right here. And we can go back and forth. And right here, this is a planning stage. So we're going to be talking with Cursor. We're going to be identifying what I need to actually do, what actually was not a good idea, probably that I mentioned before. And then by the end, after a very long sequence of back and forth, I can just ask it. Perfect. Now write a very detailed prompt that I will use with a language model. And this prompt will be used to create and implement this new feature that we have been talking about. Make sure to make it as detailed as possible and include examples whenever needed so that the language model knows exactly how to implement the feature that we have been discussing. Then there we go. And now the language model is going to be able to actually generate the prompt for me. I can actually ask it to generate the prompt inside a code block in Markdown. And there we go. Now we're going to get the actual prompt right there. And this is the actual prompt that we're going to be able to use within my application, whichever it can be. It can be Cursor, it can be Tray, it can be Windsurf, whatever you want. And this is exactly how I built the prompt that you saw right before. So as you can see, it's a pretty long prompt. It's a pretty detailed prompt. I did not go over the whole back and forth right here, but here we already have a new starting point for my next part right here. But what I want to tell you right now is that you should copy this prompt right here and actually start a new conversation. Because what some people do is that after talking about the feature for a while, they start talking about, let's now implement it. And sometimes that actually works pretty well. But I'm here to tell you that there's actually a better way, which is just copy this extracted material, this extracted prompt from the entire conversation and start a new thread with it, okay? So what I would do is right here, I would come right here. I would copy this prompt right here. I will start a new conversation right here with Cursor. And I will start it with this prompt right here. And then just maybe add a little bit of extra content before that or afterwards. And this is going to give me much better results. And as you can see, it is already writing the code and implementing it. And now I would have a much, much better implementation of what I wanted to build. So as you can see right here, I have my new methods that were created. And this is how I would actually approach the prompt engineering part right here. And there you go. So it finished generating the whole code. And something that is very important right here is to actually read the entire thing that was generated to make sure that it actually makes sense. This is especially important, especially if this is not just a very quick weekend project that you're trying to vibe code your way through. But if this is a real project that is actually going to production, you want to really understand the code that is being generated because otherwise you're going to just accumulate a lot of technical debt. Technical debt means that you're going to at some point have to come back here and understand the code, especially if there's an error. So if you understand the code from the start and are able to actually update it to whatever you actually need, because as we saw before, the language model will not always generate the best code. So if you actually read it, understand it, and actually tweak it to make sure that it is exactly what you need, you're going to be actually using the language model to save you time and not to build technical debt, which can be a hell because language models can be very good at building up a lot of technical debt for you. So just keep that in mind. Use the language models and use the code that is generated by them as though it was your code. Keep it to the same standards as you usually would with your own code and you will have everything you need to actually go faster into your development. But now I wanted to mention real quick why actually I did what I did with which was go through the conversation and then restart the whole thing again in a new thread. All right, so just very quickly, let's talk about why it is important to do what I showed you just now, which is starting a conversation within a new thread with that new, very detailed prompt that you have just created. And I mean, you do not always have to do it. Actually, if you have started your conversation with your assistant and a few messages in, say six messages in, you already have a very clear idea of what you want. You can just go into implementation right here. You can just ask it, switch to agent mode and ask it to implement it, implement the feature. And that's more than okay, all right? However, sometimes it happens that when you're exploring the idea, you're exploring the feature, you're discussing with your assistant, everything, you can, I mean, this can actually take more than just this. I mean, you can take like say 20, 30 messages or even more, and that just creates a very, very long thread, a very long conversation. And something to keep in mind is that every time that you send a message to. to CGPT, to Cursor, to Copilot, to any generative AI that you have right here, what you're actually doing is you're sending the entire history of your conversation on each message, right? Because the language model itself does not have a memory of the conversation. You have to feed it the entire conversation every single time to make sure that it knows what you were talking about. So actually, what happens is that every message is sent every time. And this starts even from the first message. When you start a conversation with your assistant, that is not actually the first message that is sent to the language model. The first message that appears in the thread is the system prompt, okay? And I'm sure that you have probably already heard about the system prompt, what it is. It is essentially the first message. It's usually a system message that describes the personality and the objectives of the assistant or the AI that you're talking to. And for example, in the case of CGPT, it's something like you're a helpful assistant, et cetera. They do not really release their system prompt. In the case of Anthropic, let me show you, Anthropic system prompts, they have actually open-sourced the system prompt. So if you go right here, you can see the system prompt from Claude. And this one is actually the first message that appears in every conversation that you have with Claude. And that is actually what I want you to think about right here. When you're talking to Cursor, you're not only sending your own message to the language model, you're sending the message and then that is being appended to the system prompt that the application created. And then after that, once the AI responded, it responded with its own AI message, then you respond with your own message and et cetera, and you continue the conversation. And as you can see, this is kind of a thread of tokens. So this is the first token and the first set of tokens. Then you send another set of tokens and the AI continues the completion with another set of tokens. And then you continue the thread with another thread of tokens, et cetera, all the way until your entire conversation. And remember that all the history of the previous tokens in the entire thread are used as context to generate the next response. So all the thread is actually being sent right here as input every single time. And that's why I said that it's sometimes a good idea to actually restart the thread, especially if you took a long time to actually figure out what you actually wanted in the feature. So let's suppose that you have been talking to the AI for like 40 messages about what you want to build. And in the meantime, you went through tangents and you considered features that in the end you will not be including. You considered other libraries that you decided not to use, then chose a different design pattern with the AI that you wanted to implement, et cetera. All of that will be in the history. And if after all of that, right here, you arrive and you're like, okay, so now implement it, it will have all the noise of the previous conversation. So that's why it's a good idea to just ask it to give you a very clear prompt like the one we had before with a very clear explanation of exactly everything. So a clear, long prompt that the AI is going to generate for you. So I'm going to make this a little bit longer like this one. And now what you can do is take this one and go up here and start a new thread from that new system prompt and start a new thread like this. So that way the thread is really focalized on your specific feature that you want to implement. All right. So that's why I recommended that you restart the thread, especially if you go very long right here. So there you go. That is how you build prompts that can actually help you build applications faster. Just remember to think about your prompts as though you would think about an actual program. You're actually describing everything that you want your application to do in your prompt. Okay. And the longer the prompt, the better. Remember that you're not talking to Google. You're talking to a language model that will take everything within your prompt to give you the most likely completion, which is going to be the code that it will generate. Okay. So just keep that in mind. I hope that this video has been useful. There are, of course, many different ways to prompt your language model. And sometimes a long, super long prompt is not the way to go. Sometimes you will have to go for shorter prompts that are very specific to whatever you're working with at the moment. But I hope that this has been quite useful. This is an approach that I see very rarely taken and that I think it's very useful because it will increase the accuracy of your language model in the generation of your feature. So thank you very much for watching and I will see you next time."
C2Pg0nWMWew,2025-05-14T11:30:17.000000,How to Build an MCP Client GUI with Streamlit and FastAPI,"Good morning everyone! How's it going today? In today's video I'm going to show you how to create an MCP client graphical user interface that looks precisely like this. So I'm going to ask it how do I integrate LamaIndex with ChromaDB. This one has access to a tool called GetDocumentation which is exposed to it via an MCP server and it's going to call the MCP server, get the response and display everything to me in just a moment. So there you go we have the response and this is what you can expect. As you can see we have the user message which is the query that I sent right here. After that we have that the assistant decided to call a tool so we have a message of call of type tool use and the input which is exactly what parameters it sent and then we have right here a tool result which is the actual result from our MCP tool and then naturally we have the actual response from our assistant after having used my MCP tools right here. And just a very quick note on the fact that in this video we're going to be plugging this front-end to a FastAPI application that we coded in the previous video that was up a few days ago and that API that FastAPI actually looks like this. So it is an API that exposes an endpoint on their query right here and it takes one parameter which is query where you send your query right here and it returns a bunch of messages. The first one is your own message then it returns the assistance tool call, tool use right here then it returns the actual response from the tool use that you did using the MCP server and then by the end it returns the assistant right here. So in this video we're going to be plugging a very nice front-end that we're going to build with very few lines of Python code with this FastAPI application that you should already have or a similar one that you may already have on your own. If you do not have that application I recommend that you go to that other video to complete that FastAPI app first and then come right here to actually build the front-end that looks like this. Okay, so let's get right into it. Alright, so what we're going to be doing right here is very straightforward. Now we're going to be going to creating a front directory right here beside our API and I'm going to initialize a main entry point in Python. It's very straightforward and in this one what I'm going to need is I'm going to need to install Streamlit, right? So I'm going to use Streamlit, there we go, super quick, and there we go. Now after that I'm going to be able to just import it like this. So this is what I'm going to be using, this I'm not going to be using it yet, so I'm going to be using asyncio, I'm going to be using a quick logger that I'm going to actually just copy from here, from my API, so I'm going to paste it right here. If you might remember from the API video, the logger that I use right here is essentially just a very quick logger that I've coded that essentially just has two debugging levels, one for info and one for debug. Info is logged in the terminal and debug is logged into a file that will be right here. Very quick, very straightforward. And after that I'm going to be importing Streamlit as st and we're going to be using asyncio. So I'm going to initialize my main function right here and then we're going to just run it when we actually execute the whole thing. And we're going to be using three different environment, well not environment, three different state variables. If you remember correctly about how Streamlit works, in Streamlit you have session state variables which essentially remain the same throughout the entire lifecycle of Streamlit, because remember that Streamlit essentially reruns your code every single time that anything happens in your application. So the variables that are stored in this session state variables are going to remain the same. So I have a boolean value right here for server connected. If my MCP server is connected, I have my tools array right here which is going to just save the information about the tools that I have in my MCP servers and the messages which is essentially going to be just the history of the messages with my assistant right here. After that I'm going to just initialize a very quick API URL variable right here which is going to be always the same one which is going to be just the API that I coded before which is in localhost if I remember correctly. There you go it's in port 8000 if I remember that correctly. And then just as you usually do you initialize when you initialize a Streamlit application you set up the set page config so you can set the title using page title and an icon. I don't remember why it was a shark here but why not. And after that, there you go, after that we're going to initialize our chatbot like this. So we're going to go create the chatbot chatbot is going to equal my chatbot that is going to take the API URL and there we go. Then all we're going to do is called chatbot.render to actually render the entire application. So there you go that is our main entry point but we're going to have to actually create the chatbot class and it's very straightforward and it will have naturally a render method right here. Okay so let's create that right here so we're going to do chatbot.py and that's where we're going to create the chatbot and that's how we're importing it right here. I'll just rename this right here chatbot.py. Right so let's start with the chatbot. Alright so in order to start with our chatbots very straightforward all we're going to have to do at start is we're going to import Streamlit as st and HTTPX for my calls to the API that I just did and there we go. So we're going to initialize our chatbot class like this and in the constructor we have two main properties. So the first one is the API URL. I mean you can choose to just define it, hard-code it in here. I decided to inject it as a dependency from here but that's alright, name it's okay. And then this one's very important that is going to be the list of messages that are going to be shown in the UI. Okay so these are the history of messages that your conversation is going to have and as you can see I am calling them straight from the session state that you see right here. That's how it works in Streamlit and it makes everything easier but you do have to learn how to work with session state. That being said if you're not familiar enough with Streamlit I do have a very complete crash course on Streamlit that you can check out in the description. It's actually one module of a complete bootcamp that I have on creating AI applications for production environments. But that one in particular is free so you can open it and get a taste of what the bootcamp is all about and I mean the Streamlit part is completely free so go for it. After this we're going to be having the render method. As you can see right here we're calling the render method and very straightforward. So what we're going to be doing is we're going to define a render method and this method what it's going to do is it is going to... there we go... it's going to make it async and this method is going to load the components that we're going to be showing in our UI. If you remember correctly the UI looks basically like this. So you have the title right here and that's the title that we're going to be putting first. So the title is going to be like this st.title. After this we're going to be doing with sidebar in order to actually add a sidebar like the one that you see right here. We're going to be adding settings and the tools. So first let's add the settings. Very straightforward. For the settings we're going to be just adding it like this. There we go. There we go. Subheader for settings and then the API URL that we imported right here. And then after that what we're going to be doing is we're going to be calling the endpoint that we created in the previous video in the API. So remember that the API right here I have it right here inside of the API main. Remember that right here I have a tools endpoint which essentially just calls the getMCPTools method from my MCP server. It's very straightforward. All that it does is that it returns all of my tools available in my server. So there you go and I'm going to tap into this thing right here. So in order to do that I'm going to have to first initialize a method called getTools. So I'm going to do here getTools like this and there we go. So we're going to be initializing a call to my async client like this. So with httpx async client as client we're going to await from my client we're going to get and right here let's call to my API URL and we're going to call into tools right here okay and basically we're just going to return the response in JSON like that. So this should do and now we're going to call that from here so we're going to say the result is going to be await self.get.getTools and the result we're going to display it under the subheader tools as we saw right here okay. So let's actually do that so we're going to do this and then we're going to do st.subheader I'm going to tap tools and we're going to write st right and we're going to write every single tool name like this for tool in result tools there we go that looks pretty good to me and then we're going to save this and this should already create the sidebar with all of my tools and this call should be working correctly so let's actually take a look at that. I'm going to open this right here going to go into my front folder right here remember that my API is running currently so I am going to tap into this part right here so let's actually do in order to run the Streamlit application I'm going to have to do Streamlit run main which is the name of my file hit enter and oh for some reason I don't have my source environment activated so there you go so now I should be able to execute this thing right here I think I made a very quick mistake it's not with st sidebar not with sidebar there you go so now I should be able to go to this browser right here and let's just enter this right here and there you go as you can see we have my setting sidebar I have my title I have my sidebar with the client tools right here and if you want to check the actual logs from the API you can see that it called the tools endpoint so there you go now we can go to the next part which is the more exciting part which is the actual interactive chat all right so now that we're right here we can initialize a next part right here I'm going to be okay I'm going to keep everything inside of the render method right here to make it easier but feel free to modularize it to modularize this into different methods so right here I'm going to be initializing my query input right here so in Streamlit you have this st.chat input element that allows you to initialize a chat input and after that we're going to test if the user actually sent something by doing if query like this and if there is a query the first thing that we're going to be doing is why not let's just log it in the message UI doing st.chat message this is just going to show it in the UI and after that what we're going to be doing is we're going to initialize an async client with our HTTPX client like this as client and what we're going to be doing is we're going to be sending that query to our API okay that's very straightforward remember that our API receives a query like this that takes one parameter which is query okay I mean this is the name of the endpoint and the parameter itself is also named query as you see right here so let's take a look at that so we're going to come right here and inside of here what we're going to do is we're going to first initialize the response which is going to be an await call to the client which is going to be post post call and and we're going to send it to our API URL slash query which is the endpoint that we just saw and the body of it is going to be a JSON object with the only parameter called query like this okay and there you go after that what we are going to do is we are going to say that if the response is correct so if we got a 200 as a response from our fast API application what we're going to do is we're going to get the messages from there so remember that our messages right here the object returned from our API call if you remember correctly from our HTTP client right here is a messages object right so I mean it's an object with one element called messages and this is the one that we're going to be trying to get so in order to get it all that we have to do is we're going to go right here and the messages we're going to set them to the response.json and we're going to tap into the messages part right here okay now after that what we can do is we update the session state of messages and we set it to these new messages that we have right here okay and there you go after that all that we have to do is show or display the messages that we are going to be sending and in order to do that all that we're going to be having to do is to show the messages all every single one of these messages in our UI and in order to do that it's also very straightforward all you're going to have to do is for message in messages you could do it like this so let me show you what this actually returns so for st chat message message role we're going to write it remember that st.message st.message what it does is that first of all it takes the type of message and then the content of the message itself this will work but let me just show you how it actually works just as a recap we sent the request to our query endpoint we verified that the request was correct and then we tapped into the messages object inside the response and we set our internal history of our application of the UI messages to messages like this the ones that we got from our API okay so essentially we were setting those to these ones right here and after that we're showing them in the application using st chat message i think our main message is going to be duplicated because if you remember correctly in the first one we already returned our own message so there you go this should work correctly so let's take a look at it so if i do if i go back to my browser right here and i reload as you can see i have my input right here which is the st chat input and i can say hello and let's see what my assistant is going to return to me so hello how can i assist you today i'm here to help you with any questions etc so so far so good okay now we want to test how the how would this work if it could actually call an mcp tool right so let's just restart this and let's ask a new question let's say how do i integrate lambda index with chroma this time let's do it with mcp and let's send that and it's going to start thinking i'm actually going to show you what is actually happening in the terminal oh seems like we had a mistake uh oh we had a timeout let's actually set the timeout to something a little bit less restrictive so let's set it to let's set the timeout to 60 seconds and there we go so this should already make it work a little bit better so i'm going to reload this so let's reload it like this and let's ask how do i integrate uh lemma index with chroma no with mcp it's going to start thinking and let's actually now take a look at our terminal right here so as you can see the api is already trying to figure out what the uh returned value from the language from the mcp call was so as you can see here we have the actual documentation and here we have some errors. Let's see, are we having any errors? It's still thinking. All right, that usually takes it a little bit of time because, there we go. So as you can see, this was a lot. So first, what happened is that we got, as returned, the first message, which is, let me search the LMA index documentation to find information about integrating MCP. So that is its thought process. And here you have the actual tool call, which is call LMA index. It got it wrong. It thought that MCP means Microsoft Cloud Platform. Not a big problem, but I mean, it's nice to be able to actually see that your language model did not mess up your call by actually logging in the terminal, I mean, in your UI, the actual arguments that were sent to your application. All right, so now something that I wanted to show you real quick. It's a quick little piece of advice so that you can handle these messages a little bit more efficiently. And right here, as you can see, we're just basically just showing everything that our API returns to us, which is a lot, but you probably want to be able to handle them differently. So what I would recommend is that in your client, you handle different types of messages independently. And there are mainly four types of messages that you are going to be the most concerned with. The first one is the user message. So like this one, the other one is the AI message, like the response. And then another one is the tool use. So the tool call from a language model and then the tool response, okay? So those are the four messages that I would want you to handle separately. And in order to do that, all you're gonna have to do is come right here. And I'm actually going to, instead of just showing every single message like this, I'm going to be using a function called display, display message. And for each message, I'm going to log it using that display. So I'm going to save it like this. And the display message, I'm going to create the function right here. So I'm gonna call it display message. And the message is going to be like this. So for now, here it's going to be currently does nothing. And there we go. So I'm going to click save. And as you can see, everything's gone because it currently does nothing. So what we're going to be doing is we're gonna handle the four different types of messages. First one is the user message. Then it is the tool call message or the tool use message. Then we're going to be handled the tool result message. And finally, the AI message, right? Now, how do we test them? The first one is very straightforward. The actual language model, when it returns a user, when you send a user message, it's very straightforward. It essentially just have to test that the message role is user and that the type of the message content is a string, right? And all you're going to do is just display it like that. So there you go. Then, I mean, the reason why I tested it as a string is because remember when we checked right here on messages, when the user, when you send a message to the language model, it counts as a content. The content is a string, but when you send a message to the user, when you send a response from a tool call, it also comes with role of a user. But as you can see in this case, the content is actually an array. So this one we're going to be handling differently under the tool response. And in order to do that, we're going to go back right here and let's actually check out the tool use. The tool use is this one right here. So it is on role assistant and the content is a list. So in order to do that, we're just going to come right here under tool use, and we're going to say that if the message role is an assistant and the type is a list, we're going to say that for each item in the message content, we're going to say that if the item is a tool, use, we're going to be just displaying it inside an ST message. And we're going to be using the JSON method of ST message. I mean, the JSON message, JSON method of ST in order to write right here. And this one's very straightforward. It takes the, we're going to type in the tool and the input. So the input's going to be input like this. And this one actually takes name. Just to be clear, what's going on right here. We tested that the role is assistant and then the content is a list, like you see right here. So the role is assistant and the content is a list. And remember that we had two different messages whenever an assistant makes a tool call. So the first one is it's reasoning. So I'm doing something like, let me search the documentation for information, blah, blah, blah. And the second one is the actual tool call, right? In this case, I'm only going to be showing the tool call. I don't really want to show this one, but you can do that too, right? So in order to pinpoint this one, I'm going to have to target the one of type tool use, which is what I did right here. And then I just logged whatever is inside of it, which is the tool item, the, sorry, the tool name right here, and also the input, which is the actual parameters that were sent to the function. So there you go. Now, if I click save like this right here and I go to my element right here, I'm actually not seeing anything because I'm not displaying my messages before anything happens. So currently my display messages is only happening while I am inside of the query conditional right here. So only if the user actually sends something, but if I want to display it right here, I can do it like this. And there you go. So you have my user question and the tool call. Now, next we're going to test, we're going to pinpoint the tool result and the tool result usually looks something like this one right here. So the role is going to be a user and the content is going to be the actual content of the whole thing right here. So let's just send it like that, like this right here. So if the message is an assistant, no, if the message is a user and the type is a list right here, we're just going to log everything actually. Yeah, I think it's just easier. Add to response. So, yeah, I guess we can just st.chat message. And this one's going to be, let's call it an assistant message, even though it technically actually is a message from the user, but I'm going to be showing it as an assistant right here just for user experience. And let's just type the whole thing like this. If I remember correctly, it's tool result. I can actually tap into the content object right here. It's probably easier. Yeah, let's just go like that. Should be good enough. There you go. And now if I open that up right here, you can see that my result is here. Now, something useful about using JSON, the JSON component right here is that you can actually call the expanded equal false so that whenever it is shown, everything is going to be shown like this. And that's quite convenient if you want to do this because sometimes the responses are super long. There you go. And then last but not least, the AI message is very straightforward as well. All you got to do is that the message role is assistant and that it is a string. And then all you got to do is just do that like that. And there you go. So now how do I integrate Lamaindex with MCP? Here you have the tool call and the result. And there you go. I hope that you enjoyed this tutorial. It was very quick, show you how to create a graphical user interface for your MCP client. Don't forget to check out the Streamly crash course that I'm linking right there in the AI Engineering Bootcamp. And also feel free to take a look at the previous video on how to create a fast API application for MCP clients, really, MCP, yeah, a fast API application for MCP clients. So great to see you and have a good one. I'll see you next time. www.mooji.org Copyright  2020 Mooji Media Ltd. All Rights Reserved. No part of this recording may be reproduced without Mooji Media Ltd.'s express consent."
mhdGVbJBswA,2025-04-29T05:00:50.000000,Create an MCP Client in Python - FastAPI Tutorial,"Good morning everyone. How's it going today? Welcome back to the channel. In today's video, we're going to be seeing how to create a clone of Claude Desktop or in other words, how to create your own MCP client. Uh that is to say, how to create your own chatbot that is going to be capable of interacting with an MCP server. And what you will have by the end of this tutorial is something that looks like something like this. So you have your chatbot here. you can send your query. So you have how do I integrate chromabb with llama index. I'm going to hit on enter right here and this is going to start thinking about this and right here as you will see it will be able to call my get documentation tool from my MCP server and based on that documentation that is going to get it is going to give me my answer right here up to date. Okay, there we go. So here you have the response. Here is my question. How do I integrate ChromadB with llama index? You can see that my language model called a tool called get documentation. It passed to it this arguments chromadeb integration uh searching through the llama index library. And here you have all the contents of the response and given that response it gave me an answer based on the latest documentation from lame index. Now, of course, you can add as many functions as you want and as many different functions as you want to your MCP server, but in this case, this is just a quick example. Now, this tutorial is going to be divided into two parts. the first one in which we're going to be building the back end for this application which is going to be a fast API application and the front end which is this makeshift very quick to set up front end in streamlid to have this final chatbot that you can add to your portfolio. Okay, so without any further ado let's get right into building. [Music] All right. So, first of all, let's take a look at what we're going to be building in this video, and it's very straightforward. Uh, by the way, if you have already seen the video on MCP clients with JavaScript, you have probably already seen this part right here. So, feel free to skip to the next part of the video if that's the case. Well, if you just want to refresh or or to take a look at how MCP clients work, let's take a look at this right now. Uh, so it's very straightforward. What we're going to be doing is we're going to be turning a chatbot that looks something like this right here. So very rudimentary in the sense that it receives a query, then it sends the query uh from the user to the language model, then receives a response from the language model, and then sends the response back to the user. Okay, this one right here is your application. All right. Now there may be other things going on right here like verification, data validation, authentication, whatever. But the idea right here is that the chatbot uh functionality is essentially what you see right here. And the process diagram looks a little bit like this. So query from user to app then to the language model then back and back. Okay. And uh what we're going to be doing is we're going to be turning that regular chatbot into a chatbot that is capable of interacting with MCP servers. Okay. And um what does that mean? Uh in case you do not uh remember or not familiar with MCP servers and MCP server is essentially just a toolbox that your um assistant or your language model can execute can use. Okay. So you can have an MCP server for interacting with your mailbox, for web scraping, for uh running some other application, etc. And these are essentially just Python functions that are in some server that your um language model has access to. Okay. Now, in this example, I'm going to be using the MCP server that I created in the previous video. By the way, if you haven't watched that video, uh probably you want to watch that that one first to really understand how MCP servers work. I'll put the link right here. And uh this MCP server that we're going to be dealing with is essentially a server that uh retrieves the latest documentation from your um favorite libraries and uses that latest documentation as context for your language model. Okay. And um as you can see the process looks very similar to what the chatbot did before but we have uh three additional operations right here that are very important. The first one is that we have to create the connection to the MCP server at start of the application. This is when the application boots you connect to the MCP server. Then you ask the MCP server what are the tools that it has available. In this case, it's just read the latest documentation from a few libraries and only then can you start receiving queries from your language model. Okay. Um from your user and sending to to the language model. And uh then another operation right here is the function that will call a tool at the MCP server in case your language model returns a tool call instead of just a regular response. Okay. And actually to make things easier uh here is a very nice uh process diagram that is very straightforward. Uh so to be very clear of what's going on uh remember that at boot of your application at the beginning we're going to be initializing the connection with the MCP server. Okay even before we start receiving the queries from the user then the MCP server is going to send us the available tools that it has uh in the server. In this example, I'm going to be using a server that can read the latest documentation from a few um libraries. And only then once the app is um aware of the tools that it has available can we start receiving queries from the user. So now the user is going to send us a query and only then can we send the query to the language model. And notice this right here. when we send the query to the language model, we append to it the list of tools that it has available. Okay. So when the lang when we send the query for example if I ask a question something like how do I connect a chromab database to say lama index in this case what is going to happen is we're going to send that query and alongside that we have the tool that says get latest documentation for whichever library and the language model will return a tool call asking for the latest documentation on lama index and chromab right when we get that we're going to send that tool call to the MCP server. My MCP server is going to return the latest documentation from that particular library and then we're going to send that back to the language model because the language model essentially uh what it did is tried to execute a function but it cannot execute functions by itself. So it sends it sends to the application the function that it wants to execute. We execute it and then we send back the response from that function. Okay. Um then we once the um the LLM got the response from the function, it will finally give us the final answer and only then can we send back the response to the user. Okay, I hope this is clear and it's very straightforward. Essentially, what's happening is that everything uh function um uh everything that relates to a function that an LLM can execute will happen within the MCP server. And the idea right here is that you will be able to connect to as many MCP servers as you want and to any MCP server that you want. Okay, so there you go. This is what we're going to be building. Uh now what we're going to do is let's actually get into the code. And something that I wanted to mention real quick right here. If you are serious about this and you want to build this kind of applications on a day-to-day basis uh for your full-time job, uh you can always get there faster by joining my AI engineer boot camp that you see right here. I have been working on it for over a year already and I am opening it for the first time to the wider public because up until now it had been a set of private cohorts every single time but now it's open for everyone to join. Um, in it I teach you everything that you need to know from the basics of generative AI to LLM pipelines to agents to multi- aent systems and everything you need to actually get in get a job in the industry and everything is project based. So at the same time you will be building your curriculum and your portfolio. Um uh many of the alumni actually have already got a job as AI engineers after they finished the boot camp and they are actually part of the community. So by joining you can always uh just ask them any questions that you want. Um so yeah the link is in the description if you want to learn more about it. And uh yeah, let's get back to the video. Okay, so what we're going to be doing now is we're going to initialize our um project. I'm going to be using UV for this. In case you're not familiar with UV, it's a great package manager for Python that was released just a few months ago. And I'm going to call it MCP client Python. There we go. Now I'm just going to load I'm going to CD into it. And um we can see I have my main, my readme, and my pi projectl. All right, sounds good. Now I can just create a virtual environment. There we go. And now I can just do source VN bin activate to activate that virtual environment. Okay, there you go. Uh now let's install the dependencies that I'm going to be using. I'm going to be using MCP anthropic. I'm going to be using Python.tnv. And uh that's pretty much all. All right. So UV Oh, sorry. It's can it has to be UV add. And there we go. As you can see, it's way faster than peep. So there you go. And now let's actually just open this in VS Code. All right. So this is the file that was created for us. Uh sorry, the directory. So we have our git ignore. We have our virtual environment. We have the Python version which is 3.7. We have our main entry point right here. Pi project readmi and our UV log. Okay. Uh now what I'm going to be doing right here is I'm going to be using the same virtual environment right here for both but I'm going to be creating an API and also I'm going to be creating a front end for this. Okay. And these are going to be two separate things. Uh so the API is going to be a fast API application that is going to include uh just an interface to be able to chat with the assistant. And this one right here is the one that is going to call the MCP server. Okay. And then I'm just going to make a very quick makeshift uh front end on Streamlit to show you how this actually works in with an actual front end. But um in reality, you can change this for a React, Angular, or whatever uh front end you want. Okay. Uh so we can start working with the API right now. So in order to do that, let's go back to API right here. Let's initialize our main entry point of our uh API. And actually, I'm going to delete this one right here because we don't need it. There we go. And there we go. So, next thing I'm going to do is I'm going to add just a very quick uh TNV uh environment file over here to actually add the um API keys that I'm going to be using. Okay. And there we go. So in this case I'm going to be using Enthropic and I'm also using Serper to make the calls to Google because remember that I'm going to be using my MCP server and since my MCP server is also coded in Python and I'm running it locally uh I want to have the API key within this um this one right here as well. I mean in a real production environment your API key will be within your MCP server anyways. So there you go. And right now once we have that, oh yeah, don't forget to add the Enthropic API key. Uh in this case, I'm just implementing this with entropic. In a future video, I'm going to be making it a little bit more LLM agnostic because entropic is a little bit uh expensive, but uh for now, we can use this. And uh let's actually start with this. Okay. So, what we're going to be doing now is we're going to be actually coding the back end of our AI assistant that is going to be able to connect to our MCP server. And, uh, that's going to be happening right here on the API site. Um, as you can see, I've added my TNV files. Um, this main.py is going to be the entry point and MCP client is going to be the one that actually contains the implementation. And uh just to give you a hint or an idea of what we're going to have by the end of this um API implementation uh we're going to be creating a fast API uh application that essentially exposes a post endpoint under query right here and um it will take one parameter called query and you will be able to send the query from your user right here and the assistant will by itself handle the query and go look for the tools that it requires in the MCP uh server, execute them and return to you a response. Okay, so this query right here is kind of eliciting a tool call from our assistant who will be able so who will have to uh call the function get documentation from langchain to see how it is implemented with chromeb and um in order to do this uh actually but as a response we're going to get the list of messages with all of the reasoning of the assistant. So you can see that the first button right here is our own message. How do I connect lang chain and chromob and uh after that we have the assistant who is reasoning that he has to uh make a tool call. So I'll search the lang chain documentation for information and then we have here a tool use kind of response with the ID of the tool that we should use. This is going to be useful when we uh execute that tool on our end. um it shows lang chain to search the documentation for and it's going to be searching this query uh chromob integration etc. Now once we get that actually what happened is that well this is still a little bit of reasoning and once we get that we send um kind of response called tool result which essentially if you remember correctly from this diagram right here would be this part right here. So we essentially already called the language model. The language model returned the tool call. Then we're going to be sending back the tool result to get the final response from the language model. And this is the tool result one right here. And this one right here is the contents of the documentation. Um not precisely formatted for human consumption but for the language model is most more than enough. Um once the language model got that the next response is actually the assistant saying that based on the documentation here's how to connect to lang chain with chromeb and this is the one that we're going to be logging or displaying in our front end. Okay. Uh very straightforward and this is what we're going to be building right here on our MCP client. So let's actually just uh start with um this implementation. It is very straightforward as you will see. Uh what we're going to do essentially is we're going to create an MCP client. Oh, not like this. An MCP client class like this. And we're going to be defining a few things right here. So the first thing that I'm going to define is an init um element right here. And actually going to import everything that I need to import from here. Uh there we go. The logger. I'm not going to use it for now. uh just to show you what's going on right here. So essentially remember that we're going to be using the MCP uh SDK from Enthropic and that means that we're going to have to initialize a session at some point which is of of type client session imported from the MCP uh package. We're going to be using async exit stack also from exit uh context library. And in this case, I'm going to be using the enthropic SDK for the language model. However, in a future version of this, you may be able to to make this completely uh agnostic of the language model that you want to use. Uh in this case, I'm just sticking to anthropic. That's the uh standard for uh VMCB tutorials. But I'll make I'll be making this um LLM agnostic very soon with other frameworks. Don't worry about it. Um, also we have the tools right here, uh, which is going to be initialized as an empty array. But remember that this one right here is the one that is going to be populated once we call the MCP server and we get the available tools. That's the one that is going to be populated, this list right here. And then we have the messages, which essentially is just the uh, chain of thought that we're going to be storing here in memory. Okay. And that's essentially all that's going on right here. And after that, we're going to be initializing a few a few methods. I'm not going to be initializing them as of now. I'm just going to be commenting them to give you an idea of what is going to happen, but we're going to have to have a method that is going to allow us to connect to the MCP server. Um, then we're going to need another method that is going to allow us to call a tool. call a tool called an MCP tool from the MCP server. Naturally, we're going to create a method called get MCP tools as well. Get MCP tool list naturally to get the list of tools that we have available. Um, we're going to have to create a method that is going to process a query. So, this one right here is going to take a string and we're going to be able to just process any query that our um that we receive from our client. And uh we're going to have a helper function right here as well that is going to be call the language model. This one right here is just going to call our anthropic language model um with all of the messages in our list right here. And uh that's essentially all that we're going to need. Um, probably going to add a couple more just for um extra. I'm going to call it like this extra just in case you want to. Uh, you can log the conversation. And we're going to add a um uh yeah, let's just do that. Oh, and I forgot about one which is going to be the cleanup. This one because remember that by the end of the entire implementation, we should clean up the entire MCP connection and to close it with the client uh correctly so that we don't have any errors. Okay, so these are the three six methods that are interesting and that we should implement uh soon enough. But before we start actually implementing the connection to the MCB server, just going to initialize my logger right here. So I'm going to do that right now. Um going to put that inside my utilities right here. And I actually already have one logger file right here. Uh which works good for me. Going to call it logger.py like this. And uh it's essentially a very straightforward logger. Uh, I have a debug level for a uh file that I'm going to be exporting with all the logs and info level for whatever is going to be logged in the terminal. Uh, it's very straightforward. I mean, by the way, all of the code right here is in the description. Um, so feel free to check it out. And uh, there we go. So now it's time to actually start implementing the connect to the MCP server method. Okay. Okay. Okay, so the first thing that we're going to be doing is let's just initialize this connect to MCP server uh method right here. It's very straightforward. It's just an async method. We're going to call it connect to server. And in this case, we're going to be uh taking as a parameter the uh server script path because we're going to be using a server path a server that we just uh coded ourselves. So, if you uh want to create your own server first, be sure to check the MCP servers uh video beforehand, but ideally, this one right here is going to allow you to connect to an MCP server that you coded locally and that you have your your script locally. Okay? So, this uh function right here is going to execute that script and connect to it. Uh and then I'm going to initialize some uh try catch logic right here or try except actually for Python. And uh in this case, we're just going to be just going to copy and paste some um code from the documentation. Essentially, we're going to validate if the server script path is a Python file or if it is a JSON file. And um essentially once it hap once that is uh happening, we're going to be uh we're going to know which command to use to actually execute it. So if it's a Python file, we're going to execute it with Python. If it's a JavaScript file, we're going to execute it with node. Okay. And then after that here, right here, you see pretty importantly, we initialize our server params using stddio server parameters. And the command is going to be the command that we're going to uh run uh to execute our server. And then the arguments are essentially just the uh script path that we have right here. Okay. And uh in this case, I could technically uh pass in my environment variables, but in this case, I'm just going to host everything in my own uh in the client uh just to make it a little bit more straightforward. But this was would be how you would use it in a more production ready environment, right? And then after that, we're going to initialize our stdio transport. And what does that mean? This is essentially just the way that um Entropic built uh MCP in order to be able to connect to it. So, we're going to be initializing our transport using the stdio client and we're passing the server frames. And this one right here is the one that we are going to be passing into our session afterwards. Okay. So, as you can see right here, this one is the one that we are going to be using later on. right here, right here in the session. And this one right here is the one that we're going to be uh calling whenever we want to get the MCP tools for example or whenever we want to uh execute a tool call as well that this session is the one that we're going to be using. Okay, so there we go with that. And after that, we're just going to initialize the session with um with uh our MCP client. So, we're going to take this one right here and we're going to say dotinitialize like this. And actually like that, we already have I'm actually going to await this because this one is asynchronous. And after that, we essentially have our connection to the MCP server done. Uh what we can do now is we can actually just log that we are connected to the MCP server. I'm actually going to actually import the logger right here. Where is it? uh from MCP utils from utils import logger and there I should be able to use my logger. There you go. Um however I want to also get the fun the tools that it has available. Right? So with this all that I have done is this part right here. So I initialize the connection with the MCP server. Now I want to ask the MCP server which tools it has available and it's very straightforward as well. So once we have the connection set up with the session what we can do is we can just right here we can just add a tool call to get MCP tools. Okay, get MCP tools. We're going to um initialize this method right here. And uh for each one of those MCP tools, let me show you. We're going to store them inside of my uh tools uh property right here. Okay. So, we're going to call the MCP tools from the from the from the server and we're going to store them in my own property. Okay. And then after that, we actually just can just uh log the available tools that we have. Okay. So, there we go. Uh now, let's actually do uh initialize this one. So, I'm going to be um going to be adding that one right here. So, I'm going to say this one's also going to be async and we're going to define it as get uh I need to add the exception handling. There you go. And uh so we're going to get the MCB tools. And just as before, it's extremely straightforward in the sense that we're just going to be uh using this one. It's not get tools, it's list tools. So, copilot. Not that perfect, is it? So, there you go. Essentially, what's happening right here is we're calling this session that we have already initialized because remember that we initialized this session in the connection to the server. And on it, we're going to be calling this function right here, this method right here called list tools. Okay? And we have to await it naturally. And this one is going to be the we're going to be returning the this one right here is just the response the response and this one right here is going to be the response tools. The tools are actually within the tools um object right here inside of of response. And uh there we go. We should this should already return our tools from the server. Now if we if we try to start running this this is not yet going to work because we have not implemented any other thing other than just getting the tools but it's already quite a good start. Um just to show you a final um cleanup uh logic right here. Uh very important uh when you just finish the process, you want to uh close the stack that you're using and just say that you have this connected to the MCP server. Uh very straightforward just uh to be sure that everything uh works correctly and that you're not cutting the connection without actually um disconnecting from the server. We're not going to use finally here. Just that is enough. Okay. So those are the three most important methods. the cleanup method, the get tools method. Uh this one technically you could not you could add it inside of here, but I'm going to be using it later on as you will see. And uh there you go. This should already get you as far as let me show you here right here. So we have initialized the connection, got the available tools. Now we should be able to start processing the query from the user. Okay. So, let's do that. All right. Perfect. So, we have uh essentially finished this part right here where we initialized the connection with the MCP server. We have got the available tools. And now what we're going to be doing is all of this that you see right here. Okay. So, we're going to create a method in our MCB client that is going to be able to process a query sent by our client, by our user. And then we're going to send that query to the language model. And in order to send it, we're going to append to it the MCP tools that we have available because we previously just found out that they're available. We're going to uh process any tool call that the language model may return to us or not. If it returns to us a tool call, we're going to uh make the tool call at the MCP server, get the response back, send the response from that tool uh execution to the language model, and then get the final answer and then return that to the user. Okay, so all of this is what we're going to be implementing right now. And it's actually very straightforward. Uh we're going to be implementing that right here under the process query method right here. Okay. And this one right here is also going to be an async method. And it's going to be take it's going to take a query argument. Uh in this case, it's going to be just a string. And I'm going to be implementing as well just a try catch. No, it's not catch, it's accept in Python uh logic. And right here, let's just say that we're going to be processing the query first. And then after that, after we start processing the query, we're going to initialize the message from the user. Okay, so remember that we had up here a messages list right here. That's what we're going to be doing right here. We're going to initialize the first message of our stack. It's going to be the message from the user, the one that we are processing right now. Okay. Uh in this particular example, we're not going to be adding some uh long-term or conversational memory in the sense that this assistant is not really going to remember uh past messages uh beyond this scope of this um thought process. But you can see that it would be very simple to implement that. You would just have to um store the messages in memory while we're running the whole thing. Okay. Uh but for now, we're just going to leave it as is right here. And uh so let's see what are we going to do. First of all, we're going to initialize the user message. And this right here is not going to look like this. This the message actually looks like a dictionary which takes this form right here. So it looks like a dictionary with two uh properties. one is the role and when it's the user or the human who is sending this message it's going to be user and the content is going to be the query that they just sent us. Okay. And then after that we are going to be able to just um send that our messages our messages are going to equal our user message like that. Okay. Very straightforward. Um, okay. So now what are we going to do? Uh, we're going to initialize an infinite loop right here. Uh, that will run until we until our assistant finds out that it has the final answer. Okay, so it will run then if our assistant returns a tool call, we'll restart uh another uh iteration. Then if it returns another tool call, we'll restart another iteration until the assistant finds out that he has pretty much all the information that he needs to return to us the response. Okay. Um, so in order to do this, the first thing that we're going to do is we are going to uh add this. Actually, this one right here goes in self do messages, not right here. There you go. Um, and then you go. So right here we're going to be initializing the response by saying that the first thing we're going to say that the response is going to be we're going to await self dot call the language model and let me show you what this one right here is going to do because we have not implemented it yet today. So let's just um implement this function right here. Remember that we said that this but right here we're going to call the language model and we want to call it with all of the messages that we have available. Okay. So, in order to do that, we're going to come right here and we're going to initialize this call um LLM function, which is actually just calling the anthropic language model. So, let's come over here. We're also going to implement this as an async function. And uh this one right here is essentially well, we can log this calling language model. Why not? And we can say that the response is going to be equal to self llm dot and in this case we're going to be tapping into the messages um method right here at create. So the messages API create this one naturally comes from the anthropic SDK. Remember that we initialized this one right here. If you're using any other uh framework uh for calling language models, here is the way here is the moment where you can implement that one instead of just the entropic API, right? And this will also make it a little bit more agnostic if you change this to implement another uh language model. Okay? But in my case, I'm just going to add it like this. And uh right here, I have to define the model that I'm going to be using. And in this case, I'm going to be using going to be using claude 3.5 set. Why not? And um I'm going to say that the maximum tokens that I get in response are going to be a thousand so that I don't spend too much money. And the messages are going to be my self messages that I have up here. Okay, which now contain one message which is the query from my user. Right? Because remember that this one right here I am calling it only after I have updated my messages object and this is the one that I'm calling right here. So there you go uh the messages and then very importantly we want to append the tool um method right here the the tool parameter right here which essentially just takes the list of tools that we are going to give our assistant available. Okay, this pipe right here extremely important. It is essentially what you saw right here. We're sending the query to our language model with the MCP tools and the MCP tools remember that we got them while we were connecting to our server right here self tools and naturally uh this schema is the one that anthropic supports. So it has to have the name, the tool name, the description of the tool, extremely important so that the language model knows what it tool is about and the input schema and uh this right here is what is going to be going to the language model right here. Okay, so very straightforward. Um so there you go. The response is that and actually let's just return the response itself. There you go. And then let's just say that we're going to accept uh we're going to handle the exception. And uh oops shouldn't be an equal here. So there you go. We have my call language model function. And here remember that you can switch this for any other language model that you want. Okay. So now let's continue with the logic. Right here we have called the language model with all of the messages that I have in my list. Now, now what happens? What comes next? Uh, well, it's very straightforward. What comes next is essentially we're going to handle the response. If it's a um we're going to check if it's a simple text response, which means that the language model did not make a function call, we're just going to return the fun the text as it was before. I mean, just like a regular chatbot. But if it returns an MCP function call, we're going to handle that as well. Okay, so let's take a look right here. And inside the response that we have right here, we're going to handle uh two uh different cases. The response is a is a text message. In that case, we're going to handle that. And if the response is a tool call, okay, so there you go. If the response is a text response, I'm just going to give you this right here. Um, just going to copy it. So, there you go. Uh, if the response, uh, if the type of the response of the content is text and there is only one response because when your model responds, sometimes it responds a text message and a tool call message. So, it's important to test that it only responded one uh message. Um because sometimes, as I showed you before, remember right here, sometimes it responds uh where was it? I think it was right here. Yeah. Um no, it was not this one. This one, it returned two different messages. One of which was of type text, but the other one was a tool use. Okay. So you want to test that the first message is a text and that there it's the only that's the only message that was returned by your language model. Okay. Now after that you're going to initialize your assistant message. In this case it is the assistant and we are going to add the text to it. We're going to append that one to our We're going to append that one to our uh history. Essentially, the assistant message is going to go to our self messages history. And here, this one right here seems to be uh okay, there you go. This is how it should go. Um, and I'm not going to log the conversation as of now. So, there you go. Essentially, what we're doing is initializing my assistant message and appending it to my history. So right now I have two messages in my history. The first one is um the user message right here and after that the response from the assistant but that is only if the assistant responded with a simple text message like this one right here. Okay. So we have the content and we know that it is well not this one um this one right here for example. We know that it returned only the text. Okay. So if that's the case, we're just going to log it. But if it did not do that, if it returned a tool call, what we're going to do is we're going to handle that. Okay. So let's handle the tool call right now. All right. So uh if the message is a more complex message, let's handle that right here. Okay. And just to be clear, this break uh part right here, actually what it will do is it will break this uh infinite loop. Okay, so when we get here, this will be the end of our loop. Uh, very important. Uh, if you want to make this a little bit more robust, you can of course add a limit in iterations right here. Um, but for now, I suppose that this should be good for um, just a quick tutorial. So, there you go. What we want to do right now is we want to uh, log the assist, I mean, store the assistant message. So, we're going to say that we're going to check the assistant and we're going to um add the content right here inside our content pod right here. So, essentially this is going to be creating a new assistant message with our content and um what we're going to be doing with that is we're going to be storing that in our messages uh history right here. Okay. So now we will have our user message and this new uh rich message from our assistant. And uh that's quite convenient because the idea of uh doing this is that we're going to be able to explore what is inside of this one right here. And in order to explore that, we're going to be using a for loop right here. So for every element inside of the uh content of our of our of our response in this case I'm going to call it content like this. For content in response uh content we're going to test two things cuz remember that sometimes it responds with a text message and sometimes it responds with a tool uh call. So, if the content type equals uh first of all, let's just check if it's just text. Okay, if the content type is text, we're going to do something. And if the content type is tool call, we're going to do something else. Okay, you can do l if here if you like that a little bit more. I just like if statements quite a bit. So, there you go. Uh these are the two things that we're going to want to test. Uh just to be clear that everyone's on the same page. What we're doing right here is we received the query. I mean we received the response from the language model after we called it. We um identified that it's not a simple text message but it is a more complex message that contains more than one uh more than one element. Okay. So we're going to look into each one of those elements because some of them might be a text message but others might be a tool call. So if it's a tool call we want to make that tool that execution. Okay. So first of all if it's just a text message we're essentially just going to uh we can append it to our messages actually. So if it's just a text message we can just append it right here. So let's do uh self dot messages. We're going to append it uh like that. So we're going to append the ro assistant and we're going to say that this is the text that we got from it. Very straightforward. Okay. Now uh secondly, we want to handle if it is a tool call. And this one right here is a little bit more uh more important. So what is going to happen if the message is a tool call? Um a few things. First let's just extract from our tool call the important information that we need. So if it's a tool call inside the name object we will have the tool name inside the input we will have the arguments and inside the content inside the ID we're going to have the tool ID and this is going to be um these three are going to be very important when we uh start um running our calling our tool from the MCP server. Okay, so we're going to say calling the tool with this arguments right here and very straightforward. Now, uh let's actually start another try catch statement right here. So, we're going to do try not like this try. And in Python, it's not catch, it's accept. And there we go. So, let's just um call our tool. Actually, it's very straightforward. So if we're here, if we if we if we're right here, this means that we uh the language model asked us to perform a tool execution. And just to be clear that everyone's on the same page, we have received I mean right here we're in the case in which we received the response from the language model and the language model actually contains a tool call. So we're going to have to execute that in the MCB server. So let's do that. So the first thing that we're going to want to do just very straightforward. We're going to we're going to do right here the result of my tool call. I'm going to do self session because remember that the session object is the one that is that contains the connection or the session with my MCP server. I'm going to do call tool like this. And this method right here takes as u arguments essentially just two things right here. The tool um the tool name the tool name like this and the tool arguments like this. If you hover over it you can see that it takes the name of the function and the arguments of the function that you have to execute. Okay. And uh let's just log in my in my logger the result of my tool call like this. There we go. Um actually just return the first um 100 characters so that we don't uh so that we don't uh overload our login. Um there we go. So now that we have returned now that we got the response from our function calling uh we're going to be able to append that to our messages. So we're going to do self messages and we're going to append to it. We're going to append the message just show you like this. The role is going to be user. Whenever you're responding to a tool call you're going to respond to it with the role user. Okay. And uh right here we're going to say that the content is going to be um actually we're going to have to uh organize it a little bit better. So the content is going to be an array of messages and our messages is going to be of type of type not tool call but tool result. And this is very important because this one has to come right after the tool call message that you just appended. Okay. So um right right here um calling tool [Applause] um yeah right here we appended this message from our assistant. And this one if it contains a tool call it will contain the the the message type tool call. And it's important that after a message of type tool call you append a message of type tool result for the language model to work correctly. Okay. And after that you're going to mention the tool ID. And this one is the one that you added right here. And lastly, we're going to, of course, add the content of the result, which is just going to be I'm just going to tap into the content of um uh object of my result right here. Okay. And uh there you go. Essentially, this is um already going to allow you to log the entire thing with your um this is already going to allow you to uh have a final uh response to your tool call. And there you go. And then by the end, what we're going to do is we're just going to return the messages that we got. Okay. Um, let me just make sure that the indentation is correct. Uh, so the return statement is outside of my for loop and it has to be outside of my while loop too. There we go. Um, yeah, there we go. Uh, so just a quick um, uh, check on everything that we did right now. We received the query from our user. Okay, we created a message uh for it, a message format and we initialized our history with that message. Okay, once we have that message, we call the language model and this function calls the language model with all of the messages in our memory. Okay, and then we tested whether or not the the response from this language model contained only a text message in which case it did not make a tool call or if it contained a tool call and we handled it. Okay, if it returned only the text message, that means that it finished reasoning. It didn't have to use a tool, so it just gave us a response. So, we can get out of this loop. If it did not give us a simple message, that means that it tried to execute a tool. So, it will require the response from the tool to continue reasoning. So, we cannot just get out of the of the uh loop as of now. Okay. So, if that is what happened, we handled it right here. So um we created a new message called this assistant message and we added the content right here and after that we appended that to our message history and there here we have it the next uh the handling of that because remember if we returned a tool call there might be more than one element in our in our response one of which can be a text message and another one can be a tool call. So let's if it's just a text message, we append it to the history. If it's a tool call, we are going to add it right here to our history. And in order to do that, very straightforward. We extract the elements that are important to us. To execute the tool, we execute the tool from the MCP using the session.all tool and the response we appended to messages under the type of tool result. Okay. Um, I know it looks a little bit um like a lot of code, but it's actually very straightforward. I mean, there are of course ways to improve on this code. This is not extremely uh the cleanest way that you can go about it, but I think it's uh uh quite straightforward for showcase um and to actually show you what is actually going on behind the scenes. Okay. Uh so there you go. We have essentially implemented pretty much everything. I and I'm not going to be doing the log conversation that kind of like bonus and I don't want to make this tutorial super long, but we have everything that we need so far. Essentially, we created a uh tool call um sorry, a few um a few methods right here. In the end, I did not abstract the MCP uh tool uh call into its own method, although we could do it if you wanted to. and uh we connected to the server, we got the MCP tools from there, we processed the query, we call the language model, and by the end, we're going to be using this cleanup method right here. Okay. Uh so there you go. That is uh what we need. Now, what we're going to do is we're going to import this MCP client into our fast API application so that we can actually access it like this right here. Okay, so let's do that. Okay, just a quick recap of what we have done so far. Um, with the MCP client that we have already coded, which is that component that already allows us to have this connection with our MCP server, we have created a few methods that are going to be very useful. But essentially, we initialized the connection, got the available tools from it, then we handled the query from the user. This one right here is a single method. However, it uses multiple helper methods inside of it. um it calls the language model with the tools that we got from the from our toll from our uh connection right here. Then if the language model responds with a tool call, we executed it in the MCP server. Else we just returned a simple text message right here. Okay. And this part right here is actually an infinite loop if you remember correctly or I mean a while loop uh that only breaks if the language model returns a single message with a text content. Okay, so no tool calls. Um again I mean want to make this clear if you want to make this robust and uh production ready you probably do not want to leave the infinite loop over there. um and do not leave it to the language model to actually um break it. You want you probably want to have a limit of iterations that you want uh hard set right there. But um once you got that, everything becomes pretty straightforward. Okay, so there you go. Here's the cleaner version of this thing right here. And now I suppose that we can actually start implementing the actual API. And as you will see, it's also very straightforward. Uh you're going to want to install fast API. So in order to do that, I think I've already done it. Yeah. So you do uv at fast API or pip install fast API if you're using pip. And after that, we're going to initialize the project right here. Um I'm going to be importing this from MCP client. I'm going to be importing um this is actually supposed to be MCP load-client. So now this works. There we go. From MCP client import MCP client like this. We're going to be importing from context li async context manager. I'm going to show you how that works in just a minute. Going to be using paidantic for validation and we're going to be using fast API uh right here. Load.tnv. This essentially just allows us to run our env um API secrets. So there we go. First things first, we're going to initialize the settings part right here. And it's very straightforward. What we're going to need is the path to our server that we had previously created. And um remember um in this particular example, I am connecting to an MCP server that I coded myself in the previous video. Uh so I if you want to code your own MCP server I would recommend to watch that one and then once you have the script you can plug it in right here. Um in the next video I'll show you how to run uh remote uh MCP server so that you can connect to MCP servers not only from your uh own making hosted locally but also in some MCP server hosted in uh GitHub or a Docker file or whatever. Okay. Um so there we go. We're going to initialize the settings right here. Not like that. Going to initialize the settings like this. There we go. And uh now we are going to initialize a function called lifespan. And this is the function that will dictate the lifespan of our application in the sense that remember that I told you right here that we have to initialize the connection to our MCP server at the start of at the when the application boots. Okay. So in order for that to happen we have to have this function called lifespan which is going to run at the beginning of the execution of our application and then also at the end. Okay. So, it's essentially going to run during the entire lifespan of our project. Um, and in order to do that, uh, the first thing that we're going to want to do, remember, we're want to want to, oops, initialize our client, which is the one that we see that we just created right here. And once we initialize that client, we're going to want to do a few things. So, we're going to do a try catch logic. try and I'm going to do try except try except and finally like this um there we go. Uh just leave it like this for now. Uh so first things first, we're going to want to initialize the connection. Okay, remember that the first thing that we want to do is we want to initialize the connection. So we want to run this method right here which remember if you remember correctly it will run uh this code right here which will initialize the connection and actually give us um is store in this uh object the tools that we have available. So let's run that method right there. in order to run it. Very straightforward. All we want to do is do connected equals await and we're going to do client.connect to server and we're going to connect to this server script that we just uh stored up there. Okay. Uh secondly, if we did not get any connection for some reason, we're just going to raise an exception and we're going to say that there was a problem. That's all. Okay. Um, and there you go. And then after that, we're going to go to app.stateclient and we're going to set um, oh, I forgot to initialize my API application. Um, let's just initialize it right here. I'm going to say that the app is going to equal to my life uh to my fast API application. I'm going to call it title. is going to be um MCP client API and the lifespan is going to be this lifespan application right here. So now I can run my app inside of here and I can tap into the state of my application and uh link this client to it. Okay, what this mean is what this means is that this client right here will be in the same object throughout the the entire lifespan of my application. That way uh I will not have to re uh start a connection to my MCP server on every uh call to the language model for example. Right? So once we have that we just handle the exceptions if there are any. And uh finally, very important, this one happens when we shut down um shutdown the application. And right here, we're just going to await the client. And in this case, we're going to use cleanup because remember this is a method that we initialized uh that we created ourselves. And this method, what it does right here is it disconnects from our um from our MCP server. Okay, very important to tell your MCB server that the connection is done and that everything happened uh correctly. So there you go. This is the lifespan. We have already initialized my um fast API application like this. Now what we can do is we can actually start writing our uh endpoints. Okay, so first of all we're going to want to initialize some middleware to be sure that we can connect. So I'm just going to say for development purposes only that all origins can connect. So course uh middleware right here and then I'm going to initialize some of this um some of these types right here for data validation. So the query request is going to be a string. This is going to be the request that the user is going to send to us. The message is essentially as we have said before is essentially just an object that has a role and a content and the content can be whatever we want and the role is going to be a string because usually it is only either user or assistant right and the tool call it's going to have the name and the arguments which will be pretty much any arguments that our function accepts. And uh there we go. Uh so we're going to do how about we do a couple of functions right here. So uh this one right here is the query function. Very straightforward. Uh there we go. The query function. What it does is essentially we're going to be able to process the query. And this one right here is going to be our post endpoint. Remember the one that we saw right here. So we're tapping into the query uh endpoint right here. If you're not familiar with fast API, this is how you create an endpoint in fast API. And this is the uh parameter that it takes. And in this case, we're going to be validating it with the query request. So it will raise an error if the uh send respon if the um um request body does not contain a query uh parameter um with a which is a string. Okay. And uh for this one, all that we're going to do, we're going to initialize our messages. And then we're going to um actually I don't know why we initialize the messages like this right here. There you go. And uh there you go. Uh what we're going to be doing is we're going to be getting the messages from the process query method that we initialized in our client. Now note that we're calling the client from app.state.client. And that is because we're calling the client from this one that we have defined at the start of our application. Okay. Uh if you're familiar with streamllet, you can think about it as the uh session state of a streamllet application. Essentially what this is is doing is it is uh initializing um I mean calling the client from the state of my entire application so that it does not have to restart the client every single time. And we're processing the query using this method from here right here. And if you remember correctly, my uh process query method returns the entire list of messages. And that's what we want to get right here. And that's what we're returning to um my um uh to my user right here from the API. Okay. So very straightforward. Um not I don't think that we uh need to do much more right here. So let's just actually initialize this uh application. We're going to do that if we're executing this thing. We're going to be calling this on Uicorn going to host it on localhost like this. and we're going to store it in post import in port 8,000 like this. So there we go. We should be able to run the application now. So let's um let's try this. All right, there we go. Just a quick thing, a quick erata before uh continuing. I had to before actually running this, I had to fix a few things that I had some errors that I had made while coding this with you. So essentially um I forgot to add this async context manager and essentially naturally it's the um the decorator that you have to decorate with the the lifespan function that you're going to be passing right here. Okay. And you have to yield every single time that you're uh right here in the try part. Okay. In order to not uh stop the entire thing every single time um that thing. So I added this yield the decorator and um something else that I forgot to do before is right here in the client I forgot to just return uh true if the connection to the server was correct. Okay. Uh instead of um waiting for an error to happen. So that way because remember we are awaiting a response right here from connect to server. It was not returning anything. So just remember to return true if everything happened correctly. And uh there you go. So now we should be able to come right here and I actually had to cuz remember my my project is right here at the base. So if I want to uh execute my main file right here, I'm going to have to do uh cd API. And in here I'm going to have to do uv corn main app. And I can just do reload so it works correctly. And now this is quite a long um quite a long log. Probably going to fix that. Oh, and also I forgot to when when importing there was an error here too. I imported from utils and I had to import from utils.logger for this to work correctly. And um there we go. Let me show you something right here because I'm uh doing this uh self tools but I don't want to import to show all the tools. just want the tool names. So there you go. Now if I do this like this, I should be able to see. Let me just show you. If I reload the application, you can see that I am running the application in the port 8000. Uh start reloading process, the server process, waiting for the application startup. And there you go. We are connected to my MCP server. And the available tools are get documentation and then just here a quick debug uh tool that I have in this MCP server. So the application startup is complete and now technically I can start quering it. So let's take a look at how this um this application responds. All right. So let's take a look. So let's take a look at this um and let's try this. I'm going to execute this. We have an error apparently. So messages create got an unexpected keyword tool. Oh, apparently I made a mistake right here when calling the language model. Um, yeah, it's not supposed to be tool. It's supposed to be tools like this. Um, there we go. Uh, we're using cluts on it 5. We're sending all the messages. And there we go. We can send that again. And okay, we're getting another error. So, uh, invalid request error. uh tool use ids were found without tool result blocks immediately after. Okay, so this may be an error of some uh related to something that I was uh telling you about before that if you send a message and the LLM returns a tool uh call, it will expect that the next message in the sequence is a tool response. And if you do not do that, it will have a problem. Okay, so let's take a look at uh what is actually going on right here. Um so time to debug this app. All right, so it's time to start adding um a bit of debugging material right here. And this is actually going to be extremely useful for you because language models are usually kind of a black box and it's not very straightforward to see what they're actually thinking and what their thought process is uh before getting the response. So what you want to do is log the entire uh chain of thought until you get the response to see if at some point during the chain of thought you're having a problem. And um this is very straightforward to do if you're using lang for example. But um uh since right here we did not implement langu monitoring technique right here which is essentially we're just going to be logging the whole thing right here. And uh let's do that right now. So in order to do this uh what we're going to be doing is we're going to create a new method right here which I have already written for you. It's a very straightforward method. Just locks the conversation. It creates a directory called conversations. Then we just create my serialized conversation. And for each message in self messages, we're going to create the message object and we're going to append it to the conversation. Um, and then this conversation uh object, we're going to dump it into a JSON file right here that is going to be stored inside the conversations directory that we just created. And uh it's going to be called conversation uh underscore the timestamp of the conversation. Okay. And then what we want going to want to do is we're going to want to call this log conversation every single time that a message is appended to the history. Okay? So every time that we add a message to the history of my conversation, I'm going to append this one right here. So I could do that right after calling the language model. Actually, that could be uh an answer. Or we can go let's go right here after query. So what I'm going to do so I'm going to go right after messages append I am going to come right here and I am going to do uh await selflog conversation like that and uh before doing that I'm going to have to actually take a look at whenever I am uh appending anything to my messages like this. So, I have appended things to my messages four times. So, let's copy this right here. And every time that we append anything to the messages, we're going to log the conversation afterwards. Here it is. So, we'll log the conversation right after. And here it is. So, we'll log the conversation right after. Like this. So, now this is saved. Now, every time that we append anything to the messages property, we're going to be logging that into my JSON file that will be dumped right here. So, let's take a look at that. Now, if I re-execute this, I should have my conversations directory being created right here. And there it is. And here is my first conversation. So, how do I connect to ChromeB? That's the user u message. And then we have the assistant message with uh I'll search the languin documentation for information about Chromeab blah blah blah. And then we have the tool use uh right here. So after this one technically we should have a tool result or tool response sorry. But instead of that we're having this uh other assistant message right here which we do not want here. So what can we do? uh we can probably go right here and figure out where this is happening because remember that when you call um when you make a call to the language model like that the assistant is actually sometimes returning two messages in the same response. So it's it's returning as you can see right here it's returning the text message and this one right here. So maybe we are adding this one twice. All right. All right. So, I'm going to take a look at this. Just give me a couple of minutes. All right, I'm back. Um, actually, I had made a very quick dump mistake. Uh, let me just show you uh the lock conversation. I just made it tried to make it to make it a little bit longer to actually serialize all of the content uh of the messages, but uh it's taking a bit of uh a bit too much of time to do that. So, I'll show you exactly what I did. Um essentially I added this log conversation to make sure everything is going on correctly and um all also I changed this part right here. So I had made the mistake of using if content type equals tool call. It is not tool call it is tool use. Okay. And uh there we go. After that also something else I did that I actually recommend that you do is when you call the language model if you're using anthropic uh haiku also supports uh tool calling and it's also quite good. So and it's way more affordable than than uh sonnet. So I would recommend that you use this one for debugging and for testing if you're sticking to anthropic models. So once I did that it actually just started working correctly. I can show you how do I connect um lang chain and chromab. You can see that after each message it's logging right here into my conversations and uh right here we'll have the entire conversation uh I mean all of the thought process of the agent or the assistant and um that's what we're going to be able to log or to display in our front- end application. So here you can see that the messages are myself how do I connect langchain in chromeb then the assistant saying let me search the langchain documentation etc. And then at the same time it returns a tool call which calls the get docs uh function in our MCP server and then queries chromadb integration with line chain in the library line chain and then my tool result returns this result of the entire thing. Um, there you go. And uh, there you go. Right here. As you can see, you have the ID of the tool, which is exactly the same as the ID of the tool result. So, the ID of the tool use, the same one as the one from tool result. Very important to not have any errors. And uh, then we have the answer right here, which is the final answer of the assistant, which based it on the documentation that we got from our tool use. Okay. Now, this uh tutorial already got a bit uh longer than I expected. So, I'll make a second video for the front end and I'll upload it within a couple of days or a few days just to to make the continuation of this. It's already ready so I don't have to prepare the whole thing again. Um but yeah uh that way this video is a standalone API uh tutorial and the next one's going to be the integration with a very makeshift uh front end in Streamlit. Okay. Uh to actually be able to display this and display this very nice conversation in a front end. Um so there you go. I hope that you liked this uh tutorial. I hope that you managed to create your own API for your MCP chatbot and I'm very keen of hearing um what you want to see next and thank you very much for being here. It's a pleasure. Uh don't forget to check the AI boot camp for software engineers that I host over there in the links in the description. And without any further things to mention, thank you very much and see you next time. [Music]"
5tl6D-h2_Qc,2025-03-27T17:33:33.000000,Create MCP Clients in JavaScript - Tutorial,good morning everyone how's it going today welcome back to the channel in today's video we're going to be covering mCP clients uh in a previous video we covered mCP servers and how they work uh click over here if you haven't seen that one uh in this video we're going to be covering the other side which is how to create the client that is going to communicate with the mCP server in other words how to create the agent that is going to be using the tools from the mCP server and you will see it's actually very straightforward um in other words this is also going to allow you to integrate mCP server support to your application that you already probably have and that's what we're going to be doing today um more in detail what we're going to be covering is how mCP clients work we're going to be explaining that with a few very nice diagrams that are coming up in a moment we're going to be integrating I mean creating a complete mCP client in JavaScript we're going to be integrating it with an express application and we're going to be using that one to connect to the mCP server that we created in our previous video okay so that's what we're going to be working today um next video we're going to be doing the same thing but with python if that's something that interests you uh let me know if that's something that you would like to see in the comments so without any further Ado let's get right into it [Music] okay so I have this very neat diagrams right here to show you how to turn your regular chatbot into a chatbot that supports mCP servers and it's very straightforward as you will see um I am assuming that you already have a working chatbot with a back end that literally all that it does is that it receives a query from the user that it sends the query to the language model gets a response and then Returns the response okay so this one right here you may have some other data validation here you may have some authentication Services Etc but I am assuming that you already have a chatbot that does pretty much this um it may have some other toolboxes right here it may already be an agent that's okay uh all that I'm going to do right now is I'm going to turn a very simple vanilla chatbot into a chatbot that supports an mCP server okay or any mCP servers um so uh in order to do this actually something that has to be quite clear is that even though we are creating an mCP client uh we're not actually working on the client side of your application uh this is going to be happening wherever you're uh handling the business logic of your application in other words um it might probably be happening in the back end of your application so uh for example let's suppose that you have a chatbot that all it does is it's sort of a clone of chat GPT without any tools so you have a user interface may you may say it may be in react or angular whatever and the user sends a query to your application your application is going to handle the query handle authentication whatever send the query to the language model the language model is going to response it's going to return a response and then you're going to get your response back to the user interface okay and uh then your client is going to be very happy happy because they're talking with a language model through your application what we're going to be doing is we're going to be turning that into something that looks like this right here okay uh but in order to do that let me just show you very quickly the process diagram of of the starting point of what we're going to be working with as you see very very clear we're starting with a client that sends a query to the application the application sends a query to the language model the language model responds uh to the to your application and then your application sends back a response to the user okay very straightforward now let's take a look at what is going to be uh the result of what we're going to be building right here and the after is going to look something like this so essentially you have a your same application uh I mean again there may be other processes going on right here but uh what you have right here is the same application that receives the query but as you can see there are just three main uh operations that you will add to your logic in order to actually make it compatible to with mCP the first one is we're going to make it we're going to create a method that allows you to connect to an mCP server and that's probably the more um important one and this one is actually going to be happening uh at the start of the session okay so when you initialize a session with uh with your user your application is going to connect to the mCP server and it is going to get from the mCP server the list of tools available in that mCP server okay so let's suppose that here you have a tool called read email and then you have another tool called write email okay uh so this mCP server is going to allow you to handle your email inbox uh so there you go uh so you initialize your application it creates the connection to your server it lists the tools that you have available and now you have those tools within your application now what you're going to do is you're going to send the query to your language model okay but alongside the query you're going to append um within the the the request that you're sending to your language model you're going to append the tools that it has available okay so you're going to say so if the user says Hey read me the latest email that I have and you're going to append the tools that it has available which are read email and write email the language model May return instead of just a response it may return a tool call okay so uh in order to do this of course naturally you're going to need to use a language model that supports tool calling or function calling okay nowadays pretty much all the language models that are available um uh and that are the latest ones uh they all support function calling but just make sure that it supports more function calling before actually implementing mCP servers otherwise this is not going to work okay uh so once you do that it will return a tool call instead of the response the tool call would be something like tool call the read email and read the latest email and then you yourself are going to execute that function in the mCP server okay so you're going to send that tool call to the mCP server the mCP server is going to return to you the response of that tool call so it's going to return to you the latest the content of the latest email and then you're going to send that back to the language model and then the language model is going to be able to summarize the latest email to the user okay so that's what we're that's going to be happening right here and if you want a process diagram to make it uh look a little bit easier it would look like this so when you start the session even before the user sends a query you start the session and your application is going to initialize the connection with the mCP server and the mCP server is going to respond with the available tools that it has in this example it was read and write an email then once it has those available tools and the application is already set up uh it's going to be able to accept a query from the user the user is going to ask a question of something that involves the tool call if it doesn't involve a tool then the language model is going to respond um right away without calling a tool call okay but if it does it will call a tool call uh it will make a tool call so um the application is going to send the query with the list of the tools available to the language model the language model is going to respond with a tool call then your application is going to send that function call to the mCP server the mCP server is going to execute that on its side then it's going to return the response of the function and then you're going to send back the response of that function to the language model and then the language model it knows that it um performed the that it executed a function and now it got the response and now it can answer with the response from that function call and then you get the final answer to the user okay so that's essentially all that we're going to be building right here and uh let's actually jump back jump into the code to integrate this uh we're going to be doing this in JavaScript for now um usually cover python but I feel like most clients might be working with um JavaScript in this sense uh but I will make a video in Python if you're interested in that just let me know in the comments okay so let's do that okay so here I have a new directory that I just created and what we're going to be doing is we're going to be initializing the whole project going to be using npm to initialize this uh so there we go I have my backage tojson now initialized and um I'm going to be following the default tutorial in this case um so I'm going to be using anthropic anthropics llms but uh be sure to use any client for your llms that you want if you're using Gro make open AI whatever or if you're using uh llm Frameworks like Lang chain or L index that's also compatible okay I'm probably going to do some videos about that if you want uh so we're going to be installing the anthropic SDK we're going to be installing the um mCP SDK and going to be installing EnV there we go and now on the dep side we're going to be using typescripts I'm going to be installing typescript and uh there we go so now we can just touch an index and index.ts right here and this is going to be our entry point okay uh now something quite useful right here is that we're going to be adding a build uh script to our package right here oops like this and essentially all it's going to do is going to uh compile typescript okay that's all we're going to be doing um so there we go uh now once we do that um let's just create our types uh typescript uh config config file so TS config do Json and this one I'm copying it straight from anthropic very straightforward uh just very straightforward typescript config I'm going to set up the TMV uh right here and I'm going to be using anthropic in this case so and anthropic API key and here you're going to add your API key okay so I'm just going to rename this one to do example and this is the one that you're going to be using yourself and uh there we go now let's actually create the client okay so now that we have everything set up um let's just actually we go to create our mCP our anthropic Keys first though all right so what we're going to be doing right now is we're going to go to console. anthropic tocom you can create your account if you don't have one yet uh I mean in this case I'm using a anthropic llms but uh feel free to use whichever you want and I'm just going to create an API key just going to call it temp because I'm going to delete it uh right after I record this video and um there we go then once we do that I'm just going to copy this and I'm going to come right here and paste it um under the anthropic API key okay and this is the one that we're going to be using during the whole project uh so there we go that's the setup now we can actually start creating our mCP client okay so the first thing that we're going to be doing is uh let me just uh import the things that I need to import right here um I told you before I'm going to be using anthropic so um there we go so this is going to be anthropic the anthropic SDK okay and um after that we're going to be importing the mCP SDK okay so mCP SDK right here uh so we're going to be importing client from here and the STD IO client transport uh right here in order to create the client okay um and and uh there we go that's all that we actually need we're going to need TMV and um just for this example I'm going to be using like in the tutorial the read line um uh it's essentially just like the input uh command in Python where you add an input to your uh to your terminal uh but this ideally would work within an Express server okay uh we're going to be turning this into an Express server in just a few minutes um so there we go once we have imported everything we can just initialize the EnV uh config with our do config right here actually let me just uh this is not going to be the example anymore it's going to be the actual EnV uh there we go and then after that let's just initialize the anthropic API key with the process uh from anthropic if there is no anthropic API key we're going to throw an error okay just uh there we go and uh now what we're going to be doing is we're going to be initializing a class called mCP client okay and it's going to look something like this uh in it we're going to be first initializing a few uh properties they're going to look like this we're going to initialize the mCP client we're going to uh initialize anthropic this one is going to be the llm to make it a little bit more uh agnostic and uh we're going to be initializing the transport the client transport we're going to be seeing how that works uh later and then the list of um the array of tools that we're going to be having available okay and then we're just going to set up a Constructor right here uh which is going to look something like this so uh let's just turn this into an llm so the Constructor is going to initialize the llm from from the anthropic SDK and it's going to initialize the mCP client from the uh mCP SDK like this okay uh so far that's what we're going to be building with the Constructor and after we have finished the Constructor we're going to create a couple of u a couple of uh methods that are going to be quite important the first one is going to be the one that's is going to connect you to the mCP server and the other one is going to be the one that processes the query okay um so these are the most important two methods that we're going to be uh implementing and actually the two methods that I told you about before um in the uh when I explained uh the mCP client concept okay this one is going to connect make the connection to the mCP server and get the tools and this one right here is going to process the query and send the tool call back to the mCP server if there is any tool call okay uh so let's start with those all right so what we're going to be doing now is we're going to create the method that allows us to connect to our mCP server and this one is going to be called like this connect to server I'm just close this like this and um uh to be clear this method right here is going to take the script um the server path of our mCP server um so this is going to allow us to connect to the server that we created in the past video and uh to be very clear this is actually what's going to be happening at the initialization at the setup of the application okay so when we create we start a session with the app uh our app is going to initialize the connection to the mCP server and the mCP server is going to return the available tools that our app has okay so that's what is going to be happening right here so uh let's create that uh the first thing that we're going to do is we're going to handle um the the case in which our server is written in python or in JavaScript this is only relevant if you're running your uh server locally um not if you're running the server um if you're like calling from coming it calling it from a uh Docker container or something like that but uh if you created the server like we did in the previous video this is useful in order to handle if it was written with python with JavaScript whatever okay and um after that what we're going to do is we're going to initialize the transport system uh now not want to get very much into details right here but the transport system is essentially what allows you to actually um to actually connect to the mCP server uh and you have this very very straightforward uh SDK from um anthropic that allows you to do that so you initialize the transport this transport equals stdio client transport and you're going to pass in the command the command is the one that we initialized right here uh essentially it is going to look something like uh python um and then the path the path to your server and this is essentially all that it's going to look like or node if it is a node if it is a node server right uh so that's essentially all that is going to look like in our case it's going to be python because the previous server that we built we built it in in Python and then the arguments are the ones that are going to be uh right after the the server that we added okay that we're passing in as a script as a path right here so there we go now that we have the transport something very important that is actually uh wrong in the documentation is that you have to connect to the mCP server like this and now if you do it like this it's going to not work because naturally the con conect um The Connect method right here returns a promise so you're going to have to await it in order for it to work okay so this await was not in documentation just remember to add it otherwise it will not work uh so there you go now that you are connected to the mCP uh server you can now register the tools that you're going to be using okay and it's very straightforward uh the first thing that you're going to do is you're going to call oops like this so uh we're going to initialize our tools result and we're going to just call the method list tools from the mCP server that we initialized above okay uh we initialized it up here remember we initialized it from here and uh we now connected to it and now we're going to list the tools that we have available and then we're going to add those tools that we got right here and we're going to add add them we're going to add them to our uh property of the class okay so here we're going to say that this um this tools right here they're going to become whatever tools we have in our mCP server right here so the tools is going to be we're going to map through uh the results that we got in the tools object right here and in it we're going to uh for it we're going to return an object that is going to have uh multiple objects going that are going to have the tool name the description and the input schema okay uh if you don't know why or how your mCP server knows that feel free to check out the mCP servers uh video that essentially shows you that uh you're going to have to uh to add a doc string to your tools in all and that doc string is going to be converted to the description the input schema that you add to the to the documentation as well is going to be added right here and the name natural is going to be the name of the function that you created uh so this is listing the tools in your uh application and uh there you go now just for um user experience we're going to list the tools that we have available and there we go so connected to the server with this tools now this is very similar to what you see when you run Cloud for example you can see that I have I am CL I'm running cloud and um oh I don't think I have uh any server right here do I um MC Cloud mCP list uh oh yeah no I did not configure them here but yeah I mean when you start an application that has mCP configured usually you see a list of the tools that are available in your mCP server okay so this is what that does uh so there you go now that function effectively does everything that we saw right here it initializes the connection responds with the available tools and it lists the tools that it has available inside your assistant okay so now whenever you send a query to your language model you're going to be able to send it with those tools and we're going to see how to do that in a moment all right so just a quick word from our sponsor before we continue and our sponsor is actually myself because I host this AI engineer boot camp uh where I teach you how to become an AI engineer it's actually a complete road map with everything you need and I've been doing this for almost a year already and it's uh grown amazingly uh but now I'm opening it to a wider public and that's um just so great so in it you will get to master the fundamentals of AI engineering you will get to learn with Hands-On projects you will get to access a community of wonderful people can't believe I am uh so lucky to actually get to hang out with them and they are actually going through the same Journey as you and as everyone here so it's a just a great part uh you get unlimited course updates and you get monthly workshops to actually uh try the new technologies that are coming out every month and uh you get live weekly Q&A calls with me where I can help you out if you ever get uh if you ever get stock during the course material okay uh the curriculum is pretty large already and it's con stly growing and uh the community is uh already quite big so I'm sure that everyone here would be very happy to have you be a part of the community if you're interested in that click the link in the description to join join the wait list and uh yeah I can't wait to see you there I'm opening that very soon so be sure to uh to join the wait list to learn when it's open okay uh see you there then and without any further info let's get back to the video all right so what we're going to be doing right now is let's just create a makeshift interface uh in order to chat with it okay and I'm going to add it as a method right here this is what the uh gu said anthropic did let very straightforward just a very quick chat Loop that works in the terminal U we're using read line to process each line kind of as an input from python uh just logging that everything's correct and creating an infinite Loop uh until some some one uh um uh says quit or just returns an empty message and uh yeah this is essentially just going to allow us to have a chat put within the terminal okay and then just create the very quick async method for cleaning up the whole mess um just to close the connection to the mCP server uh quite important once you finish the session okay uh so there you go after that we can just run the whole thing by creating this main function um so what we're going to be doing is this file is actually going to be executed using node then the path to this file and then the as argument it is going to take the location of our mCP server and this is what this does right here it's going to process that argument and it's going to pass it into the mCP server with that argument right there okay essentially that's all that it's going on right here here we're initializing our own class that we created above and we're connecting to the server naturally as I told you before then we're creating the chat Loop and then by the end we just clean up the whole thing uh let me just save this and uh let's try to connect to the mCP server that I had created uh in the previous um in the previous example right so in order to do that I am working locally so I'm going to have to I'm going to have to activate the environment for the documentation um um mCP server so in case you did not watch the previous video that video we created a an mCP server that allows uh your llm to look for the latest documentation of a few libraries and use that latest documentation uh before uh suggesting any code to you so that you always have the latest code available it's a very educational um um mCP server very educational project it's not supposed to be a production level mCP server or anything uh for that matter but uh it shows you how it works okay um so there we go we have the we have enabled the documentation virtual environment because um that one was built with um uh Python and now what we can do is we can first of all we can npm run build to actually uh to actually uh create the build of our typescript um server that we just created and once that we have that we can actually execute it using node okay so what we're going to do is we're going to execute the index.js that was just oops that was just um created here on their build and as an argument remember that uh it is supposed to take in the path to my server that I want to connect to and in this case that server is documentation inside the documentation directory at main.py so that's how this is going to work so I'm going to click enter and there you go so I can see that I'm connected to the server with this tools get docks and I've had a debug Search tool over there as well so here if I say hello how are you you can see that it is uh essentially just responding without calling any tool but if I ask it for the latest documentation of any Library so what is the latest uh way to implement chroma DP in Lama index now it should use a tool call in this case so there you go processing request of tile of type call tool request there you go and uh now it is actually reading the response from our tool call and now it is returning to us the actual answer so there we go so the actual answer contains I'll search the L index documentation calling the tool and now that it had all that information it can return uh the information to us okay so this call tool get docs with arguments chrb implementation Vector store Etc this remember it is exactly what we coded uh right here um right here uh where is it here so when we call a tool we add to the final text calling tool blah blah blah with arguments Jada Jada there you go and that's exactly what happened right here okay so there you go now you have actually created an mCP client now let's just look very quickly at how uh an Express server would look with this uh logic right here okay all right so what I'm going to be doing now is I'm going to create a new Branch real quick just to use the just to create the express application so if you want to see the code for the express application go to the GitHub server uh so sry to the GitHub reposer and open the the express app um Branch okay so I have created this new Branch right here it's called Express app there we go and here is where the server is going to be Al okay uh so first things first I am going to have to not this first things first I am going to have to install Express and its types uh for everything to work okay and um there we go so I just did that and now let me show you what the express application looks like so the express application is right here like this so I'm just going to paste this right here and uh there we go so I have the same thing as before my anthropic SDK I have added Express naturally and uh as you can see not much has changed so I initialize anthropic again I have here my mCP U I renamed it anthropic for some reason so I'm just going to name it llm again my transfer there we go everything seems to be correct uh the Constructor has not changed at all so that's convenient and uh here we have my connect to server uh function that we had before and it hasn't changed either so everything seems to be in order we use we initialize the connection and then we get the tools then we list the tools in our uh property that we created right here okay after that we have the process query method which does the same thing as we did before uh in that case nothing has changed let me see what changed just the comment yeah just the comments have changed so not much and um there we go so as you can see everything is exactly the same as before um just uh yeah so now we can actually use it so we have the cleanup method right here so there we go and now the interesting part actually comes right here so I'm going to minimize I'm going to uh toggle this right here and I'm going to show you this part right here which is the actual uh express application okay so we have first when we initialize the entire application we are going to initialize it on Express uh set the port uh set up the middleware and uh we connect to server first okay and again just like before we're going to be using uh the path to the server as an argument uh just created a very quick endpoint right here for/ Health just to see that the server is up and uh here we have the chat Handler which is going to be the post post request Handler right here uh under the chat endpoint okay and essentially all that this does is it uh validates the query that you sent to that um endpoint and uh then just calls from the mCP client the process query method and that's all there is to it then Returns the response that's all we got all you need in order to have an express application that runs with with an mCP client and uh then we just initialize the listen Port right here on the port 3000 and uh then when the process uh ends we just close the connection to the mCP client and that's all okay so uh what I'm going to do right now is I'm going to do npm run um run build like this so there you go now this build should now be the actual build that I have um from the express application and now I can actually do this right here so node I'm going to run this one right here and I'm going to run it with my uh server that I did before so there you go connected to the server with this tools and now I have my chat endpoint okay uh so let's just take a look at it uh so I'm going to do it like this I'm going to send a get request to it from here and uh there we go let's just create a new request call from here and um there we go so we get okay and we get that the tools are get tools and debug research in my uh server so that looks great to me okay perfect uh now let's take a look at the chat endpoint and the chat endpoint is called chat like this this is essentially just an API um an HTTP client very straightforward and uh this one is a post request and uh we are we going to send a query that is going to be tell me the latest uh integration with chroma DP and LMA index let's go with Lang chain this time Lang chain there we go so if I run this right here it should take a little bit more because it's actually executing the call and um let's see what it returns so there we go so we have the response from the assistant we see that it search a langing documentation for information then it called the get docs from uh the mCP server with this arguments right here it got the response and here are are the points to consider I mean this is of course just not a very uh user experience friendly um way to query this API but you can see this is the beginning of a an assistant that actually has access to an mCP server and um I hope that this is useful for you okay so there you go I'm going to put the whole GitHub repository online uh for you to check it out and let me know what you think okay um all right so uh there we go so there we go we have successfully understood how mCP clients work how they connect to your mCP server how to implement the mCP client logic into your application and as you can see it is very straightforward all you have to do is create the connection to the mCP server add the tools of the mCP server into your application and whenever you call your language model add those tools to your language model now something to keep mind is that each llm provider may have a different uh schema for sending the tools so you can check out the schema for each llm provider or you can use an llm framework such as Lang Lang chain or uh Lama index to deal with that okay so uh and then if we deal with the tool calls Whenever there are any okay if there are any tool calls we call them from the mCP server and then return the response to the user uh so there you go um we created the client in JavaScript we integrated it within an express application and we connected to the previous uh mCP server that we had created in the previous module previous uh lesson sorry uh so there you go uh thank you very much for watching let me know if you want to see the same tutorial in Python it's also very straightforward and um happy to see you here and I will see you next time [Music] [Music]
Ek8JHgZtmcI,2025-03-13T06:05:00.000000,Learn MCP Servers with Python (EASY),good morning everyone how's it going today welcome back to the channel in today's video we're doing an mCP servers crash course okay so the idea is that by the end of this video you will understand everything that you need to know about how to use mCP servers and how to create your own okay so this is what we're going to be doing first in less than 10 minutes we're going to be covering what is mCP so that you understand actually the theory behind it and the uh agentic workflow that takes place in it after that we're going to be creating our own server using Python and the server that we're going to be creating is one that will allow our AI assistance to check the latest documentation of the library that we are using uh before actually suggesting code to us okay so that the code that our AI assistant suggests to us is always up to date um and then we're going to be seeing how to use that server that we just created in both Cloud desktop and in Cloud code okay we're going to walk you through everything uh on how to set this up because sometimes it's a little bit tricky and uh then we're also going to show you how to debug these mCP servers cuz yeah that's also a little bit tricky if you want to debug them it's not just like running the function um so there you go that's what we're going to be doing today uh as usual feel free to uh drop a like And subscribe if you like these kind of videos and uh let's get right into it [Music] all right so let's start this off by going over what an agent is if you are already familiar with how an agent Works uh feel free to skip to the part of the video where I talk about how this affects the mCP servers but if you're not it really just takes a couple of minutes don't worry uh we're going to go over it really quick and uh it's actually important to understand how an agent works because pretty much all of the llm applications that you currently use are actually agents so chpt CLA clein cursor all of those use agents uh they're not just calling the llm ones and um to understand what an agent is itself and it's very straightforward an agent is essentially a loop of calls to a language model that simulate a thought process okay a Chain of Thought So in this way um when you send a query to your agentic framework it enters this Loop that you see right here it starts with a thought then it already knows because of its system prompt the available actions that it can take this can be functions usually uh just API calls or anything and then the observation is the result of that of executing that action okay so this kind of tries to emulate when you articulate the thoughts in your head before acting so let's say that for example you're making in a cake and at some point you need to mail but you don't have it with you so you're like okay so I don't have it here oh it has to be in the fridge I'm going to go to the fridge and then you go to the fridge so that articulation of the thought uh LED you to actually perform the action and I know that's that's not always how it works but um in an agent it's very useful to use a language model to simulate that thought and then uh it uh then choose the action from the tools that it has available that we have specified in the system and then once the application executes the action the observation is when it uh when you send the output of that execution to the llm and then it can start thinking again so let's say that for example uh let's say that you give your agent a tool that allows it to uh read your email so if you ask your um agent hey give me a summary of my email um it will be like okay so I have to check the summary the email so I have to check the emails um the latest emails in the Inbox and there's a tool that reads the latest emails in the inbox then the observation is going to be the return value of that which is going to be the actual uh content of the emails and now we can go back to the thinking part and the agent's going to be like okay so now I have the emails now I'm going to summarize them and now it can output the summary uh to the user okay that's essentially all that's going on and this is just another way of um of showing this so you have the user query that enters this thought uh loop then if it has to use a tool it uses the tool then it Returns the observation if it has to use the tool again it uses the tool and Returns the observation and then if by the end it already has the response it gives you the response okay that's essentially how an agent works and uh that is why it is useful uh mCP servers because the idea behind an mCP server is that here you have a toolkit but uh imagine that this toolkit you could have multiple toolkits and they all have the same input output protocol so now everyone can can create their own toolkits and you can just switch them over and be like okay so now I I want to use um now I want to use this other toolkit or now I want to use the two of them and your agent is going to be able to choose which one to to use okay um so that's essentially how an agent works and how it relates to the mCP servers um now let's actually take a look at how the mCP servers work okay so now that we have understood how an agent works now it's actually way easier to understand how an mCP server works because essentially every single server is going to be treated as a toolbox in this case so here we have a documentation toolbox that is going to allow us to search I mean in this example we have a documentation toolbox that is going to allow us to search for the document ation of a given library for example here we have another toolbox that is going to allow us to read email and send emails and this one itself is going to be another mCP server and this one right here is going to be another server that allows you to search the web okay and the idea right here is that this AI assistant can be pretty much any assistant that you want so this one can be chbt clot uh or any assistant that you wrote If you make it compatible with the mCP protocol and that's actually the kind of revolutionary part right here is that all of this is possible because we have this mCP protocol right here so happy protocol and um the idea of this is that you can use this mCP protocol to connect to all of these servers and um as long as you make your application compatible with the mCP protocol it has access to the servers that people are going to be developing themselves uh even if they are not at all related to your application okay so that's kind of the um new thing now let me actually show you the actual diagram that is the one that is shown by theanthropic and uh this is what it what we actually finally get to so we have the mCP client which is the one that you have to create for your application so if you have your chat application your chat put your assistant whatever you can use uh the mCP um SDK to make it compatible with the mCP protocol and now it is going to be able to connect to all the servers mCP servers that are essentially these toolboxes for specialized uh tools and specialized features that you can add to your server so um I mean and to be clear your servers can expose I mean can give your assistant access to of course tools like we saw before but they can also give it access to uh custom prompts and uh to resources themselves like for example uh markdown files Etc that that can be useful for documentation for example okay um so now that we have understood how an mCP server Works let's actually create our own all right so what we're going to be building right here is essentially uh this uh server that you see right here uh we're not going to be adding this resource like this we're just going to be creating this tool and we're going to be adding it to an mCP server that we're going to start and that we're going to uh use with our Cloud desktop application and also with code uh with clo code okay and the idea right here is that usually when you use an llm to help you code um you have the common problem that it does not know about the latest releases of the libraries that you're using so for example if you're using Lang chain or L index maybe there were some updates to the library a couple weeks ago or a couple months ago and that naturally is not within the pre-trained material but that uh trained the language model so they will not be aware of that so an alternative to this is that you create this mCP server that allows your coding assistant to go look for the latest documentation before answering question or before generating a code suggestion for the given um for the given library that you're using okay and that's what we're going to be building right now so let's actually start doing that okay so what we're going to be building first is let's just uh start by setting up our environment uh all the commands that I'm going to be using right here are actually in the blog post and the description so feel free to check that out and um so the first thing is that actually the guys at anthropic they recommend using UV as a package manager and I've actually been using it um for a few days now it's it's amazing I really like it um way it's kind of like pip but faster so feel free to use one if you want and um so the first thing that we're going to do is we're going to initialize our project and in this case I'm going to call my project documentation okay so I go UV init documentation and after that I am essentially just going to go into my documentation and open it with cursor okay so let's do that okay so as you can see this has created um our project right here with a very quick get ignore path and version we have our main entry point file and uh basically just the starting point of the entire thing okay um now let's actually continue with the setup just going to open my terminal right here and uh let's do a couple of things first first thing we're going to have to create our virtual environment and uh there you go now it's created right here so what I'm going to do is just um activate it and there you go now I have my virtual environment working within here and uh next thing is you're going to have to install these dependencies so I'm going to be using I can just give it more space right here I'm going to be using the mCP CLI and the httpx uh library to make the calls to Google which is what we're going to be using to search for the documentation okay so I execute this there you go and uh now I have pretty much everything thing I need now I can actually start building my mCP server all right so let's start actually building our server okay so the first thing that we're going to do is we're going to import fast mCP from mCP server fast mCP and this is the one that we're actually going to be using to initialize our server okay and there we go so then you just do mCP equals fast mCP and we name it in this case I'm just going to name it docs like this and and uh there we go uh we're also going to be needing some API keys so I'm going to be just importing uh from from tnv let me just copy it from here from tnv I'm going to import load. tnv and then I'm just going to run it before anything else happens right here okay and there we go then we're just going to initialize a few constants the first one um actually the only one that we're going to be using is this one the US user agent and um let's actually also initialize the uh serer URL like this okay and this one we're going to paste it a little bit later when we see how serer works and just to give you an idea of what the whole thing that we're going to be building we're going to be building uh three methods right here three functions the first one is going to be search web so search web this one is essentially going to allow us to this one's going to to return uh the web results from a Google search um then we're going to let me just like this uh we're also going to be creating another one called Fetch URL and this one is going to get us the results from the from just uh to scrape uh URL and to get the actual contents off it and then we're actually going to get the get docs which is actually going to be the tool that we're going to be building okay uh and this one is going to be decorated with mCP do tool like this and this is the one that the agent is going to be able to call and this one is going to first search the web to find the relevant documentation Pages for our library and then we're going to fetch those pages to actually get the contents and actually in order to do that we're going to have to use a quick little uh hack of YouTube that allows us to check only search results from a given URL and we're going to give it this URL for python this URL for L index and this URL for open AI okay you're going to see how that works in just a moment but let's actually first take a look at how serper Works to show you how to uh create this uh search web um function right here all right and just a quick uh Showcase of what we're going to be using to build this we're going to be searching the documentation using Google and in order to do this we're going to be using serer it's essentially just Google within an API and it gives you 2500 free queries when you start your first account we can see that I've been testing it a little bit and uh essentially let me just show you how it works so you just send the query and it sends the query within the payload right here under the Q parameter and then you send that to the your this URL right here and um then you just send it all to this endpoint and it returns to you the results so if we search for Apple going to get actually just uh say uh three results per per query there you go oh I can only get 10 here in the playground all right so there you go I send this and then I get from this organic results this are the ones that I'm actually interested in I get the actual results from my Google search Okay and actually what I'm going to be doing is I'm going to be appending it or prepending it with site and then the URL of where I want to search for the documentation so here if I want to say for example I want to look for Chroma DB right here now all of my results are going to be from this URL ling.com dooc so now I am sure that I'm getting actually the latest documentation from um langing and the same goes for L index say for example if you wanted to search for this thing on L index only I can prepend this with this and now all the results actually come from Doc L index stable so I'm sure that this documentation is going to be up toate and uh the idea right here is that I'm going to have my agent first uh perform the search and then go through the link that's listed right here and actually get the results using beautiful soup okay uh so let's actually first get our API keys I'm going to copy it and then I am going to paste it right here into mymv file that I'm just going to create and I'm going to say serer API key I'm just going to paste it right here and uh now I'm going to actually be able to use it with my load. tnv file right here and uh now we're ready to actually start coding actually one thing I forgot is to copy this URL right here now we can actually start uh creating this search uh web function all right so now let's actually start creating these two helper functions that we're going to be using okay so as a reminder our agent is going to first search the web for the query that it requests and then use those search results to actually access the URL of the search results and get the contents okay so this one gets the contents of the URL and this one gets the results in the form of a URL okay uh so let's first do the search web function it's going to take a query that is going to be a string like this the string and uh it's going to return a dictionary or none okay uh let me just copy and paste this one right here because this is not um um exactly uh this I mean this is not a video about how to create a search um web function so there we go um as you can see we're using async in here so I'm going to do async to and I'm gonna have to also import J httpx Json and Os for this to work so just to go over this very quickly I initialized the payload and I send the query so this search web function is essentially just going to uh uh search the web for any query that I sent to it and it is going to return a number of two uh it's going to return two results only okay so I'm just going to be focusing on the top two results um the headers the first header that it takes is my API key and then we have the content type right here as well and uh secondly we're going to initialize this Asing client and we're going to call our server API using this and actually the URL is going to be my server URL right here and there we go my headers we send my data and then I just set a time out of 30 seconds as well and uh there we go then we just response race for status and then return the Json object as a dictionary okay that's all that we're doing with this search web function so essentially just returns our search results in a dictionary and I'm going to do the same thing with the fetch URL it's essentially just the same thing but uh instead of using serper it just sends a get request to my URL and gives me the results and then I just parse them using beautiful soup okay again I am using async here so I'm just going to async it like this and I'm going to have to import beautiful soup too so there we go I essentially just send the SK request and then I parse it with beautiful soup and now I just get the text and return only the text of the uh URL okay so what my agent is going to do when they when it calls this get docs function it is going to first search the web get two results in the form of the title and the and the URL of the search result and uh then we're going to open the UR L using the fetch URL and it's going to return by the end only the results of the two top results on Google that come from a given uh Library uh documentation okay so there we go that's our helper functions we can now start actually coding the get documentation um tool all right all right so now it's time to actually start creating the tool um now very importantly you have to create well to create your tool that your agent is going to be able to use you have to decorate it with this decorator right here which is mCP do tool okay and this essential is going to convert the function definition that you're doing right now into an actual tool that is compatible with the mCP protocol okay and uh importantly I'm just going to add here uh my uh parameters as we mentioned before we're going to be taking the URL and the query um so uh something extremely important that you have to do when you initialize a tool for any agent but I mean of course right now for mCP is that you have to add a doc string specifying very clearly what your tool does this is the description that is going to appear to the user when they see the mCP server that is connected and also this is going to be the description that is available for your llm your language model to see what this tool actually does and to select it when it is when it is um useful because if your um doc string is not specific enough your agent or your application your language model is not going to be able to use it so here as you can see I specified that this one is the sear allows you to search for the documentation of a given of um for a given query in library and for now it supports Lang chain open Ai and llama index as I mentioned up here okay now the arguments also specify them very importantly because these are going to be parsed as Arguments for the function goal of your language model and then the actual uh returned value and here it's not actually going to return a list of dictionary it's going to return um the text uh from the documentation okay and let's actually start by doing this so I am going to just right now uh the first thing that I'm going to do is I'm going to test if the library that was passed right here is actually within the supported libraries that I have right here okay if it is not in uh wait if it is not in that Library I'm just going to raise an error and uh then I'm going to build the query that we're going to be sending okay remember as I mentioned before we're going to be using site uh colum and then the actual URL where we're going to be um searching and then the actual query from the language model that wants to for whatever documentation it wants to find and then I am just going to get the results right here from the search web um helper tool helper function that I had right here now I'm using a weight right here so I'm just going to have to turn this into an ASN function and uh there you go let's see what this does now if there are no results I'm just going to return results not found and then for every single one of those results I'm going to tap um into the result URL link if you remember correctly that's what the results look like if I show you again right here if I go to the results I go to the organic part and then I go to the link this is what we are going to try to fetch actually here um yeah We're looping through the organic pot and then for each one of those we're tapping into the link one and we're fetching the URL which remember with beautiful soup it returns just the text of that page and then uh instead of printing this we are going to be adding them to a dictionary so the text is going to be like this and then we just return the text like that okay so there you go now we have the tool that's working correctly and we have that it is already returning um all the text from the documentation which is going to be added it's going to be returned by the tool and it's going to be added to our um language model function call okay uh so there we go now last thing to do is to come right here to if name equals Main and we're going to do mCP do run like this mCP do run and transport equals St standard input output and uh then we save this and now we have actually complete finished our mCP server it was that easy I mean you can of course have your coding assistant write it for you but I just wanted you to understand how this is all working so essentially the tool is the one that is going to be called and um you're Avail you're able to have as many helper functions as you want um and as many tools as you want as well all right so let's actually um run this and connect it to our Cloud desktop application okay all right so quick little thing that I wanted to mention before actually showing you how this works in cloud is that I actually do not have a Plus subscription to clot because I do everything with the API so uh this tool is probably not going to work with the free version because it Returns the entire contents of two different web pages and that's a lot for the that's a lot of context for the free tier of the clot desktop app so if you have a Plus subscription to Cloud this should work perfectly uh if not then uh you probably want to uh Plus subscription if you want to use this with with Cloud desktop um that being said for the demo I am actually going to be mocking the response with a shorter response uh just so just to make sure that it fits within the context window of uh Cloud desktop okay and uh after that I'm going to show this to you on cloud code and for that I'm actually going to be using the real tool uh just to show you that uh because that one works with the API okay so let's actually uh show this on CL desktop and then on cloud code all right so what I'm going to show you right now is how to use uh this mCP server that we just created with CLA okay and we're going to be using Cloud desktop for this in order for actually be able to handle this and uh the first thing you're going to want to do is you're going to go to settings developer edit configuration and it's going to show you this Json file now you're going to edit it with it any text editor you want going to be using Sublime here and under mCP servers you're going to paste the configuration for your server okay now in my case I created my server in Python so I'm going to be using UV to run it uh there is a common error uh sometimes when you do not add the entire binary so if you just do uh if you set S command UV uh this may raise an error depending on your path but um there you go I mean we can take a look at this in a moment uh so you're going to add the command to actually run your server which is UV then you're going to move your um terminal to the directory where you'll build your server in my case this is let me show you this is this one right here puid is print working directory by the way so you copy this come right here and you right here going to paste the full directory of where you're server is located then you're going to add run and main.py which is the name of our file where our server is okay this is essentially telling Claud to run the server at start okay so I'm going to save this I'm going to go back to Cloud I'm going to open it again restarted as you can see we have these errors and uh most of the time the reason for this is that your your cloud is not finding the binary for UV so what I want to do is I want to find which UV I am using here where I was actually using it and it was working so I'm just going to copy the actual full path to the binary going to back go back to my um Cloud config file and instead of just saying UV I'm going to add the entire binary path right here so now I can close this and I can restart cloud and uh there you go so as you can see now I have this little Hammer right here which uh if I click it I see the list of the tools that my uh Cloud desktop has available for me right now so in order to uh use these tools I can only I can just go right here and ask Claud for a question that will likely use this tool so for example how do I um Implement a chroma DB in blank chain and as you can see it's going to try to run this tool it going to ask me for my permission to actually run the tool it's calling library and the query then it got the answer strives to run it a few times and um there you go uh and uh there you go so now it is actually answering the question and it is actually giving me the implementation to do it using the latest uh documentation from from Lang chain and chroma so there you go now this works correctly let me show you how this looks so chroma DB implementation and now you have the result is this uh the answer right here on how on the actual documentation so there you go and that's how you do this with CLA desktop now let's actually take a quick look at how to do this with um with Cloud code and um and then let's check on debugging all right so now I'm back here at my ID and to actually run this uh mCP server with code CL uh Cloud code okay so what we're going to be doing first is I'm going to be removing this mock um uh tool result to actually use the real tool and uh what I'm going to do is add it to Cloud code first okay so I'm going to do CLA uh code to show you that I currently don't have any tools or any mCP servers running I'm going to close this and in order to add it what we're going to be doing first is we're going to do Cloud mCP at okay and this is this is going to open an interactive uh helper to actually add the mCP server or if you know the parameters you can just add them right here okay I'm going to open the interactive tool and it asks me to create a server name going to call it documentation docs because it's going to look for the latest documentation um the project is going to be the local one and enter I command to start my mCP server okay so in my case I wrote this uh mCP server in Python so I'm going to be using UV to run it however remember that sometimes if you just do UV it may u uh do some errors so I'm going to check where my binary for my UB UV is so I'm going to paste the entire binary and then for the parameters remember just like with uh uh CLA desktop we're going to do directory and then we're going to paste the working directory where my um where my uh server is so I'm going to come right here I'm going to paste this then we're going to run the actual uh mained py file that we have right here okay and the main the P file is the one naturally where my server is coded okay uh so I'm going to hit enter for the environment variables I am using some environment variables but I don't have to add them here because I have already loaded them in mymv file I'm going to leave this empty I just check that everything is correct directory uh Etc documentation I can confirm this and just hit enter to finish and if you want to check uh the mCP servers running on that you have on cloud you can do m mCP uh list clot mCP list and you will see that your new server is here just added and now if I run Cloud you can see that I have my docs uh right here okay so everything seems to be working correctly now I'm actually going to test it so let's uh ask it to create a new function that implements a chroma DB database um yeah V database with lank chain and um make sure to use the latest uh integration let's run this and hopefully it's going to use my tool so let's see if that's if it actually does it it actually used the tool um and this is the results from my tool I had actually already tested this before and it asked me to validate this and I validated that I wanted to do it so if this is the first time that you're running this tool um it is going to ask you for the validation if you actually want to run the tool so I'm going to say yes to everything to all the changes that it wants to do just to show you instead of actually TR having to validate every single thing and um as you can see it's now thinking and it used the tool that I added to it and it's using the latest now document ation from uh Lang chain to to perform this integration okay I'm going to cut the video uh right now and get back when it's finished to show you the final result okay that was actually quite fast so it says that I've created a comprehensive implementation blah blah blah and as you can see it used the tool that I asked it to use um doc uh get docs and the query was Chrome integration with Lang chain and this is what it got okay now if I close this I can come back to my main.py and see that actually there were um there's this new tool create from a vector store okay um so there you go that's how you uh use this with cl code now what we want to what I want to show you uh afterwards is how to deug this because I mean sometimes when you're building this there you can encounter errors so and that's normal so let me show you how to deug this all right so uh in order to show you how to debug this I'm going to go back to the the previous state of my mCP server which is the one that I developed right here and save this and actually let me just close uh clot code so you can see that costed me uh 14 cents for just one query so not the most affordable AI assistant but uh there you go so now what I want to do is I want to open npx uh um you're going to run this like this right here let me show you um like this so you're going to do npx at model context protocol SL inspector and then you're going to run your server within it okay so in other words in this particular case my server is on main.py and remember that in order in order to run it you do UV run and then the file of your server and in this case it is UV run main.py so I'm going to enter this and it's going to open my inspector on Local Host 5173 so here I now open my inspector so you can see and uh this is essentially just a a tool that allows you to debug your mCP server so now you can do UV is the command the arguments are this now I can do connect I'm connected to my server uh as you can as you remember from the explanation you can add uh resources prompt Etc to your mCP servers but in this case we're focusing on the tool side so in order to create to check the tools you go to tools and list the available tools that your server has right here and as you can see here's the tool that I created so you open it and here you can actually start testing it so the query what's going to be the query uh let's say that in my case it's going to be Chrome ADP and the library that I want to check for is uh say LMA index and this naturally comes from the fact that I have support for this right here in my documentation URLs and then I can run the tool and I can check the results right here and this is what is going to be shown to my language model when it calls this uh this tool so I can see that it's working correctly just a very straightforward way to test your your mCP server tools because not a straightforward to run in a notebook or in the script itself because it's using the mCP decorators so this is a way to test them and it's a very reliable and very very neat way to actually check that your mCP server is working correctly okay uh so there you go so there you go we have successfully finished the video we explained at the beginning what is mCP exactly and how it works we created our own mCP server using python um in the future maybe we can make a video about how to do this using node um in JavaScript uh we connected it to both Cloud desktop and Cloud code and uh we also learned how to buug it real quick so that's it for this video feel free to subscribe if you want to more videos like this uh feel free to drop a like and also feel free to check out the boot camp that the AI engineering boot camp that I set up the link is also in the description to take you from Zero to Hero in the AI engineering world okay so uh drop any questions in the comments and I will see you next time [Music] [Music]
yzPQaNhuVGU,2025-02-28T06:00:47.000000,Advanced RAG with LlamaIndex - Metadata Extraction [2025],good morning everyone how's it going today welcome back to the channel and uh welcome to this tutorial where we're going to be covering a little bit more advanced topics on rag we're going to be building a complete rag pipeline using L Index this time um usually if you're familiar with L indix you know that there is a very famous feliner that allows you to chat pretty much with any document you want uh in this case what we're going to be doing is we're going to be building the entire pipeline by our ourselves and that is going to allow us to perform some pretty sophisticated Transformations on the text uh chunks that we're going to be extracting uh to be more precise we're going to be uh doing something that we call um metadata augmentation which is the fact that we're going to be taking every single one of the chunks that we're going to be extracting from our PDFs and our documents and adding as metadata example questions and answers that they can answer to example titles Etc before for embedding everything and putting everything together into the vector store okay this is of course going to help us with ranking and when uh retrieval during the retrieval process to find the most relevant uh pieces of um information related to our query okay uh so that's what we're going to be doing today I hope that you find that interesting and uh before I forget I wanted also to mention that I'm currently hosting an AI engineering cohort which is you say 12we uh course where I'm going to be live um answering your questions and uh doing some q&as with you and having some FaceTime with you to be sure to take you from Zero to Hero and to that you become an AI engineer okay and you can start implementing all these topics in your job or in uh your freelance uh work okay uh you can check the link in the description the website's over here and um yeah please join the weight list and we're already 50 over there so I can't wait to have you um join too okay so without any further Ado let's actually go to building this a super cool rag [Music] [Music] pipeline all right so before actually going into the notebook I wanted to take a look at this uh diagram again I mean in case you're not familiar with the whole rag over structure data uh pipeline essentially we're going to be extracting the text from our unstructured data right here it can be Word documents PDF files HTML files uh PowerPoint presentations whatever we're going to use a loader from L index in this case we're going to be using the simple directory loader which essentially just extracts the text out of pretty much any file that we have in a direct and uh from that we're going to get a a bunch of um documents in the form of text with their metadata uh we're going to split that into different chunks as well and uh something particular that we're going to be doing in this uh implementation is that we're going to be doing some extra Transformations at this point right here okay so once we have the chunks um this chunks uh that are going to be shorter so that we can send them as context to the language model um we're going to be adding some extra metadata to them and this metadata is going to be some examples of questions and answers that the information within the chunk is capable of answering for example if the chunk talks about um say the Renaissance period uh we're going to be adding some questions and answers about the Renaissance period to the metadata to improve the the embeddings and to actually put this uh Chunk in the correct Vector space okay uh we're also going to be adding some custom title to it and actually something pretty important right here is that we're going to be adding that metadata in the embeddings okay so we're not only embedding the chunk of text itself we're embedding the metadata with it as well okay so that is quite important and it's going to help with the retrieval then after that uh straightforward rag the user is going to send their query and something pretty important here as well is that we have to add the same transformations to the user query um at least at least we have to use the same embeddings model and uh it would be ideal to to add the same Transformations that we're going to be using right here uh to the user query as well although that is not mandatory okay and uh once we have that query with the embeddings of the query we're going to send that to the vector database the vector database is going to return to us the chunks of text that are the most relevant uh related to the uh user query and we're going to select the top ranked one and send it as context to our language model so our language model is capable capable of answering a question about that topic right there okay uh so that's essentially what we're going to be doing as you can see the more um new uh thing right here is the Transformations right here um as I mentioned before these are transformations that we're going to be applying using L index however uh rest assured that if you're not using L index these Transformations are pretty straightforward to apply in pretty much any other uh llm framework okay so I'm using here L index because it has these Transformations pre-built as modules within it but uh it shouldn't be very very hard to implement this and say langra Lang chain l or whatever rag framework you're using okay so there you go that is what we're going to be building so let's actually get uh right into the notebook to start actually extracting information from this pretty nice um paper that was released a few days ago okay so there we go first thing that we're going to do is we're going to be installing Nest as KO because we're going to be using some uh in code in this um notebook and in order to make sure that it works correctly in our uh notebook we should do Nest as KO do apply and then we're going to be installing L index and uh something that I didn't mention is that we're going to be using pretty much only open source models to keep costs low I'm going to be using huging face um for embeddings and I'm going to be uh bringing my language models from Gro okay so I'm going to be showing that in just a moment so first things first we're going to go to extracting the data all right so now it is time to actually extract the contents of our document okay for this example I'm going to be using a single document however you can uh feel free to use as many as you want I'm going to be using this one right here it's just a pretty recent paper on um an AI called Health GPT I haven't actually uh read it through but it's U one of the newer ones uh if you're interested essentially just introduces a an AI that is uh capable of solving uh medical large um Vision language models uh tasks so there you go this is what we're going to be using it's a 19 page uh PDF document and we're going to extract it using this simple directory reader okay so in order to do that what I did is I created a data directory right here and within it I just added my file okay now once I have that file all I have to do is do simple directory reader and then I just pass as a parameter the input directory and this simple directory reader that you import from L index essentially just extracts the text from every single document within that directory okay and it doesn't matter the format that you're using so you can be using um you can have several PowerPoint presentations in there you can have um PDF files in it and uh it's going to extract the text from all of those okay so pretty um easy to use interface and uh so we're going to round it like this and as you can see we get 19 documents from this single um file and as you can see of course this 19 corresponds to the 19 pages so I generated a document for each page um now actually let's take a look at what they look like as you can see each document has an ID um and a bunch of other metadata actually um to be clear right here uh document in uh when talking about a document under the framework of L index essentially it means an object that contains some information and is also linked to a source file okay so this one right here is going to to contain uh this text right here from the off from the original document and it's also going to contain a bunch of metadata that links it to its original file okay um so we have an ID we do not have embeddings and we have a bunch of metadata as you can see we have one document per page so 19 documents right here and you have the label for the page number right here as well in the metadata we have the file name we have the file path as well pretty convenient file type file size the creation date the last modified date and um this piece of metadata is quite uh useful I'm going to be going a little bit more deeply into that but it basically uh controls which data which um metadata is going to be sent to your embeddings model okay because you probably do not want for example the modified date to go to your embedding model because that's going to it's probably not going to be useful at all to uh find to locate the meaning of your of your document in the semantic field okay uh same thing for the language model going to be going a little bit more uh in detail into that later and uh there you go we have no relationships for any metadata template uh this we're also going to be covering in a moment metadata separator we're going to cover that a little bit later on and the text resources essentially what I showed you essentially all the text that will that is corresponds to that page so there you go we have the data that was extracted conveniently for us uh we didn't do anything other than just use Simple directory reader and it automatically added all of this very useful metadata for us now something very convenient I mean in case you want to do that you can actually extract ract the documents using the name the file name as ID so as you can see right here I am using a unique Universal ID uh but you can do that uh using but you can use instead the file name as ID not like this one second you can do that instead using the file name as ID that's also possible um I personally prefer to to use just the regular um unique identifier but uh do as you as you feel like as it is convenient for your application okay so there you go that is for the extraction now we're going to go to the more convenient and interesting part which is the transformation and we're going to be applying a lot of Transformations that are going to help us to uh improve the retrieval process of our information okay all right so we're getting to the fun part right now we're talking about Transformations we're going to apply some very useful and sophisticated transformations to our data before sending them to the embeddings model and also to the language model now this is going to help us have a more reliable rack Pipeline and something also that I should mention is that although of course we're using L Index right now and it has them L index has this uh Transformations built in um these are transformations that are not very difficult to implement if you want to use them in any other framework that you're using in general these are just very good techniques uh for improving the performance of your rag pipel okay so uh first thing that I'm going to do right now is I'm going to show you uh how to do um what we're going to be doing essentially is we're going to be updating or expanding the metadata of each one of our documents before um indexing it okay so as you can see uh our documents they look like this they're super long they have a lot of metadata that we're probably not going to be using um and uh yeah so you probably do not want to send all of this to either your embeddings model or to your language model okay so in order to fix this what we can do is we are going to first of all Define which um keys from your metadata are actually going to be sent to both both your embeddings model and your language model and um this is something to take into consideration because sometimes you don't consider the fact that when you are sending your document or your node to your embeddings model before putting it into your vector database you're actually sending the metadata as well not only the content of the text okay and um that can be useful in some cases if you but only if you add the uh relevant uh parts of your uh metadata to it okay so in this case we're going to be just creating a very simple document uh just to Showcase this um uh the text of the document is this is just a super customized document um by the way this comes straight from the documentation from L index and then we have three uh key value pairs right here in the metadata so we have the file name the category and the author and then we have this excluded embed metadata keys and actually I'm going to add the same thing for the llm and these are the keys I'm just going to comment this out first and these are the keys that are not going to be sent to the embeddings model okay and I'm going to hide this for now too uh so let's see what the embedding model is going to see in order to see uh just for testing what your embedding model is going to see uh and try to embed in the vector space we can use this metadata mode uh module right here and uh you're just going to do document. get content and as metadata mode you're going to in include the embed uh metadata mode. embed right here so I'm going to execute this and as you can see the embedding model sees this the category the author and then the contents of the document now sometimes you want the category to be embedded uh because probably that will help to find uh to position your embeddings at the correct Point sometimes you may want the author to be embedded as well because you want that as well to be located within your vector space but let's suppose that for example you have the page number right there you probably do not want the page number to be embedded and uh uh and add it to your vector okay that's definitely not going to help you with the semantic search so that is what this is useful for and same thing for the language model I'm just going to uncomment this spot right here and let's see what the language model actually sees so excluded LM metadata keys and right here I'm going to say that I'm going to remove the category uh from here I'm going to put this and you can see that the llm sees that the file name is this one right here this one's probably going to be important for the language model in case it wants to for example um uh mention the source where it got the context from uh if it's a rack system for example and um then we have the author and then the content right here okay very convenient uh so far so good but uh something else that I wanted to show you is how to actually format the metadata when it is sent to the language model and also to your embeddings model okay so there are essentially three parameters that you can change uh the first one is the metadata separator essentially what is going to what character is going to be uh between each part of each metadata so in this case we have file name category and author and I just said that for everyone uh we have a jump line this one by the way it's the the default value for this setting right here and then for the metadata template we're going to have the key and then a column and the value like you see right here simp to be working fine for me but I mean you can update it if you want you can add an arrow here instead and it will do something like this and this is what is going to be sent to the language model um this is probably not super useful but just know that you can tweak this if your language model for some reason works better with other separators and uh this one right here is probably the more useful one so the text template essentially takes this two variables right here metadata string and content content and uh those essentially are replaced with the content of the document and the metadata so my metadata is going to be um applied like this I'm actually going to add a jump line right here and then just a separator and then the content like this I'm just going to add a jump line here too and uh let's take a look at what the language model sees now so as you can see we have the metadata and we have the actual information right here for the metadata and then we have content right here this is probably going to make it easier for the language model to see what is going on um or sometimes if you want to do the the anthropic way well I don't know if it's really the anthropic guys who made uh made this up but um I uh these are they are the first ones that I saw use using B for language models so essentially you add them add your data between um uh Mark uh markup TX uh so yeah there you go that is how you format your metadata and how you U make sure that it is correctly uh formatted before you send it to your language model or to your embeddings model um so that's the first part but uh something else that I want to show you is that you I mean so let's actually take a look at our own data and how it's supposed to look so right here you have the page label and the file path because remember that we had some values by default um when we extracted our data so we had that our let's find them right here we had that the excluded embedding the excluded meta metadata keys from the embeddings are going to be the file name the file type the file size the creation date the last modified date and the last access date which makes complete sense you probably do not want to embed those they have nothing to do with the meaning of of your uh yeah with the semantic value of your vector so you probably do not want them and for the llm we are for some reason we excluding the file name I think that's okay because we are not excluding The Source uh there we go I mean the path file uh the file path sorry the file type the file size we don't need that either there you go so it seems to be okay for me um but uh some thing that was not included here is the the page label so for some reason we are sending the page label to our embeddings model so we probably do not want that and in order to remove that all that we're going to have to do is just say that for every single document in our documents that we just extracted we're going to first of all add this nice text template with the metadata right here as I showed you before and then if the P if the page label is not in the excluded embed metadata Keys array within the um metad data of the document we're going to add it so that the page label is not sent to our embeddings model okay so let's execute that and let's take a look at how it looks like now so now what is going to be sent to our embedding model it's going to be sent the file path and the content and in this case we could also remove the file PA the file path if you want but I mean it's going to leave it like that for now but uh there you go that is already adding some uh useful granular control over what is actually sent to your language model and to your embeddings model uh to be sure that you do not send uh just a trash to your models that they're just going to be confused about it okay so there you go now the next thing that we're going to do is we're going to apply more sophisticated transformations and uh for this Transformations we're going to be using um language models to actually extract information from these nodes okay so let's take a look at that okay so even more fun now we're actually going to be extracting some data some information from each one of our documents before um before embedding them uh to add more uh information to the embeddings okay so right now as you can see we have our documents just like they are and we did uh update a little bit the metadata that is going to be sent but we want something a little bit even more granular right we want to have more control and we have to also uh augment the metadata of each one of our documents to be sure that they contain uh that they actually contain the that are easier to to retrieve okay so for example let's suppose that the information that I want to query is located on this document right here and this document yeah let's say this this one right here now this let's go for the first one okay uh so the document that I the information that I want to retrieve actually comes from the first document um but the first document is just uh the text itself it does not it's not a description of the text itself it's just the text itself right so it just talks about something um some interest an interesting technique to to improve rack is essentially to extract um uh a summary from this spot right here or the title from it or some example questions and answers that this piece of text could uh potentially help solve and that's what we're going to be doing here we're going to be using a language model so that for each one of our of these documents we're going to be extracting a title for the single document we're going to be extracting a set of questions and answers that this particular piece of information could potentially help us answer okay so in order to do this uh we're going to be using some modules that are pre-built with uh L index uh but first of all of course to extract this information we're going to need to use a language model and in my case I'm going to be using an open source language model um and in this case the use case is quite uh small it's just extracting a summary extracting a title extracting a list of questions and answers and I can do this with a fairly small uh language model and I'm using Gro right here so I'm going to take a look at the at the pricing so I'm pretty sure that a very small language model would be more than enough for this so even say which one let's say this one right here even quen uh Q 2.5 uh it's going to be enough it has a very very affordable uh uh price tag right here per million tokens I mean for reference um um uh open AI is like three times more expensive than even the more the most expensive one right here and this ones are open source so there you go this is the one that I'm going to be using right here and um just for reference it's actually located right here okay um so in order to use it I'm going to first just create an API key right here just going to call it temp one to remember that I have to remove it later call it temp temp two cuz I think I used temp one already going to copy this and let's go right here and um just going to be importing from Lama index LMS Gro I'm going to be importing Grog right here and just going to initialize my API key like this so uh very straightforward um this is going to ask me the API key there you go enter and there we go so here's the model that I'm going to be using for extracting these titles and also the questions and answers for examples okay uh also make sure to select I mean if if you're using Gro or whichever uh language model system you're using uh be sure to select one that has quite a High um rate limit per um per minute because uh we're going to be uh sending a bunch of requests to the language model because we're going to be sending a lot of requests in batch to actually make sure that we're getting the summary of every single document okay so if you have 19 documents for example it's going to send the document and then ask a question about it uh so that you get the title then it's going to do the same thing about three questions so you're going to get end up having a bunch of question a bunch of API calls right here uh just be sure with be sure uh to consider that uh to consider that into your uh expenses as well if you're paying for this um so this is the llm for the Transformations that I'm um initializing and uh there we go so the Transformations that I told you we're going to be doing is we're going to use title extractor and questions answered extractor so essentially it's going to take each document it's going to generate a title and it's also going to generate a questions answered question uh a few pairs of questions and answers that that particular document is capable of responding to um and then we're going to be just splitting every single one okay um actually in this particular case maybe we want to use the text splitter um yeah no we probably need that at the beginning yeah that's good point and in this case we're going to be using the ingestion pipeline essentially this just um lists a list of Transformations that we're going to be applying to all of our notes or or all of our documents so the pipeline we initialize it like this ingestion Pipeline and then we pass in the parameter of Transformations which is going to just an array of every single one of your Transformations uh in order of course so the first one that is going to be applied is a text splitter essentially we're initializing this sentence splitter right here with about a th um tokens per split and we're going to have an overlap of 128 just remember that the overlap is uh to make sure that we don't cut um that we don't cut paragraphs in half or something like that um in any case the sentence splitter already uh tries to optimize uh so that no sentence is left uh it's got in the middle but anyways um this is still probably a good idea to use um so there you go we initialize our Pipeline and then we just do pipeline run and we pass in the documents we say that in place is true and we're going to be showing the document the process um right here so the documents are the ones that I just extracted raed and I can now oh and something that uh is quite important too I initialize this title and Q&A extractors and both of them require that you pass in as a parameter a language model of course because it is not going to just magically come up with a title and the set of questions and answers for your document you have to actually use the language model to get them um here is the batches and the number of questions that you want for each um um for each one of them so there you go there you go that it's parsing them first and then it's going to start using my language model to actually generate the questions and answers and um then we can start seeing what that comes up with I'm probably going to pause the video right here a little bit uh because this may take a few minutes so I'll be back in a moment well actually it didn't take that long that was pretty fast so there you go we should now have our documents uh with the metadata extracted and uh with a bunch of new things so let's take a look at them we have 30 new documents and um now let's actually take a look at what the uh Metadate oh let's just take a look at the docu let's just take a look at one first um before actually printing this let's just take a look at the first one [Music] um let's do pretty print let's pretty print everything and see what they look like um module is not colable so I did not import PR the print don't po po this there you go so we have all the notes you can see that every single one has its ID no embeddings yet of course we have not done that yet and we have a bunch of metadata so we have one uh note for the first page two notes for the second one the third page was divided into two into two notes fourth one was left like that so there we go we have a bunch of splits of course splitting is useful as you're if you're using a language model with uh lower context if you have a pretty long context you probably do not probably can use a longer chunk size than this one but um yeah just just to be clear um we have the file name too right here we have the file path pretty convenient file name file size okay we have a document title and there we go we have the title and then we have another title right here okay um and then a little bit later we have the set of questions and answers I'm going to show you that in just a moment um actually I'm going to going to show you that when we go right here so first let me just check the first note okay so we have the first Noe right here and I'm going to print it as a dictionary like this so to actually take a look at it and this is the full dictionary here so we have the embedding none um the file name file path Etc and then here we have another piece of metadata very useful questions that this excer excerpt can answer so I mean you can see that of course you can see that this language model that generated it um but as you can see what are the specific findings of pathological changes observed in the font's image provided in the document Etc and then the question the answer to the question is this one Etc so this is essentially going to help you to locate this particular node in your vector space more accurately because you will now have examples of the answers and questions that this particular piece of uh data can answer to and it's going to be easier to retrieve her later on uh to retrieve it later on uh so if you want to take a look at what actually the embeddings model is going to see when you send this uh kind of document so as you can see it will first of all send the file path the document title and also a set of questions right here um this one is probably useful uh with longer documents probably not super convenient to have a title for every single um excerpt of a thousand words but uh in any case this um is also one technique I think that the one that is a little bit more useful and interesting is this one the set of questions and answers that is going to be added to the to the embeddings and then we have the content right here and now let's take a look at what the LM is going to see uh so the LM also includes the title and the questions and answers and then the actual content so very convenient there we go um so that is already how to add some bunch of uh more useful information to every single one of your documents of your notes that you're going to be uh embedding before even creating your index so as I said before this is something useful not only for when using lamb Index this is going to be useful if you're using langra for example or Lang chain site um probably going to be a little bit more manual um but uh yeah these are techniques in general that will always help you um have better results in rack okay so there you go awesome so now that we have our our notes complete we have selected which uh metadata is going to be sent to the embedding and to the language model and we have also augmented that metadata uh we're going to be able to actually create a an index for them okay and in case you're not you don't remember an index is essentially a um set of all of your notes that are going to make it more easy to retrieve and in rag what we usually do is that is this index is a semantic index which means that it comes from a Vector database and in this case we're going to be using two different types of indexes the first one is just going to we're going to be embedding our documents and we're going to be putting them into a simple list uh without a vector database and then we're going to be using a d a vector database okay um but first of all we're going to have to select an an embedding model I usually use open AI because it's cheap and I mean it's affordable and pretty fast and the API works great but if you want to use a free one you can always use uh something from hug and face for example and that's what I'm going to do right now so I'm going to say that from L index embeddings hugging phase I think if I remember correctly I installed it uh up here probably I should move this uh cell down here uh to be clear that this is the one that this is the one that I'm using right here so I'm going to put it here and um I'm going to be us using this one right here just a small embeding model that should be able to work so in order to do this we do L index. embeddings hogging face and from there we import uh hugging face embedding and um here you just name uh whichever you want to use from hugging phase um and then right here I'm just testing it so I'm essentially going to be running get text embedding for just a very quick hello World um just to show you that this is what is actually returned so it's probably going to take a little bit of time because it has to actually download the embeddings model and run it within my uh computer but uh once that is finished it should be able to there you go now it has actually printed the embeddings for um hello world and these are the this is essentially the multi-dimensional vector that represents the the sentence hello world so there you go uh what we're going to be doing is we're going to be passing this one right here to our simple Vector store index uh to actually generate an index okay so we just run this part right here so from L index score we import Vector store index and we pass in our notes of course these are the notes that we just previously run through several Transformations and we augmented the metadata and this is the index that we're going to be able to query afterwards okay so uh in order to query it I'm going to just wait for this to actually finish the embeddings because it's probably going to take a little bit of time uh when I'm running a hog on hogging phase it's a little bit slower but um there you go that one now that this is finished we can actually start actually quering this uh index and in order to do this I'm going to be using another language model uh previously I showed you I was using uh I think it was qan uh but in this case I'm going to be using a more powerful language model to actually uh synthetize the answers I probably don't want a very small model doing that so I'm going to use a bigger one in this case I which one did I choose LMA 3.3 70b uh so it is this one right here and I have a developer account on on Gro so I have higher uh limits right here but uh feel free to use the one I mean you can use the free tier as well right um and this one right here is also very very affordable so very convenient um so there we go I'm going to initialize it as llm quering uh from Grog which I imported before and the API ke is going to be the same one that I used before and pretty much every index uh element in L index has this a method called s query engine and it takes the language model that you're going to be using for it and it essentially just converts it into a query engine that you can just pass any um string and it will return an answer to it U by adding the context that you previously loaded to your vector database right so um so my response is going to be what does this I mean my question is going to be what does this model do when you do query and and there you can see that the model known as health GPT is a medical large Vision language model Etc works pretty good and now you already have a query engine that you can use on top of pretty much any document you want okay and uh you have also augmented the metadata to make sure that the retrieval is much better than it would be you had if you had just um extracted the contents um like that and something else is that we can check the uh the full um uh the full schema of the response because it's not just this text right here actually the response contains much more information so it has the response yes but it also has the source nodes where this data came from in this particular case it has uh it came from we can actually take a look at this so we're going to do up like this we're going to take we're going to see which are the notes that it took them from so we're going to check this uh it took them from this two and it says that from page one and from page six and um as you can see it also retrieved part of the questions and answers that we had because we am them as well okay so very convenient and that is of course not the only piece of information that comes within this within this uh within the response object we have a lot of things um actually going to not use pretty print for this um we have the file name the file path the file size Etc I mean in case you want that that'll have the document title so you can see I mean even though all of this metadata was not sent to the language model or to the edics model you are actually retrieving it um so that is quite convenient uh so there you go that is how this works now what you can do is you can and now that you have an index you probably do not want to re-embed every single time all of your notes every single time that you're going to be running this because now if I turn this off and I reload I mean I restart the this U this notebook uh it's going to try to re-embed everything again and I probably do not want that I probably want my index to remain uh uh persistent in my machine so I don't have to spend time and money uh regenerating the embeddings and the vectors so in order to do that all I have to do is to um store this in a persistent store uh so let's see how to do that all right so uh what we're going to be doing now is we're going to be doing pretty much the same thing that we did before but uh instead of doing it with just simple key value pairs of your embeddings uh for your vectors we're going to be doing the same thing but with an actual Vector database because this is what you would probably do in a real world scenario uh so in order to do this we're going to be installing chrom ADB it's an open- Source uh Vector database very useful and very easy to use and of course we're going to be using the uh integration with L index I'm going to be uh running this installers right here so pip install chroma DB and pip install L index Vector stores chroma and uh once's that once that's done I'm actually going to be just initializing it from the same notes that I have already uh generated right remember that I had uh in the in the previous part of this this lesson I have already created the nodes I have expanded them using several Transformations uh in order to improve the rag system and in this case we're going to be doing the same thing but with um uh we're going to be using those same notes but adding them to the vector database instead of just to a simple uh key value per store like this one right here uh so in order to do that we're going to first initialize chrom ad db. persistent client now for your information this is actually um is not related to L index you're using directly the chrom ADB client from chroma which is kind of a a quick difference from how for example Lang chain does it Lang chain uh does not require you to touch the prev the foreign uh I mean the third party uh client right here uh you can they of course do that in langing too but in L index that is how they do it by default so you initialize your chrom ADB uh you set a persistent client in this case they I called it chrom ADB like this we create a collection of course uh so we do get or create collection I'm going to call it um Health GPT like this and uh then I'm going to assign chroma as the vector store to the context so I'm going to say that Vector store chroma Vector store um Vector store is going to be be equal to chrona Vector store and the collection is going to be taking this one right here which is the uh actual collection object returned from the chroma client okay so this one right here is where the native chroma client um comes in contact with the third party integration of uh LMA index okay um then we're just going to initialize our storage context so storage context from default just like before but remember that above here uh when we did this let me just show you when we created the index right here um where was it um uh storage context from default we just loaded the persistent directory like that and in this case we're loading the vector store like that okay so quick uh difference right here uh uh but um since this one is already linked to this persistent path you don't have to pass in the persistent path right here okay and there you go and then you just uh initialize your index Vector store index you pass in your storage context and your noes which are the ones that I had previously identified and then I'm just going to initialize the query engine because index um always takes as engine always has this as engine method which which returns um query engine that you can just query uh so I'm just going to execute this probably going to take a little bit um have an error right here um oh yeah probably going to have to add the the hugging face embedding model like that so there we go uh probably going to take a little bit of time because it's going to have to re-embed everything uh using my local em settings from huging face and then I'm going to be able to just initialize my query engine um for reference you can also do this uh with documents so in this case I'm running I'm running it directly on the notes if you want it uh to run directly on the documents that you get from just your simple directory reader you can use Vector store index like this and instead of just calling it like that you can just do from document and you're pass in the documents right here and if you want to do the Transformations like we did before you can just pass them right here um uh on the spot with the Transformations parameters right here and here you can do what we did before like uh your splitter your Tex your title extractor your Q&A extractor Etc okay uh but that is just in case you want to uh load the documents directly and uh now I can just uh query this one again using the vector database this time and this model specifically Health you ptl1 14 excels at Medical visual answering tasks um achieving optimal or near optimal results across all subtasks with an average score of 74 okay so there you go now my answers are being retrieved from my chrom ADB uh Vector store which I have right here and it's also persistent so I can just turn off this uh notebook or this server or restart the application if I'm running this in in a back end and uh just load the Chrome Vector store that I have in a persistent um volume and uh just be able to run it directly so there you go that is essentially how you do a little bit more advanced implementations of um rag using L index and also do keep in mind that the things that I just showed you are not specific to L index or to any uh pretty much any uh llm framework that you may find um the more uh useful thing that I showed you right now are essentially the Transformations that we uh did essentially the metadata augmentation and uh choosing which metadata is actually being sent to your language model and to your embedding model and those are things that you can can absolutely do in any uh framework uh be it be it l be it Lang graph be it Lang chain and um the idea right here is that these are just general techniques that help you improve the quality of your rag pipeline uh for any application you're developing um Lama index does make it uh quite easy because they have these modules already pre-built but uh the idea right here is that you have this um possibil this techniques uh that you can Implement in pretty much any any uh application you have so I hope this was useful for you let me know if you have any questions and uh yeah remember if you want to learn more about this I host a cohort um where we uh go over all of these topics uh from zero to to expert AI engineer um it's a 12we cohort and I'm there to answer all your questions and to be sure that everything is clear so there you go thank you very much for watching and I'll see you next time [Music] [Music]
uLrReyH5cu0,2024-11-12T10:07:00.000000,Multimodal RAG: Chat with PDFs (Images & Tables) [2025],"good morning everyone how's it going today welcome back to the channel and welcome to this new video in today's video I want to show you how to chat with a PDF and take into account the images the tables the plots and everything else that can be in your in your document for the generation of the response okay and we're going to be doing that and that's going to be looking something like this so in essence you're going to be querying your your pipeline so here I have an sample with the attention is all un need paper from Google and I qued what do the authors mean by attention Okay and as you can see that the retrieved part of the document was this part right here attention and you can see that we also have the images that will retrieved and this is everything that is going to be sent to the language model including the images so that the language model can give us a response uh based on the this okay um so yeah everything everything in here is going to go into the language model as a context and it's going to give us an answer and in order to do this we're going to be explaining the whole process with this very nice diagram that you see right here we're going to be using unstructured or parsing our document into images tables and text and we're of course going to be using a language model that has multimodal input okay uh that is to say a language model with vision uh in this case we're going to be using GPT 40 mini uh in order to interpret the images the tables and the text and as you can see we're going to be uh creating this very sophisticated multi Vector store uh using uh L chain very cool very convenient and it's actually easier than you may think um so we're going to be going through the entire process of this notebook and uh the notebook of course is available in the description and uh if you have any questions don't hesitate to ask me and if you don't understand um what rack is because you probably want to know how to do rag or retrieval augmented generation without the images only with text you should probably watch that video first and that is also in the description of this video um and then take a look at multimodel Rack okay so there you go without any further Ado let's get right into the video [Music] all right so let's uh explain a little bit about what we're going to be uh what method we're going to be introducing right here as I mentioned before this is not the only method and I am only going to be explaining to you in this uh particular video the process we're going to be covering the code for how to do this in the next lesson for now let's just cover the process that's going that's uh the one that uh that's going to be going on in this spip plane um and the process is actually um very well represented in this diagram right here um we're going to be using this library right here that you can see right here it is unstructured unstructured is an open source library that allows you to extract uh structured data from your unstructured documents in other words it allows you to take your unstructured and semi-structured data that can be coming from PDF files HTML files like your websites uh it can come from a CSV file for example from an Excel file um uh basically pretty much any uh kind of any format of a file that you that you can think of um as long as it is uh unstructured or semi-structured and it will split it into different components so you you will have your PDF document you will pass through the unstructured um the unstructured uh library that we're going to be using and we're going to get uh one array with all of the images from from your entire document another array with all of your tables from your entire document and another array with all of the text of your entire document and this is going to be very convenient because this will allow us to treat those types of um elements differently and to embed them them and to load them to our database differently depending on what they actually are and what they need uh to be loaded and what transformation we need to do in order to use them in our rag pipeline okay um so that's the first step the extraction uh once you have extracted this that is probably the most uh difficult thing to do and the most magical one because I'm structured is just so amazing for this uh we're going to be uh we're going to be loading this to we're going to be using a language model in order to summarize them okay so we're going to attach a summary to every single element that we have right here uh what I did in this particular example is I used a regular uh language model for the tables and the text so I converted I mean of course the text and the tables are regular text representation actually unstructured allows you to extract the HTML representation of a table that is within your PDF so um you will send what what we're going to be doing is we're going to be sending the HTML representation of all of our tables to a very quick language model in this case I'm going to be using language models from Gro I think I was using liap uh 3.1 and create a summary for the table and then we're going to do the same thing for every uh long piece of text we're going to be creating a summary for that piece of text that is going to allow us to embed the summary instead of embedding the entire text this is going to help us with retrieval usually that's a good technique uh because it allows you to to focus on the keywords that are actually relevant to the text that you're going to be embedding and for the image we're going to do the same thing we're going to also summarize or more than summarize describe the image that we're going to be covering and in order to do that we're going to use a language model that has multimodel capabilities in the case of this example I was using GPT 40 mini okay but feel free to use any language model that has uh multimodal input you can use for example Gemini 3 uh sorry Gemini 1.5 from Google you can use um Lava for example if you want an open source model um but yeah just to be clear up until this part right here we have already extracted all of the images all of the T all of the texts and we have also tagged them with a summary and it is the summary the one that we're going to embed using the embeddings model okay so that is the next step once you have extracted every single thing we're going to uh tie them together the summary and the original element using a doc ID okay this is going to be just a string with a with a Unicode uh very not a unic code but a a very specific ID that is going to link the original document to its summary okay so we're going to have all of our summaries linked um we're going to create documents from the summaries and in the metadata of each one of our documents we're going to put the ID and the same thing we're going to create an element right here and we're going to tag them uh the metadata of each one of these elements is going to have the dock the same dock ID pass their summary and then these summaries are the ones that are going to go into our Vector store and uh this right here is pretty much the same thing that we have been doing so far we're going to be vectorizing them using a text embeddings model then we're going to load it into a vector database in this case if I remember correctly I was using chrom ADB and uh the documents actually they're not going to go into the vector store because we are not going to be embedding them as I told you before that could be a possibility and that is actually one way of doing this if you want you could embed the whole thing using a multimodel embeddings model but in our case we're not using a multimodel embeddings model we're only using a text embeddings model and we're only going to uh vectorize the summaries okay so we're going to put the summaries into a vector database and the documents we're going to load them to a different database we're going to call it our documents tour okay but remember that even if they are in two different databases they are still linked by this doc ID metadata that we have assigned to them okay and this is very relevant because now retrieval becomes much more um becomes possible because now you can query your vector database like you would query a regular rack Pipeline and then the vector database will return to you the most relevant documents for your query so for example let's say that you're embedding uh let's say that you're loading a document uh for example you're loading the the document um the research paper attention is whole unit from um from Google right and um you're querying something like what is multi-ad attention so you're going to get the you're that is going to retrieve the summaries of the documents that talk about multi-ad attention okay so that's the the retrieve documents but in this case remember that our Vector database only contains the summaries not the documents themselves that is very important because we have the doc ID metadata assigned to them and this doc ID is the one that we're going to use to fetch from the vector store the documents that are actually um that we're actually looking for so then we're going to fetch those documents and since those documents uh remember that could be images tables and text we could actually uh get from the retrieve documents not only text but also images tables and texts so that is essentially uh what we're going to be doing and how multimodel retrieval Works in this particular uh way of doing this so we have our uh yeah I mean so just by the end as you can see we have a very simple retrieval pipeline in which we just ask a question send a query in text and as a return we get documents that can be images tables uh whatever we want whatever we loaded to our Vector store and whatever we were able to tag with a summary okay um and then we use that to generate an answer if we get images as context then we're probably going to have to use a language model that has multimodel input uh capabilities if you want to use the images as context which I suppose that that is what we want to do so yeah that is the whole process that we're going to be building in the next lesson we're going to be showing the code about how all of this works all right so let's actually start with the code right now and uh the first thing that I want you to do is to install the packages that we're going to need um in order to run the dependencies Okay so so it depends on what uh OS you're running uh but you're going to need popler TCT and lip magic here are just the quick instructions to do this to install them for Mac or Linux if you were using Windows there's also like U the instructions to to build this I'm probably going to to post them um under this video but uh yeah just get that installed I already have it installed but uh you can do that the next thing to do is to install the dependencies that we're going to need and and the ones that we're going to need in this case is unstructured uh oh by the way this notebook is of course available uh like in this lesson you can go uh right under this video there is the link to open it and um and uh yeah you will have access to the entire thing that the entire code that is right here so that you can run it on your on your end and implement it to your own pipeline um so as as I was telling you we are going to be installing onru shirt while we're going to be installing pillow lxml lxml um I installed pillow twice because why not uh well in my case I'm going to be using Chrome ADB uh we're going to need to have t token installed for the tokening tokenization uh we're going to be using Lang chain we're going to be using Lang chain Community Lang chain open AI because I'm going to be using the as my vision model where I'm going to be using uh GPT 40 uh mini fire remember correctly and for the just text based language models I'm going to be using uh L 3 if I'm not mistaken and uh just python. tnv for my um for my uh library for my environment variables and um if you're if you're um if you have any questions about it so I'm going to be of course initializing a Gro API key to use my uh open source llm models from The Croc API the open AI API key of course which you can get from the platform uh dashboard and then I also initialized a lang chain API tracing and the Lang chain API and Lang chain API key which are the API keys that we're going to use for lsmith now because I want to be able to trace what's going on behind the scenes in this Pipeline and uh once that is run I'm actually going to run it like this um you know I'm actually going to restart the kernel because I realized that uh the whole thing I had already run it so I'm on uh run 101 right now so just to make sure that we're all working with a similar environment now I'm going to rerun the whole thing uh so once you have installed everything the first thing that we're going to do is we're going to partition our PDF okay now in our case uh we're going to be dealing with with uh the attention is all un need PDF which we have right here and uh this is just an example of course um feel free to use any PDF you want but um I figured that this was a good example because even if it's a bit um a bit short it's just 15 pages it has some images it has a lot of text it has some equations as well if I remember correctly and uh yeah I mean it's just a multimodel uh document that is actually like more similar to the PDFs that you would see in real life here we have a table as well we're going to see how uh unstructured and how our pipeline extracts it but um this is the file that we're going to be loading uh so the first thing that we're going to do is we're going to partition it and in order to partition it we're going to be using unstructured Okay so let's get into how we're going to be using unstructured and what each um parameter right here does and before I forget to mention this uh this video is actually a lesson from the AI engineering cohort that I host H where I teach you how to go from beginner to this level of creating multimodel rack applications and from this level also all the way to creating uh multi-agent systems okay and this is a program that not only includes uh pre-recorded material with all of the content but also includes my personal help if you if you get stuck or something I can be there to solve your questions there are live sessions it is a cohort course which means that you will be uh interacting with me live so be sure to join that if you're interested in that and joining the community it is pretty fun and I can't wait to meet you there if you're interested just let me know if you have any questions about that too okay so on with the video okay so what do I have right here I have this um this function right here I mean I'm this call I'm calling this method from unstructured uh remember that we have already installed unstructured and I actually installed support for all kinds of documents uh in this case I'm only going to be using PDF so I could have technically just R just install the PDF um uh packages but I I mean if you you're going to want to install all dogs if you're going to be parsing a lot of different formats and in this case I'm going to be using the Partition p F uh method from unstructured now something that I uh might um it might be important to mention is that right here I am not using the loader from Lang chain okay Lang chain actually has a loader for unstructured and it works pretty well uh you can use it both locally and also with the serverless API but I wanted to show you a little bit more of the flexibility that you have with unstructured uh so that we can can see actually how all of these parameters work with the unstructured API uh so that you can actually feel and see what's actually going on under the hood when you're using unstructured so the partition PDF uh method and pretty much any partitioning method um from unstructured basically takes the file path to the file that you want to partition and it Returns the partitioned elements okay that's the only mandatory uh parameter that you're going to pass but here are other arguments that are available and let's take a look at them okay um so first of all we have the strategy which can be highr or it can be normal and uh in this case we're going to be choosing highr because we're setting this um this um this parameter to True infer table structure and this parameter essentially just means if you want to extract tables from your document or not and if you want to to extract tables from your document you're going to have to set it to true and if you want to extract tables then the high resolution strategy is mandatory you're going to have to choose this one if you want to extract tables okay so that's the first thing and in our case we are going to want to extract table so we're going to choose this settings right here now uh something else is that you're going to want to choose the the kind of images that you want to extract okay so in this case I have actually yeah I don't have it here so that's good uh I have this right here and um in this particular case uh what I have seen in previous examples of this tutorial because I am basing this on a cookbook from langing is they were using this parameter right here which is extract images in PDF and I said it to true however that parameter is actually deprecated or in uh on the way of being deprecated so you don't need to add it anymore I just added it it here for context because you're probably going to find it uh in the wild or in other tutorials if you don't uh mean if you're um so you don't get like um uh confused about it um so the new way of doing this I mean the updated way of doing this is with this parameter right here which is extract image block type and right here you're going to set it to image if you want uh to extract the images from your PDF if you want to extract the tables to for example you're going to tap table two like this now in our case we only want to extract the images this is not necessarily not going this is not necessarily not going to extract the tables it's just not going to extract the tables as images okay it's still going to extract the tables as I'm going to show you you in a minute and uh if you want to extract the images to an actual folder to an actual directory in your computer you can enable this and you can pass in an output path to get the to save the images to okay that's also a possibility in my case I'm not going to enable it just going to set it like this because I don't want to have the images uh from my PDF downloaded to my computer just want to have them in the partitioned uh element but uh feel free to enable this and play around with it and you will see that this will create a new folder right here with all your images okay um next thing that we have right here is extract image block uh to payload and this essentially means that we are going to be extracting the images and the image is going to be uh is going to have a metadata uh element that is going to contain the base 64 object of the image okay so if you set this to false you're not going to be extracting the Bas 64 um representation of your image which would be terrible because you're going to need the B 64 representation of your images if you want to send them to your language model because if you want to send an image to your language model you're going to have to send it uh to the API using a base 64 representation so this is the way to do it then this part right here is actually very interesting and um actually I'm going to show you how this works without it first um because it's it's super powerful and super cool but let me just show you how this works without it so without it I'm going to run this and um I mean it's going to start running it's probably going to take a a few seconds but um what is going to happen right now is that it is going to extract every single element from my PDF so it's going to return the table it's going to return this paragraph this other paragraph This title right here this other table and it's going to return everything just at once all the elements of my of my entire document are going to be returned into a single array and that's okay that's that could be what you want to do but um the unstructured uh service actually allows you to do something super cool which is to chunk it to to similar um um yeah to chunk it by at by by a strategy that you can choose okay you have by title or basic and this essentially means chunking usually you're you might be used to thinking of it but that it means making things smaller but actually in this case in their case when they when you implement a chunking strategy in unstructured it means you're putting elements together so right now without the chunkin strategy we're going to see that we if we see what kind of documents were returned to us you can see that we have title documents we have narrative documents we have footer documents image documents Etc so all of this are actually um the ones that are are available to us okay um yeah sorry this one's right here and um that's great that's that's great we have all the documents in a single in a single in a single array but you probably don't want that actually let me just show you uh what this looks like so if I do length of chunks you're going to see that we have 218 uh different elements inside the document so it split the entire PDF document into 218 uh different uh elements so we have this one might be one this one might be another one this title might be another one the table might be another one so you don't really want that what you want is to have them together uh to have the elements together that are um related to each other and that's where the chunking strategy comes into play I will let you play around with this to see what it actually does but uh if we enable chunking going to rerun this but with chunking this time I'm going to set the chunking strategy to by title a maximum um size of the chunk to 10,000 characters uh we're going to combine text character we're going to combine different elements um when they are under 2,000 characters and we're going to start a new uh part of the of the document after 6,000 characters if you can take a look at the documentation if you want to um delve into this a little bit more deeply but what this is essentially doing is that it is taking the elements from the 218 elements that we have in the document it's putting together those that are related inside the document and if you choose by title then it's probably going to go right here to our document and it's going to be like okay so this is one title so all of the documents inside this title are going to be assigned to a single chunk that's how they call it and then all of the elements assigned to this other title are going to be under a sing a single chunk as well and this is actually super useful for rag because if you're dealing with a like this one you're going to have um a single I mean a title A titled chapter talk about one single topic one single uh like it's going to have uh cohesive uh meaning and that's going to be super useful for rag So you you're going to be able to embed an entire chunk that is related um it's basically extracting chapter by chapter of the document so that's pretty useful uh it actually finished uh exporting it and you will see that in this case we don't have 218 uh documents anymore we only have 17 and uh the same way we don't have all of the different types we only have this two types which is composite element and table okay and composite element actually let me just show you what it looks like um going to go right here um going to go right here and um let's say so from chunks I'm going to see the first one let's see so the first one is a composite element I'm going to say to dictionary and you you can see right here the the elements of this uh composite element you can see that it's type of composite it has an ID it has some text it has some metadata it says which page number it is it comes from Etc which is very cool but uh interestingly it has this um this property inside of its metadata and that property right there let me show you um actually yeah metadata and I'm going to use this property right here which is original documents and that one right there a b show you not like that that that one right there actually contains all of the documents that are related or Associated to this particular chunk okay so remember that we had 218 documents um or elements inside the entire uh PDF so for 15 pages unstructured extracted 215 or 17 uh elements and then it Associated them together using a by tile chunking strategy and the 17 chunks that it returned to us are actually sets of these components right here and since we used the by tile um technique these are supposed to be one after another under the same section of the PDF I'm going to show you how this looks like in the actual PDF in just a moment but just I mean start figuring start visualizing it um actually just going to show you right now like how it how it looks um where do we have this I think it is here uh was just running some text tests but here as you can see here is one chunk um I'm going to be displaying one chunk and as you can see this chunk right here has uh it starts at this title called attention and it goes all the way up to here so as you can see it is kind of um uh a chapter in the in the document and it's it contains one two 3 4 5 6 7 8 9 10 11 12 13 elements inside of this chunk and they are all Associated to the same title that is because we used the chunking strategy okay and that is also the reason why we only have composite element and tables uh that were extracted okay because the composite elements are the ones that contain all of the other elements inside of their metadata and they under the key of original documents okay so so far so good we have successfully extracted our documents I'm going to erase this one because I had already shown you shown it to you right here but as you can see inside of the metadata um inside of the metadata uh original elements key we have a title narrative text a footer some a couple of images for this one in particular we have images uh the title Etc okay and uh let me show you how the images look like in inside of an unstructured uh document so in this in this um in this cell right here what I'm doing is essentially just extracting only the chunks I mean only the elements that have and that are of Type image okay so in here I basically listed all of the elements in chunk three um here we have a title a narrative Etc so what I'm doing right here is I'm just extracting those elements that have images uh so I'm taking all of the chunk all of the elements from from the chunk three and then I am extracting the images from that chunk um and I'm just selecting the first one and converting it to a dictionary and here you can see the representation of an image that was extracted by unstructured so you can see that it has a type of image it has some text because it is able to extract the text inside within the image it has the coordinates within the document itself this is going to be very useful um afterwards if you want to highlight where in the document this particular element is located and then very importantly right here we have the image base 64 representation and as you can see it's super long um but that's exactly what we want and we are only getting this because remember we set this parameter to True extract image block to payload to true and that is the only reason why we are getting this um this key right here okay and it is of course very important because this is the one that we're going to be sending to our multimodel language model okay so so far so good we have successfully extracted the elements and we can actually now split them uh so by the end of this splitting technique we're going to essentially have three different arrays one of tables one of texts and one of images just like we had in the diagram that we showed before so for Chunk in chunks like so for the 17 chunks that we extracted we're going to append the thing the element into um into table if it's a table and we're going to append it to texts if it's part of the composite element now this is technically a shortcut because remember that inside composite element there is also images but we're going to treat the images differently I mean of course you can improve on this spy plan if you want and actually pars the images within the composite element as well you feel free to do that but in this case I'm just going to be extracting the images and the composite elements and treating them um as these two different elements okay and then third I'm going to extract the images and in order to extract the images I'm going to extract them from the composite element right here going to tap into every single composite element if within the composite element I have an image element I'm going to add it to my images array so that way by the end I have these three different arrays one for tables one for texts and one for images and we have successfully completed the partitioning part or the extraction part now what we're going to do is we're going to have to is we're going to have to uh transform it okay and here I just have a very quick uh function that displays any image in base uh 64 so here just very quick function made with Chad GPT but essentially just takes the base 64 code of an image and it displays it um and here you can see that one from the array that we created the first element of the array I'm going to show it and as you can see this is the first image that was extracted from the document uh seems to be working pretty well so now we have this three arrays now it is time to actually go to the next part of this um this exercise which is summarizing the data that we just extracted so we're going to be creating a summary for each image for each table and for each piece of text all right so now it is time to start summarizing the data okay and that's what I'm going to do right here in order to summarize it I'm going to be using uh first of all a model from Gro I'm going to be using L uh 3.1 if I remember correctly and um in order to do that I'm going to be be installing of course Gro I'm going to be using chat Gro importing it from here I import chat PR template and my regular string output procer to create a chain okay now uh the chain to that is going to generate the summaries for my um for my text elements is going to be uh this one right here here an assistant tasked with summarizing the tables Etc just a very simple chain it's going to pass into prompt and model and then the output parer and as you can see I'm initializing LMA 3.1 from chat Grog okay uh so going to run this right here I actually think I forgot to execute this one right here there we go and uh now just show you what texts uh look like because remember that we um split all of our elements into tables texts and images within the retrieved documents uh text itself remember that it is a composite ele I mean it is a collection of composite elements right and um what does that mean remember that I told you that it means that in its metadata there are the original elements and that essentially means uh I have to tap into the first one just to show you that essentially means that all of the elements are within original n elements like this okay but however you can still print it oops you can still print it like this and it's going to show you all the elements of that um of that collection of elements okay of that chunk so here I have my scroll B element um and as you can see here's all the collection of all the text for this first chunk as you can see it's just the title and the abstract that's the first chunk um now what we're going to to do right now is we're going to use that in order to summarize it okay so we're going to pass in every single one of those texts every single one of those composite elements and we're going to summarize them and I'm going to show you what it looks like on Langs Smith a little bit later on if you want but the idea right here is that it is going to take the entire contents of all of the elements within the composite element it's going to batch um execute the summarized chain and that's going to go to summarize and the same thing is going to go to the tables however let me show you something quick about the tables so the tables are the tables basically look like this okay we have four tables in the document and let me show you what it looks like so two dictionary and actually oh I'm going to have to click on the first one right here and you can say this is the first table that we have uh we have the element ID we have some text within it and then it has this very convenient feature I mean very convenient property which is text as HTML and that essentially means that it is the extracted table but in HTML format and this is the only thing that we actually need to send to our language model in order to summarize it right we don't really need uh it original elements because if we try to tap into the original elements for example um let's see um metad dat original elements let's see what it looks like um to dictionary um so look like anything no there's no to dictionary here um it's a take apparently I don't know why I have a b 64 thing right here but um yeah I mean what I wanted to show you is that we have the HTML code inside of here and this is the one that we're going to send to our language model in order to actually get the summary because remember how mean if you have a language model you have to send it text uh you cannot send it just or an image if it's a multimodel but you cannot send it just the text like this it's probably not going to understand the divisions there is no headings or anything right here you want want to send it the actual mark down uh the actual markup language uh so that it can understand where is the header what is the table cell Etc so these are the ones that we're going to be tapping into and that's what's actually going on right here so I say that the tables HTML is actually going to be the property text as HTML of each table in the array tables and um then I batch that too let me just execute this take a few seconds and let me just show you what it looks like have it right here so uh that's where the text summary is as you can see we have one two three bunch of text summaries like a about of composite elements all of these are the composite elements um and here you have every single summary and then we're going to do let's check the same thing for the tables table summaries table summaries and here we have four tables the table Compares four types of neural network layer self attention concurrent Etc and as you can see these are the summaries that I am going to be uh vectorizing and embedding uh and adding to my Vector database and now let's do the same thing for our images and in order to do that we're going to be using open AI of course so first thing to do is to install it there here we go and similarly to the previous examples uh we're going to be also creating a chain that is going to summarize the image but in this case we're not going to be sending a regular um PR a regular uh prompt like we did before but we're going to be loading the message with the image itself and if you have I mean if you you can check the API documentation of whichever llm you're using to see how you you can send um an image to it um in Lang chain it is pretty uniform you just send a user a user message and uh you send whatever you want to send it as text within the type text dictionary and then you create another dictionary within it with Type image URL and then you send it in base uh 64 you know so that it understands that uh image and that's essentially how we're going to be sending that image so as you can see here we have a prompt template that is going to take only one variable which is image and here we have another template that is not taking any variable so that's convenient and um then right here this part right here is going to be the base 64 code of the image that we want to convert and in order to do that we just like initialize our chain in this case we're going to be using GPT 40 Mini because we want a language model that has multimodal input okay and then just batch the summaries let's execute that that actually takes a little bit of time when it is trying to ingest all of those uh images you can see I think we have uh 1 2 3 4 5 six seven images right here so let's see how long it takes take 16 seconds to um to process all those 16 images now let's see the summaries here we have all the summaries let's print the the first uh the third the fourth one there we have it then image appears to illustrate the attention mechanism used in Transformer architecture then we have the key elements words and tokens attention weights highlighted tokens Etc let's actually take a look at that one to see what it actually looks like so what was the name of the function that I had up here that displayed the image display base 64 image so let's use it right here and let's print images number three uh here we have the image number three let's check the number one in the Strat key concept of the Transformer architecture trying to find an easier one to visualize let's see which one was this one it was image zero uh so image zero is of course still this one that we saw before and um if we check the summary of that one we can see that the overall structure is a diagram structured into two many sections we have the encoder and the decoder then some errors and connections okay so this is exactly what uh we want um to embed okay these are the summaries that we're going to be vectorizing and adding to our Vector database um I'm going to remove these two samples right here just to make it easier but there we go so that was creating the summaries of all of our elements and as you can see we already have um the three arrays with um the images the text and the tables and then we have other three arrays with the corresponding summaries for the text the summaries for the tables and the summaries for the images now what we're going to have to do as we saw in the diagram that we saw before we're going to have to link them together using an ID and that's what we're going to be doing right now and then we're going to be loading them to our Vector database and to our document store okay so now it's actually time to start talking about how to load those summaries and the elements that we want to load into our Vector store and to our document store uh and in order to do this is actually very simple we're going to be using this langine abstraction called multi Vector retriever it's actually pretty straightforward and uh what we're going to be doing with this one is what we saw before we're going to be creating an ID for every single document and we're going to add it as metadata to both our summary and to our document and the document is going to go to the vector store which is right here and the sorry the document is going to go to the document store which is right here and the summary is going to go to the vector store and it is the summary which we are going to uh retrieve using semantic uh search semantic similarity and uh once we have retrieved the summary we're going to check the ID of the document that it's in its metadata and go fetch the corresponding document in the document store that has the same ID okay and that's essentially all that we're doing and uh this is what the multiv vector uh retriever does in langing now of course uh you can code this yourself if you want you you're not forced to use multi Vector retriever I just feel like this is a good level of abstraction to start to to stop that uh because I feel like what's going on under the hood is pretty self-explanatory and um this one right here does is very very simply so you just pass it the vector store you pass it the document store and you pass it the ID um that it's going to add to the metadata I mean the key that is going to add to the metadata to connect both of them that's essentially all that we're doing so we're pass we're initializing a chroma Vector store we're initializing then a document store in memory in this case and we're initializing a metadata ID which is going to be document ID like this one right here and uh then we're just loading everything into I mean just creating this abstraction that is going to help us link them together and this retriever is actually going to just return to us the documents that are going to be relevant for this it's not even going to return to us to summaries it's only going to return us to documents so let's execute this right here now we have created this and now we can actually start loading our documents now that we have created it this is actually empty for now okay and now let's actually just load every single thing that we want to load so the first thing that we want to load is the documents and just as I showed you before we have to create some IDs for each one of them uh sorry the first thing that we're going to load is the texts which are the composite elements and um as I told you before well first we're going to have to create an ID for each one of them so this array right here is going to create a u ID D for every single uh element in text and then we're going to append that ID we're going to add that ID to the metadata of every single document that we're going to be generating so this essentially is just a oneliner that creates a document uh a lang chain document for every single composite element that was returned to us from unstructured which is in with which is in the text um variable okay so this is creating the summary texts um documents then we're loading those documents to our our Vector store and then the actual text the actual uh composite um the actual composite element the composite element that we extracted from unstructured is going to go to the document store and this one is the one that is going to be retrieved not the summary the summary is only used for finding it but the one that we're going to actually get from the retriever is this one right here okay uh we're going to do exactly the same thing with tables we're creating a langing document in case you don't remember I imported document from here from Lang chain. schema actually I think this is wrong that is old school I think now it's from Lang chain core documents we import document yeah W this this is all code all right uh let me just fix this from L chain open AI uh we're going to import open embeddings yeah I don't know what this is old code L from line chain core. retrievers we're going to import multi Vector retrie there we go um is this working correctly uh multiv Vector retriever um actually I think this is yeah sorry this is the only one that actually comes from lanch and retrieval mode Vector so there we go and then we're going to add every single thing uh we're going to be doing exactly the same thing for the images just generating an ID for every single image creating a document for every single summary and then just adding the images themselves to the document store and it is the image themselves it itself in Bas 64 which is going to be retrieved okay so it's going to take a few seconds to load everything and now we have everything within our uh retriever our document store which has a assigned a vector store assigned to it and now we can actually start testing it so now if I do what is multi-head attention on this retriever that I have right here remember that my retriever is a multi Vector retriever okay so now I can essentially just execute this and now the chunks are going to are going to be right here actually let's just see there we go so the first chunk is a composite element the second chunk is actually a base 64 thing which has to be an image because that is what we added to our document store here we have another composite element and another composite element so pretty convenient now right here this is some extra code uh you don't necessarily need it this is high code some code that actually was available at um one of Lang Chain's um documentation Pages I'll add a link to that one in the description essentially just renders the page and highlights uh whatever um elements you send to it I just had to update that a little bit but uh let me show you I'm just going to create the function and let me show you what each one of those chunks that we just retrieved has inside of it okay so these are our four chunks okay and remember that for the composite elements and they actually have some more elements within it okay so this first one we're going to tap into this first one is a composite element remember that it has a lot of things within it and uh let's actually just take a look at what it has inside of it so for every single composite element we're going to check first we're going to print the number of it and uh then and we're going to just uh write down what type of element it is and which page it is on okay just to just to see so you can see that the first chunk that it retrieved has a title narrative text and all the way to a list item and you can see that it spans from page four to page five pretty good here we have the chunk number two Let me just run this a scrollable object here we have chunk number two you can see it has a title a narrative text the footer all the way to a narrative text and it actually spans from page two all the way to page four pretty good same for chunk three all right pretty good now let's actually take a look at the first chunk right here um I think I forgot to do something right here chunks. metadata oh yeah because this one right here is actually the image uh let's open the first one all right so the first chunk and the first original element from the chunk is a title just like we saw before it's in page number four there we go it came and actually right here I just coded a couple of quick uh functions I don't want to to to confuse you with this functions essentially all they do is they extract which Pages a given chunk has because remember that a chunk in itself uh contains a bunch of elements right so the first first one contains uh as we saw right here the first one contains the title from page four all the way to a list item in page five uh the chunk number two contains um all the way from the title in page number three to a narrative text in page number four um and here I just coded a very quick two functions that actually display the IM the the picture the pages of whichever um chunks you pass to it so here I'm going to pass the chunk number the first chunk and um wait what uh this one was actually not useful all right so there we go uh the first the the fourth chunk uh contains an introduction background Etc okay so it's only one page this one right here uh let's see let's check the chunk number two it is supposed to span from page number three all the way to page number four so let's check that one right here so which one was it chunk number chunk number two so let's see that one chunk number two so it spans from here from attention all the way to page number four and these are the elements that were retrieved so as you can see this Chunk in itself is pretty self-contained and it contains all of the information that we need uh that is related to this particular topic and that is why it is so useful and so important to use uh chunking uh by title in this kind of documents when you're using unstructured it becomes super easy because everything I mean the entire chunk is interconnected it's not like it's not like it split the text randomly and it sto chunking here and then the next text the next uh chunk starts here it literally is by titled which is very very convenient and it actually has the images here here um now in this particular example I am not extracting the images from the chunks themselves because as you may have noticed so far I am embedding the images separately but you could just extract the images from here and that would work pretty well uh so now that we have that we can actually start uh creating the rack pipeline which uh we have all the element so far we have the retriever that is working um the retriever is multimodel actually let me show you that it is actually multimodel uh where was the function right here that we had that could display images uh this one right here so this um this query retrieved four documents and as you can see the second document is a b a base 64 document so let's take a look at it so we're going to check chunks and we're going to check the second one right here this is going to tap into this element right here okay so let's execute so there we go we have retrieve the image we have retrieved all of the documents themselves and um now we can essentially uh start creating our rack pipeline so let's actually get to do that right so now in order to create our rack pipeline essentially all that we're doing here is we're actually going to be using a couple of helper functions uh first of all we're going to be importing the runnable pass through and runable Lambda uh things we're going to be using and um and remember that this chain right here is supposed to actually give you an answer based on the retrieved documents okay and uh that essentially means that the docu the since the documents that will be retrieved some of them will be images um the chain has to include a language model that has multimodel input uh which is the case with chat with GPT 40 mini right here and that's the model that I am using for this one right here okay so I created a couple of um chains right here the first one is the simpler one and um probably the one that you that you would uh intuitively uh create and uh the idea right here is essentially just a very regular uh rag pipeline like the ones that we have built before okay so the entire chain actually takes just a single um input which is going to be the query from the user and in this case that query is going to be passed through the runable pass through uh ass a question and um for the context we're going to be using the retriever however the retriever we're going to be parsing it um using the function par stocks okay and as you can see right here we have a runnable Lambda and a runnable Lambda is essentially just the same thing as creating a Lambda function um and let me show you what that one does so essentially it just splits our retrieved documents to know whether or not they're and to uh whether or not they are an image okay so it essentially tries to to decode it if it was space 64 and if it cannot do it that means that it is not an image and that it is text so it appends that to my text array and it returns images and texts okay basically this function right here so this one right here will return just the retrieved documents like this okay so that is what the retriever is going to return and an object like this is going to be passed to my parse documents function and that par documents function is going to try to decode every single element in this array and if it can decode it it's going to add that to the images array and if it cannot decode it it's going to be added to the texts array and the texts are going to be added I mean texts within the text one we're going to have the tables and the text okay um those texts are going to be right here and um they images are going to be right here and this is the dictionary that is going to be returned and that is pretty important because our prompt is going to take these two keywords right here which is the ones that are going to be sent to this other runable Lambda that we have right here okay so by the end of this thing right here this one right here is going to get a Contex a dictionary with the key context and question and within the context um key the value is going to be another dictionary with these two keys okay so far so good there we go and this function right here is going to take whatever is within the context and send it to this new prompt that is creating okay so very simple um here we have the context uh text and essentially we're just appending more context text if um the context from our uh retriever uh the element in the context from our retriever is of type texts okay so we're tapping into the documents by type right here and so we're just appending those right here and if it is not text if it is image we're going to be appending this part right here to the message because remember that if you want to send an image to a language model you're going to be adding it like this okay so other than the message which we have right here of type text we're going to have the image Type image URL and then appending the base 64 image right here and um then just creating a human message with this prompt content that we have right here okay that's all we're doing and if there are no images then this is going to be ignore and we're just going to be appending the composite elements inside of the prompt and that's all that we're going to be doing okay so far so good perfect um I mean this can of course be improved I feel like I'm not dealing with a tables correctly like perfectly I feel like I could um I could um um like structure this better to deal with the tables a little bit more neatly but uh this is just a very quick example to show you how this would work uh so this is what the chain would look like after that we just pass everything to the language model model and just string output pause it that's all and then here right here just have a very very quick example of doing exactly the same thing but with retrieving the sources so we're creating a rubble pass through that is going to create remember that if you run assign on a runnable pass through this is all of course by the way in the Lang chain module that we have in the previous part of the course okay so if you're having trouble with the runable pass through um there is uh a video about that in the previous module that we talked where we had um where we were covering Lang chain um and it essentially this thing right here is going to return a three key dictionary context question and response and the response is of course going to be returned uh the response from the language model um so here we have the first example which is chain invoke what do the authors mean by attention and then it gives us the answer but we don't really see what's going on right here so actually let me just execute this so there we go um it's going to take a little bit of time because it is retrieving the images and if if it finds images it's going to retrieve them uh the authors Define attention as mechanism that Maps a query instead of key value pairs Etc okay so here we have the answer um in the next part right here we're going to be start we're going to be checking the lsmith logs of these two qu ques but uh just to show you what's going on right here and um let's try this other one which is essentially actually let's try the same exact question there we go we're going to try the same exact question but this time we're going to execute it with the run with sources sorry chain with sources and this one essentially is going to return a three key um dictionary with response context and and question so what I did right here is I basically just printed the response then I print context actually gone to add another empty line another couple of empty lines right here and then for each text inside of it we're going to just print it and you're going to print the page number as well because um the page number is if you might remember inside of the metadata inside of the page number of the document retrieved because we build the document using the unstructured composite elements that would return to us um and then if it is an image we're going to just display it using this function that we had up there okay so let's execute this again going to take a few seconds and there we go so here we have the response in the context provided attention refers to mechanism used in neural networks Etc so working pretty good good and then for the context right here we have attention and we have it so it essentially fetched uh this part right here so attention tuck tuck tuck and then it fetched a couple of images so let's see let's see if I I mean if it did exactly the same thing it should have returned this chunk so let's see uh it had and it fetched these two images right here all right not bad there we go and it fetched um a Time mention it actually apparently fetched only two text documents uh one from page number three and the other one from page number 10 and I suppose that it actually fetched this one up kind of like by mistake because I mentioned authors what do the authors meant what did the authors meant by this mean by this and um here's just a list of a lot of authors um and then it fetched a couple of images that I'm not sure if it actually helped it answer it but uh you can see how this is going to be useful like if your document if your document contains a bunch of charts for example um this is going to be super useful because in the response you're going to be able to get the image itself and this is something that you can L that you can uh display in the front end of your application right you don't really um you don't necessarily need to just site it uh with a short u um uh with a short reference to the page you can even display the image because it is being returned to you in Bas 64 right and um and you can even use the image within the answer as well if you allow the language model to to print the B 64 uh elements that it is returning so that is very convenient and I can't wait to see how you um build your own workflows for this kind of uh implementation and yeah I mean essentially this is going to make you this going to allow you to work with more real life um more real life scenarios where you have more realistic PDFs with images tables graphs plots equations Etc and it's going to be able to parse them so this is a rudimentary explanation I mean there's of course a lot to go uh deeper into but uh I hope that it was clear here and of course there are like multiple ways to improve on this particular uh code that we have right here but I feel like it'll give you a very good starting point so that you can start experimenting with it and creating your own workflows all right so there you go that was how to create a multimodel rack um Pipeline and I hope that you learned a lot from it now let's actually start putting this into action so the next part that we're going to be doing is going to be implementing this thing right here into a front end uh we can use stream lead for that right so let's do that um afterwards [Music] [Music]"
2Qr0yUGGpCE,2024-11-04T06:07:00.000000,LlamaIndex: How to Get Structured Data from LLMs,hey everyone how's it going today's video very quick about how to get structured output out of your language model in Lama index okay now the idea behind this is that usually when you have your language model and you query it you're going to get just text from it okay now what happens if instead of getting text you want to get something like a Json file with very specific keys and value um formats that you want from that Json file okay your average language model is not going to be able to accurately get that just by prompting it okay so the idea that we have right here is that we're going to be initializing a schema using pantic adding it to our language model using Lama index and this is the language model that we're going to query and every time we're going to get a response with the schema that we have determined okay so let's take a look at how to do that [Music] okay so the first thing to do as I mentioned before is to create the schema of the data that we want to get in our case we're going to be using pantic in order to uh initialize our schema in case you're not familiar with it pantic is essentially just a library uh for python for high for data validation and essentially what it allows you to do is to create classes which are going to become the schemas of your data and you're going to be able to validate your data using these schemas okay um in this case I'm going to be asking my language model to create an album and an album is going to contain a name the name is always going to be a string an artist which is always going to be a string and a list of songs and each song is also going to have its own schema and it it's going to have a title and a length in seconds and the length in seconds is in integers okay now for the record this example comes straight from the documentation of L index um but let's actually take a look at this so I'm going to execute this and right here I'm going to go from L index core import a chat message and here as you can see I had previously initialized my language model let me just show you before because I was doing another tutorial before this one um so here I have initialized my language model from open AI okay so in this case I'm going to be using open ey for this I am using GPT 40 mini and this language model is the same one that I'm using right here however this is not the instance that I'm going to be quering like that I am actually going to going to be running as structured llm method on it and I'm going to Define this parameter right here output CLS as the uh output schema that I want my language model to return on every single location okay and in this case I am passing it the album schema that I created right here which contains a reference to the song schema as well okay and this I am going to be assigning it to a variable called s llm for structured llm and now anytime I am going to query this this language model right here I am going to get the response in the exact schema that I specialized right here so let's see I'm going to initialize a chat model um sorry a chat message from this string right here generate an example album for the film uh for the film uh who frame Roger Rabbit and let's see what it returns to us I am going to call the slm using the chat method and let's see now here we have the response and as you can see here the chat message is from the assistant and the content is not just the string of text it is actually the object that I want to get so here you have the name of the album is Who Framed Roger Rabbit the soundtrack um Roger Rabbit soundtrack sorry the artist is going to be various artists and then we have a list of songs okay so let's take a look at it under the microscope and here I'm for the record using pretty print I imported It Up Above in the dictionary in the notebook but essentially I'm using pretty print to print these objects more neatly but as you can see we have the artist right here various artists the name is who frame Roger Rabbit and the songs which are all of them I mean each one of them an element an instance of song which each one has a title and a length in seconds so there you go I mean as you can see this follows exactly the same um the same schema that we defined above right here so there we go that is how to use on how to use structured outputs in language models using L index let me know if you have any questions and let's continue with this course [Music]
M6fdbgOGFHc,2024-10-29T20:03:00.000000,LlamaIndex: How to use LLMs,good morning everyone how's it going welcome back to the channel and today's video I want to show you just a very quick continuation of the previous uh video and this continuation in the Lama index series uh the idea is that I'm going to be showing you how to use language model Integrations with Lama index essentially how to call any language model you want with from Lama index and how to use it okay now we're going to be seeing the common interface that you can use to call language models and what the different responses from different interfaces look like uh in this case I'm going to be using Gro and open to Showcase all of the examples openi of course is the most popular LM provider and Gro because I want to give you an option to do this for free and Gro is of course free to use if you have a if you're using it for personal projects Etc so yeah that's what we're going to be working with right now okay so let's get right into the video [Music] all right so just to give you an overview of the whole thing that what we're going to be doing uh the first thing that you want to do is to set up your environment now I am going to be using a cond environment to do this so I'm going to activate my cond environment doing cond activate and um I have already created this environment called L index course so once that is activated I'm going to be able to um use it to install my dependencies actually I think I also have to install to activate it here so um let's see so L index course there we go and now let's actually start uh running this thing uh the first thing that I want to do is I want to install my dependencies so as you can see right here let me just close this right here um uh the first thing that I want to do is to install index Lama index Integrations as well so we're going to be showcasing this with open Ai and Gro okay now open AI of course because it is the most famous and most commonly used llm providers but we are going to be using Gro as well because I want to give you the option to do this for free and of course gr has a wonderful um offer for uh your personal projects where you can use the open source models from their service uh for free so so there you go we're going to run this like this and it's probably going to take a little bit of time that actually didn't take so much because I had already installed it um after that I'm just going to load my API Keys uh in this case I have added them to a do TMV file but if you don't have them in a do tnv file you're going to be able to load them like this just type if open I key not I mean of course by the way all of this is available in the notebook in the description but um yeah you're going to do if there is no open AI key in my environment variables I'm going to initialize it uh same thing for Gro and just for the record I am using L index 011120 there we go now of course this all already set up I'm just going to initialize pretty print just for uh debugging and printing very neatly the things that we're going to be printing right now and let's actually start um initializing our language models and calling them with the different uh methods that we have in the common interface okay so let's do that now awesome so the next thing to do is we're going to want to import our language model okay remember that we already have set up our API keys if you have not set up your API keys this is not going to work um so from lame index I'm going to import from the llms module I'm going to import I'm going to tap into the gro module remember that we had to install this dependency separately from lamain so you have to install each dependency each third party um uh integration that you want to use you'll have to install it separately uh from here I'm going to import groc and uh right here I'm going to just initialize it like this llm equals an instance of my Gro client and I'm going to say which model I want to use with it okay in case you're not familiar with Gro uh it's a service that allows you to serve this uh this language models for free uh at least at a personal level they do have some rate limits if you want to do this more professionally in which case you would be able to get a professional uh plan they're super fast super good and they allow you to serve this super good uh open source model such as in this case we're using lameth 3 um so I'm just going to execute this and now I will have my client for Gro right here inside the variable LM okay and the first thing that I want you to see is um how to use the complete method okay now complete method is part of this common interface that comes with pretty much any language model that you're going to be able to use in Lama index and something particular about this method is that it is a text to text method okay so you can see right here text to text that's what it means essentially it means that when you're going to call your language model you're going to be sending a string of text as input and you can expect to get a string of text as output okay essentially that's all that this method is doing right here now this is um rather um different to most ways that we usually call language models because it's a way that was most used mostly used before we had a switch towards message based apis uh before we had more often than not a the apis from these language models were in the sense that you would send them a piece of text and then you would get the completion in return now the apis are mostly organized in a sense that you send them a list of messages and then you get the response from the assistant as another message um so just a change in the interface but um this adapts to some other circumstances like if you wanted to I don't know just summarize something or something more quickly that is text to text based this is the method that you want to use and as you can see the type of response that you get from this is completion response which is different to the kind of response that you would get from the other method which is chat method which we're going to see in just a moment but just to show you the P the microscope the real like the complete object of the response that we got here it is I'm just converting it into a dictionary and printing it and as you can see right here um we have the text so here is the text that was printed when I printed the whole thing H here we have the raw object which is the chat completion but I mean we'll see that a little bit later um and um yeah essentially this is all that we're getting now let's take a look at the chat completion I mean that the chat Method All right so now let's take a look at the chat method and how is it different to the uh complete method that we just saw a moment ago as you can see here what I'm doing is calling the llm but instead of using do complete I am using chat and that essentially means that instead of taking a string of text as an input it is going to take a list of messages as input and it is going to return to me a message okay this is going to allow me to have more conversational applications and actually this is the way that most applications work nowadays um in the past a couple years ago U most of the apis were textto text centered in nowadays pretty much all of the apis that expose language models are message-based apis so this is essentially how most apis are going to work and how most of the logic of your application is going to work it also uh is better because it allows you to add a system message okay in case you're not familiar with it the system message is essentially just the first message that you give your entire assistant to give it a personality or give it instructions about how it is supposed to to uh react and respond to the user's queries uh in this case my very simple system uh message is you are Sherlock Holmes so just giving it a very quick personality and uh here I have another message by a user Who Framed Roger Rabbit because why not then we have um the assistant this is the assistant now responding I am not sure but I can help you find out tell me J okay so this probably not let's just erase this and let's just send this like this okay and let's see what it returns as you can see the assistant says any string in case my dear fellow curious Affair Roger Rabbit Etc so it's probably going to help me figure out who shame Who Framed Roger Rabbit and as you can see uh this right here is actually a message in the response it is not just text we're going to see it under the microscope in a little bit but the convenient part about this is that you can take this message right here and append it to the end of my list of messages and then you're going to start to have a history of the conversation and note that you can send pretty much a set of messages to the chat um method right here which means that you're going to be able to append the message to the conversation and then send the whole thing again and then append the response and then the whole thing send the whole thing back again and this is essentially how you create a assistant that has conversational memory okay so as you can see this is the method that you're going to be using most of the time and let's just take a look at it under the microscope as you can see the returned object was actually a chat response object and um if we actually take a look at it under the microscope we're going to convert it into a dictionary and printed and let's see so we have the completion tokens and the prompt tokens total tokens that were um um spent during this interaction here we have the message let's take a look at it um let me just just print it like this response. message let me just print it as well as dictionary and there we go so here we have the content of the message an intriguing case Etc let's make it an nice scrollable element and you have the role and you can see that the role is the assistant so we can basically take this entire message and we can append it back right here and we can just resend I mean send another query send a follow-up question and continue the conversation with our assistant okay so that is essentially how the chat uh model uh Works sorry how the chat uh method works now let's consider the streaming version of both of these methods okay all right so both both of these methods that we have covered so far actually have a streaming equivalent okay so a streaming version of them uh in this case for example this one right here is the stream complete method it does exactly the same thing as the complete method it is a textto text method but in this case instead of returning the entire generated content all at once it is going to return one token at a time as it is being generated which means that as a user you're going to have feedback and you're going to see that the llm is generating something immediately after you send your your query and that is very important for user experience uh in other words this is exactly what pretty much any llm application does nowadays like chpt um um CLA Etc all of those when you send your query it starts generating the content right immediately after you send it okay that's exactly what streaming means and in this case as you can see I am using an llm from open AI this time just to show you that you can use these um these methods to pretty with pretty much any language model that you want in this case all that I doing is switching this line right here and I'm going to be using that allows me to use another language model instead of the gro models that I was using above so that is very very convenient now as you can see I am just um um creating my response right here using stream complete and after that I am going to be able to actually just just display the generated content as it is being generated so I can print it for token in response I'm going to print each token I mean the text from each token now this of course um I mean I feel like there's a problem right here I think that it comes from the fact that uh my notebook is not designed for asynchronous operations but um as you can see it actually returned one token at a time and it yielded the whole thing one and one after another as it was being generated this is very convenient if you want to create your own applications and of course just to show you the type of this object that was returned is actually a generator uh and the same equivalent exists for L index actually so you can just do from L index score llms and you import the chat message just like we did before exactly the same thing so you have a system message then a user message by the way the system message is optional but it's usually better to have it because it gives your llm instructions about how to how to behave and uh once you have that you can use stream chat which essentially does exactly the same thing as the chat version that we had above but in a streaming by streaming each token at a time okay as you can see the return value is also a generator so there you go we have effectively covered how to use l index with any pretty much any language model that you want as long as they have an integration with it uh we have covered the common interface that is exposed for all of these language models that is to say the textto text and the message based um interfaces in the next video we're going to be covering how to use these language models for getting structured output out of them okay that is to say if you don't want to get just a string of text as a result or a message but if you want to get something more specific with a specific schema like for example a Json file with very specific keys and value types okay uh so there you go um in case you're interested in that you can check out which language models are available um as an integration with Lama index by going right here in their documentation you're going to go to component guides then you're going to go to models and within here you're going to go to language models and right here you're going to go to available llm integration okay and right here you have all of the Integrations that they have available um on L index as you can see they have anthropic they have Grog they have hugging phase Integrations of course they have open AI Etc so be sure to check that out if you want to check if you want to try your own language models with uh L index okay so there you go uh hope this video was useful for you uh don't forget to subscribe uh to get the next parts of this course or to see other tutorial in this um in this channel okay thank you very much for watching and I will see you next time [Music]
cCyYGYyCka4,2024-07-30T10:45:03.000000,Introduction to LlamaIndex with Python (2025),good morning everyone how's it going today welcome back to the channel coming to you from France today sunny France we're at 40 today we're melting that is in Celsius I'm not sure how much that is in Fahrenheit but it's very very high uh today we're going to be covering Lama index and uh the reason for that is that I was recently researching about this framework and I figured that most of the content online about L index is kind of out of date so right now it's probably a very good time to create a longer series about all of llama index's capabilities and features that you can um use in your projects and in your company because now the company is at a much more stable and mature phase so I figured that this uh series of tutorials is going to remain Evergreen for a longer time so yeah in this first video of the series we're going to be covering pretty much what is L index uh its particular take on context augmentation and drag we're going to be covering that with a very cute diagram that we have right here and then we're going to be going to the code so that you can just get your foot wet on the water so that uh you can start using this framework which is uh pretty pretty useful um so there you go that's that's what we're going to do right now so let's actually start talking about what is Lama index [Music] [Music] all right so first of all let's talk a little bit about what is Lama index now if you're here I suppose that you already have a bit of an Intuition or an idea of what is Lama index but in case you don't and for the new Commerce as well I'm going to explain that really quick for you a good way to think about this if you have already a little bit of um background in this is that there is a lot of overlap between Lama index and Lang chain they both allow you to create llm applications however there are a some some differences that we will be covering during this series as well uh L index essentially is a framework or an ecosystem that allows you to create llm applications such as chatbots AI assistance translation machines or any other kind of applications that would require a language model in their services and something that is very useful about them is that they also provide a lot of data loaders that allow you to enrich the knowledge of your language model with your own data for example your language model might not know anything about the contents of your email inbox or your company's database or your noes in notion well the idea is that a framework like L index can allow you to access to enrich your the knowledge of your language model with that information so that it can answer questions about your your personal data or your company's data all right and they also allow you to create much more sophisticated programs such as AI agents multi-agents Etc okay now other than that they also have some Enterprise Solutions such as lamama cloud and lamma pars which are essentially the same thing that you would be able to code yourself but taken care of by their own teams in in San Francisco in other words in other words what lamac cloud can allow you to do is to ingest to help you ingest all of your personal data or all of the data of your company put it in an index and use it with their own with their with the language models that they have available so that you can use create these kind of applications already within your company so it's kind of a hosted version of the thing that you would be able to code yourself if you had a team of machine learning scientists and software engineers and other than that they also have this service called Lama pars which allows you to parse pretty much any kind of document and output a structured um document from it so for example if you if you you send a PowerPoint presentation to their API at lamap pars they will return to you a structured document with all of the the contents of your PowerPoint presentation with a very easy to use API so that is very very useful I also have a video about this if you're interested you can check that out and there you go so that is essentially the introduction of Lama index what their open-source um libraries uh do for you and what their enter Solutions can do for you as well so let's actually start by looking at what they and how they do this that I uh explain to you real quick right now and we're going to do that explaining this with a very nice diagram so here we have the diagram and the idea right here is that I want to introduce you to what L index does and how they deal with context documentation now if you have any experience with rag or retrieval augmented generation you may already understand a lot just by looking at this diagram but the idea behind this introduction to Lama index is that I wanted to go through the entire diagram again highlighting the differences in how Lama index deals with this and also highlighting the main components of the Lama index ecosystem okay that's why some of this items are in color in different colors okay so let's actually start by taking a look at the components and the high level components of the L index ecosystem all right so let's start off by talking about the first component of the Lama index ecosystem and that is data connectors okay now remember that I told you that Lama index is a an ecosystem or a library that allows you to ingest your data in order to use it in your application now that data is usually stored in unstructured or or structured sources what does this mean that you may have your data in PDF files in HTML files if they are websites in csb files in Excel files in Word documents Etc and if you want to use them within your large language model application you will need to take all of that data from all of these different formats and put them together in an uniform way and that is essentially what the data connectors do um now data connectors are probably one of the most um popular parts of the L index ecosystem because lately they have been putting a lot of effort into creating very sophisticated data connectors that allow you to ingest pretty much any kind of document you want in a much more Smart Way um that is actually what they do with lamah Hub they lamah Hub is essentially um an API with a data connector that allows that takes pretty much any kind of format to it and then gives out structured documents so that you can organize your data and you can use it with your language model applications okay and they also have lamah Hub which is an open- Source Community where you can also contribute if you want and essentially this community allows you to create any kind of the components in the Lama IND ecosystem and make them available to the community but I feel that the most popular uh use of lamah Hub is also their data connector so someone may develop an independent data connector for say notion so now you can uh you can use a the notion data connector to ingest your data from your notion databases and use it in your Lama index application uh so that is data connectors and so essentially they just allow you to take all of your unstructured or structured documents and put them together into a more organized way that you can use in your llm application now the next thing to consider is the output of your data connector and that is the documents so what is the document that we see right here now as I told you before you have these data connectors that will take all of your structured and on structure files and will output documents from this data that you have right here now you may be tempted to think that these documents are U PDF documents or Word documents or things like that but actually not at all these documents actually are just programming objects with different properties okay now this document for example may come directly from your PDF so your PDF after being passed through your data connector it will output this document right here and this document is essentially just a programming object with one property titled text or it may be titled content depending on the framework and that property will contain all of the text inside of this file so it's essentially just a distillation of the contents of this of this data source and then in another property under the same object you will find a metadata and this metadata will include the name of this source file so that when you use this document in your application you will know exactly from which file it came from it may also contain the page range from where the information comes from in your original file it may also contain the date at which your file was ingested in the data connector Etc so essentially that is what a document is it's just a structured representation of all of your data source and this makes it much more easy to handle your data in this pipeline okay now the next thing that we have to consider is how these documents are then turned into nodes so now let's talk about this concept right here of the node and this is a very particular concept conceptt and very special one because it is um very ingrained in how Lama index works and it does not do this by default when you try to do the same thing with Lang chain for example so as you can see I mean remember that the whole idea of this presentation of this diagram right here is that we're trying to uh we're explaining how we would create a data processing pipeline that will take our unstructured and and structured data sources and turn them into an index that you then will be able to query using a language model so this index will will contain your personal information and then you will be able to use a language model to ask about to ask um questions about your personal information that your model was not initially trained on so what we are what we have done so far is we have taken these unstructured data sources passed them through a data connector and put them into documents what is happening after that is that the documents are split into different nodes now what is one of these nodes a no is essentially in the at the highest level just um a chunk of your document okay so depending on the length of your document it may be split into one or more or several notes and the idea is that the Noe retains the metadata from the document so if this document contains the metadata that it came from this PDF this node will also contain that metadata uh but it is kind of a more granular piece of information whereas the document contains a larger amount of information from the PDF now there is one uh very important distinction between the node and the document and is that not only is the node more granular it is also interconnected with other nodes creating sort of a network of knowledge okay so the idea right here is that your document may be split into several nodes each note containing more granular information and these nodes will be interconnected among themselves and that the same thing between all of your documents from all of your data sources that were um that were uh ingested so that is essentially this step right here of creating the nodes and that is a a different step from the more simple implementation of this that we could have seen for for example in the Lang Chain video that we did before and L index does this by default so by default L index is going to be working with with nodes and it makes it more explicit that you're going to be manipulating them during your data ingestion process okay so once that you have this network of knowledge in the nodes um we're going to go to the embeddings and then finally in this data processing pipeline you have the embeddings of each one of your nodes so each part of your network right here will going to be converted using an embeddings model into a numerical representation of itself okay so here there are several embeddings models to choose from I mean you can use uh open AIS you can use many open source models as well and the idea is that you're going to be embedding the contents from your your node creating a numerical representation of this this numerical representation will also contain in some way will capture the meaning behind the contents of the information inside of the node and then all of these numerical representations of all of the material that you had in your PDFs HTML and all of your files will will be added together inside the index and that is how we get to the index right here which is another core component of LMA index and the idea is that the index is essentially just your vector database which essentially is just a database that is going to contain all of your numerical representations of all of your nodes and all of your I mean and thus of all of your data and this index is what you're going to be able to query in order to get the relevant information to any information that you're looking for which in this case is going to be queried by via your router and your retrievers but let's let's take a look at what these are right now but for now just keep in mind that the index is a concept that you will be referred to several times during these minseries and also inside of the LMA index documentation so that is what that is what they mean when they say index now let's take a look at um the retrieval process and now we get to the part of the retrieval and the retrieval is essentially when the client sends a query to your API or to your application and you want to find the relevant documents that are relevant to this query now the idea is that you have this thing that they call router right here which is um another core component of Lama index and the idea of this router is that it is going to decide which retriever it is going to use to get information from your index okay okay now each each one of these retrievers is of course another component of Lama index and the idea is that each one of these retrievers May um may use a different strategy to query your index okay so the router will analyze your query will then route it to the most appropriate retriever that will find the most relevant information and then these retrievers are going to get back the relevant information from your index which is the information from your data from your custom data and that is kind of the job of the router and the retrievals and so we have our response synthetizer right here which is another component from Lama index which will essentially just put together the documents that you got from your retrieval and then put them together with another prompt send them to your language model and then get a response with your enriched information okay so that is essentially how Lama index deals with a very simple and very regular rag Pipeline and as you can see it is very similar to what you would do in for example Lang chain but I wanted to go over this all over again but highlighting the specificities of how Lama index does it so now you know what what what they are actually talking about when you see response synthesizer or router or index or data connector in the L index documentation or even in some other videos in this miniseries okay okay so now we have successfully understood what are the components of L index and why what they actually do uh we're actually going to start implementing them using a little bit of code right here and you will see that it is actually very very simple so the first thing that you want to do is of course to install Lama index and to do that you have to run pip install Lama index - uq means upgrade and quiet so that as you can see I don't have any output right here and after that we're going to initialize my API key from openai now um L index actually uses by default the language models from openai and to be more specific it uses GPT 3. 5 turbo which is a very inexpensive model so you should be okay uh but in case you don't want to use open aai in I one of the future videos in this miniseries I'm going to be adding how to use this with local models too so there you go now we have our openai API key set up correctly now it is time to actually start implementing this pipeline that we saw right here and llama index actually has this very very famous and um one of which they're very proud of this feliner which in five lines of code essentially just implements the entire pipeline that you have right here uh so let's take a look at that uh so the first thing that we're going to want to do is we're going to create a new folder called Data where we're going to store all of the documents that we're going to be uh ingesting this documents that were right here and in order to do that actually I'm going to be importing the constitution of the USA and that's all that I'm going to be adding right here so I have the constitution. PDF um just a quick reference to an old video that that I did about a year ago about rag as well so there you go um all of I mean I am only going to be adding one single document right here but just to be clear you can add as many as you want inside of the data folder right here and they're all going to be ingested as part of your pipeline so there you go so now the this very famous feliner so from Lama index. core import Vector score vector vector store index and Sample directory reader so these are the two classes that we're going to be using Vector store index is essentially the index that you saw right here so in other words your vector database and we have SIMPLE directory reader which is itself a the ingestion uh object I mean yeah the the ingestion class that is going to allow you to ingest all of the data inside of your data folder right here um so there we go the first line right here is going to be initializing all of our documents so with this very simple line what is what we're doing is we're generating the documents from our PDFs and we using uh as data connector this simple directory reader and now the simple directory reader takes as input I mean takes as parameter the folder where all of your documents are and if you want to see I mean in case you're using um cab if you want to see where you are and what uh what documents you have access to right now you can run LS like this and then you can see that you're already in the working directory where your data folder is so you can do CD data and then see what's inside of data and then you can see that um well apparently that's not how you concatenate commands here but that's okay CD data and LS let's see does that work better yeah so there you have it so we're inside content data and then we have that constitution. PDF is inside of here so just by passing data like this or you could also do this like this your going to be passing it the data the data folder and then we just run the load data um method right there then the second line of this feliner is creating your index so you're going to be generating your index from documents so you're going to be creating this Vector store index from the documents this part is actually very similar to what you would find in another Library like uh L chain and then you will be able to query this index by converting it into a query engine and this thing right here is essentially just uh initializing the retrievers uh in this case we're only going to have one retriever so we're not going to be using a a router as we specified right here but essentially that is what we're doing right now and this query engine is already one that you can ask questions to so let's query it using this line right here so the response is going to be equal to query engine do query and then you pass in your query and then we can just print our response and let's see what that is so we're we going to be asking about the first article of the Constitution of the USA so we're importing from my my index all of this and apparently there was a problem locating our data um directory data does not exist apparently it does not exist what do you mean or maybe we're still in data so yeah there we go so we're back okay so this actually persists uh in the terminal so when I moved myself inside of data I was running all of this inside of data so now if we do this again it should be okay it it ingested all the documents inside of data and there we go the first article is about the establishment of the legislative powers Etc so there you go I mean that's the F the famous feliner from Lama index and now you have this very quick introduction of how to do this uh just a quick note that inside of data you can add pretty much any any kind of um any kind of uh file uh let me grab you a link right uh list right here so here is the list of all of the files that you can add inside of your data folder so it can be a CSV do uh Word file UB Etc I mean it is able to ingest all of these formats as you may notice Lama index is becoming a very very good add un struct structure data ingestion so they I mean they even created this fabulous Lama pars API for that so yeah I mean they're very strong at this and this is all done automatically you don't have to load CSV loaders by the by hand um Jupiter notebook loader by hand and everything right here is going to be dealt dealt with automatically and you can of course get um get more detailed information about this if you go to the L indexc documentation let me just um do this like this going to paste this yeah the index documentation s sample directory reader and here you have all of the supported file types and they also have a specific Json loader and of course they come from the labah hob lamah hob as we mentioned right here okay so that was the famous feliner let me just just show you how to make the data persistent as well so if you want to make your data persistent this index that you see right here is the one that you're going to be querying every single time that you're going to be asking your questions to your language model and if we run this again we're going to be redefining our index so every single time we're going to be ingesting all of the documents inside of data inside of the data directory and that's okay if you only have one document like this but if you have several documents you probably don't want to ingest them and to do all of this every single time you run your your pipeline so the idea right right here is just instead of storing this in memory you're going to make it persistent and in order to do that they have this very quick very quick um show you this very quick script to show you how they do it I mean this is this comes of course directly from their documentation so as you can see they're importing os. paath essentially just to deal with the paths in your file system then from Lama index core they're importing again Vector store index simple directory index but this time they're going to be importing storage context as well as well and load index from Storage as well in case you already have created your storage context and essentially this just makes your vector database persistent in your local machine uh here they're initializing the directory where they local storage is going to be stored so here as you might remember we have the data directory right here so this is going to be a directory added right underneath right here and so here we essentially just test if the path exists for this one and if it doesn't exist we're going to be creating that persistent storage so if storage does not exist essentially means that we have not yet created our index so we do that so we do documents we ingest the documents we create our index with exactly the same line that we created it up here and then we just store it for later in the persistent directory and this is the function that you use in order to do that so if you were doing this in for example your own application or your server this is essentially the function that you would use to store this in your locals I mean in your server okay so index which is this one storage context persist and then you pass in the persist directory which in this case is going to be storage and then if the path already exists which means that this one right here this is going to be triggered the else statement and if the path already exists it means that we have already ingested the documents and they have already been stored in our local storage so what we do is essentially we just index them from Storage so we say storage context from defaults we pass in the persistent directory then the index and then either way we can now query the index just like we did before okay so that's very very quick um explanation of what's actually going on and how to store for this let's ask about the third article right now real quick here you can see I mean it saw that we have not yet a storage directory and then the third article is about the terms of the president by President Etc and if we go right here you can see that the storage uh directory has been created and inside of it is of course all of the necessary information for Lama index to retrieve um information from our personal data store which is right here before we leave actually I wanted to show you something a little bit about the documents that we got ingested from here and the idea is that we talked a lot about what the documents are in the pipeline right here and I told you that they are programming object Etc but I didn't actually show you what they look like so here we're going to be tapping into the documents that we ingested right here from the simple directory reader which essentially uh converted our PDF into several documents and we're going to tap into it first but first of all let's take a look at its length so the length of the documents is 19 so we got 19 documents for our PDF file and let's take a look at one of them to see how it is composed so let's look at the the fourth one and as you can see it's a document object it has a property of ID embeddings which is a Boolean and that has the metadata right here and this this property is very important because it tells you the file the original file where it came from so you have the page lab label where this uh the contents of this document comes from you have the file name to say that it actually came from the constitution. PDF file and you even have the complete file path to the file in your server or whatever you're persisting this this files then you have the file type the file size the creation date of your file the last modified date of your file um so yeah I mean that this is of course you can see why this would be very important if you were implementing this functionality in your application and then right here you have the property of text which essentially contains all of the raw text of your file okay now in this case um it's not super pretty it has a lot of uh line jumps like this but it is good enough for a language model to interpret it and there you go so that is what the document is and what it looks like so let me show you what the text itself looks like so text just going to print it and there you go so here's all of the text so as you can see we have the the title the section seven and here you have all of the text from the section seven okay all right now something else that I wanted to show you is how to do pretty much the same thing but using their API on Lama pars okay so essentially remember that right here we ingested the constitution. PDF file and we converted it essentially to Raw text okay that was pretty convenient but the constitution. PDF file that I am using right here is actually a very simple file it contains only text uh in case you have a more complicated file let's say that you have tables and images Etc this regular simple directory reader is not going to do a great job with that so what you can do instead of using this simple directory reader is using the Lama pars service that Lama index uh introduced a few months ago and the idea is that you go to L index.com you click here on sign up so that you get ACC to their lamac Cloud platform and you're going to be prompted to create an account if you don't already have one and once you're in here what you're going to want to do is you're going to want to First create an API key of course and once you have that you're going to be able to ingest any number I mean to ingest up to a thousand pages per day of complex documents so the idea is that instead of using this simple directory reader you're going to be sending your documents to their API and they're going to be returning you the organized or even structured text that came from your unstructured file um so let me show you real quick how this works I actually made a video about Lama Pars in the past um but it works pretty well for ingesting complicated formats um so I'm just going to copy the API key and going to implement this right here with essentially the same feliner that I had right here so what we're going to do is replace this line that takes all the documents and we're going to replace it with this other line right here which essentially just does the same thing but instead of using the simple directory reader we're going to be using Lama pars and in order to do that you're going to have to do from llama pars we're going to input Lama pars and there you go but actually in order to use this you're going to have to add the API key that I showed you how to get just a moment ago and in order to get the API key you can just use this you can just set your lamac Cloud API key environment variable actually here is just a quick mistake just going to get the password right here I'm going to copy and paste it from what I created ated up here at lamac Cloud now I have my API key set to the lam Cloud API key variable and now actually something else that I should probably do now that I am working in a Jupiter notebook since lamac cloud and Lama Pars in particular is an async first API going to have to run this NE Nest async IO um just to emulate an async API and there we go so now now that we have set our API key and our nest in Kyo we should be able to call Lama pars and as you can see we just specify the type of um of data that we want in return in this case we just want the text from our file and then we load the data and in order to load it we're going to pass in the path to our file so in this case it was St inside of data and if I remember correctly it's called constittution .pdf so Constitution constit dopdf there you go and now this should be able to work now and as you can see it is Ines in the documents indexing and then again we have the response from what is the first article about the first article this cusses the principles Etc and as you may be able to see right here my thousand pages per day us it should be updated um let's see well it's not updated automatically apparently but yeah I mean I just used uh I don't know probably 19 pages off of my thousand pages per day and there you go let me show you what the documents from these ones uh from this API looks like as you can see it's pretty much the same thing but also as you can see the the text is a little bit cleaner so let's see the text um let me just use print to make it look better there we go so yeah here we have it that it's I mean the the fourth document in this case starts at this paragraph right here with the section seven and as you can see it's a little bit cleaner I mean it doesn't really make a difference for this file in particular because this is a very easy file the constitution. PDF but yeah I mean you can use this for more complicated files as well so there you go that is just um I felt like I needed to include a quick introduction to Lama Pars in this lama lama index introduction video so that's essentially how L index works it is um I mean this is a much more simple uh implementation um of what you would do probably in production but of course this is an introductory video and I just wanted to introduce you to a very quick rag example um in L index okay uh in the next videos in this series we're going to be covering much more detailed and and advanced topics of Lama index but please let me know if you have any questions and if you're excited about more content about Lama index I'll be happy to be making more of it um so yeah thank you very much for watching if you have any questions suggestions or even Corrections please be sure to leave them in the comments below and I will see you next time [Music]
W03paqjbWAg,2024-07-19T05:00:16.000000,New Groq Models: Best for Function-Calling Agents,[Music] good morning everyone how's it going today so today I bring you a very quick video showing you the two new models that were released by Gro earlier this week and the idea is that these are two very useful models and probably the best in the market uh when it comes to function calling so we're going to be going over the blog post of the release and also I'm going to be showing you how to use them on a Jupiter notebook really really quick okay so let's get right into that all right so earlier this week Gro released two new models in working with GLI and the idea is that these are two models that are fine-tuned to work with function calling now what does that mean this means that essentially you usually have General fun General language models such as CLA Sonet gp4 that are work pretty good with pretty much any kind of task and they are also pretty good at function calling however if you want to have a model that specializes at function calling that one's probably going to beat all of the other ones and that's essentially what's going on with this one what gr it is they took the open source Lama 3 model and they fine-tuned it in order to be great at function calling which is going to be super useful for creating your agents okay if you remember remember correctly I think it was yesterday or the day before that we published a video showing how to create an agent using the react pattern and that worked pretty well but we did not use any function calling language model over there and in a future video I think probably this week or the week after we're going to be creating an agent using function calling and this is going to be super useful for us to do that so let's go over this very quick blog post so we have have that they created this these two new models Lama 3 Gro 70b tool use and Lama 3 Gro 8B tool use so it's a 70 billion parameter model and another 8 billion parameter model and something pretty cool that they say is that according to the Berkeley function calling leaderboard it is the highest performing model in the market right now and if you want to see that you can actually click right here and you will see the actual leaderboard however they are not there yet I don't know if they're going to be um included soon but the idea is that this is an opsource leaderboard and the code in order to perform this tests is actually in their GitHub repository so what the people from Gro did is they went to this repository and they ran the test right there and The Benchmark and so they ran it and what they got is that they actually I mean you can go check the comet where they run the tests and you can see their results right here so we have the first model now I mean according to to this Benchmark the best model for Tool use is LMA 3 gr 70b the second one is LMA 3 gr 8B and then after that comes the later the other models that are um in the website right now so apparently the best function tool function calling models in the market as of today now of course this comes with a problem because this is a model that was fine-tuned especially for this which makes this model I mean these two Models Super good for calling functions and for creating these kinds of Agents but if what you want to do is to have a more General language model um these are probably not going to be the ones you want to use so what they recommend is that actually when you want to create an agent that uses function calling you in you implement a step called query analysis okay and the idea behind this is that you're going to send your query to your to your agent uh or to a query analysis layer before it gets to your agent and it is this step that is going to decide whether or not you're going to be using a function calling specialized language model or a more General language model if it's a query that requires tool calling then we can we can analyze it and then the query analysis part is going to Define that it actually requires you to use a function calling agent and function calling language model and it's going to Route the query towards um the one of these models and then if it's a regular uh query it's going to be sending that to a more General language model such as Lama 370b clot Sonet Etc okay so that's the overall uh blog post and that's what they um advise you to do now let's actually take a look at the model and test it real quick okay great okay so in order to test it I'm I actually just prepared a very quick jupy turn out book here for you so what I did was essentially just pip install Gro which is our Gro right here and the idea behind all of this is that we're going to essentially just be calling the language model as they ask you to do in the Kickstart okay so that's essentially what I did I went and got an API key then I initialize my client right here with my API key and then here is where the font part starts so I actually just copied right here here a very very simple system prompt that is actually in their hogging face page because yes um this is a Gro model and it's of course available in their Gro um in their Gro platform but it is also available here on hugging face however I am of course going to be using it from the gro Cloud because I mean if you're if it's already on Gro you probably want the fastest architecture right so I'm going to be using it from Gro right here and let's do that so I just copied the all this um this initialization of the client right here have it right here and the template is this one right here let's go over it real quick and essentially it's just asking the language model to return adjacent instead of a regular text okay so here it goes you are a function calling AI model you are provided with function signatures within whoops with function signatures with tools tools XML TXS you may call one or more functions to assist with the user query don't make assum assumptions about what values to plug into the functions for each function return a Json object with function name and arguments within a tool call XML TX as follows and then we have an example right here of how a response from this language model is going to look like so here we have have the name which is going to be the function name and the arguments which is going to be our arguments for our function now if you checked the previous video where we created a react agent without a function calling agent sorry a function calling language model uh you remember that what we actually did was we parsed the response from the language model using reix and yeah I mean that was okay for that example but in production and with more sophisticated Frameworks you probably want to use uh function calling language model that actually returns a Json file like this one so that it's much easier to parse okay and since this uh language model is fine-tuned for that that's great then you pass in the available tools also within XML tags and this of course makes it much more easier much easier for your language model to understand what actually it has to pass in to your to what what actually it has to return as a response okay then here we have just one example which is one tool the tool name is get the current weather so essentially you would have a function uh a python function called get current weather and here you have the properties it allows you to enter the location and the unit that you want and then of course the location is a simple string and the unit is also to a simple string here we have an example um where is the example get current weather arguments location San Francisco and the unit was Celsius uh so that is the system prompt message and what we're going to do is we're going to pass in I mean we passed in this system prompt essentially just telling it what we expect from it and then we just pass in a simple query saying what is the weather like in New York City to see what it returns so let's run that we run the chat completion and we print it and here we have it here we have the function call we have an ID for the function call the name of the function that was returned get current weather and the arguments which is the location New York City and the unit which is Celsius so there you go that's a very quick uh example of how to use these new models from Gro cloud and and we're going to be using them in a future in a future tutorial where we're going to be creating another react agent but this time with a more sophisticated language model that is actually uh aimed at at using uh the function tolling capabilities from these language models okay so that's going to be kind of a a second part to the previous tutorial that we saw here a couple days ago so yeah this was a very quick video and just a Showcase of this new tech near new piece of tech that was released this week let me know if you like this kind of short videos just showcasing this um new technologies and just a very quick overview of it um or if you prefer the longer kind of tutorials that we have been seeing so far in the channel um so yeah thank you very much for being here it was great sharing this moment with you and uh we'll see you next time [Music] [Music] [Music]
hKVhRA9kfeM,2024-07-17T09:59:03.000000,Python: Create a ReAct Agent from Scratch,so let's see there we go oh good good well okay so that's an agent good morning everyone how's it going today welcome back to the channel and welcome to this video in today's video I'm going to show you how to create a react agent from scratch in other words we are not going to be using any framework such as Lama index or langing we're going to be creating it from scratch using only python okay now the idea behind this is that I want you to better understand how the react pattern Works in agents and also by the end of the video something pretty interesting is that I'm going to be talking to you a little bit about a program that I'm going to be opening which is a coaching program where I'm going to be taking a few of you of you to learn um AI engineering and creating AI applications it's kind of a private course okay so I'll let you know a little bit more about that by end of the course but right now let's actually focus on creating react agents so the first thing that we want to do is to understand what is the react pattern and after that we're going to start coding it all right so let's do [Music] that all right so the first thing that I want us to understand is what is a react agent and first of all let's actually talk about agents what is an agent and one of the answers that or one of the explanations that I've seen people use the most and which is actually very intuitive is that let's suppose that you go to Chad GPT and you have a question and you ask Chad your question now Chad is going to give you an answer but most of the time that first answer that you're going to get from chpt is not going to be the final answer that you actually want you may want to to go a little bit further from that answer or to tweak it a little bit or change some details in the answer that it gave you now you're going to go back and forth with chpt a few messages in this conversation and after let's say five messages or so you're going to arrive to a result that you actually want and you want to use and now you're going to copy that result and use it in your workflow okay now an agent is essentially that however that Loop is going to be automated okay in other words an agent is just essentially a loop that is going to go to the language model ask for a question then get a response then ask for another question and then sent I mean um improve on that message until you get the final result that you want and that is essentially the broad definition of an agent okay now once we have that in mind we can start understanding what is the react model for agents okay so let's now now that we have understood what is an agent in itself let's talk about what is say react agent okay so now that we have successfully kind of understood what is an agent and what it actually does let's actually consider the react pattern which is a very nice pattern and very intuitive way of Designing agents that can interact with the real world through the usage of tools okay now the react pattern essentially um land I mean depends on this very simple Loop that we see right here it's a loop called thought action observation and essentially what it relies on is on this observation I mean this idea that when we are humans and we want to do something sometimes we articulate that thought in our head before actually performing the action so for example let's say that you're um you're creating you're baking a cake or something in the kitchen and then you may need some milk so what is going to happen is that you're going to read the recipe you will see that you need some milk and inside your head you're going to think okay I now need two glasses of milk I'm going to go look for the milk in the fridge okay and once that thought was articulated then you go to the mil then you go to the fridge to find the milk and that is essentially what they are trying to do here so they're going to be using a language model in order to make the agent think of this thought and then select an action from the available action so let's say that you ask your agent what is the mass of let's say the Earth so it's going to enter this Loop and it's going to the first thing it's going to do is going to enter through the thought so it's going to be something like okay so now I have to find the mass of the earth now I should look on the internet to find the mass of the Earth and internet is searching the internet is going to be one of its available tool so it's going to look on the internet it's going to find an output and that output is is going to be called an observation and the observation is going to put back into the original prompt and we're going to restart the cycle again the loop so we're going to add the observation right here let's say that we found that the mass of the earth is I don't know um one trillion tons and it's going to put it back into the thought and now that it has the V information it's going to go back to thinking it's going to be like okay so now I have the total mass of the earth now I can answer the question and now instead of choosing an action it's going to exit this Loop and it's going to give you the final answer it's going to be something like according to let's say Wikipedia you have um the the Earth weights I don't know how many tons all right and that is essentially how it works now what I what I actually prepared for you is a an even more detailed um diagram for for you right here so let's suppose that you have your agent right here and the first thing that you have to consider is that it has an initial system prompt okay so the initial system prompt looks something like this so you are an agent and you work on in a cycle in a loop so your Loop is going to be thought then it's going to be your action and it's going to be your observation if you choose an action you will have to pause so let me actually just let me just edit this real quick right here so if you choose an action if you choose an action you're going to pause there you go okay so there we go so it CH you choose an action then you you run the action you get the observation back and then you work on this Loop until you find the answer by the end you will select an answer okay now something important to include in the initial prompt as well is the available tools that the agent has available so in this case I'm just going to give it one tool which is going to be search Wikipedia and it is going to know when to use search Wikipedia because search Wikipedia may have this additional description something like use this tool when you want to find some information from Wikipedia Etc okay and then now answer this question and that is when it enters the loop so we're going to ask it what is the total mass of the Earth and let me just put this all together like this so we're asking a question what is the total mass of the Earth and it enters this thought action observation Loop so the first thought we're going to send the prompt and we're going to get this thought right here so the first thought is going to be something like I need to find the mass of the earth and the action that it's going to choose from the list of actions that we made available to it and in this case we just have one action which is search Wikipedia it's going to select the action search Wikipedia and it's going to search for the mass of the earth I mean of course this is just a uh very very broad example and then after we get this response we're going to put this back into the prompt and then we're going to call this tool that the agent selected so we selected um search Wikipedia and we're passing the parameter mass of the Earth because that is what the agent say selected and then the tool is going to select the result and this one right here is what we call the observation okay so remember this diagram it selected its tool then it SE then the tool got an output we got an observation and then the observation is incorporated back into the prompt and in this case we only have one single iteration for the loop but the idea is that you can have an agent with multiple tools or multiple um stages and steps of the in the thought process and the idea is that it's going to continue looping through this until it finds a solution so here you have this um here you have the observation and actually this observation is already the final answer to it so it's going to be um here it is going to respond something like okay so now I have the an it's going to think and it's going to send all of this back to the language model and this is going to get back something like okay so now I have the answer to the actual question and then it's going to respond something like according to Wikipedia the total mass of the earth is 5.9 * 10^ 24th okay so there you go I mean that is essentially how a react agent works this is the loop and if the question had been a little bit more complicated let's let's say what is the joint mass of all of the planets then we will have this question right here and it would enter the loop it would search for the mass of the first plan Planet search for the mass of the second planet Etc and then we could have another tool that is going to be something like calculate and then it would sum everything together and then give you the response okay so you can see how this Loop would work and it is thanks to this initial system prompt and we're going to be coding all of this in Python within a few minutes okay so that is how the react framework works and now let's actually start coding this in Python all right so now the next thing that we're going to want to do is we're going to go to grock and to Gro Cloud okay so that is console. gro.com and the idea is that you're going to get your API keys and in case you don't know what Gro is it is essentially this service that allows you that uh allows you to use these open source models they have Lama llama 8B 11 70b mix strol Etc and the idea is that you can use them for free actually I mean within a certain limit and and and yeah I mean it's it's super fast because they have probably the fastest architecture for completion for generating completions of these models so what we're going to do is we're going to go to um API Keys going to go to create a new API key I'm just going to call it temp to be sure to delete it before I upload the video and then we're going to go to our we're going to go to our colab notebook right here and we're going to initialize it so I'm going to say import OS and we're going to say os. Environ and we're going to set groc API key we're going to set it to the API key that we just initialized and something else that we're going to want to do is probably we're going to want to install Gro so let's do that too we're going to do pip pip install grock and once that is done we're going to be able to actually start creating our our agent so there we go and remember that we're not going to be using any uh language Frameworks any large language model Frameworks like L index or uh or Lang chain I mean of course in production you would probably want to use one of those but the idea behind this tutorial is to show you how this works behind the scenes so once that we have this let's actually start creating the agent all right so what we're going to do right now is we're going to actually test these models right here so in order to do that the first thing that I want you to do is to go to the documentation of grow Cloud we go to the quick start and as you can see right here here we have just a very quick example of how you perform my completion with Gro so I'm just going to copy it we don't have to do this again because we already did pip install Gro and now I can just click right here and actually paste all of this code inside of here it's going to minimize this there we go so what we're going to do is we're going to say import first OS we're going to import groc from groc this essentially Imports the class that allows us to interact with the gro API and here we have that they're calling I mean they're initializing it passing the API key that we initialized up here and then they're passing in the messages uh this API of course receives a list of messages as the prompt instead of just a single string and here the message that we're going to be passing is just a simple message saying explain the importance of fast language models and then the second parameter that we have to set is the model that we want to use and remember that in order to choose a model you're going to have to go to documentation as well to models and here you can choose whichever you want by default I think that we had LMA 8B yeah which is this one but for agentic Behavior you probably want to use 70b which is better so I'm just going to change that right here and let's actually execute that and oh and yeah by the end we're just printing whatever the chat completion is tapping into the first choice that it returned the message inside of it and the content of the message which is tap because I mean essentially it returns an object that looks a little bit like this and then it return from this object we want to tap into the content um property so to actually get the the the answer from the language model so let's just execute this and there we have it this is the response f l language models how revolutionized the field Lada and there we go so that was good uh now that we have successfully imported Grog we can actually start creating the agent itself so let's create this agent class okay so now let's just initialize this agent class I'm going to create it like this class agent like this and there are a few things that I want to do the first thing that I want to do is to Define an init function and this function essentially is just going to just going to initialize my agent and what do I need in order to initialize this well first of all I am going to need the client and in this case the client I'm just going to be saying that it's going to be a groc you know what I'm not going to use typing here just going to use like this and the system which is going to be the system message okay and this one is essentially just going to initialize it all saying that the self client is going to equal client then the system prompt is going to equal to the system prompt then the self we're going to initialize a property called messages and this is essentially going to be a list of messages that our that our agent is going to include inside of its it's its memory in some way okay so all of this Loop of messages is going to be stored here you're going to to see how that works in just a moment and then last but not least we're going to say that if we have a system message we're going to append it to the messages and as you can see right here we're just going to append it saying that the role is going to be the system and then the content is going to be self system that we initialized right here and there we go so that is the first init function then we're going to initialize a function called call which is essentially just going to be executed whenever we execute we call this agent and this one essentially just will take a I'll take a message like this and this one right here we're going to say that if there is a message we are going to append that message into our history of messages right so we're going to say self messages we're going to append it and we're going to append it on the side of the user because if we are um thinking I mean if we are um entering this Loop of the user of the if if we're calling the agent with a parameter we are going to essentially be the user who is going to be adding an a a system message to this thing a message to this agent so let's just plug it right in right here and then we're going to find that the result of that is going to be whatever the agent gives us from the execute method which we have not initialized yet we're going to initialize it a little bit later down here then from the messages we're going to append the result from that and then we're just going to return the result and then of course the execute method that we haven't created this one is going to be first of all we're going to create a completion just like with did up here okay let's actually just copy this right here because remember that we're passing in a client like this so this is here we're going to there we go it should look something like this so completion the completion is essentially just going to call the client completions Etc and here instead of just passing in the messages like this what we're going to do is we're going to pass in the messages that are inside that are the property right here okay so um what else do we do right here and then we just return the completion choices message and content just like we did right here okay and there we go that is essentially our agent and it should work already but um let me just uh tour you around a little bit behind the logic uh of all of this so that you understand what is actually going on so uh we have the agent when we initialize the agent with a client and a system message we're going to first initialize the property of the client we're going to initialize the system message which is the one that we saw right here the system prompt which is something like you're working a you know it's not a cycle it's a Loop you work in a loop and then you're you working a loop of thought action observation Etc and then that is the system message that we're initializing right here we're going to be writing that in a moment then we're going to be creating this list of messages and then if there is this system message in in here and I mean if it's not an empty message we're going to append it to our list of messages as a as the system message remember that when you're creating an agent or a any kind of call to your language model the system message essentially just gives the initial instructions to your language model to follow from uh to follow during the entire conversation so that is the first part right here then we have the call method which is essentially going to be triggered anytime we do agent parenthesis okay I mean the instance of our agent with parenthesis so if we call it with a message then we're going to say that we're going to append the message into our list of messages and then we're going to execute the language model and this execute I mean execute the agent is essentially just going to uh run a completion with all of the messages that are in our history right here and then it's going to append the result from that completion and return the result okay so that is essentially all that is happening and you can see that if we run the same agent without doing anything more than initializing it and running it several times it is going to um it is going to call the it is going to make a call to to the language model right here it's going to append it and then it's going to call that again append it call it again append it and you can see how that can go in a sort of infinite Loop so it's important to stop that loop at some point but we're going to do that in just a moment so far we have successfully coded this agent and let's actually take a look at creating the system prompt and the tools that our agent is going to have available okay okay so now let's actually write the system prompt for our agent now the system prompt is essentially just going to prompt our agent to respond with a thought and an action whenever possible and pause afterwards and then we're going to run the observation I mean run the tool that it selected return the observation ourselves and then um get the response from the agent so the idea right here is to write this prompt in a more verbos and more clear way and I'm actually going to be taking this from this blog post from Simon will Willison um great great blog post and the ideas is that he has written this prompt right here which is pretty pretty useful and we're just going to copy it I mean I I changed it a little bit in order to to fit to the example that I'm using so but I'm just I just wanted to give a quick shout out to Simon Willison from which I took this great so let's go back here and I'm just going to copy and paste this prompt right here so the prompt essentially looks like this so the system prompt goes you run in a loop of thought action pause and then observation at the end of the loop you output an answer use thought to describe your thoughts about the question you have asked use action to run one of the actions available to you then return pause okay this is very important that it should always return pause once it returns an action because we're going to be parsing that okay then the observation will be the result of running the the action in question so your available actions are bar and here we're just going to T to give it the action that it has uh that it can choose from and here it is calculate which runs a calculation and returns a number use Python to be sure uh so be sure to use floating point in syntax if necessary so for example the action is going to be calculate 4 * 7 over three and then the other available action is going to be get the planet Mass okay so the the idea behind this agent is that it is going to be able to get the mass of any planet in the solar system and then make calculations with whichever numbers it wants so get Planet Mass Returns the weight of a planet in kilograms and the way to call it here we give an example of how to call it Etc okay now this is very important this is essentially this is essentially the tool set of your agent so you want to you want to write this very um in a very detailed way okay so there you go and then we give it an example because I mean giving an example to your agent is very useful to make sure that it always uh responds with the format that you expect it to respond okay so the question for this example is what is the mass of the Earth time 2 so the thought is going to be something like I need to find the mass of the Earth the action is going to be get the planet Mass Earth and here you can see that we we are using the action from the actions available and then passing in the parameter which is a string right here and just which is just a name of the of the of the planet and then we return pause then you will be called again here we have this with the observation oops and the observation is just the response then the second thought is going to be something like I need to multiply this by two and as you can see we are already in the same second iteration of this slot so we run the action selected the the tool U uh sorry we selected the action run the action got the observation and fed it back to the to the prompt in order to get a new thought and that new thought is now I need to multiply this by two so we the action that it returned is calculate this by two then we pause and you will be called again with this which is the observation and once you have the final answer you have to Output the answer here you have answer mass of the Earth * 2 is da da da and there you go and now I just prompted it with now it's your turn so that it knows that it is um the agent's turn I mean its turn to actually perform this entire um this entire Loop okay so that's what's going on behind the scenes in this in this prompt um we're going to be fitting this into the agent within the system parameter Right Here and Now what we have to do is is actually code these two functions right here which are calculate and get Planet Mass so let's do that right now okay so we have successfully got this right here I'm just going to run this in order to actually create this and the second thing we're going to do is we're going to define the tools so remember that we said that the tools available are going to be calculate and get Mass so the first one is going to be calculate and then we have the input and then we'll return the evaluation of whichever that input is I'm just going to call this instead of input going to call it operation like that so there we go we're essentially just returning the evaluation of whichever is run right here as a string and the second one is going to be get Planet Mass so what I'm going to do right here is actually just mock a um an actual search in the internet or something like that so we're going to define a get Planet Mass function and this is very important to keep in mind that the actions or the tools that your agent has access to are essentially just functions okay so here we have calculate and we have get Planet mass and this is calculate get Planet mass and it takes in the name of the planet and it returns um you know what instead of doing like this let's actually use a a match case thing there we go so let's do like this there we go so we have this match if so we're going to match it's just a switch case essentially for python so we have the planet we're going to lower switch it to lower case to be sure that we are not uh having troubles with the cases so if it's Earth we're going to return this Jupiter da da da until all of the planets sorry for Pluto and there we go so now we have initialized our our tools now let's actually start using them so let's it is now turn it is now the time to initialize our agent and actually run this so let's do that right now okay so now it's actually time to start running our agent but however I mean something that I forgot to do before it's a little mistake right here when we call our agent uh message has to be optional because remember that here we're testing if message so I'm going to give message a default value of an empty string and if this is an empty string then this is going to be uh evaluated to false so this is not going to run okay so I'm just going to save this I mean rerun this cell right here and let's actually then initialize our agent so let's just initialize our agent so let's call it something that makes sense as someone who is an expert in planets I'm going to call it um Neil Neil Tyson and this guy is going to be an agent and remember that when you initialize an agent you want to initialize it with these parameters that you said right here so the first one is the client which is the instance that is going to allow us to communicate with our language model and in this case our client is the one from Gro so so the client we already initialized it this is the one that we're going to be passing and then we have to pass in the system message which is the one that is going to be incorporated into the first uh message right here so this system message is going to be the system prompt that we defined a little bit a few minutes ago so let's just set the client to client and the system to the system prompt and just run this okay so there we go that is the initial part of our client of our agent now we can actually start running it so let's say Neil Tyson what is the mass of the Earth times let's say times five and let's just check the result you're going to print the result right here so what what is the mass of the Earth * 5 we're going to execute this and in order so that you see what's actually going to happen we're actually calling our agent and that is actually executing this call function right here and since we are passing a message it is going to append that message to the messages list that we have right here and then it's going to execute that list of messages and then um then append the resulting message to its list of messages too so let's take a look at how that looks right here so we're going to execute this and here we get the thought I need to find the mass of the Earth and just to show you what actually happened in the list of messages let's take a look at Neil Tyson and let's tap into the messages so here you see that we initialized it using the system prompt and we have this system prompt that we initialized up here then the second message is the user message which is our message right here so here it says that the user message in the content is what is the mass of the Earth which is the one that we passed in right here and which was added in during this line of code right here and then we executed it and then we got whatever response it got to the list of messages too and that is this one right here I need to find the mass of the Earth now what we want to do is we want to reexecute the agent with this messages right here to get the next step in the loop which is going to be the action we already got the thought now we're expecting the action so what we do is we run the agent but this time we don't pass in any message because we already passed in our question now we just want to rerun the messages that it has already in it so let's do that enter and that we see that the next one is the action so the next the action that it chose is get Planet mass and it chose and it passed in the parameter of Earth so what we're going to do with that is we're going to manually ourselves on our side we're going to write the next prompt uh sorry yeah we're going to write the next prompt with the observation and we're going to run this so the result let's call it the observation the observation is going to equal to get Planet mass and here we're going to pass in the earth and let's see the observation so we have that the planet mass is 5.9 * uh 10 24th and that essentially is the function that we created right here okay um and this is of course a mock function and the the idea is that you can have any function right here you can have a function that targets the API from Google to find search results you can write a function that um updates your local calendar a function that sends an email Etc okay so that is the the magic behind all of this and then we got the observation now what we're going to do is we're going to run again our agent and this time we're going to pass in the observation to it so let's say that the next prompt is going to be an F string like this and we're going to say observation equals and then we're going to pass in the observation right here and this is the next prompt and this is the next promt that we're going to be passing into our agent right now okay so let's do that let's do that right here and then just repeat what we did right here result equals Neil Tyson but this time we're going to pass in the next prompt which is the observation okay then we print the result okay so its next thought is I need to multiply this by five now let's Also let's take a look again at the messages to see what's going on so we had the system message that we talked about already then we had the what is the m the initial message that I sent to this agent then the first thing thing that it thought is I need to find the mass of the Earth it executed the action then we manually executed the action ourselves and sent it back to it so with this observation right here and now it decided that it needs to perform a multiplication for this so remember this time we do this again and we do not need an observation this time because we're just going to reexecute this thing right here and then chose an action we're going to calculate this and let's let's actually run that so in order to calculate it just going to call that observation again and the observation is this one and then just like before we're going to pass in our observation right here we're going to pass in the observation as an observation and then see the result okay so then we have the final answer and let's take a look at the messages again just to be sure to that we understand everything that happened inside of the agent we had our message system message then we had our initial question what is the mass of the Earth our assistant who thought action and then we ourselves sent it an observation then same thing thought action observation until it found the answer okay now you can see how we can use this in inside a loop okay so all that we're going to have to do now is to create a loop that is going to execute all of this automatically and it is going to allow our agents to to think by themselves without us having to manually uh run uh recall the agent every single time that we wanted to think okay so let's write this Loop that is going to allow our agent to to think gradually until it finds the the final um solution to to its um to its answer so let's do that perfect okay so let's actually run let's actually create this Loop that is going to run the agent uh until it finds the final answer to the question that we an that we asked it um and in order to do this we're going to just I mean I actually encourage you to try to write this Loop yourself I think it's a pretty educational exercise and it's not super hard so what you have to do is essentially call the agent in a loop of a maximum iteration so let's say that we're going to set the maximum iterations to 10 and then we're going to run the agent and we're going to analyze the string that it returns every single time and if it has pause inside of it we're going to read the action that it selected execute the action and then return uh re I mean call again the agent with the observation and that until it has an answer I mean until it returns something that looks like answer whatever or or until we reach the maximum number of iterations okay so let's actually code that I mean please PA you can pause the video right now try to do it yourselves and or you can uh watch the solution right now so um the first thing that we need to do is we're going to import regular Expressions um regx uh because we're going to need to to analyze a string and to analyze the contents of the string and there is no better way to do that than using Rix so let's define first of all our Loop and we're going to initialize it saying the maximum iterations and then our query um okay uh however actually let's just change this name it's not going to be loop it's going to let's call it agent agent Loop there we go and right here we're going to initialize our agent again we're going to call it agent and just like we did before we're going to call it client system and we're going to pass in the system prompt that we initialized up here um and actually let's pass in the system prompt right here too and then we're going to have to define the tools that we're going to have available right here and the tools in this case are going to be the ones that we selected so it's going to be calculate and the other one is going to be get Planet Mass there we go um and then let's just Define our next prompt which is going to be the first prompt in this case which is going to be the query and then let's just initialize our counter to zero okay H in order so that we only run the number of iterations that we that we want actually want to run so let's initialize this so while the maximum uh while we are inside of the maximum iterations we're just going to uh count the iteration and let's actually call our agent so we're going to call the agent with the next prompt and let's just print print the result there we go so we're calling the agent and printing the result this is essentially the same thing as we're doing right here right there we go and once we call once we get that result we're going to analyze that result that we got from the agent so if we have pause in the result that means that it got into an action selection something like this so if we have pause right here we're going to have to find what action it chose and in order to find the the action so if pause sorry if pause in result and yeah let's just set for the action too and then and there is an action inside the result we're going to set the action equal to action da da daada result. group one okay so I mean this is what uh copilot is suggesting here and actually co-pilot suggested me another one in my test so I'm just going to use this other one and mean and I mean of course I mean I'm not great with reject so I all I did was just asked cha GPT uh for the regular expression that is going to identify the action name and the parameter from a string that looks like this so that's all I did and that's how I got this piece of code right here okay so I mean if you're good at Rex you can probably do it yourself um so there you go well this essentially is going to return to us the action name and the action name and the parameters okay um actually let me just show you how that looks so so the action is going to be this one right here and let's call the result something like something like this so if the result is the result is the action calculate da da daada then you have that oops what's going on here apparently we have a problem here so name re is not defined okay so I have to import re and let's just take a look at action and you can see that the action is calculate and then here we have the parameter so it's I mean it's pretty useful Rex to actually just get the name of the action and the parameter that we want just by using this Rex expression okay uh so there we go there we go now we have the action right here and we can just select the chosen Tool The Chosen tool to be the first element of this action array and then the tool input to be the second one right here I'm just going to call it argument there we go um so I mean just to be clear argument is going to be tapping into this part right here and the chosen tool is going to be tapping into this one right here okay so now what we want to do is is check if the chosen tool is within our our tool set that we have for the agent and in order to do that we're going to say if the chosen tool is in tools then all that we're going to do is we're going to execute this so the result from the tool is going to be equal to well autocomplete is not helping me here so we're just going to evaluate the result from The Chosen tool I'm going to have to type it great okay so the first is the chosen tool and then we're going to pass in the argument like this there we go um I mean in case you don't know what's actually going on right here eval essentially just runs whatever code you pass in right here and what the code that we're passing right here is just the chosen tool which is remember calculate in this I mean in this example or it can be get ma get Planet mass and then between parenthesis we're passing the argument that we got from here too okay so essentially this one right here is going to have the result of us executing our tool with the argument that was selected okay now once we have that what we're going to do is we're going to define the next prompt to be equal to and FST string saying observation and then we're going to pass in just the result from the tool and this is essentially the same thing as we did right here um right here okay and now with this observation right here we're going to be able to right so now we have the next prompt and we're going to tap in we're going to say else which is if there is no if the chosen is not in tools we're just going to return an observation saying something like sorry about the tool is no the tool was not found in the in the array or something let's say I have this right here observation tool not found so there we go and okay so let me just go over the whole loop again so far so we are in initializing our agent we are initializing the name of the tools that we have and we in we're setting the first prompt to be the query that we're going to send to the agent Loop and then we're setting we're initializing a loop that is going to call our agent and check the result if the result includes pause then what we're going to do is we or I mean if it includes pause it should also include action and if it includes these two then we're going to run the ACT I mean get the action name and the parameters then we're going to run this right here if the action if the tool selected is actually within the tools that we have right here so we're going to run this tool and then set the next prompt in the iteration to this observation and if the I mean if there was an an error during the completion and for some reason the language model returned an action that was not within the specified actions where just going to say that the tool was not found in order to actually to try to make it um think that it found it didn't select the right tool so it will probably select the right tool um so this is the this is um so far what's going on now what we're going to do right now is we're going to print the next prompt just to just to be sure that we're understanding what's happening here and we're going to continue and this continue is essentially just going to exit this it the first iteration I mean this iteration right here so if there is a pause and an action in the result we're going to just run this and then restart the loop which essentially is going to reun our agent with the next prompt okay now if if there is answer in the result which means that we got an answer like this then that means that the agent already found the final answer so if that is the case what we're going to do if answer in result we're just going to break out of the loop so this is essentially just going to um this is essentially just going to tell us that we we have completed the task and we should not complete we should not go over more iterations in this Loop and this is all actually this is the full loop let me just zoom out a little bit so that you can see all of it and yeah I mean this is essentially all that we have right here so we have we imported Rex we initialized our agent we selected the tools that we have available we called um I mean we said that the first thing that we're going to call our agent with I mean the first message is going to be the query from our agent Loop and then we run all of this iterations until um we reach the maximum number of iterations and then every single time we're executing the agent and if in the result we have pause we're going to run the tool and if we have answer we're just going to break out of the of the entire Loop and That's essential so let's say if I did not make any mistakes while uh writing this so let's just let's just run this so we're going to say agent Loop uh we're going to set the maximum iterations to let's say 10 the system message is the system prompt that we defined before and the query is going to be let's say what is the mass of the Earth plus the mass of mercury and all of it times five why not so let's see how it how it goes uh remember that we're using LMA L which one are we using LMA 370b I recommend that you use this one if you're using this for agentic Behavior although it might work for with slower models but with smaller models but um yeah I mean for agentic Behavior I recommend at least Lama 70b uh so let's see how this looks let's execute this uh we have an error apparently Earth is not defined what is the problem here oh apparently we forgot to put this in between in between uh quotes in order to tell it that it's a string so let's see there we go oh good good well okay so that's an agent great so we have the thought I need to find the mass of the Earth and Mercury separately so the action the first action is get the planet get the mass uh of the planet Earth we got the observation the second thought is I have the mass of the earth now I need the mass of mercury got the mass of mercury got an observation the next thought is now I have the mass of both now we need to add them together calculated them we got the observation next thought is now I have to sum both of them and multi oh no now I have the sum I have to multiply them by five executed this got an observation and then we have the final answer which is the mass of the Earth plus the mass of mercury and all of it * 5 is this so well um we have successfully created our agent congratulations for getting all the way here um it was a really fun trip and I hope you enjoyed it uh now you understand how agents work and how the react uh framework I mean the react um uh design works and yeah I mean in in a more robust implementation of this you would not be uh parsing the string like this you would be calling the language model that supports tool calling because as you might um as you might have noticed we did not use any tool calling functionality we're parsing this directly from the text and you may see that this is probably not as robust as it could be uh however some language models and Gro models actually do support tool calling which allows us to get get uh the output from the language model in a Json format and this is of course way more useful because we can get the action I mean the tool and the parameters already inside um a Json object without having us to parse it with with regx which is good but it's probably not as robust as it could be uh but yeah I mean this is just a very rudimentary example just to show you how this works and yeah I mean you have successfully created a a working react agent so congratulations for that and okay something that I told you that I was going to mention is that I'm going to be starting an AI engineering boot camp uh which is not actually just a boot camp that you buy and you complete yourself it's kind of a more more of a cohort where you're going to be signing up and you're going to have a direct uh interaction with me so every week we're going to have live sessions I'm going to be sending you course material Theory and exercises so that you can complete them every week and every week you can ask me questions personally and I will be there to answer your questions to make sure that you get to the end of the program and the idea is that by the end of the program you're going to be able to create any kind of llm application using Python and also with a front end okay so it's kind of a full stack course now this is the first instance of the course and of course for the first instance it's going to be um guided so I'm I'm going to be there answering your questions for you and the spots are limited of course because I want to have a more personalized interaction with you guys so be sure to check that out I mean you it's not open yet you by going to the landing page that I'll link in the description you can sign up for the wait list and you will get a link within 3 weeks when I'm going to be opening the signups um so yeah and right here in the landing page as well you have this nice little button that you can click and actually you can talk directly to me so this one goes right to my phone so if you have any questions about the about the course you can ask me a question here and if not uh I mean if you have a question about the course I mean of the video content you can of course leave it in in the description of the video sorry in the comments of this video and I will answer that too so great thank you for your attention and I will hope to see you either in the comment section or in the course so see you soon [Music] [Music]
N-IYzyi86yY,2024-07-02T08:45:00.000000,Joe Moura | Multi Agent Systems and CrewAI,"good morning everyone I hope you're doing okay today today I bring you a conversation with Joe MOA Joe is a software engineer from Brazil and the creator of crew AI a framework that allows you to create systems of AI agents Joe started a career as a software engineer and transitioned into machine learning and artificial intelligence later on this time he has created his own company that focuses on creating multi-agent systems this company cre AI is backed by some of the greatest and most influential people in the industry of AI so much that Joe himself has become one of the most influential figures in the industry crew AI as I mentioned is a framework that allows you to create multi-agent systems from a very high level perspect persective the systems are very useful to automate complex workflows and tasks in pretty much any company in any industry in this conversation we're going to be talking about the development of crei how he started it and the big revolution that this kind of Frameworks and workflows are going to start in the industry in general this revolution involves the automation of several departments in many companies and the introduction of a new new kind of Workforce with the Advent of AI agents we talk about the deployment of this kind of multi-agent systems to production and some of the recommendations for those who want to start off in this new industry I'm pretty sure that you will find this conversation very educational and without any further Ado I bring you Joe MOA there we go okay Joe thank you for joining thank you so much thank you for having me great to see you again it's been a it's been a while since our last call and um glad to be here to pick your brain about crei the AI industry and what you see coming up in the future of your company and uh the sphere in general I gotta say I love this the the more chance I have to appear in podcast the better because people are start to thinking that I'm an agent myself so that helps well U we we I'll try to uncover that in a moment we'll [Laughter] see you were you were in San Francisco recently right yes uh my life has been a lot of traveling a lot of back and forth for a while was basically like uh when every four weeks I would be traveling to San Francisco right now it's a little less is whenever six or whenever eight weeks yeah have you ever lived her before or I have been a little bit all over the place so um I I used to do a lot of conference speaking back in the day uh thinking back like uh 2014 2013 2012 so I would travel a lot and I spend some time in New York but I I never I never like leave that F year abroad or anything right always him so Pao s Paulo Brazil is where K home is where I have the family and everything I I have no doubts that because of CI I'm going to end up moving to SF eventually it's just like figuring out the right timing why is there not a big enough AI scene in Sal Paulo or in Brazil in general I think like it's starting to trending up you're stying to see like more conferences and more people talking about it and there's definitely like great Engineers that have been thinking about this so that is good but I don't think it Compares what is going on in SF SF is kind of crazy right now like you have like three meetups a day uh to the point that whenever I'm inw I wonder how people get work done in here because like if you if you try to attend every meet up like there's not enough time left yeah yeah I bet it is yeah same I mean uh haven't really considered going to SF but at least moving closer to Paris that would definitely make it more um active in the AI Sphere for me yeah cool I I gotta say one of like the conference that I used to do a lot was a conference called take off conference in Lil uh in uh in France and uh and I did that like three or four years and I was amazed about the community it feels like you folks have a lot going on there I remember that uh leoy Merling was a big like a a big like hub for engineers but uh but yeah that's my extent of the knowledge of the friends culture around the AI startup yeah France has a pretty big culture in AI but it's rather I feel like it's condensed in France it doesn't really uh overflow to other countries I feel not enough probably it's the language barrier I don't know yeah maybe my being all right okay so let's talk a little bit about crei your company can you tell us what is crei yes uh cayi is an orchestration platform for multi-agent systems that's the best way to describe it uh CI started as a framework matter of fact it's a still a framework you can go on GitHub and check it out and people have been using this framework to build amazing things honestly we get impressed with like what people are able to build using crei and uh and then we turn into a company where we on top of keepering building the opers we are also building and shipping solutions for Enterprises that want to use um multi-agent systems all right so in I mean to make it a little bit more easier for people who are not um litera in crei you mean that you're able you allow them to create agents autonomous agents that are powered by AI who are going to be able to complete tasks on their own what kind of automations are there are possible with Qi yeah so usually the way that I try to expl explain to people is like um everyone kind of has used chat GPT and they understand how that works and it's great you go into it you ask it to do something it give you an answer that is not great it's okay and then you through interation you get it to give you a better answer you give it feedback you ask it to make it longer then you ask it to make it shorter then in the end of the day you get something that you really like so that works great but in that dynamic you can see how the user is kind of like a a blocker right like you you gotta be engaged in order to fulfill the task that you're trying to accomplish or writing an email writing a copy whatever that might be so AI agents is basically you allow the llms to do that themselves either by self like inating and critiquing its on work or by pairing this llm with another one so both together can integrate over that work so when you do that you kind of like remove the human component out of the equation and this becomes autonomous and that's how an agent is born now this agent can perform a task on itself you can tell you what it wanted to do and if you give it the right tools it can do some things um a lot of the usual examples and things that we have been seeing in the marketing is all around like research reporting uh data aggregation all sorts of things have been kind of like uh enabled by this because it's basically automations 3.0 right yeah what what kind of of of processes or workflows would you say that are better for this kind of automations so this is pretty cool because we we got access because we're an open seource project we have a lot of exposure about what people are building and how they're building it either because of the community or because of telemetry we understand a lot of like uh what is going on like what works and what not so um I would say that a lot of the use cases that work the best is right now the more text based work so that doesn't involve multi Modo at least for now I think that's going to change this year and also like uh anything that that you would basically delegate to a junior analyst kind of work so let's say that you for example for pharmaceutical companies they do a lot of research that's one use case that we have for uh one of our leads they do a bunch of like research on drugs in order to understand how to better Market them how to better like uh talk to doctors about them and all of that you can basically have agents do all that research read the interviews understand what is happening and kind of like come up with these reports and these presentations and this talking points that you can then use to train your sales team you can then use to train your marketing team and all of that this is just one example but I have seen people automate all crazy stuff even like uh manufacturing processes I think have been uh have been using some crew Ai and has been very interesting well okay so just to I mean to to kind of set a checkpoint here on what CI is you are creating this auton agents who Reason by themselves they iterate over their own prompts to get to the actual best answer that you would get by iterating yourself and then you allow I mean what CI allows you to do is to um put several of these agents together so that they can automate U these kinds of of workflows right that is part of it but the other part is like a lot of what allows these agents to do do great work is like how they interact with like the word and right now it's like apis or whatever that might be so you need to provide the right tools uh you can have an agent basically talk with itself and create a good text but if you give it the ability to search the web and just create websites now it can find content it can get inspiration and can learn from that uh you can allow it to connect your database so it now knows your customers it can search in so I think like tools is another big component and what makes like great agents so what CI is on the open source side is a is a framework that allows you to do all that super easily so any engineer that has tried queri so far came back to us saying like this is the easiest thing like honestly don't compare with anything that we have out there it's so easy to build this Frameworks with this because it almost reads a splain English it's like agent task it's it's Concepts are easier to grasp yeah that's my experience with it as well it's it just makes it so uh like as though you were kind of designing your team of humans actually right exactly that's a lot like what we're doing that is somewhat of the inspiration I think the other F inspiration as well well there there I think there's two things that inspired me there one is rails so I come from a ruby Community back in the day and I useed a lot of raos and raos is kind of like borderline magical for some Engineers some love it some hate it for it but one thing that R gets right is is the idea of conventions over configuration and it's so simple that alos reads that as pain English some of the times uh so I took some inspiration from Ruby and from Rayos on that to make sure that we could we could make some so simple and then as you said I think like one thing that I realized early on is that the people that were putting the best agents together were managers because they understood a few things one they they already had that mental model of like if I'm trying to accomplish something who are the people that I would like hire for this and then if I want to delegate some work how do I set expectations of exactly what I want to come out of it so I think that because managers already have that mental muscle Co off thinking that way they end up creating amazing agents because they create the right agents they create very descriptive tasks they set very specific expectations so um I think that there is a lot of what the inspiration for K ey cames from right so I mean this kind of means that when creating this kind of cruise of autonomous agents one of the most important abilities I mean at least for this high level Frameworks like C ey are more Comm communication skills rather than programming skills am I right I think you are unless you're trying to do something super complex that would involve like a bunch of external tools and all that then programming become like also like a major scre that you want to have but I think like just understanding the problem being able to dissect the problem and then communicate that clearly I think that goes such a long way I still remember the first agents that I created the reason why they worked so well was because before I created them I did it myself and then I took note of the whole process and like what I did when I did what I thought was good what I didn't thought was good so once I had a completely understand of the process was easy for me to translate that into an agent or into multi-agents in that case I see do you have any examples of of workflows that you have seen that work well with these kinds of automations with autonomous agents uh or like the most impressive that you have found for example or the most useful that you have found the most all right so there are a few different answers there uh we have a few very useful ones so one that we use internally and we have customers that use as well and they really like is around sales that helps a lot because in the past how sales works is basically like you get a you get someone that might want to buy your product and usually you learn about them because they fill the form so you have some information about them you have their email or you might know like what company they work at but that's basically it so in the past what people would do is they would enrich this data they would basically like buy data from companies like clearbit or um or other companies out there that sell data like some for now that in order to get more data about this potential customer so they now would learn well where this customer is based how much money they might make and all that and with that information they would then would do what they call lead routing so say like all right so because this person fits kind of this profile I'm going to delegate it to Alejandro because Alejandro will know like how to uh how to handle them here is an expert of this kind of like business uh and that's how things have been working in the past but now with AI agents you can do so much more and we use that internally and we have customers that use this as well so as the lead as the potential customer fuse the form and you get that information I have a few different agents One agent research that person online the other one researches the company online another one looks at our existing customers and try to find common customers similar to this one another one look at the things that we offer and try to find the vendor diagram between the things that we offer and this customer potential needs and then another one basically come up with talking points like hey when you sit with this customer these are the things that you should be mentioning giving like where they are their recent news their data their use cases and all of that and you can go even a step further and in case of crei we do we have we have this agent right initial email that we can then choose if we want to use it or not but you can see like how this make the sales process so much better because now you basically can you can still have like your salese as you would but now they have the two that basically give them way more information not only about the person but like what they should be talking about and anything else way more than what he used to have before well that's I mean practically it is kind of a team of humans that you just created out of thin air right yeah in some sense is that yeah and the cool thing is that they are saving like a lot of time for example we we we right now at crei on the business side there have come somewhat of champagne problems uh we have too much inbound there's too many people their interest into uh paying for K plus and use it so it's important for us to kind of like understand and pick and choose at least why are we don't want everyone using and to select what are the companies that we want to work with at this first point so that we can test it out so uh this helps us to do it in a scale that would take us like dozens of hours to do ourselves like we would need to research every company take notes on every company compare them with existing companies this this would take hours for someone to do and this group of Agents can do in a matter of a few minutes well and I mean this is kind of a new uh way of thinking about applica software and automations how did you start developing this kinds of this kinds of um of framework what how did the idea came to you well I guess you're right this is kind of new kind of software I think like we have regular software that we have developed it so far and we have this new category that's kind of like AI software that is very different from what we used to have so if you think about regular program in and regular engineering we basically had strict inputs strict Transformations and then strict outputs so you would have like very strong like typeit inputs you would know this is a string this is an integer then you have like a very specific set of rules you know like this is going to be multiplied or whatever and then you're going to have a very clear understanding on what's going to come out of it but if you think about AI applications in general and multi-agent systems is one of these applications it's the exactly opposite you have fuzzy inputs so you don't really know what is coming in you have fuzzy Transformations you don't really know what the llm would do with it and you have fuzzy outputs so you don't really know what is going to come out of it but I think people love that because that application like can help you do things that regular applications don't for example chat GPT fuzzy input the user can type any you don't know what they might be typing might be a math operation might be a text might be a code might be a table data you don't know then the GPT is going to do something with that and you're gonna have a fuzzy output basically a long string so when you think about things that way people love it because of that so it's basically a different to allow you to do something different and I think there's a place for it um but sorry I didn't answer your question your question is how I start to develop the framework right right so um I was doing AI since 2017 uh I thought that I was late for the game uh little little I know uh I was doing I was doing a lot of regression and classification back then uh llms were not such a hit um and I joined CLA bit on 2019 and in clearbit I was basically a director of AI engineering so I was basically hiring people to be this platform uh for Enterprise back then and with llms kind of like coming out of the gate and taking the word by the storm I was spending a lot of time rethinking our systems and rebuilding them using llms and that was such an interesting work especially back like 12 months ago there was not a lot of people actually deploying systems like this in production especially not at the scale that we were doing at at clear bed uh was honestly impressive scale back then and um and people were just like people are just like wow this is so interesting so my wife came to me and said why don't you why don't you share more about this online she's a very wise woman by the way and she was like why don't you share more of this online uh why don't you make like posts on LinkedIn or something I was like all right uh I'm gonna give it a try turns out I suck at it I'm great at cheat posting an ax and I can do all day but LinkedIn it's kind of like you want a well format idea right so uh that that was not as easy for me so instead of doing it I did what what any engineer would do I automated it I created a few agents to do it for me uh and those are my first agents I basically had four agents that would write me I would put their my refi IDE in and they would basically transform into a fully flagged LinkedIn post and I love it and worked so great I got so many views and like things are doing so good that I got I got hooked I was like I want to create more agents I want to automate my life away so um so that's kind of like what prompted me to to think about I want to create more so how do I do it I looked around that the tools that we had back then uh basically out of gem was the as the main one and that that didn't work for me I was like this is too much of a steep curve like what is an agent manager proxy whatever I was like this is not it I'm not this is not what I want I learned later that the AO gem comes from like a research paper so that makes more sense for me some of the like decisions that they made and how they did it um but I look at chat daav and I really liked it I was like oh chat daav is cool but again it's kind of like more experiment it's not like a software for deploying production so I didn't find anything that did what I needed so I put together myself and that's how C I came to be and when was that exactly the thing I mean when you started creating the first agents for LinkedIn which year was it uh I started Crea my agents for LinkedIn last year um around October I want to say because it was it was my anniversary and I remember I was traveling with my wife and what I would do is I would wake up super early so while she was asleep I would do some coding and that was that was how I buil the first version of gray eye oh that's just impressive and how did it start taking traction did you already have like a network in in like the end in the AI scene in Silicon Valley or how did you how did it start taking off uh not not really I think that um I think a lot was like people really liking it people really liking it and I I had some people that I knew in the valley just because I have been working remotely for companies in the US for the last 10 years so a lot of companies in New York and the valley so I have friends I have people that I know but definitely not enough to make like a huge influence like like Ki um but I think like people just start to using it and then I think in December things had a big spike and then in January had another and and then we have been growing steadily since then has been like nonstop um I remember that back in the early days like we would have a few people try crew and now there's not one single day that goes by that at least 880,000 crews are executed even on weekends and stuff it's it's crazy honestly that's amazing well congratulations for that by the way it's an amazing job thank you awesome I really appreciate that and um let's talk a little bit as well about the design of the of the software I'm interested in how you told me that you got um some inspiration from Ruby on Rails um thinking about the main abstractions that you have created for your Crews you have if I am correct please correct me if I am not um you have tasks agents tools and then you have the processes that you are continuing to to develop uh how did this uh abstractions come to mind did you get any inspiration from any other orchestration Frameworks or was it completely your idea because it sounds very very very simple and very powerful yeah I think basically it it what made sense for me because I had initially when I buil my LinkedIn agents they were not crei agents they're just like agents that I coded manually so when I was trying to convert them into something that I could reuse I was like well this feels like people and tasks and actually a lot of the work that I did is still back in this in this whiteboard here this is like this I need to clean it up this is from back of September October uh was basically me trying to understand like how how will these things work so was a lot of like writing honestly playing with different ideas uh I think one of The Inspirations was um was chatav and their paper um I really like this idea of role playing and how they prove it that role playing can make make a huge difference on the output so if you have an llm that uh is pretending to be a CTO it's going to behave in a certain way and it's G to answer like uh questions differently and I I put that to the test and I was like all right this this makes sense this works so um I think that's where the Roop playing aspect of it came and then uh and then was a lot of like experimentation honestly I think a lot of what we do is experimentation so we have have like benchmarks so whenever want to try something new we kind of like addit the framework and then we run a full Benchmark that basically execute this 300 automations so 300 Crews and compare the results between 150 and 150 when without using the thing when using the thing and we see like all right is this better is this worse um so we try to be uh to take a very scientific approach on what we add and what we don't add awesome all right and in in all of this scientific approach that you are I mean when you're developing it what would you say that has been the most difficult part to to develop in your framework so far I think like the beginning is very easy because it's Green Field right so it's simple for you to add things but later down you start to have like this tough decisions and any like as any Legacy or like no Legacy but as any code that grows uh you end up finding yourselves in conflicting situations where you're like do I break this in order to add this new thing how do I make sure that I still support this for existing users so I think a lot of that like starts to happening as you grow and as you launch new versions uh uh I think memory was a thing that was harder to add than I expected um I would expect it to a little more simple but there's still work to be done there I think there's still things that need to improve in memory uh let me see what other feature was kind of like tricky to add uh well on the Enterprise side things were way more tricky because on the Enterprise side is where like we got a bunch of the work to kind of like allow you to basically bring your Crews into production and that was tricky so uh that was I got to say that was that was probably the hardest part uh of so far even more than the framework itself um but yeah we have so many ideas honestly it's like we don't share the road map publicly but if people knew I think people would go crazy about some of the stuff that we were going to ship this week not this week this year sorry I bet I bet um I bet I'm sure that um I want to ask you as well a little bit more about the the Enterprise offer that you have but before that I'm interested in what you said about memory what was the most uh what was the difficult part of integrating memory into agents so it's just about integrating it's about like finding like uh memory has a purpose right memory is basically not only storing content but also then retrieving content and then why do you store and why do you retrieve and then when you store and when you retrieve um so for example let's say that during the execution while your agents are working together you wna you want to have a shared memory among them that's how CI works so you have a shared memory among all our agents yeah so what happens is when do you store the memory and what do you store in that memory do you store the progress do you restore the final result do you do an extra l call in order to extract learnings and then you store those learnings do you do all of the tree uh and then if you do it when do you do it do you do it in the end of the task if you do it you want to probably do as a background process so you might want to use mood trading so the crew doesn't take longer because you added memory now but then if you're doing mood trading what happens if the next agent wants to use that memory but that memories is still being generated or written uh and then like when you retrieve this memory what exactly do you retrieve do you want to do rag over it do you specifically like search so you can see there's a lot of different ways that you can cut here and um I don't think there's one right or wrong I just think like you need to again you need to test it like on a scientific process you need to test it like what works if I like write a summary if I write the actual output if if I try to do an extra call and start the learnings so there's a lot of different ways and lot of different things that we played with in order to build long memory short memory and entity memory within crew AI um and honestly I I'm very convinced that there is room to improve there I think it's doing great and we can notice the Improvement already but I think there's room to make it even better yeah amazing yeah and I mean memory has always been uh difficult part to integrate with LM applications right and everyone seems to be doing them differently or there there seem to be so many ways to do it that finding the correct one for specifically your purpose is not always an easy task right and the other thing is that like what is my purpose right because we're a framework so there's many people that are building different use cases on that so whatever we do like it must be like somewh generic that works for everyone uh or we need to take a a very strong stance and say like this is the way that we're going to do it and it's not going to be great for people doing X or Y but it's going to work for everyone else um so yeah we I believe that one thing that has been serving as well and we're going to probably keep doing it is just have like be a very like very opinionated about how we want to do things I see all right well I'm very eager to see how that comes about um talking about I mean we have already explored a little bit about how crei works and how it allows you to create your agents locally to to automate pretty much any kind of tasks that is a bit step by stepwise in your workflow but once you have these agents in a local machine how do you deploy them to production how does crei help you with that honestly that's a big piece that is missing out there and we're trying to fix it as as well so if you think about at cre AI or any of the other Frameworks that you have out there uh what you end up doing is you develop those and now you have something that runs on our computer so it's either on your terminal or maybe in a UI but you see you see it working there is not much value on that unless you can I mean there is value on that but the way that you multiply that value is by being able to integrating that with existing software regular software that you might have either UI or API or whatever it is so that's part of what we offer on crei plus so the idea there is uh there's a bunch of features but I think the main feature that people really like is this idea that you can turn your crew into an API in a matter of minutes so you don't need to change anything on your code you put your crew together you push to GitHub you go into the platform you click a few buttons to make sure that you select the crew and you click deploy there you go in a few minutes that is now an API behind SSL with auto scaling and a private VPC production grade you can basically Now integrate that with anything that you want uh and then you didn't have to change a single line of code so that alone like it's super helpful because it kind like Fast Track the experimentation to production phase and that's what people really want especially like companies they're trying this out most F Engineers don't necessarily care about it because they're trying it out but once that you go to production use cases where you want to be making money of it this is a major feature we're like hey all right now I'm willing to pay for this because I'm actually going to bring this into a production environment I'm actually G to make money from this and whatever it might be um so that's one of the main features but there's so much more like we have a bunch of templates that you can deploy in one click there's like so much that we are building in there wow that that sounds really impressive and yeah I mean this step from experimentation to production is probably the most expensive one actually right because I mean for experimentation you pretty much need uh prompt design and for deploying to production that requires some very very tough skills for mlops and server management and all that is am I correct exactly like if you think about it like you could still like do this without crei plus like yes but then how many people we would need and how long would take for you to figure out how to convert that crew into an API then set up server then deployment then CI then CD then monitoring then have people to monitor that then keep things up to date like that can be a problem right so uh we basically like we we take all that for you you don't need to worry about any of that and it just works um so I think that's a that's a big component out of it yes and yeah goes a long way wow yeah and all of that is also makes me think that it's not only geared towards software Engineers but also towards General U Managers from other companies that would want their processes automated that and they would be able to automate them without creating a machine learning team within their company am I correct or or is that an error no you are correct honestly like cre I believe crei is simple enough that you don't need to have an AI engineer to use it like regular software Engineers can use this and deploy AI applications within their companies without having to worry about it uh and the cool thing is that we're also shipping the UI uh say the UI that allows you to build these agents without having to do any coding so I think that's going to be another big unlock because now imagine that you can go into ci+ you can build your agent using this UI you can click deploy and they are live and you don't need to do anything about it so this can be like super useful and you're going to probably be dropping that UI in the next 30 days and because I know that the community is super excited about it we're going to probably allow anyone to use it it's going to be a it's going to be probably part of a premium account so that anyone can use the UI because I think it's something that everyone should get access to well that that's super cool and yeah I mean just to to be clear that the people listening to this understand this um because so far in order to use screw aai you have to code you have to create your classes you have to you have to know a little bit of python in order to create your automations like this uh would that graphical user interface allow non-technical people to create their automations or or not yes actually you would need to code at all you can just like click and create your crew and click deploy and it's going to be live and there's more features that you're are building on top of that is that I don't want to screw up the surprise but uh honestly it's GNA be so cool but yeah people like basically without any like coded knowledge will be able to deploy this cruise and what we are finding is that because we made it so simple on crei like the syntax is so simple what we are learning is that a lot of people that never coded before is actually working with the library and writing the python code uh because it's so simple to do uh we have like two people in the community for example and I was amazed about it they used to work on uh design agencies and they would basically do work for like other companies as members of these agencies but they they're not Engineers they're basically researchers in that and they using crei they build a fully flaged research crew that can go online research articles uh research news put together report fors and now they're selling that they're making money out of it because uh they have the crew that does the works for pennies and they selling it for big Brands uh last time that I checked I think they're selling to like companies like Almar and such it's it's honestly it's amazing yeah that's that's super impressive and yeah I mean this shift from code to a graphical user interface will probably make it a super powerful tool for pretty much much um anyone in in any business that's okay um very disruptive I have to say awesome I'm excited for it yeah um about that um tell me also I mean we have covered a little bit about CI plus but just to summarize what it is can you please answer the question what is crei plus CI Plus is an Enterprise offering on top of cre framework so it's basically uh four different things one it's a platform so it's something that you can log in into and in that platform you have access to a few features between those features among those features is the ability to deploy your Crews and you can turn them into apis you can turn them into react components you can do a bunch of them uh on top of that there other features in there you have templates that you can use you're going to have the UI and they going to have a lot of other features in there then the other three pieces are more geared store regular Enterprise contracts that imply you have support so all these open source projects out there they're great but what happens on a random Friday when things go offline who do you call if you're on an open source maybe you jump in a Discord you ask for help you create a pro request whatever it might be uh what when cre I plus you actually get proper support we have a support team you're going to be able to call us you're going to get us online you're gonna be able to help you um then there's the security part you got things like single signon you have SLA you have everything that you need in order to bring those things into production and then one the final piece is this ability to have access to our team and this is more for like the high-end plans people that are really going like for production and like they're going to be pay a lot of money for CI plus to get into that but that's like when you get what we call implementation partner so that is basically access to people on our team senior members from the CI team that will help you a few hours a month to figure it out how to implement how to think about this how to break this concept it's a very interesting offer but again it always Builds on top of the open source uh we internally we use the closed version of crei that has a few things that we need in order to make all of that work but it's based on a fork from the open source so the open source not going away anytime soon that's good to know yeah and okay so about about that I am um interested in the support part that you that you mentioned um does this mean that if you have a company um because some companies do not really have a tech uh um um Department maybe they might they may have one person responsible for the tech side of their company right um and we also mentioned that this offer would allow you your company to automate your workflow without having a machine learning team which would be ridiculously expensive um how many people would you say that you need in order to collaborate with this service that you offer on Ci or do you not I mean can you do it without any tech people is a manager a regular consultant going to do the uh going to be capable of interacting with the crei team I think it depends on how technical you want to get like how how custom is the process that we're trying to automate right if it's like as long as it's not to to technical you might not even need to be a tag person if you have the UI but if it's like a very specific specific technical implementation there is internal rag there's internal connections to databases and all that then you're going to need an engineer doesn't need to be an AI or an ml engineer can be a software engineer but you're going to need them um so yeah that's kind of like where it drown the line I think in the end of the day it's going to probably be something that uh Engineers teams will use to build complex automations and then they going to have smaller departments like sales marketing and all that and simpler ones using the UI all right awesome okay so in short I mean in summary about that does that mean that um a company that would like to automate their business using RI uh the orchestration framework with uh the graphical user interface would go from having a machine learning team to hiring a single Tech person who will be able to collaborate with the CI staff who would would in turn imp do the implementations and the the deployments of all of these automations am I correct there yeah that could be one way to roll it yes awesome that's wellow that's going to changeed a lot of things uh in the indust in many Industries I I suppose um can you give me more examples of places where this kind of automations could be useful because you mentioned in sales which is uh uh for what I see extremely useful you use it yourself uh which other examples do you see people applying this for yeah I think it's very much a long taale where you have a few areas they're very like people using it a lot and then you have like this a set of like small use cases and custom use cases that people use it um other than Salos marketing is another one that we see a lot of people using it um again during research on the product research on competitors sorry about that so research on uh on the product research on competitors uh finding out all the commonalities thinkering about positioning then writing copy creating content so Marketing in general has been another great use case from like generating newsletters to generating blog posts generating Instagram posts and not only generating the content like you would do with like Reg jat GPT but tying that with doing the research with looking at your data with like everything that would come before that that would make like a very good end resuit something that you wouldn't get for free if you're just using like cat GPT um so marketing is another big use case and development is also trending up so uh we use it for development uh locally as well for example uh the documentation for crew aai all the docks of crew AI right now are by a crew like we don't spend like time riding docs ourselves uh so we basically we update the code and then we have a crew that'll do rag over the code rag over the docs see what is missing and update the docs to include it and that's [Laughter] it there you go uh we're going to probably make that a template but yeah writing documentation is like something that we don't do anymore unless when it's like a brand new feature that like there was no previous documentation about then we kind of like start writing those offs but like updating docs with like new attributes new features added we don't do any of that uh and even the bench mark that I mentioned like how we compare new versions of Crews with old versions of Crews we actually have a crew that does that so the crew look at the result score it look at the other result score compar the both and elepant all right wow impressive um some something else that I wanted to ask you about this this software that you have um and it is probably um among the most important ones is about monitoring and observability is that taken care of by crei Plus or do does the company have to incorporate their own observability service how does that work so right now if you look at the market uh the way that look at observability is I think that is such a complex problem itself especially if you're trying to do it well I think that can be such a big component that we just are not spending much time with it so what we find is that people are usually deploying their Crews using agent Ops or lsmith in order to do observability uh we do have metrics and we do have logs that we show to you and we allow you to see like what is happening and and the memory and even like are looking to allow you to replay certain steps so you don't need to replay the entire crew but um I think they're right now they better tools out there they're dedicated only to fixing that problem they're doing great work uh like Lang Smith and agent Ops so uh so yeah we're not we're not really trying to fix that I don't think that you would necessarily need them to get going but uh but yeah it's something that you probably will want if you're bringing things into production settings I see I mean just for the listeners agent Ops and lsmith are two tools that allow you to to monitor your agents and to see step by step what they're thinking about and how they perform the action so that you can debug your own prompts am I correct with with that description or do you have something to add no you're correct I think agent Ops is more a specific to uh geared towards agents and Lings Smith is more like gears to any l m application but yeah you got on point basically monitor your llms your prompts your uh your calls and give you metrics on all of that all right thanks and um okay so we talked about uh crew AI the open source project we talked about crew AI plus the service that you that you proposed to companies that allow them to deploy their automations without having to create their own machine learning team which would probably be too expensive um and taking advantage of the expertise of your team um now that is going to be I hope very disruptive um how how do you see the world I mean the the industries in general uh changing in the next few years with the implementation of these kinds of automations with agents running parts of people's business I got to say I believe that uh even even if you look at cre AI itself like our business is partially operated by agents like we have agents riding docks we have agents helping with sales so like we we have more agents Than People employed on our team uh just because we have so many of them doing so much stuff so I think like this is a reality uh coming no matter what but what I'm finding from uh the leads and customers that we are working with is that the the ones that do the best are the ones that frame this as not replacing humans but you're promoting humans to now manage these agents so now agents is just like another two in the two set similar like a bunch of like very highly skilled and fast inters so uh basically you have like this people now managing this agent and say like hey let's trigger this to do the research let's trigger that to do the report but the humans is still kind of like packaging things up thinking about how to presenting putting these things together so all that is still happening um and I I think like the companies that doing it that way are probably the ones that are benefiting the most right I I see that as a light at the end of the tunnel at least for the people who are who are pretty pessimistic about AI replacing humans in many jobs that means that we're I mean do you think that does that mean that humans are not going to be completely replaced but rather they are going to be able to make to get more done am I correct in that or do you think that there are some people who are probably not going to have a job at all later I think both are true I think people people that are going to still get a job they going to be able to get more done faster and similar when you introduce any other tools like even going back to Industrial Revolution like we're just going to be able to do more with less uh but yes there's going to be people that are going to lose their jobs due to AI for sure and I think we as a society we need to figure out what that means and how we're going to go about it and I know there's all sorts of interesting ideas um like a uh Universal income is one of them and there are other ideas out there and how like you could address some of that I think like this debates will need to happen way faster than what they are happening right now because I think we're not too far from people like actually like uh Missing jobs because of that I think some of that might be already be happening but it's just like not at this scale where like people are really worrying but you can definitely tell that companies are start to wondering like all right how how much can I automate with this how can I deploy this and how much time can I save and if that free my people to do something else that's great but then the next follow-up question is that like do I need these people then so um I think it's something that need to be mindful of I think both statements are true people that work are going to be able to do more with less and other people are going to probably have a harder time to find a job this sounds like a double HED word to me because that would mean that some people who are not precisely the entrepreneurial type would have it harder to get going especially if they are not into the AI scene and some of the people who are creating projects will be able to get things 100 times faster right yeah 100% like if you again I just gave you an example a few minutes ago of two people that never coded before and now have their own thing and they're making money on it because they're using AI agents not everyone is a fast learner like that like not everyone's going to be able to catch up so fast people that do will have better opportunities and will move super fast and people that don't were definitely going to take behind right yeah it's going to be up to our societies to find a way to to help with that um change of age in some sense right because this age of automation is probably going to take a lot of people um uh without expecting that yeah 100% I think there's going to be honestly intense debate around all of this and I think we're already seeing some of it happens right Congress in the US has started talking about regulations on AI and all of that so uh and also EU is taking like a very strong instance on like Ai and how training data and all of that uh and training data is just like one way like to try to protect and preserve rights from like people that do artistic work in elephant but there's like there's so many other components beyond the training data right uh and how you can actually deploy these agents and these AIS so yeah I think it's going to be an intense debate as anything in the word right now but uh hopefully we as Society find a way to work around it yeah hopefully uh let's uh make it our job to to try to make it as smooth as possible this transition but yeah yeah it's probably going to be very disruptive and I mean uh that's probably a good thing um because we're going to be able to get much more done and to in the process help a lot more people as well I agree I agree I agree honestly I think I think overall is going to be net positive for sure that's my hot take um what other hot takes do you have about this uh kind of scene uh I think think AGI will come sooner than later um I know I don't think it's I think sooner than later I don't think it's GNA be in the forms of Transformers though I think it's we're gonna need to figure out something else but I think it's G to come sooner later I think right now we got into a stage where the incentives aligned where like one you bridge the gap between software Engineers entrepreneurs and Ai and ml experts because now everyone converged and like the wall that used to keep like people separate now it's has a big hole on it so these people are talking and then two all that is generating a lot of money so because generating money people are pouring more money into that so you have all the right components in there it's just it's just about giving it time and mixture in the right way and you're gonna get some stuff that's going to be amazing so I don't see the development Pace de accelerating anytime soon what give me uh what makes me think that AGI is not too too far along if keep things the PA they are and about this this position that you have I mean this this um idea that you have about AGI I'm interested as well about your your background I don't think I asked you before what you studied um if you're more on the side of machine learning or did you have um because you told me that you had experience with Ruby on Rails do you come from originally a software engineering background I come originally from a software engineering background uh yeah my my personal life has been a lot of like learning different things uh so I I started programming super early uh I started learning Visual Basic at the age of 12 and uh I never stopped since then so um I learned HTML then action script then I started to play around with fireworks Dream Weaver back in the day freehand um I'm probably giving away my age here but that was some of that and uh and I never stopped since then so my background is definitely around software engineering um and that's what I did for most of my career um a lot of like some of PHP some Ruby some python a lot of Elixir actually um then all the front end stuff and yeah that has been a treat uh I enjoyed every single language that I played with so far and then again I joined the AI game in my mind what was late in 2017 uh where I actually start to do regression and classification models with python and psych learn and Pyar and all that and uh and yeah super super interested on that as well all right and yeah I mean so can you tell me more about how what would you recommend for a software engineer who wants to transition into the AI business well I would say there's one there's a lot of content out there so that's good people are putting content on a lot of different stuff so if you want to learn something you can definitely find on YouTube for sure um the matter is if you find in a way that is easy to digest and easy to learn so uh without giving away too much by the way quick question when when does this podcast drop when people will know will hear it um probably in a couple of weeks or three weeks all right so by now the multi-agent course with Andrew in and myself will have dropped so um you if you want to learn about AI agents specifically and multi agent systems specifically I would recommend that just because it's very like from the beginning you know nothing out the way to like I want to put like this very complex use cases together um so I partner with urang and uh in the Deep learning AI team to put together this course and uh it should drop on May 15 unclear Let's see we are really rushing it but um but yeah we did all the recording and now we're putting together the final edits and everything so this is one research but again this is only for multiagents like there's so much more around AI that you could learn uh you can learn regular like regression classification there's a lot of value on that still so I would recommend checking out anything around psychic learn for that uh definitely recommend you get familiar with like some of the most common Library Pi python libraries that helps with like AI in general things like Punda and numai and uh and then yeah any of like the the new fence AI applications that we have floating around things like Rag and all of that oh okay so first thing for the course that you mentioned uh would you mind providing a link so that I can add it in the in the description that could that way we can sync the the the publishing of this interview with with the prase of your course that sounds pretty cool uh when the course drops I let you know I don't have a link Because deep learning AI is doing other things it's going to be on their platform it's going to be free uh so uh they I'll let you know yeah I'll let you know once they when they give me the link but yeah it's it's a free CSE on deep learning AI if you you probably if you're in this podcast you probably know Andrew Yang but if you don't he's one of the founders of Cera and he is the creator of one of the most famous courses on AI and machine learning ever um a matter of fact he's hard to talk to I got to tell you uh it's not everyone and that sometimes it's like just visiting the White House so uh I gotta tell he's a he's a big deal and was was great to work with him on this and I'm super excited there's going to be a free course explaining everything about multi-agent systems uh the examples are going to be crew AI but the course is not about crew AI the course is about multi-agent systems what is an agent how to make them work everything about it awesome okay so whoever is listening to this please be sure to click the link in the description if you're interested in that I'll try to get you uh to that course as soon as possible nice and second thing uh about the the the road map that you would should take if you're a software engineer in this case you mention that someone would probably need to know the basic machine learning algorithm and the basic machine learning models in order to to transition into an AI engineer is that mandatory or is it all right if someone just understands how to use a large language model API no it's not mandatory I think we're past that uh as long as you can as long as you learn how to use llms you learn the apis and you learn some of the most important Frameworks out there so crei linkchain LMA index that should allow you to do anything that you need uh a good way to compare is like U I don't know you can do you can do great programs using like Python and Ruby without necessarily understanding C for example that is the compiler of python so you don't need to learn C in order to Learn Python and use like jeno to build an amazing framework so this would be a good comparison like right now like you can learn the higher level abstractions and you can build amazing things with that without having a deep understanding on what is happening behind the scenes I do believe that if you learn what is happening behind the scenes you tend to be better at it just because you have like this mental model and you know like what you're like what what you're writing what is going to be the impact of that but uh but I don't think one should or must learn I think no one one should and must learn sorry let me grab this one I don't think one must learn it in order to build amazing applications and become an AI engineer I do think there's benefits in learning it but I also understand it's a big undertaking right all right that's that's very interesting thank you for sharing that um and last uh last last couple of questions that I wanted to ask you uh more towards um the career of my of the listeners of the podcast what if you were starting off today do you think is it too late to get into the AI scene to start a business in the AI scene because you mentioned that 2017 felt a little bit like too late uh do you feel like today it is too late to get into the AI uh software hell no so I have a few I have a few things that I have a strong beliefs in and one of them is that time's going to pass anyway like if you think about oh it's G to take me a year well guess what this year is not going to stop it's not going to pause the year is going to pass anyway like the two year three year four year whatever it might be your time frame to learn something that time is not going to wait for you it's going to pass anyway so I think what you need to ask yourself is like hey one year from now what I what I would wish I have done and that's what you should do like even if you think about hey am I'm going to have a job in a year from now I know a lot of people like are wondering about that like how this will impact myself my career in Nan honestly we have way less control over our lives than what would like to believe we like to believe that we have more control but in in matter of fact we just don't you don't know you might be crossing the Tre Street and buz hit you so what I would say is what are the things that you do have control well you have control about the things that you use and the things that you learn that's within your control so think with me independent L of like what happens to the market will you be better off by learning these TOS now or not and I strongly believe that you're going to be better off if you learn those tools now because whatever happens to the market I think who knows these TOS who had familiar with them are going to be better positioned to the Future than someone that don't so even though you don't have control over the market and the conditions and the companies and all that maybe use the levers that you have your control to make sure that you're setting yourself up for Success okay that's that's pretty interesting advice and very useful advice I'm sure um so it's never never too late to get into to get into this amazing I mean I usually say I usually say like sometimes when I miss a date that I think that was important for example I would say well I wish I had start learning AI on Twitter 2015 but I didn't well I guess I would need to do the second best time and that's now right because you're already missed you missed the best but now you have the second best that's right now so don't yeah like just like like investing the best thing to the best moment to start investing was 20 years ago second best time is now exactly awesome and this is investing this is investing in yourself indeed indeed probably the most important type of investing that you can make um and last um uh question in this in this topic uh if you were starting of today what kind of company would you would you create o honestly I would create crei again uh someone like when I was when I was like um deciding making K into a company or not um a good friend of mine asked me a question he asked me uh like hey you know that if you start this this is something that people don't realize when you start a company especially like if it takes traction or if you raise money there's no way out for you everyone can fire can quit can leave you can't so this is something that people don't realize so this person asks me like hey are you sure you want to do this because you're going to be doing AI agents for like 10 years that's like that's like what to start to comp is and my answer was so ready I was like what else would I do like honestly think about this if I was not building crew aai I would be building agents for another like company and this is just the way that business are going to work in the future so whether you want or not you're gonna be building agents moving forward and you're gonna be doing that for different companies so I I would rather be building this platform rather than anything else so if I had to start something new I would start C really all right so agents it is it is the the topic of the of the decade probably it's what I'm going to be doing for the next few years probably the next decade so you know where to find me awesome I can only wish you the best for that thank you I really appreciate that awesome um all right so we're getting to the end do you have any other things that you would like to share um I don't know maybe some teaser teaser for new develop that you're um that you're doing or something else that you would like to mention let me think about the features that we have on our road map and one that I could tease people with all right all right I don't know if I should share this one but I'm gonna do it anyway uh but I'm not gonna share it all I'm just gonna hinted so you build you build your crew right your crew has has a bunch of Agents on it they're going to do some work and that's great sometimes they're not consistent though if you think if they were human what makes humans to do more consistent work well I guess you could train them I'm going to leave at that all right okay that sounds interesting sounds like you're G to give some sort of personalities to your people let's see how that let's see can't wait to see that coming out it's not too much but I can tell you it's GNA be pretty sick once people see it all right awesome okay I'm sure that that'll ring a bell then when it comes out so people who have heard this awesome well um uh that's pretty much all for my questions um thank you thank you very much Joe for joining the podcast and it was an absolute pleasure talking to you you're a wonderful person thank you so much thank you for having me thank you for everyone listening if you're using CI honestly goes without saying but I'm so thankful for you honestly it is a lot of work building this but it's so much fun and that's because you use it so uh I don't take any of this for granted I really appreciate the fact that you're using CI and they're having fun with that I'm super open to feedback follow me on Twitter I post a lot in that about crei and send me notes if you find any bugs or anything just shoot me a message and I'm gonna reply to you for sure um and yes I really appreciate all the community thank you for everyone on the crei team uh and that's it awesome thank you Joe amazing talking to you thank you"
gXET04dJ66A,2024-06-12T18:00:30.000000,CrewAI + Exa: Generate a Newsletter with Research Agents (Part 1),"okay so we have the first one we have the first thought the first thought comes from the research agent we can see that he used the search and contents tool and what he thought in order to get here was to find the latest and most relevant news about the USA stock market I should start with a broad search query using the search and queries tool and the query that he searched for was search news good morning everyone how's it going today welcome back to the channel in today's video we're going to be talking about how to create a crew of AI agents that is going to create a newsletter for you this is interesting because we're going to have a team of AI agents that are going to coordinate themselves talk to each other and they're going to research the internet and give us a summary of the most recent news about any topic we want so that we can create a newsletter about that and send that to our subscribers okay it's going to be kind of an automation that's going to replace a very rudimentary team in our marketing department um so in order to do this we're going to be using crei uh if you have been following the channel for a while you already know how crei Works a little bit but in case you don't crei is basically just a framework that allows you to coordinate how different AI agents work together within a workflow so you're going to be able to have several AI agents each one of them with their own expertise and they're going to be able to work together in order to solve any problem we want in this case it is going to be creating a newsletter and we're also going to be using EXA which is a service that allows us to search the internet um in a very different way from Google and a way that is actually more useful for language models because they do not work on keywords but they allow you to search by meaning which is precisely how language models think so this is going to be super useful I'm going to show you exactly how you can build research agents using EXA how you can create tools for your agents that use EXA and yeah so I hope that you find this useful and oh yeah and by the end you will also have a graphical user interface that you're going to be able to use um so that you can use this yourself with your clients with your uh Team your co-workers Etc so yeah uh this is going to be awesome thank you for being here and let's get right into this [Music] [Music] all right so the first thing that we're going to want to do is to create our cond environment and in case you don't know what a cond environment is a cond environment is basically just a virtual environment that allows you to contain all of your python dependencies for a single project it will also contain the python version that you're going to be using for this project in particular in case you don't know how it is installed you can always click the link in the description get it installed and then continue with this tutorial uh so the next thing that we're going to do is to cond create and then we're going to do D- name and then we're going to name our content environment in my case I am just going to name it crei and then you're going to say python equals and whichever python version you want to work with going to hit enter and I have actually already created this content environment but to you it might take a little bit longer uh just follow the instructions for that uh once you have it created you're going to be able to do cond activate and then call the Conta environment that you had previously created by the name that you gave it like right here so in my case I named it crei so I'm going to just activate crei and you should see somewhere within your terminal that your new environment has been activated once that it is activated what we're going to do right here is to install crew AI so I'm going to do pip install crew Ai and it's probably going to take a little bit longer for you because I already had it installed but once it is installed uh just by doing pep install crei you're going to be able to use the crew crew AI command that is going to allow you to create a project uh with all the project structure that you're going to need and in order to do this you're going to do crei create and just name your project in my case I'm going to name name it newsletter gen like this and then as you can see it has created this new folder called newslet gen and it has created all the folder structure that I'm going to need to bootstrap this automation okay so let's get right on with that opening it with code newsletter gen all right so here's the directory folder that was created for us as you can see we have a source directory with the name of our Automation and within it we have a config directory and a tools directory the config directory contains our agents. yaml file which is basically just an example of the agents that we could build here's an example of a researcher and as you can see we have the role the goal and the backstory for each of this and this is very important to improve the results of your Automation and here we have the test t as well we have two examples of tasks that we can build here is a research task and here we have the description and the expected output I am going to give you in a moment more uh more detailed explanations of of how to write these descriptions but just keep in mind that this is the prompt that is going to be sent to your language model in order to complete each task okay then we have here an example of a tool that our agents could use to to complete the tasks the crew. py file which is the main class that we're going to be working with it contains methods which can be your agents or your tasks and then the final crew that is going to be generated and then right here we have the main.py file which is our uh which actually just runs the automation okay then just all these config files. dnv for your API keys at an empty test directory and there you go so now what I want you to do is to actually understand how to plan these agents and tasks before trying to populate them right here because you may find that if you jump into populating these tasks from the beginning without proper planning your automation is most likely not going to work so you have to have a proper planning on what you want to automate and how you want to automate it before jumping in and completing this part right here and that is what I'm going to show you right now how to do how to plan uh an automation with creai all right so what we want to do right now is to see how we can plan our Automation and just to be clear for this example we're going to be creating an automation that will generate a Weekly Newsletter with the most recent news about a given topic okay and it will output the HTML code with all of the contents of the newsletter ready to be sent by email okay so um in order to do this we're we're going to be using crew AI which is the framework that will we will use to orchestrate our team of AI autonomous agents as you can see right here this team is going to work for us in solve and complete different tasks that will take us to the final result that we expect from this automation okay now in crei as you might remember there are four main abstractions well three main abstractions in this case which is tasks which are the steps to complete to complete complet your automation agents who are the AI agents or the entities who will actually complete the tasks these are um you can think of them as your employees and the tools which are the functions or the services that your agents are going to need to use in order to complete the tasks okay now when I do my planning for these kinds of automations I like to divide my planning into four different steps first I Define the input and the output that I expect from my Automation and this is very important because of course you want to be consistent in what you will give to your automation as an input in this case it is going to be the topic of my newsletter it can be uh recent news about AI recent news about the USA stock market and the HTML template that I'm going to be using for my newslet for my newsletter this is of course important because I want that every time that I run this automation I will get the exactly same uh design okay I want my design to be consistent in other words I do not not want that the first time I run this automation the font is going to be times NE romen and the second time that I run this automation the font is going to be something like um comic sense okay so that is the first step to define the inputs and the outputs then the second step is to define the tasks that will take you from your inputs to your outputs and you can think of it as the tasks that you yourself would do if you were the one uh performing this Mission okay now in our case since we're going to be creating or generating this newsletter remember that if you were doing this probably the first thing that you would do is research the recent news about the given topic then summarize those news as you can see that is also part of this of this task and then with the summarized version of this news you were probably going to verify that they work correctly you're going to order them in order of relevance and then lastly you're going to complete your HTML template with the new stories that you found okay okay so that is the tasks that you would follow and that is the second part of planning this automation so first one was defining your inputs and outputs and second one is defining the tasks that will take you from your inputs to your outputs okay now the third thing that I usually like to do is to Define my agents once I have my tasks okay so once I have my tasks pretty well defined the idea is to create the agents and think of your agents as the members of your team who will be in charge of this automation and try to describe them as you would describe a team of humans think of what you would like your employees to have um what skills you would like your employees to have if you were uh delegating this task or this automation to your team and in this case as you can see we have a researcher who will conduct a research for our news a chief editor who will verify the news and reorder them and also provide some insight about them and our HTML composer or developer who will populate the HTML template with whatever the editor and the researcher give him okay so that was the first step and the last step that I usually like to do is to define the tools that my agents are going to need to use in order to complete the tasks okay and remember that our agents are powered by Ai and by that I mean that they are powered by language models okay which means that they can recursively call a language model until they have a response that is decent or something closer to what you would expect and they can also ask questions to each other in case they feel like they need help from one of their colleagues that is also why it is possibly a good idea to have agents lying around not assigned to any task because when you have a team of Agents a given agent who is assigned to a task can ask a question to anyone even if they are not uh specifically assigned to a task so you can have another agent right here who can be I don't know a copywriter or something like that and the researcher might ask a question to them if they need some copywriting for example and as you can see right here some of our agents are going to require access to external Services right because if we do not give them access to these external Services all they can do is recursively call the language model or ask each other which will also recursively call the language model so we have to create tools for them to actually have access to more sophisticated um services in this case the tool that we want to create is a tool that will allow them to search the internet for recent news and in order to do that we're going to be creating a research tool using the EXA service provider and I'm going to tell you a little bit more about how EXA works but just to summarize it very very quickly it is a search engine that works by meaning rather than by keyword which is very useful because language models usually think by meaning rather than by keyword okay and we're going to be creating three different tools the first one is going to be search and contents that will allow our agents to search for a query and get the results from the search results and also the contents from that page then find similar we'll take uh URL and we'll return similar websites that contain similar content to the contents of the website of that URL and then lastly we will have get contents which will get the contents of a given URL okay and these tools we're going to assign them to the research and I am actually also going to assign them to the chief editor so that they can also get contents and find similar websites just in case they need them okay and oh and I forgot to mention I remember that I said that the agents are going to be able to talk to each other most of them are going to be able to do that except for the HTML composer or the developer right here because remember that when we were creating it or when we're going to be creating it we're we're going to set the allow delegation to FS because we don't want them to be talking to their colleagues we only want this guy to be focused on just replacing the contents that the researcher and the chief editor are going to give them within the HTML template okay so those are the three abstractions that you're going to need to plan for your automation something useful that you can do as I mentioned in the previous video is to brainstorm your idea to CH PT and to ask it to give you the tasks and the agents and the tools that you might need that will however will not get you super far but it will give you a head start especially if you're using the GPT from crei I'll add a link in the description to that GPT but to use it of course you need to have uh GPT plus so there we go now that we have defined all of our elements of our automation we can actually start creating the prompts within our our configuration files okay so let's do that right now all right so here we are back at vs code or whichever ID you prefer to use and the first thing that we're going to want to do now is to populate the tasks okay we have already planned our automations now it is time to actually write the prompts that we're going to be using okay in the previous video I actually showed you how to bootstrap this prompt writing by using the GPT from crew AI so you just brainstorm your idea to the GPT and it gives you some prompts some descriptions and expected out that you can use however those are usually not completely optimized it was going to be up to you to optimize them via trial and error okay and that is actually what I have already done right here I have already uh started off with a few prompts I have optimized them via trial and error until I found that they work correctly and what I'm going to do is I'm going to replace this right here with the prompts that I have already created and I'm going to explain to you some of the characteristics of these prompts so that you can actually build your own and improve them to make them as as good as possible okay all right so as you can see right here I have the three different tasks that I had already planned the research task the edit task and the newsletter task and let's take a look at the research task as you can see the description is pretty long the expected output is pretty long so let's take a look at that so here you have the description here it says conduct a thorough research about the latest news on and then the variable that I'm going to be using right here is going to be between curly braces because this variable is going to be sent as an input to my Automation and it is going to be populated in the prompt whenever I have thisly braces like this okay be sure to look for sources that are reliable and publish recent news do not include articles that are not news material or that are not directly related to my topic with this research compile a list of the most relevant news stories that you found okay so this is a very very specific and very clear description of what I want my agent to do now a good technique of something that you can do after that is to give it some rules to follow okay and something that you will find yourself doing is updating your rules on every iteration of trial and error in order to correct for common mistakes that your agents are doing so in this case we have only include articles that are specially related to topic and in this case as you might imagine I added this rule because my agents were returning top um were returning articles that were not necessarily relevant to the topic in question then we have do not include sources that are not a news article if the content of the page includes a list of Articles or looks like the front page of a website do not include it in the list now as you might imagine the this one was also to correct for a common mistake from my agents in which they were actually returning lisal articles I mean lisal Pages which had several lists of Articles um in them some of them which were not relevant to the topic in question so that's why I added this one right here so that they can get rid of those summarize the news in a few sentences make the summary as long as POS as long as necessary to include all the relevant information but not too long for a news later now this one I added it afterwards because as you might remember what I told you before this one was actually a separate task and so I realized when I was uh running this in one of my trial and error iterations that the list that was returned from the first research task was already pretty good and already had a pretty good summary of what the news was so I just asked you to complete the summary right here and that was all that I needed to do to remove the Redundant task of summarization next we have include the URL of the article where you found the news include a minimum of seven news articles and a maximum of 10 news articles in the list and I will show you later how this affects the automation but as you can see this one was also to correct for some problems that the agents were having when using the research API okay so there you go this this is a good Tech technique that you can use when you're creating your automations and you're creating the prompts for your agents to follow now here as you can see I have some extra instructions about using tools and this one was as well to correct for some common mistakes that some of the models were having all right so that was the description very detailed and with a set of rules to follow now I want you to take a look at the expected output right here here as you can see we have just a description of the output U marked on document with the most relevant news stories each news story should contain the following then the title of the news the summary of the news and the URL of the article where in news was found now here is something very interesting and that I would recommend that you do every single time that you're running an automation like this this is called one shot or few shot example and it is a prompt engineering technique that consists of enriching The Prompt with some examples of what you want to get uh from the language model completion okay so right here we say here's an example of the format of a use article that you could include in the document and here you have the title and a real title and the summary and a real summary of what it would look like the URL and a real URL so you can of course add several examples like here I only added one but yeah this is a super good technique to make sure that your results are consistent with what you expect them to be because language models are known for being very um non-deterministic so this can help you improve that um deterministic element um significantly okay so I would encourage you to add these examples and just a note on the mark down markup TXS right here there they are of course not necessary but I have found that they do help the language model identify when a certain part of the prompt start starts and when I it ends okay so here's just example tag and end that example tag all right so now let's actually take a look at our agents and write the prompts for them I am not going to be writing the entire prompts in front of you because it is a very lengthy process and just as with the tasks it also requires a lot of trial and error to get them right but I am going to paste the ones that I have right here and I'm going to explain them to you okay so here as you can as you might remember from the planning stage of our automation we have three different agents we have a researcher an editor and a designer or I mean you can name it whatever you want which is the one that's going to be populating the HTML template for our newsletter the researcher will search the internet the editor will um make sure that whatever the researcher returned is correct and also provide an insight on that and then the designer is going to populate the HTML template with whatever the editor returns okay now let's take a look at the elements from the researcher one here you can see that we have a role a goal and a backstory in this case the role is a senior researcher this is going to be the role of our agent then we have the goal of our agent in this particular project which is going to be uncover Cutting Edge developments in and here we have the topic which is the variable that is going to be interpolated from our input variables okay remember that those input variables are supposed to be in curly braces like this and then right here we have the backstory now this is a very interesting part of it and the idea behind this remember that you have to think about this like a manager you have to think of the backstory of the employee that you would like to have uh performing this task okay so here for example we have a researcher and it says you're assistant journalist with notes for news you're known for great research skills and the ability to dig up the most interesting stories your reports are always thorough and well research researched making you a trusted source of information you always all follow the rules and guidelines provided to you this is of course uh making reference to the rules that we wrote in the tasks prompts right here the rules and and you never forget to include the complete URL of the article where you found the news and this as you might be guessing the this is to correct for a common error that I was having where the actual URL was not pointing to the right um article in the web okay so there you go remember that in order to write a correct backstory you have to think of it like a manager and you have to think of the backstory that you would like your employee to have if it was your employee performing this task okay we have the same for the editor and for the designer so there you go that is how you create the prompts for your agents now let's actually Implement them in our class for our crew okay so now that we have our agents and our tasks prompts we can go to crew. py right here and we can start populating this placeholder file that was generated to us when we initiated our project okay here as you can see you have the main class which is going to be named with the name that you gave to your crew in my case it is newsletter gen crew and right here you have The Decorator which is going to help you to automate a lot of the things that you would otherwise have to do by hand okay here you have the first property which points to the configuration file for the agents this is of of course the file that we just finished uh editing which is this one right here in which we defined our agents prompts now the next one is the tasks config which also points to tasks. yaml right here which is the configuration file that we just finished editing as well then you have a couple of placeholder methods decorated with The Decorator agent which is imported from crei and right here these are the methods that you're going to replace with the agents that are in your agents. yaml file same thing for your tasks then of course you have some parameters right here and last but not least you have the crew method which will return an instance of the crew object which is the one that is actually going to um run the automation with all of your team of Agents okay so here you have of course that it takes the agents as parameter the tasks as parameter and these are of course automatically this I mean these properties are automatically uh created by the decorators and here you have the process in this case we're going to be using sequential which just goes from task to task uh you could also add hierarchical right here but that will require you to add a manager llm which would basically create kind of a manager for your team and this manager would assign the the the different tasks to different agents depending on the expertise of each agent this is a little bit more complicated so we're not going to be focusing on that and I feel like for most use cases sequential is the most useful um process that you want to use um just remember that if you are going to use hierarchical and you want to you want to test how the manager llm works here you can pass in any instance of a language model instantiated using the blank chain classes all right so you can use chat groc open AI chat Etc okay all right so let's start with the first one right here the first one is going to be our researcher so we're not going to change the name for this one and as you can see right here it says that the configuration is going to be getting it from Agents config and the key inside agents config is going to be researcher and let's see what that means researcher is this key right here so that means it's going to be accessing the information within this key in our yaml file now in case you haven't watched the previous video where I explained this um what is happening here behind the scenes is that this decorator is taking the FI the yaml file right here and recreating the property agents config as a dictionary okay so here it might look as though you are indexing uh string because this one right here is a string but you're actually indexing a dictionary so that's okay but that's happening behind the scenes all right so this one right this line right here will assign the role the goal and the backstory to our agent we have to set verbos true in this case in order to actually see in our terminal what our agent is thinking behind the scenes and this one right here is just a I mean the tools parameter is just a list of all the tools that your agent is going to need to perform the actions we're going to add them once we have coded those tools okay so that's for the first agent right here let me copy and paste the second and the third agent which correspond to the editor and the designer right here all right so I'm going to delete this one right here and I'm going to replace them with this agents that I have created right here so as you can see right here oh I am missing a decorator right here so as you can see I have the editor and the designer which are pointing to the editor key right here and the designer key right here okay uh here I have the tools but I haven't created them so I'm going to leave that empty for now and there you go so you have the configuration that's been added like this and for the designer or the HTML uh composer I added another parameter right here which is allow delegation equal false and the reason for this is that in crew AI every agent has the possibility of delegating their work to any other agent or asking questions to any other agent whenever whenever they are stuck okay now that is usually a very good feature however some agents have some tasks assigned for which they really cannot get any help from anyone else and that is the case of the designer or the HTML composer agent which is this one right here uh his job is only to replace the contents of a HTML template there is nothing that the editor or the researcher can do to help him so by setting this to false I force him to finish the task by himself without having to talk to to their colleagues and it is important for you to identify the agents that are have very specific tasks for which they cannot get help from anyone else because know that when your agents have the possib AB ility to talk to their colleagues they will most likely do it and that of course is going to cost you resources because it is additional calls to the API so make sure that you set allow delegation to fals if you are sure that the task can be completed by the agent itself so there you go now you have the three agents right here and now it's time to add our tasks now the first one actually looks very much much like this one we have research task and it's accessing the research task key from our yaml file now let's take a look at how that one looks like research task here we have the description and the expected output for this one so this is correct and each task remember that I told you that each task has to have at least one agent that is assigned to it because it has to be performed by someone and in this case we are assigning the researcher agent which is up here to complete it all right now for the second task we're actually going to be replacing this so let me copy and paste that from here all right so here this one right here I'm going to be replacing it for this ones right here got a lot of python and its indentations okay so here you have task The Decorator remember that for every task that you create you should decorate it with task if you're using this project setup if you're using just the crei abstractions on your own of course it is not necessary to add these decorators but if you're using this setup it is a good idea to use them here you have the second task which is edit task and as you can see it is accessing the edit task key from my task. yaml and it is it is being assigned to the editor and last but not least we have the newsletter task which is the one that is going to be populating the HTML template and it has the configuration from the newsletter task right here okay and as you can see we have created our three tasks each one assigned to a different agent uh remember that you could assign two or more tasks to a single agent but in this case we're using different agents for each one of them all right so congratulations we have successfully created our agents and our tasks now the next thing to do is to create a tools that our agents are going to be able to use in order to complete the tasks because remember that so far all that our agents can do is to query the language model recursively that is to say that they can think recursively until they find the the required answer or they can also ask questions to other members of the team that is to say to other agents the only agent that cannot ask questions to its colleagues is the HTML composer or for developer because remember that we set that setting to fals while we were creating it so in other words all they can do is ask questions to each other and generate text if we want to give them more sophisticated capabilities like accessing external Services we have to create tools for them to use and that is what we're going to be creating right now we're going to be creating a research tool set that will allow them to search the internet and read the contents of those results I'm going to explain a a little bit more about the um individual Tools in a moment but first I want to tell you a little bit more about the service that we're going to be using to create these tools and the idea right here is that we're going to be using EXA so very broadly EXA is a semantic or neural search engine this means that it allows you to search for information on the web in a different and probably more efficient way you can think of it as an alternative to Google uh but instead of searching by keywords it will search by the meaning of your query okay now what does this mean let's take a look at that I have some explanation right here in the in the blog post now as mentioned before we are going to be creating a research agent and this agent should be able to find the most recent news on a given topic right for our newsletter this topic can be the USA stock market artificial intelligence or whatever you want so let's think about the query that our language model is going to generate in order to use our tool right because remember that our tools are essentially functions python functions that they can call and they take a parameter and this parameter in this case is going to be the search query okay so if our research agent is going to be using this tool it is going to generate a query that is going to look something like this latest news on AI or latest news on the USA stock market right in order to find the most recent news news on that topic now let's take a look at what happens when we look at that on Google let's see so latest news on AI and you can see that these are the results the first one is the sponsored one we can probably ignore it but you can see that the other ones are also front pages of other blogs or other newspapers and something important about this is that they contain the word latest news on AI which means that they are optimized to appear on the first results based on the keywords of your query okay and that is a problem because if our language model looks for this query it will only find the front pages of other websites now let's compare this with a semantic or neural search engine like EXA now EXA has a graphical user interface as well that allows you to use their API through their website I think that you can use it right here there you go and let's take a look at what happens when we look for latest newon AI so so let's do that latest news on AI and we can filter by time I'm going to say that we're going to work for the past month for example and we're going to click on search as you can see the results are the actual news because it is searching by meaning so we're talking about the meaning of the query okay and this is most likely going to be much more useful for our language model and this is of course because our language model models think on meaning rather than on keywords now that's how this works and their API works pretty well and they have a th000 requests per month for free so you can use them and so we can actually now start creating these three tools that we will be creating using their API okay so right now we're going to create the tools for our research agent and we're going to be using exit to create these tools okay so we have the placeholder right here that was generated by us um by the crei CLI for us um and we're just going to populate it with our own classes in importing EXA okay so once that EXA has been installed either with poetry at XA py or with Pip install XA py you can do from EXA we're going to import not EXA like this but EXA like that and here you have the placeholder for what a tool would look like um here we're going to name it search and contents because this tool is going to return the search results and the contents of the search results and here the first property is the name so we're going to name it search and contents tool and then the description remember that it has to be a very clear description of what your tool actually does because this is what the agent is going to read and this is what it's going to use in order to decide whether or not it has to use this tool to complete the task in question okay so in other words if the task is a research task it will be able to read this description that this tool searches the web based on search query for the latest results the results are only from the last week it uses the EXA API and it also Returns the contents of the search results so this is a very clear description of what the tool does and now your agent will know that it has to use this tool if it wants to search the internet okay and then right here we have the method the main method of run which is the one that is going to be executed when we when the agent wants to use this tool okay and any parameters you want to add to the tool you're going to have to pass them as arguments right here so in our case the parameter that our agent is going to pass is going to be the search query and right here let's just add the implementation of EXA so the first thing to do is to initialize our EXA client like this and this one actually takes the API parameter so let's import it from the environment variable called XA API key let going to come to umv and as you can see I have already added my EXA API key variable right here I'm just going to populate it in a second when I get it from their dashboard so I'm going to come right here I have to import OS for this to work and there we go so now let's actually get the search results from this client so we're going to going to we're going to say that the search results are going to be EXA do search and we're going to tap into the method search and contents which will return the search results and also the contents of those search results okay now you could pass only the query like that but let's add a few more parameters to show you um the flexibility of this method so the first thing as you can see right here we have to say what is the query that we're going to be using um and we're going to be sending the search query that our uh agent is going to formulate then we're going to say use Auto prompt to true so that because remember that XA works on a Transformers architecture so if for some reason your agent does not formulate a query that works good with EXA EXA is going to reformulate the query to give you the best results okay so that's what you get use autoprint to true and then let's actually say that we only want the search results from the previous week so in order to do that I am going to add a start published date and I'm going to create a date Cod of that equals to the previous seven days and in order to do this I'm going to import from daytime I'm going to import daytime and time Delta and let's initialize right here the one week ago date which is going to be equal to now minus at time Delta of 7 days and the actual date cut off which is going to be equal to that date in the format year month day which is the one that EXA likes for this okay so let's now here just say that this start is going to be the date cff like this and right here you can send a couple more parameters that I want to share with you and might prove useful at some point which is the text parameter right here here you can specify several uh parameters that want you can for example add include let me just move this up right here you can for example add include HTML TX and what this is going to do is this is going to return I mean if you set this to true this is going to return the HTML tax of the content so it's going to return the P TX the a tax and if the search results contain a table this is also going to return the HTML text of the table so this might prev for some kind of results probably not for all and maybe it will make your results too verbose but if you're looking for table like content this might Pro useful to set this to true just going to set it to false for now which is the default and something that is also pretty important is Max characters I don't remember what is the default value for this one but in my experience while I was doing some tests for this I found that the contents of the search results that this method was returning learning were too short so I wasn't actually getting enough information for my search results so here I just said that I want 8,000 characters for each search result um and that is going to give me enough information for my agents to actually summarize the new story okay and then with those search results we can just return them right here there you go so now our first tool is pretty much finished and let's create the other two tools which are find similar which is going to take a URL and return similar websites that talk about the same topic as that URL and get contents okay I could create separate files for this but I'm just going to create the three classes inside of here so I'm going to say find similar and just like before let's see what co-pilot tells me so find similar tool it's going to be the name and the description is going to be searches for similar articles to a given article using the EXA API takes in a URL of the article there you go and then right here we're going to define the run method which is going to take the URL the article URL okay so now just like before we're going to set this to one week ago we're going to set Delta under date cff and then right here we're going to also initialize a EXA client I mean we could do this as I did in the previous video using an EXA uh method but this works pretty good and let's say that the search results are going to be EXA Dot and we're going to tap into the find similar method which will return the similar URL keys so right here let's pass in that the first parameter is going to be the URL which is the article URL and this start publish date is going to be date artical cff because we do not want similar articles from two year two years ago we want just from the previous week so there we go and then we can just return our search results now let's create the third tool which is going to be get contents and in order to do this we're also going to initialize a class we're going to call it get contents like this and it is also going to be based on the base tool imported from C tools the name is going to be get contents tool and the description here we have U detail description let me copy this for you so the description have it right here it's going to look something like this gets the contents of a specific article using the XI API and it takes the ID of the article in a list like this okay so here I provide an example of how the language model or the agent should send the parameter and as you can see see it has to be an array or a list of strings and each string is going to be an ID of the articles for which we want to find the content okay so here you could have a second URL Etc now here please consider that we are saying that the agent should pass in the ID however in practice the ID is actually the URL in the XI API so just keep that in mind so once that the description is finished we can actually Define the run method so let's see the article IDs is going to be the argument that we're going to pass and that article ID is going to be the URLs and that article ID is going to be a list and it's going to out this method is going to Output a string so just like we did before let's initialize our XA client by doing like this and just calling an our environment variable for the API key and right here let's just say that the contents are going to be equal to XM we're going to be using the method called get contents like this right here okay and this get contents method as you can see it takes in either a string or a list of strings as we specified right here and there we go actually I'm just going to say that here it can be a string because a language model will always pass in a string at the beginning so there we go so now we can pass in the article IDs and we can return the contents like that all right so now to get the EXA API key and in order to actually test that our tools are working we're going to go to xa. aai and once you have created an account we're going to go to dashboard and right here on the overview tab you have your API keys if you don't have any you can create one just going to copy it and let's go back to visual studio code to to add it to our environment variables okay so we're now back at our project right here we can go to tnv and here we are going to paste our EXA API key like this I'm of course going to disable this API key before publishing the video but just to let you know that here's where you can put it now let's go back right here and let's actually start testing these tools to see if they actually work so in order to test them I am just going to execute them directly so I'm going to do if name equals Main and I'm going to create initialize the search and contents tool and I'm going to run the Run command and the search query that I'm actually going to pass in is going to be latest news on the USA stock market and then I'm going to print the results there we go so now let's open the terminal let's clear this right here and let's execute this so there you go here we have the results as you can see let me just open this a little bit more here as you can see we have that it used the search and contents tool here we have the title of the first result here we have its URL its ID which as you can see it's the same as the URL the score which is how relevant it is to our query and here you have the contents of that result okay uh same thing for the second one third and we have a bunch of results that might prove useful so the first tool is working correctly now let's actually copy one of the IDS right here and pass it on to the other tools so I'm going to close this and let's actually initialize the other tools so let's say that the other tools are going to be find similar and let's run print our similar are going to be find similar and we're going to run that the article URL and I'm going to past the ID of our find similar uh URL that was retrieved by the previous method just going to comment this one out and let's print this one right here and see what it returns so let's execute this and there we go we have some other similar articles and as you can see these ones don't actually include the content so this is an instance where the get contents tool might be useful for us okay so here are similar articles that contain similar contents to the news that was retrieved in this URL so the second tool is working correctly now let's test the get contents tool and this one remember that it takes in also the article IDs in a list so let's do that right now so what we're going to do is we're going to say first going to initialize and get content tool and we're going to call it like this contents are going to be equal to our get contents we're going to run and we're going to pass in our ID which is the URL and let's print the contents of this URL right here so let's see if that works I'm going to click on enter actually it is yeah it's using the fine similar as well because I forgot to comment that out but as you can see here it used the get contents tool for the URL that I pass in and it Returns the contents and just to be clear this is not actually scraping the website this is retrieving the contents that are already within the EXA index okay so XA is not necessarily helping you to scrape the data it just already has scraped the data itself okay so that's why it's pretty useful so you don't have to code your own web scraper in order to get the contents of the websites retrieved by EXA so there you go apparently our tools are working correctly we can go back to our crew. py file and add them to our agents right here and in order to do that we're going to have to first import them so we're going to have to say that from newsletter gen do tools. research we're going to be able to import search and contents find similar and get contents which are the names of the three tools that we have created and now what we can do is is just add them right here like that and remember that we said that the editor was also going to have access to this tool so I'm just going to add them right here like that so search and contents find similar and get contents there we go so now that our agents have the tools we can actually start testing our crew to see how it works so let's do that right now all right one quick thing that I wanted to add right here is that when adding the tools I made a mistake right here actually you have to initialize them when you are importing them so right here don't forget to add the parenthesis otherwise when you try to execute this this will not work okay now once the DAT is fixed we can continue with the video okay pretty good so now we have successfully created all of our tasks our agents and our tools now we're going to just add our inputs to our Automation and run it to see in that everything is working correctly okay so in order to do that actually remember that we had the topic of the newsletter as an input we had the HTML template as an input and I'm actually going to be adding a third input right here which is going to be a short personal message that we're going to be adding to the top of the newsletter you're going to see how that works in a moment but just remember that these are inputs that we don't we haven't yet uh defined so we are using them right here in our prompts remember that everything that you put in between these curly braces is going to be interpolated with the inputs that we're going to pass in but also note that right here we have another two input variables which is personal message which is the one that I told you that I was going to be adding real quick and the HTML template which is the one that is going to allow us to have a consistent design every time we run the automation so in order to do this I'm going to go right here to my config directory and I'm just going to add a newsletter template. HTML and right here I'm just going to add in some HTML code that I had already prepared here you can see that I have already defined the Styles and here you can see that I have the H1 for the title of the entire newsletter here I'm going to add the personal message that I told you about so that I have a personal a title a personal message then a list of all of the relevant stories each list is going to have a H2 for the title of the story the summary of the story why the story is important and a couple of links or the sources for the for the story and there you go so that is the template and in order to actually pass in all of this as an input what we can do is go right here to Main and execute our automation from here and what this file here is doing it is basically just importing newslet crew from crew. py right here it is calling the crew method which as you might remember right here returns an instance of crew and on that instance of crew it is running the kickoff method which takes inputs that are going to be interpolated remember that the Ki of method all that it does is it runs your automation okay so what we can do right now is just update this inputs dictionary with our actual inputs now since we're going to be testing this I am just going to say that this one right here is going to be an input for the user in the terminal I'm going to say that enter the topic that you want your newsletter to be about so enter the topic for your newsletter then the second one is going to be the personal message and this one as well let's let's say that it is going to be an input enter a personal message for your newsletter and very importantly we are going to pass in the HTML template now remember that the keys for these variables right here in the dictionary have to be the exact variable names that you are using in your prompts so here you have HTML template and here you have HTML template okay here you have personal message and here you have where is it here you have personal message okay so just be sure that you are using the exact same variable names because otherwise it is not going to work and here we're just going to load the contents of this file right here and in other to do that let's just create a quick function right here let's say load load HTML template and it is going to return with open and the path is going to be SRC newsletter gen config new newslet template R in order to be able to read it as file and the HTML template is going to be equal to file. read and then we're just going to return HTML template like that okay so this function is going to read the contents of this file and it's going to return them as a string right here and this is exactly what we want I am going to run here load HTML template like that great so now now that we have added all of our inputs right here let me just be sure that this is saved we can just go to readme.md and make sure how to run this using the framework that CI suggests that we use which is using the Poetry scripts which work pretty much just like npm scripts as you can see right here here is a poetry script already created called newsletter gen and what it does it basically goes to newsletter gen. main which is this file and executes the method run which is this one right here okay okay all right so now time to test this and before we do that we have to make sure that our API keys are correctly set up as you can see right here I have already added my open a API key don't worry I will disable this before uploading the video in case you do not have an API an openai API key you can go get it at open.com and in case you do not want to use a paid API like open AIS don't worry in a few seconds I'm going to show you how to do this using pretty much any model you want want and this other environment barel right here can be pretty useful for you especially if you're using the default configuration of crei because I'm pretty sure that crei by default points to an older version of gp4 so this one right here will'll set this one to the latest version and you can of course change this to any to the latest model at the time of watching okay so once that that is set up remember that in order to run all of this all you have to do is do poetry run and then the name of your project and in this case I'm going to do it like this let me just open this a little bit bigger we have a um deprecation warning hopefully it's not going to cause any big troubles and here you're going to say the topic of your newsletter it's going to say that it's going to be the USA stock market let's make a USA stock market a financial newsletter and a personal message hello here is the news for your week there we go all right so I'm actually going to pause the video right here and I'll be back once the run is complete because it might take a few minutes to finish okay so as you can see the automation is finished let's actually take a look a little bit at what it actually did so as you can see here um it checked some some contents of a website apparently it searched more the internet communicated then there you have the thought now I've verified the URL so actually here it was verifying the URLs now that I verified the URLs lead to a proper articles I need to enhance the the titles for better engagement provide context and reorder the stories here you see that it made a mistake and something that is pretty useful about these kind of automations with AI agencies that when they make a mistake they can correct it by themselves as you can see right here it made several mistakes while trying to use a few tools then it went on and said I need to enhance the titles and use and then it went on to give a final answer and here we have the final answer for our most recent stories so there you go these are the recent stories and then down here we have the last task which as if you might remember from The Prompt that we have right here remember that we have follow these rules Etc and here we had the HTML template that we were passing to it so that's exactly what's going on right here here um I think it is right here yeah fill the following HTML template with exactly the same information that is given to you Etc and then I provide the HTML template right here and then I can now give a great answer and it Returns the HTML okay I actually forgot to save the output as a file so what we're going to do right here is we're going to copy this right here and let's actually just create a new file right here just for test I'm going to call it test. HTML and I'm going to paste the HTML that was generated and see what it looks like on the previews so let's serve this right here and it was made right here okay so here we go um seems to be okay we have weekly stock market op dat a searching uptimum then we have our personal message right here and then we have one story for each relevant story that our agents found uh let's see if the links work I click this one seems to be okay perfect let's see nastic climb has tag semiconductor stocks rally there we go okay pretty good well apparently our newsletter was generated correctly now let's add a little bit more features to this automation first of all let's automatically save the generated news uh newsletter file into a file not only log it on the terminal and secondly let's also add the possibility of using several language models not only gp4 okay and last but not least we will be building a graphical user interface for for this application so let's do that right now all right so now we have finally finished this automation that looks pretty good uh we have successfully created our agents we have successfully created our tasks and we have our crew that is working correctly we already run the tests and it's working okay okay the only problem is that we are working currently with gp4 that might that may or may not not be a problem but that is the default language model that CI works on if you want to use a different language model I am going to show you right here how to change that default setting and so that you can use pretty much any language model that you want that is supported by langing okay so let's do that right now let's go to the browser to show you um the language models that I'm going to be using here okay so here we are at the Lang chain documentation page and the idea right here is that actually crei is built on top of Lang chain this means that actually Lang chain crei is going to be compatible with all of the Integrations for all of the language model providers that Lang chain has available this means that if you want to use gr with anthropic with Google or with open AI models for example it is going to work just like it would on Lang chain all you will have to do is change a single line of code I'm going to show you how to do that in a moment um just be sure that the language model that you choose supports function calling because of course since we're going to be working with agents agents require function calling in order to work okay so just whenever you're choosing your language model be sure to pick one that supports that for this example I am going to be showing you how to do this using anthropic models that is clot and I am going to be showing you how to use uh Gro okay all right so now it's time to get our API Keys um the first one that I'm going to be uh getting is GR Gro so in case you don't know what Gro is it is a service that allows you to serve open source models from their architecture and they have a very specific way of implementing their architecture which allows you to get inference or to get the completions from your language models much much faster than you would from a regular API so that is very useful and they also support function calling they have right here if you go to Gro Cloud create an account and go to documentation you can see the models that they have available in these case as you can see they have Lama 3 they have mixol and they also have whisper and Gemma okay in this example we're going to be using lth 3 and mixol however when you're using Grog be sure to be careful about the usage rates because they do have some rate limits right here as you can see they have some rate limits and their models are limited depending on on the region you are I think and also on your profile let's see right here settings so here you go if you don't have a very high limit this might not work in my case uh for my particular limits that I have I do find that I hit the rate limit pretty often so in my situation Gro is probably not the most useful but if you have a higher rate limit or if by the time you're watching this video they already have released their paid setting this is definitely a thing that you should take a look at because they they have very fast inference and it works pretty good so in order to do that let's just go to API Keys create a new API key and then we're going to copy it to ourv file and the second one that I wanted to show you is cloud of course in order to get an API key from anthropic which are the creators of CLA you're going to go to anthropic Doom API you click on get started now and it will take you to the console if you haven't created an account yet it's going to prompt you to create an account once you create an account you just have to go to get API keys and then you will be able to create your keys and copy them to ourv file okay so once we have our API Keys we can go back to vs code populate ourv file and start [Music] testing okay so we're back at our crew. py file where our uh automation lives here we have all of our agents and all of our tasks but if you're not working with this kind of setting if you're just working with the main abstractions yourself you can still uh do this all you have to do is that whever you're going to initialize your agent you're going to add an extra parameter and you're going to say llm equals and here is where you are going to initialize your Lang chain language model OKAY in this case if you might remember correctly we are going to be using anthropic and uh Gro so the first thing to do is actually to to install the Integrations from these language models okay so in order to install them we're going to have to go to our terminal right here and uh to make sure that I have my virtual environment installed and activate it and I am going to install integ integration um you can check what you have to install in the documentation itself for the language model that you're trying to implement in this case since I'm going to be using anthropic I can do pip install anthropic sorry pip install Lang chain Das anthropic or in my case since I am using poetry I'm going to do poetry at L chain anthropic oops length chain anthropic like that and it's probably going to take a little bit it's going to download it there you go it wasn't that long and once we're at it let's actually install Lang chain Croc remember that some implementations come I mean some third party Integrations come within the Lang chain Community package but in this case since they are pretty big Integrations they come within their own package and this is langin anthropic and langen Gro you will have to install whichever you are trying to use and you will find that in the documentation of course okay so now that we have that installed we're going to go Tov right here and it is right here that we're going to add the API keys that we just added and actually we're not going to be needing this this thing right here we can just paste our new API key so we have the open a API key we have the gro API key and the anthropic API key for these two particular language model providers be sure to use this environment variable name otherwise it is not going to work okay so Lang chain or crei and Lang chain are going to automatically look for this API sorry for this environment variable right here so so this environment variable name so you have to name this groc API key and anthropic API key if these are the models that you're going to be using I'm going to save this go back to crew. py and I'm just going to initialize my language model uh in order to do this actually I'm just going to initialize a new method right here I'm going to call it llm like this and I am just going to initialize my language model right here I'm going to say that llm equals and in the first case I'm going to be initializing a clot model so I'm going to do from Lang chain anthropic I'm going to import chat anthropic like this going to do the same with Gro so from L chain from L chain groc I'm going to import chat groc and let's just initialize both of them right here so I'm going to say llm equals chat anthropic and this one of course the a few parameters the first one is the model name and in my case I am going to be using Cloud Sonet which I found that it's actually the one that works the best here and one thing to keep in mind especially about the anthropic models with Lang chain is that by default they don't return a very large amount a very large number of tokens so here you're going to want to update that setting I'm going to say that Max tokens and I am going to set that to 49 to6 and this is going to allow my language model to return up to 4,096 tokens per call okay because by default I think it's around a th000 and it was generating I mean I I tested this before and it was generating truncated risk responses and the second one that I am going to be initializing is chat gr and just like up there we're going to be initializing it with a model name and in this case I'm going to be testing lameth 3 and that is actually all that we need I'm actually going to be initializing another one with mixol so let's get the mixt tral name right here right here just paste it and there we go and these are the three language models that I'm going to be testing clot sonit Lama 3 and mixl okay um to be clear I am using chat gr right here on the free version which is at the moment of recording the only one available but I mean yeah so this allows me to run my automations for free as long long as I'm willing to wait in order to not hit the rate limit per minute okay and of course I'm going to be using the chat anthropic which is a paid one and I have already added credits to my account for that one and I'm just going to return llm so the first one that I'm going to be testing is chat anthropic so let's save this and I'm going to initialize this one right here I'm going to say self LM going to say that we're going to be using the same one for this one right here and the same one for this one right here I mean just to be sure that you're not lost here all I am doing is I am calling the function that I initialized up here and I'm just going to be returning the instance of the language model that I just initialized okay so once that is done we can save this and now we should be able to run our automation using these new language models that we just imported great so in order to test this actually I wanted to show you something which is how to add logs to every single step of your automation okay because it is not always easy to see what your agents are doing and we're going to see a little bit later how to do monitoring and observability but for now I just want you to see exactly what each agent is uh producing uh by the end of each task okay only by the end of each task and that is going to allow us to see precisely what the editor did what the researcher did and what the final newsletter um file is okay so in order to do that we're going to add a new parameter right here to every single one of our tasks and we're going to call it output file like this and right here you're going just to name the name of the file or the location of the file where this output is going to be stored and it is going to produce a file by the end of this task which with all of the output of this task in this case I'm going to create a new folder right here called logs like that and I am going to also import daytime actually I'm going to import from daytime I'm going to import daytime and right here actually I am going to add an F string and inside here I am going to say that I want to store this in logs and I want my file to be named after the current datetime okay so current day time now and it's going to format it by day uh month sorry year month and day and actually I also want the hour because I'm probably going to be running several tests every uh on the same day so here I'm going to add hour minute and second and then I'm going to concatenate this with the name of the task which is research task I'm going to save it in an MD file in a markdown file and I'm going to do the same thing with my edit task I'm going to say that the output file is going to be in stored inside the logs directory the named with the current time of the execution and then I'm going to do exactly the same thing with the last one which is yes like this but this one is not going to be a markdown file but it's going to be a HTML file is you if you remember correctly okay great so once that is done every single one of our tasks is going to be stored in its own file in the logs directory now we can actually execute it and see how this actually looks like so I'm going to open the terminal I'm just going to do poetry run I'm going to run my automation called newslet gen again our deprecation warning the topic of our newsletter this time is going to be real estate market in in San Francisco and let's say a personal message for the newsletter hello everyone this is your Weekly Newsletter about real estate in SF enter and we have a quick error right here because newsletter gen llm takes zero positional arguments and one was given okay yeah I forgot to add here self like this okay so let's run this again and and yeah again it's going to be the real estate market in ASF and my message is going to be again hello everyone so let's see as you can see it is starting to thing it already started to query um the internet and it found a lot of information already it found some Bay Area Housing 20 billion very fun and going to be back once all of this run is complete but just to show you that everything is running correctly okay so all of the thinking has been finished by our agents all of their research and they actually communicated with each other a lot so that looked pretty good amazing so and also they solved their own errors and by the end they produced a final um a final newsletter right here let's see our logs and take a look at how that looks like so here we have as you can see that the logs were were saved as we as we asked them to the first one was the research task and let's see so here we have Story one story two Story 3 four five 6 7 8 and nine and here we have different titles so we have Goldman Sachs and B La have a summary and we have the URL and same thing for the Story 2 and as you you can see the language model is following my example of the of the stories that I of the format of the stories that I want so remember that I I mentioned before when I was writing the prompts that I wanted it to have this exact format um let me show you real quick so if we go to configuration and we go to tasks here you can see that I asked the research task on the expected output that they put that they write these stories like this story one title summary and URL and that is exactly what it did write right here great so the research task turned out all right let's see how the oops let's see how the edit task turned out and here we have just as well the title the summary why this is important a very quick um commentary by our editor and this Source like this great um oh we seem to have a problem apparently we only have I mean we lost four uh no we lost five stories from the researcher to the editor I suppose I mean I hope that it is because the editor found that those stories were repetitive or probably not relevant for our topic we're I mean later I'm going to show you how to do this with how to check the the logs and monitor or the thinking of your agents so that you know why they made certain decisions but for now let's just stick to what they returned to us and last but not least of course we have the final generation which was the goal of our entire automation let's see here we have the HTML file that was generated let's just serve it to see how it looks like and here it is so we see that it looks okay hello everyone this is your Weekly Newsletter about about real estate in a SEF and everything seems to be working correctly we have everything and the links are working correctly as well great so good job so the automation is working and we actually managed to make it work using anthropic clot Sonet and that turned out pretty great so now it is time to actually build a front end for this application so let's do that right now [Music] [Music] [Music]"
imlQ1icxpBU,2024-06-05T08:08:00.000000,"Jerry Liu - What is LlamaIndex, Agents & Advice for AI Engineers","good morning everyone how's it going today welcome back to the podcast in today's podcast I'm going to be talking with Jerry Le Jerry is the CEO and co-founder of llama index we're going to be talking about llama index what it is and what you can do with it in case you don't know llama index is a framework that allows you to create large language model based applications although we're going to be introducing it with a little bit more detail in a moment we're also Al going to be covering Lama pars their API for parsing on structure documents and finally we're going to be talking about lamac Cloud which is their Enterprise solution to see what they have to offer and how Lama index and lamac Cloud come into that in this process we're going to be covering some technical topics and explanations as well about how the systems work including topics such as advanced Rag and data processing so it might get a little bit technical color times in addition by the end you will have some advice from Jerry on becoming an AI engineer and starting a career or a startup in this industry if you're watching the video version of this episode you have subtitles here and I hope that the subtitles will help you to understand the more technical topics in case you don't know what a concept is you can always look at the subtitle and look up the concept I also added some notes Within the subtitles to help you find the concepts more easily so yeah I invite you to consider this episode as study material it is not always that we have Jerry Le himself explaining these topics to us and during the conversation we try to make them as approachable as possible so without any further Ado let's get started I bring you Jerry Le Jerry thank you for joining I thank you for having me so let's talk a little bit about L index and uh just to start can you please tell me what is llama index great so llama index is a data framework and platform for helping developers build llm applications over their data and so we have two main product offerings we have an open source component which is a very broad orchestration fol kit enabling any developer to compose different modules together to for instance like index data put it into a vector store and also build different types of llm applications on top of that data this includes uh some very popular Concepts popping up these days uh including for instance retrieval augmented generation which is the core of building like a trap lot over your data and this is also this also includes use cases like agents which includes more autonomous um pieces of software that can go and automate workflows perform actions for you like send an email schedule a caliber meeting um write code and do other things as well I see I see many people talking about agents uh recently that's really taking some traction isn't it definitely I think there's been a lot of interest in a variety of different use cases I'd say the top most popular ones are probably uh rag and also agents um and there's actually you know we talked about this in in some of our talks uh progression between them um because we see this as like an overall Spectrum as opposed to like there's like a fence between every different uh use case um rag is really just a very simple mechanism of doing search over your unstructured data and there's ways that you can basically add a bunch of agent ingredients to make it more agatic amazing how does it feel to be part of the driving force of this this industry yeah definitely I mean as a Founder it was uh I'd expect it I'm also very grateful for the opportunity i' I'd say a lot of uh the reason the company got started was because we were at the right place of the right time um but also you know it's one of those things where we we saw it and we really try to take full advantage of this to basically create something that was really powerful um and this includes both the open source side uh which you know includes the technology but also the community um so basically you know a lot of uh the Llama index why why people like the the brand and the community is because of our um kind of education resources and ways like showing others how to build different types of things um and and not just in like a hacky way but also building at well um and so that's something that is core to the company and something that we want to continue to invest in um because part of this like ecosystem right part of this like geni hype uh is fueled by actually developers knowing how to build stuff and if we can continuously be on top of whatever Alm advances are coming up and basically show them how to take advantage of these Alm advances uh by showing them you know what are some of the new use cases that are unlocked what are some changes in like paradigms or abstractions that you should think about um that's basically what we want to focus on amazing and just to to be sure that people are like our listeners are understanding precisely what your company does you said that you allow uh developers to create applications that allow you to chat with your data and create agents that's that's correct is that like a very high level description of llama index yeah so let me let me give a little bit more color to that um so thanks for asking that question um basically llama index um the overall mission right taking a St back is to just it's is pretty broad uh is to enable any developer um to build just uh lowered applications and it turns out a lot of these L owered applications um depend on a user's own private sources of data now um the source of dat these sources of data can include a variety of different things um so it could include like unstructured documents like PDF PowerPoints docx files it can include like apis that you have access to um so uh commonly use like services like slack uh or Discord or notion um it could also include for instance uh structured databases like if you're a company you have a data warehouse of like very structured data um that's for instance the type of data you might want to get the LM to analyze and and give you insights over um and so there's a lot of data a lot of times especially if you're a bigger organization you have a lot of it and it's also in different types of silos and it turns out you actually you know maybe have some of it in use by your business analysts but also some of it is just like sitting in in a bunch of files and you really don't have time to like sip through all of it um one of the promises of llms at the same time is its ability to just rapidly process any type of information it give you back responses um to really illustrate this imagine you're in like the trbt interface and you're able to um like you just copy and paste like some piece of text from like a web page from like a book just into that little text box and trb or clad or any of these uis that are popping up and you realize the llms do a remarkable job of being able to really understand the text that's in this box um even you know if it's not in like some structured uh like field uh a structured Manner and uh actually give you back responses over and so you take that Insight that LMS are just really good at just reasoning over any type of data and then you combine it with okay well now if they're really good I want to combine that with like um you know on top of all the data that I have access to in the organization and you think about the challenges uh to basically make that happen um and so what we how we started as a company is basically building developer tools to enable that bridge um enabling any developer that was using an LM API to easily figure out how to make use of all the types of data and what the different patterns and paradigms that by being able to you know to to like to load this data into the allm pr window and you have to deal with different types of challenges for instance like figuring out how to fit context into that prop window um figuring out how to basically um get the Align to interact with different types of data interfaces uh unstructured data structured databases uh perform actions those types of things um and so that's kind of like how we started and that's where a lot of these like indexing like rag abstractions came into like kind of arose as well um because a lot of people were thinking about similar problems and they basically came up with this like general purpose technique uh like retrieval log Generation Um to figure to basically uh show to basically um uh load it a like basically set a standard for loading in different types of data putting into a VOR database and doing retrieval on top of that data to fetch only the most relevant bits and putting that into outet Contex my note um so as we've started we started off um focusing a lot on that use case because it was also a pretty big use case for the Enterprise as well um because um what what uh like what Enterprises wanted is one they wanted to actually have their developers like build these types of applications and for us as a company we wanted to give these developers like the developer tools to build these applications um and so the open source project uh going back to that is a pretty important piece of it because open um is something that most developers really enjoy using um it's m just like a set of libraries that you can just import it's very flexible and customizable and so the trick is you want to make sure that you have a library that both like beginner to Advanced developers can actually utilize um to you know VI that bridge uh connect your different types of data uh and build these different types of all use cases um and so um go uh one quick note on the different types of Alum use cases the the orchestration framework is uh pretty Broad it supports a lot of the emerging patterns that um people are building these days and so um one such pattern is again like rag uh which is basically question answering um over your data and then as I mentioned in the beginning um there's also other types of patterns that are emerging um like the autonomous like like software engineer sales assistant research assistant like basically things that can operate more in a continuous loop with a lower um like back and forth human interaction um and so that's something that we're focusing on as well and then just the last last bit which I'm happy to talk about in sub questions is the like um we have the open source project um but then we also have uh Adder press platform um which is llama cloud and so the goal of llama cloud is that it actually complements the open source project um by being a managed uh data platform um data ingestion service to basically help really solve that problem of connecting your data uh with any sort of storage system and be able to Define that workflow have it run very U be very accurate have it run reliably and then also remove the need for you as a AI Ur to really maintain those pipelines um this is an emerging systemy that we see um as part of this like overall data stack that forms like Al and software and that we realized uh for a lot of like ader prised use cases it makes sense to basically build an overall managed service around it to really solve that data quality issue for any sort of Al applications and of course you can still use the open source to build like different types of uh applications on top of that on top of that data amazing and to be sure that I understood that last part correctly in this orchestration framework that is L index you have rag which is retrieval augmented generation you have autonomous agents and then you have the Enterprise solution which is lamic cloud which which allows developers to more easily deal with the workflow of ingesting and managing data in these kinds of ecosystems right is that is that broadly correct yeah so the way to visualize llama cloud is basically imagine like a general knowledge man management interface um and so like this the goal of this platform is to just expose all the different types of data that you might want and make sure that data is cleaned and ready to go um so that like you know you're on structured PDFs uh we'll be able to process it make into a format that your LMS can consume um you know in the future for instance like structur data or any sort of like user data like conversation history um we'll also be able to process it and store it in a format that your LM can consume as well and so basically um assuming like you know if we take the rag pattern uh what does this concretely mean you have a set of like PDFs uh you want to for instance like parse it in the right representation um you want to chunk it um make sure that it's actually split up um into more bite-sized pieces so that LMS can really understand them um and you want to put it into a vector store with the right retrieval strategies uh to make sure that given kind of like any sort of question that the LM or human sends to the system um that's able to surface the relevant context and so that whole stack is kind of like the indexing retrieval piece of rag um and if we can provide that as a really nice data interface then you basically have the like set of managed apis that anyone within the organization can consume run and basically have this like guarantee of quality and that ingestion is usually one of the most complicated parts of the developing this kind of system right yeah for sure and so you can um just talking about that type of um spending a little bit of time on on talking about why it's complicated um we we've mentioned this in some of our kind of like U like talks as as well um it's basically you have um this new type of ETL um because you have like unstructured data and you want to process it into something that is a little bit more structured um and but it's a new pattern so for instance for rag um you know you're taking again like an unstructured document like a PDF and then you're parsing it and then chunking it and then putting it into a vector DB um and this actually looks a little bit different than the previous Stacks like if you think about traditional ETL it's typically just like a set of operations to move structure data from one place to another um like part of the reason like snowflake or you know some of these other uh data warehouses exist is you like load in a lot of kind of like messy data and then you typically use a human to basically write a lot of operations to massage this data into something that's very clean and structured um but again I think just like the overall stack has shifted because a lot of time like the the set of operations you need to do on the sound structure data is different for Rag and the second piece is that um the second uh reason why it's challenging is that all these parameters actually affect the final performance of your LM application so your parsing strategy uh your Chun size um it's actually there's like a lot of these knobs that you have to figure out how to tune um also adding like metadata annotations on top of your documents and um all of these affect your performance and so if you're not careful with some of these parameters you end up getting a system that um is uh just not very performant and it's also a little bit hard to improve um and so the data decisions directly uh affect your accuracy and this isn't really something that's occurred uh kind of in previous types of software right yeah I want to unpack a little bit more about the Lama index and L the L Cloud part but before that I would like to talk a little bit more about the history as well of L index because I think that our listeners will be very interested getting the inspiration from your personal experience right uh can you tell me how the company L index started how yeah um so I mean I think uh basically it started back in November of uh 2022 and um you know um this is around the time that uh or it was October uh that a lot of people were basically trying to hack on language models um because uh people were getting excited about like gpt3 again um there were a few startups popping up and I I was also getting pretty interested in just like you know trying it out seeing what happens as a developer um just to like hack around on the API and see what what are some of the some of the learnings and and what are things are hard to do what are some of the things that are easier to do and so so I I basically open up the open eyed devel account and then you know like um started playing around with h TX mry O3 um and then as I was playing around with it you know one of the emerging patterns I was I wanted to build and also I was seeing like some of the other people build as well is like you know how do I figure out how to use this to basically you know um uh answer questions about like uh you know all the sales data that I have in the company right um or just like have this have knowledge of basically everything that exists uh within the um the the organization um because what I wanted to do was I wanted to feed it all the sales conversations U because I was in a few of these like customer calls and I wanted to really like synthesize insights and help me prepare for the next meeting um because I otherwise that like that was actually taking a decent amount of time um on my plate and I was like on the entrepreneuring team U but I was just in a bunch of these customart conversations and I just um because I was bound a few different things often times like I I would just like forget or or just like have to explicitly allocate time to you know like listen to um to to review these like customer transcripts um to basically prepare right materials and so it was a it was like a slight paino for me that I wanted to solve with Allens but then I was like I was trying to build uh and prototype these applications with um initial like LM powered application and I realized that the context window is like 4,000 tokens right so I can't just like dump um like the entire set documents into the context bundo and call it a day um and what I needed to figure out is like some more clever indexing strategy so that like I could index all the documents somehow but then like you know given that I had some sort of question um the LM could somehow figure out how to Traverse this overall index of information um to basically find the right piece of information and give that back to you um so this was pre you know this idea of rag um and actually you know rag as a research paper had existed before I started this project um yeah yeah yeah but I I like independently just came up with some um technique that like to be totally honest was a lot worse than just this like idea frag because I wasn't using any embeddings um I wasn't using any text embeddings I was just trying to use the AL itself to just think about like hierarchically organizing information into like a tree um and then just like having that LM like Traverse that tree to be honest it didn't really work um the first few few times around um especially because like dentry 3 was not super good at reasoning um so it wasn't great at being able to figure out like um make a decision given like a set of choices um that said um it was interesting and I think you know the people like I put on Twitter and I think there was a decent receptive like uh uh response to it like there were a lot of people interested in the soall approach and I think a lot of people are getting just excited about LMS at the time and so provided like a nice starting point to basically grow some initial um have some initial traction um which then motivated me to keep working on this uh and in this like virtuous feedback loop I eventually realized a month later I should probably you know like um quit my current job and then also uh like think my already a company around it but really started off as like just this like developer Leed uh like I want to try to like solve this paino and this is the tool I want to build to solve that paino right so about that history of rag modern rag was actually kind of born in 2022 then right um yeah I mean I think like I forgot the exact date of the uh like the original retrieval augment of generation paper uh which is not by me um obviously was by others um and so this is either in 2021 or 2022 or even 2020 um and the like it basically proposed this overall idea oh you know you take in um some set of like documents and then you want to embed them like put them through an edting model um and then put it into some some storage system that's able to like serve uh like the relevant documents through retrieval right and so that's why it's called like retrieval augmented generation like you want to do like a retrieval pass over some storage system before you actually put it into the Allen um prompt so that kind of that resurfaced basically um as more and more people start building with lfs people like kind of start discovering that oh hey this thing is like a cool idea um and my initial version was not doing that it wasn't using embeddings um because at the time I don't know why I think it might have just been like due to like a design like my my goal at the time when I first started was not necessarily to make this useful it was to just like do something cool and so the to me like doing something cool was like oh what if we just didn't have embeddings or I thought about it briefly but I was like what I really want to do is just have the L1 um figure it out completely on its own right and I I I still think that would be a quite an interesting concept like instead of just like you know relying on a separate model just have a language model completely similar to like a human just completely figure out how to reason organize things and then also Traverse them via text um yeah and that kind of reflects in the current state of L Index right because I mean you it's kind of a central I mean as far as I can see it's kind of a central part of L index that you use language models as well in during the ingestion process not only in the in the generation process yeah so the default rag Paradigm um really only uses the LM at the very end um so you have like um inje like injection doesn't need LMS you just take in um you know some data parse it and then you just chunk it using an algorithm um and of course you use an embeding model um to put it into some Vector store and then the retrieval process uh doesn't use an LM because at a simplest it's just like top K uh embedding lookup so like you know you look up stuff by embedding similarity and so in a standard rag pipeline the uh gener the the way the place where lm's actually come in is at the very end uh and it's only responsible for um kind of just like synthesizing an answer from a piece of unstructured text and to be totally honest like you know it like even like at the start when we were just like implementing this um I thought it was a little basic uh and it didn't really like make use llm so its full potential right because like llms are not just uh for Generation um and and simple reasoning they can actually help you make decisions they can actually help you like add like greater layer of like just like understanding and decision making and so if you really wanted to make these systems more interesting you could use llms kind of like at the beginning um so for instance during the data injection phase um or you know during query time um instead of just using it at the very end for Generation use it for like query understanding um use it for uh like processing like evaluating like the quality of your retrieve context and then for instance like not only just retrieving from vector or actually using a variety of different tools um and so on the injection side um the places that you can use llms and so this this this overall concept is pretty interesting which is um the whole point of like inje is to process data for your Al map um and so that's kind of like uh ETL for LMS right but you can also use LMS for ETL um because you know LMS have an inherent capability of understanding unstructured data and transforming it and that part I I think is interesting like so for instance um let's say you know for each unstructured document you wanted to extract like a summary the table of contents um like you know extract like a set of like topics or tags for each page basically you can figure out a clever way to prompt the llm um by feeding it in a bunch of data uh from the document to basically first extract out a set of like structured annotations or tags and this represents like a data transformation basically because you're trying to like feed in some input on structur data and transform that into structured data and then you can basically attach those tags on top of the unstructured data as well and so these like this is just an example of like metadata extraction that's also powered by LMS and this is something that you know um uses LMS but is also indep like you know useful for just like the any sort of Downstream application you want to build because if you're trying to build a rag system over this having metadata tags is oftentimes very useful it gives you like better retrieval results better generation quality and and all those types of types of things and so I I think that interplay between LMS um and kind of like data transformation is very interesting because you can use it for like in the middle but also it you it helps for any sort like applications you want to build later on yeah that's fory some Advanced rack techniques over there and it kind of brings goes back to a little bit to your I mean it it's a little bit adjacent to your original idea of uh creating these kind of systems right yeah I think I think the you know I I thought about this in the at the beginning of the project that the project was not really um like close to kind of like realizing that Vision at the time um but if you think about like the overall uh picture of like where I think um LM power software will evolve it's basically like um there's a new type of like data like a data stack that's sub verging um a new set of operations within that data stack um to basically power like um like AI software and to really like um kind of uh like we want to basically provide the right tooling to help developers build that data set um and so this is helping them figure out how do you like you know um move data from one place to another um specifically for LMS to use um and that could includes like LMS in the middle as well and this also includes the orchestration piece on top of that data how do you figure out how to get LMS to interact with the data uh through these different types of uh interfaces awesome um I want to talk a little bit about your your your background your personal background as well um what did you do before uh you started Lama index yeah so I was at um I was at a series B company called um robust intelligence which was doing like ml apps like uh testing monitoring evaluation um you know it it was had a pretty talented team um you had like aison trace on your podcast and so we were all like co-workers basically awesome um at the at the same company and then yeah there were like it was it was it was fun I mean I you know um basically before that I had spent some time in both like uh bigger companies right um like kind of so cor was like 200 people Uber was like uber Uber was very big um but i' spent some time at both like ml engineering um and then uh and then research so let me actually just say you the whole background so so basically like Kora was my first job out of college and I was doing like recommendation systems and doing like very practial Hands-On ml engineering work um so that was a great first job I learned a ton um and I also learned a lot about just like how to not only like train these models but also how to apply them and basically make them reliable um and then I wanted to like really dive a little bit deeper into the research side and strengthen my ml understanding of fundamentals um and because I was very interested in training neural Nets and so I you know um did like the Uber AI like residency program which transitioned into like a full-time kind of like um uh research offer type thing but basically um I was working on like deep learning for self-driving systems and this included like uh different types of like image understanding uh sensor understanding um and also like uh planning right and and uh some of these Concepts as you dive into it they're starting to become some similarities between like kind of um like planning in the traditional like deep learning sense and then also like LM planning um and you know there's some patterns that are that are pretty interesting to explore there but basically I was I was um very interested I worked a lot on like sensor compression so how do you like compress images and sensors um using like the relevant algorithms but also using neural Nets um and then I worked a bit on like robotic clanning as well so being able to figure out how do you like make the right decisions like if a pedestrian is crossing the intersection you obviously want to make sure you break how do you predict their behavior and make the right decisions there um and then after that I um had worked at bigger companies and I really wanted to see what like an early stage um eops company was like and so I I joined robust intelligence um and robust intelligence was like um it I think I joined as like the ninth or 10th employee um so pretty early on and you know um like I wanted to really understand what it meant to one build something in the ml space that actually could make money um because as part of a business and then two is like really understand the growth journey of an early stage startup and I think I actually got a bit of both like I mean um like I I learned how to um really aggressively prioritize things um especially in a startup environment when you have like limited time and resources um and it's a little bit different than like the academic environment where uh kind of you do a PhD for instance you're supposed to you know like spend time like really reflect on kind of like wait what to do like build build something that's deep and meaningful um in a startup you don't have a lot of time and you really have to just make sure you like aggressively like 8020 like the the very first thing you want to build um and then you want to make sure that like um you're able to kind of like build initial versions of something before like diving into something more uh more deep and complicated um so I learned a bit of like you know that type of uh fundamental tradeoff the um ability to like lead a team inter interact with product a little bit of like being on these customer conversations as B I think it actually gave a pretty solid base for just like um kind of starting this company later on um I think you know in general you know if you're like a listener and you really want to like start a company I think actually a good um like training ground is to just work at like a a um like a like early stage company with very talented people uh people that you respect um and just like really just try to learn as much as possible like inhale as much and fres shot as possible in the first year or two yeah it's some amazing advice I think so would you say that as far as I understand Mo pretty much all of your experience is in machine learning um had you ever considered going to the software development side or not really you were always completely uh on the machine learning side yeah so I think as a um as was a machine learning like engineer basically um at both quora and um not at Uber but but at um Ara and and for both of these jobs I think it it does involve a decent amount of software engineering um I was more on kind of like the yeah but but obviously it's it's a little bit different than say like pure infra engineering like I I didn't I never spent like a a significant amount of time work on like distributed systems for instance or kind of like doing deployments and you know like networking like all a lot of like different types of Concepts and like traditional software engineering um I did internships like uh you know throughout the the colleg years so I built up like some some Foundation but in in general I think um Mach like the intersection between machine learning like engineering and and product was where my primary interest um uh like was like the most right what did you study to to start taking up this roles actually yeah I um I studied computer science um so I graduated from Princeton um back in like 2017 um did computer science uh and actually I got into ml pretty late um I maybe that was one part that um I didn't drop in the initial um like introduction to the background is I I started doing machine learning or or really thinking about it like the latter half of like my third year on college or junior junior year um and so a lot of people who are interested in this like especially nowadays like AI is so big um you know if you're like a high school student or something or middle school like you you started like looking into Ai and and you start like trying to understand what it's about but like um at the time I most got interested in AI because it was like junior year of college I saw like one of these example new models that just come out came out that had like really good kind of like image generation capabilities for its time um it could generate like a little icon um like 64x 64 U and it actually looked like sell realistic I was like oh that's cool I want to learn more about that um and that kind of kicked off like my academic interest in the space and maybe realized like this is kind of like an overall area I'm just like uh I guess computer science or computers that I wanted focus on and really understand a little bit more awesome um and that that when was that by the way like in like this is like year 2016 2017 yeah I mean I think it was um like I graduated in in 2017 and I think imet had come out like a few years before that like I mean I think there there was like some initial um excitement in in deep learning um and actually like to be honest I think if you were in the like ml research world uh there was like that hype had basically started around like 2014 2015 um and basically continued and then for basically everybody else for anyone who didn't have exposures like deep machine learning I think that hype kind of took off with like tragic and all these but among like the research Community a lot of the advances and kind of like the understanding of the progression of like uh Ai and results had been um have been going on for a few years right so you were pretty lucky to be like there before actually everyone else was was there I mean I think one of my biggest regrets is honestly I I wish I had just gone into ml even like a little bit earlier if I had like known about like really what it was or thought about it like freshman year it honestly was like pretty interesting um I I probably just one didn't have the right technical fundamentals to fully understand it yet and two like um I just uh it was like what I just like discovered it too late I think I'd always been interested in startups like I'd always been interested in like building something but that typle interest and and machine learning just um I just never really discover until later on awesome um and well and now you have built Lama index and it's gone super far and now you're implementing new products to the to the public so let's talk a little bit more about lamma pars and L cloud and U um yeah just tell me what is lamma pars yeah so um kind of taking a step back uh you know we have this like orchestration framework um we had lot we had we have had llama index which has been around for about like a year a year and a half um it's fully open source it's going to continue to be a core part of our strategy uh we want to make sure that you know we build the right tooling um to enable any developer to build these applications um both when they're prototyping and also when they're productionizing um I think like the overall motivation is that as we started talking to a lot of these like Enterprise developers we realize that um they're running into just like General Pain points right um to in in building something that was production quality um the response quality wasn't high enough they were having a hard time trying to improve the application um they were running into like hallucinations they they were having a hard time like trying to connect to more data sources and so fundamentally when we thought about kind of like a managed service to build we wanted to build something that actually uh solves some of these pain points especially in an Enterprise and production setting so um the overall like uh summary of like the Lama Cloud platform is it's meant to be a over like data platform that is going to process and clean your data um to the best quality for LMS and so um we think that like you know good data is essential for good like downst performance with any sort of software that you want to build um if you don't have good data quality that typically leads to all these issues that I just mentioned and so we wanted to build some overall service that can basically parse index um and clean and also let you retrieve over this dat up to give you back the best interface for your lb to work with to access any context that you have within the organization um so that's the high level picture of LL cloud and it consists of a few different uh core components the first is a set of like data connectors uh to basically load from any sort of um data source that you have so like unstructured data um like any sort of documents um and then you know we're we're building these Integrations for like semi-structured data and structured data we actually already have a ton of data connectors on the on llama hub um which is our open source like purely Community drippen set of like data connectors and we're actually working to make that all those available um within the Llama Cloud platform as well and so um llama like uh llama Hub like the open source uh integration ecosystem has been very powerful because there's actually a lot of really good stuff out there and a lot of that has been like Community contributed but anyways that's step one so like connect and load your data two is actually having proper ways of parsing your data and this is where specifically llama parse comes in um and so parsing your data um in this setting really means like you have a PDF how do I actually like load and extract the information from this PDF that basically like maintains uh kind of like the original structure of the document and also maintains all the content and so this includes like you know often times when you load in these documents it it's um a lot more complex than just like a pure wall of text you can have like tables you you can have charts you can have like uh complex like spatial layouts you can have embedded images as well um and so I think about like PowerPoint presentations as well where it's not really just the text that matters it's like the set of like objects you put in it and also the spatial uh positioning of everything um and so if you tried like traditional parsing techniques it they tended to do very poorly on um on these on on these types of documents like if you just took an open source out of the box solution so LL purse what we um had an insight into is you know like just roughly speaking it's powered by like Tren powered by LMS but we we have like an Insight that we can basically kind of like build a differentiated platform that can really like parse and extract information from these documents um in a way that's specifically geared towards getting other LMS to understand this data um and so LL parse itself exists as part of llama Cloud but also um as a standalone AP that you can go ahead and use um and so uh after you parse your document then you want to you know like process and and embed it and do a bunch of Transformations before putting it into your um your your uh storage system and that storage system basically represents like an interface that your LM can interact with so the um storage system is you know a vector database and the processing and betting include at a very basic level like all the chunking strategies that that you want to think about when you like split a piece of like process data um and then embedding of course is actually generating like a factoral representation for each TR um and so there's just all these different steps um kind of similar to what we talked about at the very beginning um toward to making this like type of ETL uh possible and we want to make sure that we provide um you know Enterprise developers with the right interface to basically perform the this type of like data cleaning uh Transformations and retrieval um so that it basically saves like the developer time in building something that's production quality um and um can basically abstract away a lot of the data processing complexity and as a result the the AI engineer within the Enterprise can focus on the um kind of like the orchestration logic on top this data all right um just to be sure that I didn't get lost there you told me there are four steps where Lama L Cloud um helps developers you talk about data connectors that live in Lama Hub you talk about parsing what what were the other two yeah so so um the three or four steps roughly is um uh data loading um data parsing um so data parsing is through lva parse uh data processing um so being able to transform that data um and then um I guess like data storage which is like putting that data into a vector store so lava Club we're not like building our own um Vector store but rather we're leveraging the fact that you know we connect a 40 plus uh Vector stores on the open source um and so we're able to basically process and transform and put that data into a storage system of your choice so developers can use pretty much any Vector store they want with lamac Cloud exactly does that mean that the data is going to be stored within your servers or not um that's a good question so from like a systems architecture standpoint um we like it it exists you know kind of like in a uh like initial State as um like a service but we don't store NE like that data at rest especially like the source data uh we might store some like metadata or annotations but like we move data from your data source and put it into like the storage system and and usually there's like API interfaces to connect to your storage system um for a lot of like larger Enterprises uh we're offering like kind of byoc options um so that we're actually able to deploy that in your uh Cloud VPC so then it's collocated with like this the both like the data sources and also like storage systems that you're using so they can have lit Cloud within their own premises as well MH amazing um talking about the first step of this process that you mentioned data connectors um you talk about Lama Hub which if I understand correctly it is a Community Driven hub for data loaders right what yeah what would you say are your favorite data connectors if there are so many are there some that were kind of unexpected that you would see yeah well so we have a bunch of fun ones um I think we have one that like you know just the reads from uh different types of websites um I think there's one that reads like I think it was either Hau or something anyways so it was just like some some like uh like fun oh there was there was like a dad jokes reader I remember and like reads dad jokes from this website anyways so so that's obviously you know Less on the useful side and more on just like oh there's like some fun Community contributed ones the most useful ones are the um document loaders this is uh Microsoft SharePoint um this is like uh S3 this is like uh like GCS um the probably the predominant way that people are using llms on data is through um processing like uh indexing documents um and so usually their documents are stored in some sort of bucket somewhere um right so this also includes like Google Drive um Azure blop store uh like basically all these different types of uh document stores Solutions the next most popular ones are probably like the common software systems that that we use um and this is probably more common for individuals or startups um but like notion um slack uh uh Discord those those are those are super popular um basically I and I think the reason for this is just like you know if you think about just where is information stored in like an employee or individuals like dat to-day use um it's typically in the form of like one files two in conversations and three in just like any productivity tool that you use right and so that that's going to be the most popular data sources awesome and then the second step that you mentioned is parsing which for which you have LMA pars just to make sure you you mentioned that you can use lamma pars as an API so you do not need to be using Lama Cloud to use LMA right yeah um so this um yeah so llama parse itself exists as a standalone API it's also natively integrated as part of this overall LL platform if you want to Define your indexing and uh in Resturant workflows so llama parse itself um as an API um you can upload your document like a PDF and you can get back like a pars markdown representation um and what this will give you is it's very good at yeah like extracting out like uh like tables um images embedded objects from this document you can actually input here's a special feature of w parse you can actually input paring instructions um so in like uh this is not really the like you don't really see this in other parsers you can basically inut a prompt you can like you can say you know please extract out all uh paragraphs as bullet points um or please extract out or like for every piece of text like tag it with a pat number um you you can do that and and I think it will probably work if you try that um and so this is um the property of the fact that you know L purse is powered by just like J out all right so I mean to be clear Lama pars allows you to ingest pretty much any kind of document be it PDFs be it um slides from PowerPoint presentation or something like that and get a structured or a text representation of all the information within your document right exactly yeah that's a good way of putting it um so it gives you back like a structure representation um and it handles most common types of documents um I think the the one one it doesn't handle which I'm pretty open about is like Excel sheets um just because Excel sheets are are like its own Beast um and and we're still try to figure out the best way to process it right and how is that different or better than just performing OCR in your document so OCR is like a part of it um but if you think about it like um there's like um there's OCR on top of like a scanned kind of like receipts or or image and and that type of thing um that that's actually part of La parse but there's other parsing complexities too so for instance let's say you have text in like a two column layout um and you also have like headers and Footers um basically like we not only perform like kind of basic OCR we also um do some general like algorithms uh to basically handle like document like reconstruction and processing um to make sure that like the spatial layouts are preserved and that we're able to tag it with like the right sections um the other thing that we do is like um like for instance for like tables right which is still represented as like text um there's like some special care that needs to be taken to basically make sure that the tables are kind of aligned so that like let's say you have a bunch of row and you have like a set of columns you want to make sure that like all the numbers in the column are preserved because often times what you see in some of these parsers is like the numbers get shifted and they get mapped like a different column or something um and that leads to obviously hallucinations because then the Alm doesn't understand what's going on um and what we found I think an interesting thing is if you can somehow solve this problem and you can somehow basically you know get the text to appear in like a nice representation it helps um helps Alan understanding and actually reduces hallucinations too awesome and that's um so that is Lama bars basically it allows you to perform OCR plus a like a real understanding of the contents of the document included images and tables which are surprisingly difficult to parse when you're not using a system that like this 100% And and just a brief note on like why why are we doing this um the goal wasn't just to create like a nice PDF fser I mean it's it's pretty good at PDF forsing like to to be totally clear it's it's actually very very good and that's why I think a lot of people are interested um the overall goal is to make sure that we can tie this into this overall story of giving you like proper like rag or like context uh without hallucinations um for so like our goal is not to build in like all the features that a traditional PDF server might have our goal is to build in um specifically the right techniques uh so that we can basically represent your data in the right way so that alms can understand it and are accurate in synthesizing uh you know information over awesome and yeah it goes back to what we mentioned at the beginning using llms also during the baring process which is kind of what you were trying to do from the beginning yeah so that that that's a good point um so actually you can so um you can have llms as part of this like paring process um you get have LMS as part of the transformation process um like the kind of like chunking the metadata extraction all these things okay um like extracting out of structured outputs and then and then and then all this is in the spirit of like actually feeding this into some more LMS that go and like do rag over your data and and like perform like a gentic workflows over your data too so yeah you can have LMS throughout this entire process and it's very interesting to see where they can be applied and how they can all work together awesome all right and is okay and so Lama just to be clear Lama pars is already open to the public can people start using it now or not yet yeah so LL parse is available uh like basically to the public you can actually sign up for like um uh there's like a free plan as well as like a paid plan um we have a pretty generous allocation you got like thousand Pages a day um just for free and then some there some like usage race pricing um and then llama cloud is uh kind of in like a private preview mode um we're hoping to open it up a little bit more um very soon but in the meantime if you're like an Enterprise that's interested in building like theform Rag and a team based way and you want to you know like save ENT your time on on connecting to your data and processing that come talk to us um and you very open to these types of conversations awesome and okay so we covered the first two steps that you mentioned the processing part can you shed a little bit more light on that how do you use H H how is the processing part smart or smarter than something that you could code uh yourself so I think for processing I think the interesting thing about processing I mean it's pretty related to uh some it's actually related to ing um it's also related to some of the stuff I mentioned before which is like how do you just extract out structured information from unstructured data um and I think like metadata extraction um I mean I guess that's an instance of the structured extraction but roughly speaking if you're able to do that then you're able to attach or augment the existing unstructured data with the right tags which then allow you to better um search in query and filter for this type of information because instead of just doing semantic search by embeddings you can actually filter by like a SQL statement or you know you're able to filter by the specific tag or topic and so I think the way you can use albs to do like structure data uh extraction is you can basically um at a very basic level feed in text into the input prct window of the Ln and ask it to generate like the set of like structured information that you want um and so if you're able to do this uh scalably and reliably over like a large Corpus of unstructured documents then you're able to like generate structure from these documents um and so the different types of structure include uh like I mentioned like kind of simple annotations they could include summaries they could also include relationships between documents um this where start getting into like knowledge graft territory where you actually not only look at kind of like the information within a document we also look at how different concepts um or or I guess like um yeah how different con how the same concept across uh um uh different documents and how you like tie different documents under the same concept and um if you're able to do that then you're basically able to kind of construct this overall like structure or ontology over your uh document set um and of course you can and probably should use LM to do that um after a certain point because to do this uh purely by hand is like super timec consuming and then and then once you have that structure you can leverage like Advanced retrieval index uh like retrieval capabilities over that and your testing I mean I suppose that generating this smart metadata and associating it to your nodes or to your documents in your vector store that improves frag uh by a lot right I suppose yeah so um this is on a very like this is a little bit technical but there's a few ways it can actually improve um generating metadata um directly plugs into metadata filters in a lot of that's implemented in a lot of VOR DPS and so um what metadata filters allow you to do is basically um filter by like structured tags um in addition to just like top case antic search um this gives you more precise retrieval results for instance if you specifically know that you know you want to search within a set by this topic or by this state or you know like uh lower than this value um you can basically imp like do that and then you're guaranteed to only have uh results that satisfy those constraints that you set out um so um this leads to more precise retrieval the the other two pieces is having tags actually helps your embedding representation a little bit so for instance let's say you feed in a piece of text to an embedding model um you could feed in just the text itself if you add in some additional context from like you know the overall summary of the document or like camic annotations like the the name of the file or the page number those types of things um that can actually help your embedding representation and really good embedding model can take that information to so that um when you ask a question relevant to the stock it's more likely to be retrieved if you had this metad dat then if you didn't um via like semantic search use sorry yeah go on oh sorry no I just mean um finally it's like a similar thing um this also helps with adding the right context when you feed this into the LM because in LM like if you um let's say you didn't have a summary of this document would just have less context on what's actually going on and so generally speaking like the more context or um you can basically ground the LM in with more information so that it's more likely to generate a result for you um that's what you want um and doesn't awesome is it does it not explode the costs of um ingesting your your data how do you deal with that if you have a lot of data in a company for example yeah I mean I think uh you bring a good point I think uh well so metadata itself can be both like llm and human generated um and so if you have like too much metadata that's also a problem because then like every piece of text every document just has like a lot of metadata and and that can actually degrade performance in many ways I in both accuracy and also costantly Andy um so it is a Troff that people have to consider um the other piece is like yeah if you use llms um always to basically just like kind of um extract out like structured metadata from all your documents that is going to uh cost a bit of money especially if uh you have a lot of documents and you're using very powerful models I think my hope is that one um the model um the the well as context Windows get longer um and as the token costs come down and as models get faster hopefully this problem does um like get alleviated a little bit over time um and then the second piece is that you can do some basic optimizations so that you don't have to fit like the entire text in the context onee if you're trying to do structure data extraction you can still do like vector search uh retrieval um to basically do structur data extraction and the trick is you just got to make sure you find the right bits of text um you know um basically you like pre-index the text and then retrieve just the right bits this is very it's basically a rag pipeline right um to just like extract out like structured information as part of that indexing or part of that like uh like processing so awesome it it really sounds like an amazing service the entire uh Cloud suit that you have um by the way I I also had a question about the embedding models that you're using over there um are the developers capable of choosing the embedding models that they that they're going to be using in lamama cloud or do you have your own embedding models that would make it more costly to migrate later on oh that's a good question I I think right now we integrate with roughly off thee shelf embedding models um I think the idea of having like custom fine to an embedding models is very interesting one um I think yeah I don't I don't know about like training one from scratch um that one's interesting to consider I think the thing that I'm interested in is like if you have a eval data store have human feedback over time uh you could potentially have like a fine tuning layer on top of your Artic model right awesome I don't think we we talk about it enough but I I mean the part of passing instructions to your parsing model that's that's just amazing uh I I suppose you have only ones who do that right I I think we're the only ones that do it right now um though you know like others might might do it it's a cool it's a cool Nifty feature right I think if you're if you're a listener I definitely encourage you to check that out and um yeah give us feedback you know we're always uh kind of hammering out like all the longtail like kind of nits and bugs and those types of things in in in the parser um and so we're very receptive to just like helping to sharing your feedback and inting the see more that's amazing amazing um also um I mean talking about that as well do you have any more uh services or products that you're thinking on bringing or is that your main focus for now um that's a good question I think that's the main focus for now I think the two main goals um for this year is basically uh one um uh expand the open source um and I can talk a little bit about that and then two like expand lava Cloud um and so 50% on each one uh and you know we basically have our team kind of like the most a lot of the team works on both um but roughly speaking you know they they work like uh the overall allocation is like 50/50 um in terms of the open source it's basically about continuing to make everything production ready robust um and basically um evolve with any new use cases that are emerging um and so being able to stay on top of like all the latest LM advances integrating with these models um building out these use cases and then from an Enterprise side is basically kind of uh it adds quite a bit more layers of complexity like adding in um really the product maturity to make this thing a scalable reliable service that's like Enterprise grade awesome and about the open source part open source projects sometimes tend to be monopolized by super big companies right do you see I mean how do you see the future of this open source um sorry not models this open source Frameworks because do you see Google or meta U jumping into the race with this like they did for example with react or how do you see the future of this industry that's good question I I actually um I actually don't believe asly in that and and part of the reason I mean it's Al always possible they might like for instance Microsoft already has a few Frameworks they have like um santic HL they have autogen and you know like some of them are actually doing pretty well like I think autogen has a decent number of downloads I I think the main thing is like um first of all all these companies are creating their own models um and uh part of the valy prop of being a framework is that you're completely agnostic to the model um and I think like the there's just always going to be like a little bit of like an adverse incentive so that they're less like Community friendly than literally like a startup that like doesn't care what model you use right and we actually just want to integrate with everybody um and so I think we take that perspective for basically all the models um all the VOR stores kind of like the set of like Integrations um like all the data sources for instance like we want to make sure that you have access to all the data that you want um and so it's just I think a little bit harder for a larger company to be able to kind of like uh build that type of ecosystem uh when they specifically have like one type of model or VOR something that they want to push yeah because they're going to be biased towards their own products yeah right yeah I mean that's some pretty interesting insight about that um let's look a little bit as well about um what you see in the future of the industry and some advice that you could give some other advice that you can give to beginners in this in this space let's say for example that you were starting off today like you're you're you're not a machine learning specialist you're a software engineer and you want to start working in this industry what would you do first yeah so um I mean not to like um like hype our do our documentation has like a nice sequence where basically it's like I would start off like the with the basics just like do the Prototype first do the thing that takes like five lines of code just so that you actually see that this this is like um like like the overall use case that you're building towards um and potentially see why it's interesting and then once you start with the basics then you start going on like a little bit more of a guided tour through some of the components let's say to build a rag system um I would try to like um as you start at the surface layer start to go a little bit deeper into each of the different components uh really understand a little bit more about how they work um and then two build in some like development principles around like iteration and evaluation I think the maybe the difference between um AI engineering and software engineering is that I think in software engineering you know when you want to like test a piece of code you're very used to like writing unit tests or integration tests and that generally speaking you know like the fun the the the types of logic you're writing are not super complex and so it's pretty easy to reason about like the overall Behavior or at least like what the outputs inputs outputs should be I think the difference with ML is that everything requires some sort of data set because the function space is like super complex like if you put something into an outline you really don't know what the output is going to be and so you need to make sure you have the proper benchmarks and ways to like test these sastic systems um and so like um having like some sort of eval approach like we have e modules you know in llama index we integrate with like a ton of different eal providers that'll provide like really nice services around like tracking these metrics and experiments um having that is pretty important um and then like from there basically work your way up towards like scaling to more data sources like if you want to scale them more like uh documents for instance like you can use like w parse or you can use like anything that you want really um and basically uh like start to add in more layers of complexity with like that kind of eval bench mark fixed so that you can make sure you're not like introducing any regressions in performance um and then as you start with the basics um I think I think rag is probably the thing you should probably learn about first um just because I think it's it's easier to learn than agents um agents can get really complicated uh and and like even I'm like confused sometimes about like uh what exactly am I supposed to be doing in like the specific module um and like and there's also high level agents there's low level agents there's multi-agents I would start off with rag ra rag is a lot more simple to digest um and it's it's not simple either you can go in and go into a rabbit ho but at least like it's easier like we saw yeah but like you you learn that piece first um and then you start kind of like uh adding on like uh some ingredients or layers like memory um the ability to do uh like uh multi promp like pipelines like chains all these types of things to to basically freeze and over things um and then you start getting a feel for how to build more complex systems right and um about about agents in particular right so that's I've heard a lot more people talk about agents recently then let's say when when GPT 4 came out or when gpt3 came out right um how do you see the future of agentic behavior in the sphere do you like what what is the future that you see with agents even though it's pretty early on in the sphere yeah I think I mean it's super exciting I mean I think like Andro for instance been tweeting about it I think like people have been building it and it started to work I think uh people started like building stuff last year with agents but at the time it just didn't really work super W and I think right now it still doesn't quite work super well but at least like it's starting to kind of work um so examples like uh like all the autonomous coding assistants like you know jupy pilot Devon um uhu agent um I'm forgetting some of the names like open Devon like some of the projects are popping up um to basically be like a worker for you that can operate independently um and autonomously as opposed to just like you chatting with it back and forth um and I think like people are like things that are cool that are really cool and this is an example of something that's really cool and then once they um uh afterwards they want to learn how to build it and so I think there's a revived interest in how do you actually build like um scalable reliable agents uh and I'm really excited about it I think we well like llama index on the open source side right um I know we we talked bit about like L floud we're making a big push like agents um just like better agent education abstractions materials resources um and like I think there's going to be like two ways that people build agents one is if you're a developer that doesn't really care as much let's say you're just like less technical or or you you don't like really need to understand the fundamentals there's going to be high Lev interfaces that you're going to be able to create agents and I think like for instance um this isn't like quite what I'm uh like the like like an example of this is like autogen or crew AI actually like if you take a look at the interface I think it's like um you can just Define like the rules uh and kind of like the overall task you want to solve um create like the network of agents that you want and then it's roughly equivalent to like pressing a button you just press like go and then let them like figure it out themselves and to some extent like you go even high than that it feels even less than like programming um because it's kind of like um you can do this through like a low code UI basically right just like kind of like Define the set of things you want to do and then just have them figure it out um and then like on the very like kind of other end of the spectrum you have people basically building Agents from scratch or kind of like writing in all the logic like all the kind of like custom like prop flows like all these like decision points and I think that's typically for people that are more advanced and really want to like have like um have control over like what uh this thing can do um but of course it takes more time um on the flip side you a lot more control over the logic um and I think like there's going to be a funnel of people going from like building these like high level things that can just like go off and do stuff uh to like um kind of more advanced users that that um can really customize it to their use case that'll probably make it easier to implement them in production right because I'm not sure if we're going to get to a moment where we can deploy to production things like these orchestration systems for agents where pretty much they just figure things out by themselves it's I'm not sure how to I mean yeah how easy it is to get to production with those I mean I think that's an open question mark I think um I think everyone's like scared about it right now um because you know obviously there's obvious concerns like okay well obvious you have like no proper guard rails you don't really have a way to inct control like those types of things but assuming you were able to Big in some of those interfaces almost like out of the box by default I could imagine like if you just have a very opinionated abstraction that somehow guarantees some degree of reliability then people would be willing to use it awesome yeah and that have you seen some that kind of uh systems being deployed in production already like agent swarms or not yet not really um however I think a lot of people yeah I think I think you know there's all these like stars popping up but yeah yeah and of course you can build agents with Lama index yeah and we're Mak that part so um yeah we're making that part a lot more uh comprehensive and and robust and specifically I think the thing that I think oftentimes people don't realize you can build like your own custom ads and l n you can basically actually do whatever you want you can use out of the box uh abstractions that we have we like function calling like some cool new agent implementations and of course react uh the one thing we don't quite have right now which is coming out hopefully relatively soon is like multi-agent stuff uh so being able to have like good ways of setting up like multi-agent communication um uh like being able s asign like a as you said like a swarm of different things um and I think that's something we're we're working on hopefully hopefully we have like an exciting release you know awesome awesome amazing and um to finish I also wanted to ask you is there any way or opportunities that people can contribute with llama index to make it grow and to maybe give you feedback how how does that work yeah I appreciate you bring that up I think um we love contributions we love the community I think we're always open to more types of contributions um I think there's different types of contributions I think the most uh a very um classic one is actually llama Hub so llama Hub is not just like data loaders it's our entire ecosystem of any type of integration and so this includes lm's Vector stores embeddings agents uh like different templates that you want to contribute we're always looking for new types of like packs or templates or new types of Integrations um so this is like a pretty easy contribution interface everything is version track and so if you uh contribute something you can pin the dependencies to make sure it doesn't break later on um and so we spend a lot of work trying to make that really good um and so uh llama Hub is is would be a great place for contributions and then the other is I think as people go through the project they submit like kind of like bunk fixes like uh Nets like documentation fixes all these things are are obviously like like very welcome as well and um one last question if you were starting off in the industry right now and you wanted to create a company what kind of companies would you think of creating yeah I um probably I mean probably L related I think yeah know it's it's interesting I I um I'm trying to think like to be realistic I think there are going to be C you can start any company you want as just like certain companies I think are going to be a little bit hard to start than others right now um I think like uh if you start a foundation model company I think that's going to be a little tricky um unless you have like a differentiated view on like Foundation models maybe it's like super domain specific um for instance I think like um I think infrastructure I think there's certainly opportunities there I think certain parts are maybe like a little bit more saturated than others um I think like EV valves for instance and observability is a little bit more saturated uh to to to be totally honest because there's like a lot of these types of companies um and I I think like if you were to build something there you'd probably need to build something more debain specific um and then actually I think this is probably the general Trend and then I think you go into the application layer which is inherently like a little bit more maybe like um kind of like domain specific uh and you can you know like um you can like try to figure out how to build like General like um like applications that really solve and use cases very well I think if I were to build a company today I probably uh and and um okay actually it's not necessarily something I would build it's just like an idea um I probably think about building actually an agent that actually works really reliably that can solve like a critical business workflow really well um I think like I think similar to how dein I think had like a really cool demo for like you know a software engineer which to be honest a really hard problem if you just built like kind of like an agent that can go ahead and actually like perform like a sales task really well uh or for instance like perform um like uh kind of Ops like assistant or even legal work really well I think that's something that I'd be really excited about yeah that would I mean so many things that they probably going to revolutionize every single industry on Earth right now um all right well I don't know if you have any other comment that you would like to make something that we forgot to mention no I mean Alandra thanks so much for giving me the opportunity to uh and and asking all these questions I think we've covered both um the open source as well as like uh some of the um the the Enterprise aspects so L index the open source you know broad orchestration framework um always improving welcome to contributions um and then uh Lama cloud is you know the Enterprise data platform for kind of like data processing and intruction um and then oh last bit is um I I mean um if you're interested in uh kind of like uh AI engineering and those types of things we do have like a career swarm so feel free to just put your name down so PR uh just a quick call out there but no thanks for thanks for having me on I think this is a fun trat and for it's been it's been amazing and thank you for for all your detailed explanations of everything that I that I asked you about sometimes I was a little redundant probably at some questions but to to make it as clear as possible for for our listeners and for me 100% yeah no I appreciate you asking doing that because I I think sometimes I just get in this mode of like kind of um uh like assuming that people already have like context into things and I think it's good to like take a step back and really go dive into like building stff ground up amazing well thank you very much Jerry it has been an absolute pleasure talking to you pleasure talking to you as well [Music] [Music] m [Music] [Music]"
7DJzHncUlpI,2024-06-05T05:07:00.000000,LlamaParse: Convert PDF (with tables) to Markdown,good morning everyone how's it going today welcome back to the channel in today's video I am going to show you how to parse a PDF file and how to convert it into a markdown file and this is very interesting not because we're not going to be using a regular method just like OCR or just regular PDF uh loaders from other libraries but right here we're going to be using an API from Lama index and it is going to allow us to parse the PDF and to also parse a little bit more complex parts of the PDF like tables and if you have been building rag applications for a while you know that parsing tables can be a headache if you're using simple methods like OCR to parse your PDF documents right now the reason for this is that when you're using OCR for parsing this kind of documents you're going to get a simple line for each line of your table and in a table of course each element of the table uh contains information not only related to its line but also to its column and Performing simple OCR is not going to allow you to get that information and if you send just the line information to your language model the language model is most likely not going to be able to interpret that information so the idea right here is that we're going to be using lamap pars API to send this document to their API and in return we will get a markdown file that looks something like this and as you can see it it has the tables in markdown format so this is the kind of uh format that you can send to your language model and it is going to be able to interpret this and it is going to then allow you to have a chat with your PDF application with table tables or with tabular data okay so let's actually get to to do this with Lama pars [Music] all right so quick um just quick explanation of what Lama pars is it is an API by L index you can send your files to this API and it will return to you the structure data from this file and something pretty interesting about this um ingestion method is that they use generative AI during the ingestion process in regular rag uh Frameworks or rag workflows the generative AI actually comes at the end of the process which means that when you're only actually just sending the data to your language model and getting the result back what they do is they actually use gen AI during the ingestion process to allow you to understand your document a little bit better uh during the parsing process and they support several types of files they support PDF PowerPoint uh Word documents Etc probably going to be making more videos about this if you're interested uh but yeah I mean Ian the idea right here is that it is an API and you can basically just parse documents without having to create your own um data transformation uh pipeline so you just send the your document to their API and you get the structure data in return um and of course they have a paid plan um but they also offer a super generous free plan of a thousand Pages a day which is super cool so I really encourage you to use this in uh your projects if you're parsing less than a thousand projects a day it's completely free and yeah so let's actually get right into into building into parsing this document so let's do that all right so we're at our Google collab file just making sure that you see everything that's going on right here um and what we're going to be doing is we're going to first install lamap pars and then we're going to download this file that we have right here so so the first thing to do is install LMA pars and in order to do this all you have to do is to pip install LMA pars and there you go and of course if you're creating your own application in your virtual environment don't don't forget to create your virtual environment before doing this and once that is done oops and once that is done we're going to be able to just download the file that I showed you just a second ago and in all the to do this I'm just going to use W get and there you go so in I mean just to be sure that you understand what's going on here W get just downloads the file that I have right here and I say that I want to download it into the Apple low d10k PDF file file and as you can see I have it right here already so there you go now the next thing to do in order to set up this um this uh project is we're going to want to oops we're going to want to create a we're going to want to initialize Nest ASN K and this you're only have to you you're only going to have to do this if you're in a Jupiter notebook or a callup notebook because LMA pars which is the API that we're going to be using remember that it is an async um we're going to be using async method methods and async methods are not to work in a cab notebook so this is only for this to work in a cab this is not necessarily related to to the to the API itself now let's just initialize our API key that we just created and we're going to name it Lama Cloud API key it is important to name it that way because that is the name that um lama lama par method is going to look for in your environment variables and here you have my API key which you can of course copy but it's going to be useless because I will have already disabled it by the time this video is up so there you go now that this is done I mean to be clear this is the place where you're going to put the API key that you can get from here so you go to cloud. Lam index. you create an account you go to API keys let me just zoom in a little bit go to API keys and you Cate and generate new key and this is where you're going to create your API key and then you're going to paste it right here all right so once that is done we can actually start parsing our document so let's do that right now great so in order to parse our file the only thing that we're going to want to do is we're going to import oh wait from LMA pars we're going to import Lama pars itself like this there you go and then we can just just actually initialize our we can just I mean literally just call it and it's going to return to us what we want so I'm going to call it document and this one we're just going to call Lama pars like this and the first um argument right here is going to be the the target uh format that you want your your structure document to be and in our case we want it to be let me just call it it is result type and this one is going to be markdown like that then we do dot load data and right here we're just going to send our actual PDF file so I'm actually going to come right here click on copy path for this file right here and I'm just going to paste it right here like that so I'm going to execute this and it's probably going to take a little bit of time because it's oh well that was pretty fast and let's see what document looks like as you can see it is quite long let me just put this right here there you go so as you can see it is quite long let's see what we have to show right here so at the beginning it is a list apparently it contains a document with an ID embedding non metadata I mean you can all of course add metadata as well within this method and right here we have the text um uh property and this is the text that is contained in the entire PDF and as you can see we have tabular data right here so that's looking pretty good let me show you real quick how it looks like so I am going to come right here and I'm going to do print going to do document and as you have saw as you saw this is um an array or a list and the first element is the only document that we have right here so I'm going to do zero and as I show you as I showed you the contents are actually within text so I'm going to show you text I'm going to show you the first thousand characters so let's see how that looks like and there you go here you have your actual PD uh markdown file for your for your PDF with tabular data in markdown that was pretty easy okay so great job uh good job so far um now I'm going to show you something super cool which is that you can actually add a prompt to to Lama pars to tell Lama pars what the document is about because remember that Lama pars uses generative AI during the parsing process um yeah so you can actually add a prompt to to Lama parts to actually tell it what to document is about and what you want um the parser to do with it because you can even ask it to summarize it if you want uh so I'm going to show you that in a moment let me just actually export the markdown file for you so that you see what's actually going on um here we actually named it document so I'm just I mean just to be clear what is going on right here I am creating a new file called Apple 10K MD and I am writing into it the contents of document zero uh. text which are basically just this I mean the contents that were exported from the from the PDF so I'm just going to run this right here and as you can see I have it right here let me just download it um download and let's just open that file to see how how it looks like um so just going to open a new window here and the downloaded file is actually this one right here so there we go let me just zoom in a little bit so there we go as you can see this is the actual file that was here this is pretty much the same file and all the tabular data is in markdown so this is going to be super useful for you if you want to create your rag application that uh that is going to perform chat with your PDF and your PDF has a lot of um PD of tabular data so there you go that's good now let's actually focus on creating a parser um that is going to take a prompt and that's actually very simple let's just go back to our let's just go back here and right here what we're going to do is we're going to add another um element to this thing right here so we're going to say documents with instruction and we're going to also call LMA Parts like this and here just like before we're going to do let me just copy it it's going to be easier like that we're going to say let's do it like this L Parts the result app is going to be marked down we're going to load the data from here but apart from this we're going to pass in another parameter that is going to be parsing let me just save parsing instruction and this is basically just a string and you can pass in any kind of um instruction you want you can ask it to summarize the document you can ask it to make a list of your tables you can ask it whatever you want uh in this case I'm just going to say this is the Apple annual report it's going to run this probably going to take a little bit more time in my experience when you use a prompt it actually takes a little bit longer but yeah I mean let me just pause the video and show you when it is done and there we go our documents with the instructions having parts let's actually just take a look at them and see what they look like so I'm going to do I'm going to do pretty much the same thing as I did up here just going to export it but I'm going to export the documents with instruction this time and I'm going to save it into Apple 10K instruction and let's see so now we should come right here we should be able to come here and download this right here let's go to code and here is our file so let's see how it looks like um as you can see it updated the title to actually represent what the what I told it what I told the language model that this was about so you can see that this is the it's titled annual report and yeah I mean it didn't change um many other things other than that but this can be very useful if you especially if you have a little bit more complex data and you want for example a summary of it instead of getting uh instead of doing all of the ingestion by yourself and trying to summarize your own document by yourself you can just use LMA pars and just ask it to summarize a given part or the tables Etc and this is going to probably give you better result than better results than if you were doing this by yourself so there you go let me just show you how it looks like in action ual uh markdown so there we go so you can you can see that you have the tabular data right here yeah so everything seems to be working correctly pretty good so there you go that was house to bar that was house to pars a PDF document using LMA pars I hope that you found it useful and yeah let me know if you're interested in more videos about Lama index and Lama Parts in general and yeah I'll see you next time [Music] [Music]
27sEXFWAbw0,2024-06-02T17:33:42.000000,Early days of RAG and LlamaIndex - Jerry Liu,right so about that history of rag modern rag was actually kind of born in 2022 then right um yeah I mean I think like I forgot the exact date of the uh like the original retrieval augmented generation paper uh which is not by me um obviously it was by others um and so this is either in 2021 or 2022 or even 2020 um and the like it basically proposed this overall idea oh you know you take in um some of like documents and then you want to embed them like put them through an embedding model um and then put it into some some storage system that's able to like serve uh like the relevant documents through retrieval right and so that's why it's called like retrieval augmented generation like you want to do like a retrieval pass over some storage system before you actually put it into the all um prompt so that kind of that resurfaced basically um as more and more people start building with lfs people like kind of started discovering that oh hey this thing is like a cool idea um and my initial version was not doing that it wasn't using embeddings um because at the time I don't know why I think it might have just been like due to like a design like my my goal at the time when I first started was not necessarily to make this useful it was to just like do something cool and so the to me like doing something cool was like oh what if we just didn't have embeddings or I thought about it briefly but I was like what I really want to do is just have the L1 um figured out completely on its own right and I I I still think that would be a quite an interesting concept like instead of just like you know relying on a separate model just have a language model completely similar to like a human just completely figure out how to reason organize things and then also Traverse them via text um yeah and that kind of reflects in the current state of L Index right because I mean you it's kind of a central I mean as far as I can see it's kind of a central part of L index that you use language models as well in during the ingestion process not only in the in generation process yeah so the default rag Paradigm um really only uses the LM at the very end um so you have like um inje like inje doesn't need LMS you just take in um you know some data pars it and then you just chunk it using an algorithm um and of course you use an embedding model um to put it into some Vector store and then the retrieval process uh doesn't use an LM because out of simplest it's just like top K uh embedding lookup so like you know um you look up stuff by adding similarity and so in a standard rag pipeline the uh General the the way the place where alms actually come in is at the very end uh and it's only responsible for um kind of just like synthesizing an answer from a piece of unstructured text and to be totally honest like you know it like even like at the start when we were just like implementing this um I thought it was a little basic uh and it didn't really like make use LM so its full potential right right CU like llms are not just uh for Generation um and and simple reasoning they can actually help you make decisions they can actually help you like add like a greater layer of like just like understanding and decision- making and so if you really wanted to make these systems more interesting you could use llms kind of like at the beginning um so for instance during the data injection phase um or you know during query time um instead of just using it at the very end for Generation use it for like query understanding um use it for uh like processing like evaluating like the quality of your retrieve context and then for instance like not only just retrieving for a vector store actually using a variety of different tools um and so on the injection side um the places that you can use llms and so this this this overall concept is pretty interesting which is um the whole point of like inje is to process data for your line map um and so that's kind of like uh ETL for LMS right but you can also use mm for ETL um because you know LMS have an inherent capability of understanding unstructured data and transforming it and that part I think is interesting like so for instance um let's say you know for each unstructured document you wanted to extract like a summary the table of contents um like you know extract like a set of like topics or tags for each page basically you can figure out a clever way to prompt the LM um by feeding it in a bunch of data uh from the document to basically first extract out a set of like structured annotations or tags and this represents like a data transformation basically because you're trying to like feed in some input unstructured data and transform that into structured data and then you can basically attach those tags on top of the unstructured data as well and so these like this is just an example of like metadata extraction that's also powered by LMS and this is something that you know um uses LMS but is also indep like you know useful for just like the any sort of Downstream application you want to build because if you're trying to build a rag system over this having metadata tags is often times very useful it gives you like better retrieval results better generation quality and and all those types of types of things and so I I think that interplay between LMS um and kind of like data transformation is very interesting because you can use it for like in the middle but also it you it helps for any sort like applications you want to build later on yeah that's pretty some Advanced rack techniques over there and it kind of brings goes back to a little bit to your I mean it it's a little bit adjacent to your original idea of uh creating this kind of systems right yeah I think I think the you know I I thought about this in the at the beginning of the project that the project was not really um like close to kind of like realizing that Vision at the time um but if you think about like the overall uh picture of like where I think um LM power software will evolve it's basically like um there's a new type of like data like a data stack that's sub verging um a new set of operations within that data stack um to basically power like um like AI software and to really like um kind of uh like we want to basically provide the right tooling to help developers build that data set um and so this is helping them figure out how do you like you know um move data from one place to another um specifically for LMS to use um and that could include like alms in the middle as well and this also includes the orchestration piece on top of that data how do you figure out how to get alms to interact with the data uh through these different types of uh interfaces awesome hello everyone thank you for watching that clip if you enjoyed that clip you can click the link in the description or somewhere right here on the screen to watch the full conversation for free if the podcast is not up yet you can always subscribe to my patreon to get early access and support the channel and this podcast or alternatively you can subscribe here on YouTube click the Bell icon and you will be notified when the full episode comes out next week thank you very much for watching and I will see you next time
vhbfs38XmKk,2024-05-20T11:57:25.000000,Build a Web App (GUI) for your CrewAI Automation (Easy with Python),"Okay, so we have the first one we have the
first thought. The first thought comes from the research agent we can see that he used the
search and contents tool and what he thought in order to get here was to find the latest and
most relevant news about the USA stock market I should start with a broad search query using
the search and queries tool and the query that he searched for was search News latest news on
the USA stock market now it is the turn of our chief editor and our chief editor also used the
search and contents tool and his thought was to accomplish this task I will need to carefully
review good morning everyone how's it going today welcome back to the channel and welcome
to this new video in today's video I am going to be showing you how to create a graphical
user interface for your crew AI automation I am assuming that you already have your crew AI
automation working and so we are just going to be building the front end in this time okay as
you saw at the beginning of the video video the front end works like this you have a sidebar with
just a short description then some inputs of your Automation in this case it is going to generate a
newsletter from a given topic so one of my input is a topic and then just a personal message
when you click on generate you will have you will be able to see all your agents thinking in
real time on this part of your application okay so you're going to be able to see who is
thinking what what tools they're using who they're asking questions to Etc okay and then
of course by the end of the automation you will have a download button that will allow you to
download whatever your agent produced we're going to be using streamlit to create this
front end which is a python framework that allows you to build front end applications with
a few lines of code now this video is actually a clip from another video that is probably coming
up in a couple of days or next week and in that video I show you how to build everything from
the automation to the actual front endend okay if you're interested in watching the full video
you can click the link in the description and if it is not up yet you can of course subscribe click
the Bell icon and you will get a notification once I upload it now something else that I wanted to
mention is that in this particular video I am using the folder structure that CI recommends
and they generate with their CLI but in case you're using just the core components you'll be
able to you to do that just importing the crew object of your automation okay in this case
just to be clear I am working with a source directory and and then my automation directory
and then my crew. py file which is the one that has a class with a method that actually returns
my crew your project structure may look a little bit different but just be sure that you have your
crew accessible and that you can import it to your graphical user interface okay great so without any
further Ado let's get right into building [Music] [Music] this okay before actually starting to
code this in Python I just wanted to make sure that you understand what the current automation
that I'm working with in this example is this is not essential for you to understand since in this
video we're only going to be working in the front end of the application but I figured that um in
during the process of this of creating the front end I probably make reference to some features of
the application and of the automation so I just wanted to make sure that you understand what the
automation is supposed to be doing so in a very in very broad terms the automation what it does is
that it takes the topic of uh for the topic of a newsletter and then just a quick personal message
and it generates a newsletter okay so this is a an automation that has a team of research agents
who are going to go to the internet and find the most relevant news in the past week about this
given topic okay so in this example for example we have the USA stock market and here we have
just a quick um personal message that is Ste readers welcome to the newsletter so by the end
of the generation I am going to get a HTML file uh with the latest news about the USA stock market
and a personal message on top okay so that is the automation that we're working with and actually
if you're interested in building this automation yourself I'm going to be uploading the video uh
about uh building the Automation in a couple of days or probably on Monday okay so yeah now that
you understand what the automation is supposed to be doing we're ready to start actually building
the uh graphical user interface all right so the first thing that I want you to do is to install
stream l okay and if you're using crei just by doing pip install crei and then just importing the
components you can do pip install streamlit like this uh however if what you did is you run crei
create and then you named your crew then you're probably going to be using poetry as your default
package manager okay and that is what I did so if that is the case you're going to do poetry add
streamlet like that and in my case I actually already have it installed so I won't be installing
it again but once you have done that you're going to be able to go to your um folder and you can
create a new a new directory you can call it uh guy or you can call it whatever you want UI front
end whatever and then inside of it you're going to just create your init.py file and then an app.py
file where you're going to in import streamlit as St okay and now let's continue with the video
perfect so in order to build this graphical user interface I'm actually going to be creating a
class called newsletter gen UI and it is this one that I'm going to be uh running to render my
application okay um and the first thing that I want to do is to Define my main method which is
going to be my render method I'm going to call self and just to be clear this is pretty much the
same thing as if I was not using a class but just to make everything easier and more organized I'm
going to be using a class so here in the render method which is the one that we are going to be
calling to actually render to front end I'm going to set my set page config method from streamlet
to this I'm going to call it newsletter generation this is used to create the title of your page and
then let's set a page icon that in this case is just going to be uh an envelope and there we go
and then let's just let's add that St title new letter generation and then down here let's say
that if name equals main we're going to run the render method from this class right here okay
so let's save this and let's start running it to see how it looks like and in order to run
it very simple all we have to do is to stream lit remember that you have to have your virtual
environment activated on which you're working and you in order to run this you do stream LD
run and then the location of your streamlit application which is in my case is um seems to be
a problem going on here apparently didn't find Q so maybe I have to call it from Source because
I am right now yeah this should work now let's see seems to be starting a virtual server so
let's see what that created um and here we have it let me just open this on the side and
here we have our application that we're starting to build so let's just close
this close this and I will continue building here and you will see in real time how
this is all changing okay um okay so the first thing that we want to do is create our sidebar
so in order to do that I am actually going to be creating another component right here when I'm
using streamlet I like to think of it as a react component with with all your helper functions up
here and then your render function on the bottom I mean this is not precisely how react works but
it just helps me get things a little bit more organized so right here let's create our sidebar
component and the sidebar component is going to have a title got a love ination of course going
to have a title called newslet generator and then just a short description of what this generator
is to generate a newsletter enter a topic and a personal message your team of AI agents will
generate a newsletter for you so let's save this and and let's click always rerun here to
be sure that everything is rerunning correctly all right there we go and now we can run this
component right here and there we go but oh yeah I forgot to say that this has to be inside a
sidebar so with st. sidebar and there we go there we go so now this is inside the sidebar going to
delete this title right here not much use for it and then there we go then let's just add a text
input and a text area for the users topic and the personal message okay because we want to get their
inputs so here's going to be let me just zoom in a little bit so here's going to be the topic and
the personal message from the user that we're going to add to the top of the newsletter okay so
the idea here is that our agents are going to take this this topic and they are going to generate the
newsletter of the most recent news related to that topic and will'll display all of their thinking
and conversation right here and then in the end they will put the final HTML template for our
I mean HTML file for our newsletter okay so now that the sidebar is finished oh let's just add a
button right here St button generate newsletter let's save this and there we go there we go so
next thing to keep in mind right here is the environment variables sorry the state session
State variables that we're going to be dealing with okay uh remember that in streamlet the
session State variables are the variables or the information that you want to keep constant during
the running cycle of your streamlet application in other words remember that anytime you do
anything like press a button or submit a text input or something like that streamlet actually
reruns your entire code which means that some of your variables are going to be redefined every
time that you use something like that in order to avoid losing information that you want to
keep during your session you want to create your session State variables for information that
is going to remain constant anytime something happens during your application and in this case
the session State variables that we're going to be working with are topic newsletter personal
message message and a generating State okay so in order to initialize them in stream L you have
to do if topic not in session State we're going to initialize st. session state. topic equals to an
empty string and what this is going to do is that when we initialize our application it is going to
initialize our state with an empty string because remember that the state lives inside this
property right here called st. session state and if you remember correctly when we created
our text input elements right here as you can see the S text input topic actually has the key topic
which means that anything we store in this let me just zoom a little bit more anything we store in
this text input right here is going to be stored in the session State variable for that particular
key okay and the same thing for this text area right here it has the key personal message which
will maintain the personal message key inside of our session State set to whatever we initialize
right here and and so we have to do the same thing with that other one so if personal message not in
session State we're going to have to initialize it with an empty string like that and there are
a couple more um session State variables that you want to make sure that you have in this case
we're going to be working with newsletter which is just the final generation that we want and
of course we want to keep it whatever happens during the runtime and second thing that we want
to create is the status of generating because we want during the generating status because
we want that if the generating status or set or state is set to true we want to be able to be
running our automation with our agents right here and once it is finished we want to show the final
newsletter and in order to do that you're going to do if generating as well not in session State
you're going to set it to false so there we go once that we have initialized all the session
State variables we can go right here to sidebar again and remember that we had a button right here
however this button is not doing anything just yet but remember that if we want to do something when
we press a button in streamlit there are several ways of doing this but one of them is just saying
if St button and then add our logic inside an if statement this will um this will run whatever you
have inside of this if statement when the button is clicked so if the button is clicked we're going
to set the generating state to true and that will trigger our logic that will start generating our
newsletter okay so let's close close the sidebar and actually write the logic for the generation
of the newsletter great so we have finally we have finished our sidebar our session State logic
we now have to create the com the component that is going to live right here which is going to have
our agents talking to one another okay so in order to do that I am just going to create another
component right here I'm going to call it new letter generation like this and right here all
that I am going to do is say that if St State I mean st. session state is generating which means
that if we have clicked on the generate button we are going to set first of all we're going
to set St session state. newsletter equal to another method that we have here which is
going to be self. generate newsletter and this function is going to take the session
topic which in this case is going to be St session State topic and it's also going to take
the personal message like this just going to close this and there we go so this is going to execute
this method right here which we have not defined yet so let's go ahead and Define it up here so
we're going to say note like this Define generate newsletter is going to take the topic and the
personal message and this method right here is basically just going to call the crew that we have
defined in the previous part of this tutorial if you're watching this video as just the front end
you can think of this as the method that is going to call your API that will return the generation
of your crew and this API will of course have to return a thread of the entire thought chain of all
of your agents okay um so yeah here if you were in a more production ready environment you would be
calling an API right here that would contain your automation from your crew in this case since we
have it all in the same folder in the same project and it is a pretty small project overall all we're
going to want to be doing here is just import from sorry from newslet gen. crew we're going to
be importing our newl gen crew class which is basically this one right here from which you can
run the crew method will act which actually just executes your entire automation okay and remember
that this this one right here let me just show you real quick this one right here takes a few
input parameters which are the topic the personal message and the HTML template okay so let's
get that right here the HTML template I'm the HTML template I'm going to copy this one from here
just going to say that my HTML template is going to come like here this one's going to be self
method like this and we have already imported our class now what we can do is just initialize our
crew saying that our crew will equal our already initialized automation with crew we're going to
let's just Define our inputs that I had right here already just going to paste them so my inputs are
basically going to be this time not an input from the terminal which was how we would usually do
things if we were working directly in the command line but we will be running this directly from the
topic that is going to be passed as an argument to this method and the personal message as well of
course it is going to be coming from the argument right here and this one is going to come from
our method right here just let me verify that the path to the newsletter file is actually correct so
newsletter template. HTML um in Source newsletter gen config and newslet template. HTML everything
seems to be working correctly so things seem to be in order this one is going to import our
HTML template which if you don't remember or have not watched that part of the video is
basically just a HTML file with the template that our agents are going to fill here we have
the title of the day the personal message for our newsletter letter and then for each one
of the stories we have a title the summary why it is important and the sources okay all
right so now our newsletter seems to be okay and right here what we're going to want to do is
let's just call that method okay and let's just return crew do remember that in order to run a
crew you have to run it with kickoff and here we're going to pass in the parameter of inputs
which is going to be the inputs that we defined right here so I'm going to click save and actually
if we run this it should already work however it will not yet log all of its thinking from our
agents right here it will just say that it's going to start thinking and then by the end it is going
to print the results um actually before doing the thinking let's just print the the results okay so
let's say that once we have this generation this thing right here the newsletter generation right
here it is going to be generating my newsletter and after it is generated I want to show it so
so right here let's add another part right here to our newsletter generation component after
it has been generated we're going to say that if as s session State newsletter and let's just
test the second thing right here and St session State um do newsletter is different than an
empty string because remember that when we first initialize this session State variable
it is going to be an empty string the next thing that we want to do is that with a
container with an st container which is um stream L component that allows you to just
contain a little bit of um other components and right here we are going to just show a preview
of our newsletter okay um so in order to do this I have actually already prepared some code right
here so to make it easier for you just going to paste it and explain it to you real real quick
okay of course we love the indentations um okay so let me explain this to you let's see um here
just to be clear that everything is under control and we haven't lost the track of what's going
on let me explain this to you again so here is our new letter generation component which is being
called from the render method right here um we're actually going to call it right here let me see
self. new SL generation like that okay and this component what it is going to do it is going to
load after the sidebar let me let me just show you just real quick without all of this clutter where
this component is so I'm going to do St the title I am the generating component going to save this
and you can see that this one is right here okay so the generating component is on the main part
of the application outside of the sidebar okay now let's uncomment all of this and what is going
on is that right here inside the main component of the application um if the generating session State
variable is set to true we're going to generate the newsletter given the topic and the personal
message that we got from the form in this in this sidebar okay so that is for getting the generation
and then secondly once the generation is complete so remember that once the generation is complete
it's going to be stored here in the newsletter and this automation actually generates just a string
of HTML code so the idea right here is that if the session state. newsletter variable exists and
if it is different to an empty string which means that if it has been changed from its initial value
because remember that down here we initialized it with an empty string what we're going to do is
we're going to create a container where we're going to show it so in other words we're going to
display the HTML code inside of this variable in a small rectangle right here okay but only once the
generation has been finished and in order to do that we run a a streamlet container we write new
letter generated successfully and then we create a download button which will actually allow the user
to download the h ml file that was generated but remember that our SD session State newsletter is
only a string so what we're going to do is we're going to create a download button which is just a
regular component from streamlet which allows you to download a file from uh string and in this case
the download button is going to say label sorry the label of our download button is going to be
download the HTML file the data is going to be of course the new translated that was generated and
the file name is going to be just let's call it newsletter. HTML and then just going to mention
that the format of our file is HTML um to show you real quick how this is actually working I'm
just going to do this without the generation so I'm going to comment out the generation and I am
going to set my new SL variable right here to a simple hello world so I'm going to do div tuck
tuck tuck I'm going to say hello world then we close this okay so we saved this and now
we have that the session State newsletter has been saved and it is this here we have
a problem components has no attribute B1 so apparently we have a problem right here let's
see all right so apparently since I coded this part right here maybe streamlet has updated
their code so I'm just going to remove this preview for now and I'm just going to show you
how the download button works so in the download button as you can see we have the download HTML
file label we have the data which comes from this variable right here which for now is just
a dummy variable and the file name we have it right here so I'm going to click on download
and as you can see we have it right here and you can see that it is the downloaded uh file
that I had created right here which is just just says hello world okay let's close this
and let's return this to how it was so that our newsletter variable actually contains the
generation of the newsletter so there we go so the preview we're going
to deal with this a little bit later I'm not sure what's going on
right here I'll I'll um clear that in a moment all right so hello back from the future
I actually just wanted to correct a quick little mistake that we made while we were coding this
right here you might have noticed it if you were paying attention um here in the function that we
are calling to generate our newsletter where are initialized ing our crew we are creating our
input and then we are returning crew. kickoff however this thing right here new SL genen
crew which is the instance of the class that we initial that we're initializing right here
it actually does not have a method kickoff the one that has a method kickoff is the instance
of crew and this one right here actually has a method let me show you so this one right here is
the one that we coded before this one has has a method called crew and it is actually the method
called crew the one which actually Returns the crew that will have the kickoff method so what
we're going to have to do is we're going to have to do crew dot crew and from here we're going
to call the kof method now this is this just becomes a little bit too ugly so what I'm going
to do is instead of initializing all of this up here I'm just going to initialize it down here
like that and it looks much more clean and neat okay so now it should work and we can continue
developing our stepbystep call back for the application okay so let's do that and then test
it in the front end all right and something that I wanted to make sure that we do by the end of
the of the process is to make sure that we stop the process that is generating the newsletter
okay so if you remember correctly here in our render method we have the sidebar and inside the
sidebar we have have this button that generates the newsletter okay and what this button does is
that it says the generating session State variable to true because remember that by default that
session State variable is set to false and when this session State variable is set to true the
component of the newslet generation is going to start generating our newsletter right with this
with this part of the logic right here um how however there is something to keep in mind that
once this is done that means that once session state. newsletter has a value that is different
to an empty string we're going to show a success message and then we're going to show a button
that allows us to download the HTML file with the final generation of our newsletter and
actually after that we have to pause the generation because otherwise it is going to
continue trying to generate newsletter over newsletter over newsletter so the idea right here
is that after this uh session State variable has a value we can set this session State generating
back to false and that is what we're going to do right now so let's do st. session State generating
equals to false there we go so now we can save this and now this is going to work correctly
and we can uh start testing our application all right so now not only is our automation
working correctly but also we have built a graphical user interface for our clients
colleagues or uh Team to use okay now the thing is that the graphical user interface currently only
has only has a quick sidebar it has some inputs a button to generate the newsletter that we're
going to be generating with this application and then by the End by on the right side or the main
part of the application we're supposed to get the final version of the newsletter that is going to
be generated by this crew um the thing about that is that it would be great to see the thought
process of our agents within the application itself and that is uh actually not very hard to
do so what I'm going to do right now is to show you how to create the step callback that will be
called every time our a agent has a thought every time each one of our agent either uses a tool or
tries to talk to a colleague and loog that not only in the terminal but also in the fronted of
our application okay uh before doing that I just wanted to make sure that everything right here
in the front end is um pretty well understood and that we are all on the same page so just to
be clear right here we have the frontend that is built with streamlet we whenever we run this file
we're going to be executing the render method from this new stat gen UI class and this render method
method basically just sets the title for our application with its icon initializes four session
State variables then renders a sidebar let me just show you a sidebar real quick the sidebar just
includes a title and just a quick text right here description of the application then we have two
different inputs the first one is the topic and the second one is just a personal message that
we will be adding to the top of our newsletter and for this one right here we have the key which
is going to be the topic of the application the topic sorry and this key is going to be stored in
this session State okay so just to be clear every time you have a text input or a text area with
a key whatever value you enter to this input is going to be stored as a session State variable
with this key right here so we have the topic key right here which is going to populate this
session State variable and this one right here in the text area with the personal message has
the key personal message which will populate this variable right here okay and then once we
have both of our inputs we're going to be able to click the button and the button is going to
change the session State variable generating to true because remember but that by default it is
set to false okay and that is the sidebar so once you have completely added your inputs and clicked
on generate it is going to set the generate to true and that is what's actually going to happen
uh want to trigger this method right here I mean the newsletter generation component is already
rendered right here and what this component does is that if the session set variable generating is
set to true it will run the generate newsletter method which is defined up here and this method
takes the topic and the personal message and all it does is basically runs the automation
from crew AI okay as you can see this method just Imports the automation newsletter gen crew
that we had previously created in in right here here there you go and it runs the crew method
which basically just renders the application and it just passes a a few inputs it takes the
topic as we mentioned right here the personal message which will passing right here and the HTML
template which is the HTML template that we had previously created okay and that one of course
we're loading it right here on top with another method which just opens the newsletter template.
HTML file that we had stored up here reads it and returns it as a string okay so there we go that is
what is happening behind the scenes but remember that we want a step call back to actually show
what is going on in the head of our agents okay so what is their thought process so that we can also
see what might be some errors that might be making that they might be making Okay so so let's go to
crew right here and actually adding a step GoBack is very very simple all you have to do is that for
the agents that you want to log the step callback you're going to go right here right where you're
we're adding the parameters for your for your agent we're going to add an extra parameter which
is going to be step call back like this and what this is going to do is that whichever function
that you pass right here is going to be executed every time your agent thinks about something okay
and something that is great about this is that you can pass in the agent output every single time uh
and use it within your callback so in order to do that we're going to be using a Lambda function and
we're going to call it step and right here we're going to we're going to call another function
that we haven't yet created it's going to be called Step callback it's just a method that we're
going to add to this class in just a moment and we're going to pass in the step and secondly we're
also going to pass in a second uh parameter which is going to be the name of this this agent and in
order to do that this one is the research agent like this there we go so now all we have to do is
create our call back function right here or call back method just going to paste it because I have
had actually already created it before and I am going to explain that to you how it works okay so
as you might see as you see right here we have a few errors and the only problem with um I mean the
reason for these errors is that we're using some typing and some libraries that we have not yet
added uh the first one that we're going to add is streamlit because we're going to be um logging the
thought process into streamlet to actually show it in the front end of our application so in order
to do that we're going to import stream L as St secondly we're going to import from typing Union
list stle and dictionary and last last but not least we're going to import from Lang chain from
Lang chain core which is the library that contains all of the abstractions for our agents and all
of the Lang chain core components uh remember that we are using crew Ai and crei is built on top
of L chain so this I mean by adding this this is going to work correctly and right here we're going
to just tap into from Lin core agents we're going to import this class Called Agent finish okay I'm
going to tell you a little bit more about how this one works in a moment but um for now let me just
explain to you what's going on right here with this step callback function now something that I
wanted to mention is that this callback function is actually just a modified version of another
method that was published in another tutorial by Sam wien who is also a YouTuber here and he has
wonderful tutorials about AI I'll leave a link in the description to his channel he is I mean
his videos are amazing you're certainly going to learn a lot about his videos um all right so let
me just explain to you the this modified version of the function um the idea here is that whatever
we have in the Callback we're going to be logging it inside an st. chat message okay and st. chat
message it's just a streamlet component that shows a chat message on the front end and this is very
useful for chatbots if you have if you're familiar with the channel we have used this component
before to create interactive chat BS or chat GPT clones and it works pretty good and I figured
that for this thought process of the agents this might be a good component to implement now the
first thing that we do is we test whether or not the output that we're getting is a Json is in Json
format I'm actually I actually forgot to import Json right here so let's do that and now yeah
so here we have that we're testing that if it's in Json format and if if it is it just takes the
contents of that Json and puts it inside the agent output variable okay and then next thing we do is
we test if it is a list and if it is a list we're just going to take it and extract the information
from it so we're going to be extracting the action and the description okay and once we have all
I mean those pieces of information we're just going to write them within the chat message so so
here as you can see we have S WR we're writing the agent name in this case this piece of information
is actually coming from our parameters right here and next we're going to S write the tool that the
agent chose to use and for that we're getting the attribute from the information that we got inside
the agent output and we after that are going to add the I we're going to log the input that our
agent is going to be adding to that tool so just to give you an example of what might be happening
here for uh for example let's say that our agent chooses to use the search search and contents
tool which searches the internet um based in a query and Returns the search results from EXA and
Returns the contents from that given website from EXA as well so right here the what would happen
is that the tool used will log search and contents and the tool input right here would log whatever
query our agent chose to look in the internet so if the agent was looking for news about AI or news
about the USA stock market here you would see tool input then you would see Json object saying search
query latest news about the US Stock Market for example okay and then right here we have the last
I mean lastly we have whatever the actual um agent thought which is within the action object right
here and this is what you would see when the agent is formulating its thought okay so right here you
would see something like okay so I need to find information about the latest news on the USA stock
market so I am going to use the tool named search and contents to find information about this and
then right here inside of expander we're going to add the observation to be clear what is happening
right here is I mean an SD expander is just a HTML expander just like um a streamlet component
that allows you to click an arrow to expand the content that is inside of it and you have like
a show observation tag and inside of it we have the observation now the observation is whatever
the agent found after performing the action so in this case if its action was to choose a tool
and if the action was then to search the internet the observation would be the search results now
I chose to put this inside of expander because usually the observations are very long especially
if you're uh have a research agent so for example if your research agent is looking for the latest
news about AI then the observation is going to be 10 or 15 search results about Ai and all of them
with their contents so that's why I put it inside of an expander I'm going to show you in a moment
how that looks in the actual front end but just to be sure that you're understanding what is going
on right here and then last but not last but not least here we have the if the agent output is
an instance of agent finish that is why I had to import agent finish right here um we're going
to do this and agent finish is basically just the class from Lang chain that the agent returns I
mean of which the agent returns an instance of once it has finished its thought process okay
because remember that an agent goes into some sort of a loop a thinking Loop where it calls
the language model gets a thought performs an action then calls the language model again then
gets a thought performs an action Etc until it finds the answer to the task that you gave it and
the idea right here is that if it has finished the task it will return an agent fin an instance of
agent finish and this says that we are going to be passing to the next task within our process
and I am testing here for agent finish precisely because we want to know uh when the agent finishes
task and I am writing a um different message in that case in which the agent is going to be like
coming up to us and saying hey I finished my task here is the output and then it's just going to
tell you what it finished then of course just handling some unexpected formats and that is the
step callback it works pretty good I have actually tested it quite um quite a few times before and
how about we actually just test it right now so let's do that oh and something that I forgot
to mention before is that right here we have added the step C back to the first agent but we
haven't done that to all of our agents so I'm just going to cop this right copy this right here go
back right here going to paste it right here and this time of course the second uh parameter that
we're going to be passing in remember that it is the agent name in this case it is not the research
agent but it is the chief editor and for the last one it is going to be the designer so I'm just
going to paste this right here and this one is going to be the designer or HTML uh um Rider let's
call it so we're going to save this and now we are going to execute this automation not from here but
from our front end and we should see the messages display on our front end with all of our thoughts
of our agents and at the same time by the end we should see a download button with the results of
the entire automation okay so let's check that wonderful it's been a few hours of hard work
now let's get to see the rewards of all this hard work and generate a newsletter using our
team of AI research agents who will communicate with each other and give us a complete newsletter
with the latest news that they have researched on the Internet by the end of a few minutes
okay so let's choose whatever topic we want right here we're going to generate a newsletter
about the USA stock market and let's just add a personal message here to add a personal touch of
this automated process let's say something like hello everyone this is a newsletter generated
completely by AI research agents so enjoy and this message is going to appear at the top of
our newsletter so now let's click on generate newsletter sit back and see our agents collaborate
with each other and communicate with each other okay let's do that okay so we have the first
one we have the first thought the first thought comes from the research agent we can see that he
used the search and content store tool and what he thought in order to get here was to find the
latest and most relevant news about the USA stock market I should start with a broad search query
using the search and queries tool and the query that he searched for was search News latest
news on the USA stock market and if we click right here on show observation we're going to
see the results that our agent got so in this case the first story that it got the da extends
its weeklong winning streak Etc and here we have all of the new stories that our agent was able to
find and that will be useful to for him to create this news letter okay let's see what he does
next and the second thing that we have right here the second thought is an exception and this
is a very educational example because we can see that the agent can make mistakes and correct
itself okay so here you can see that it made a mistake while calling one of the tools and it is
able to correct its mistake and find a solution so that by the end we have a result that we want
so here you can see that the observation is I did it wrong I passed in the invalid format I can
now give a great answer blah blah okay so that I mean it seems to have decided that it had all the
relevant information after this mistake and we can see right here that the agent said I have finished
my task and here's the story one The Story 2 The Story 4 5 6 7 and up to up to 10 stories now it
is the the turn of our chief editor and our chief editor also used the search and contents tool and
his thought was to accomplish this task I will need to carefully review each news article rewrite
the titles and make them more engaging Etc check the URL so you can see how they are interacting
with each other as though it was a team okay and the team the chief editor also found an exception
we can see the observation of the results that he got in the previous task right here we have the
exception he's like okay there was a mistake I'm going to give the final answer right now and here
you can see the chief editor finally finished his task he gave us a title and a summary for each
one of our stories he chose the most relevant stories in this case he chose four of them and
now we have that the the final agent who is the HTML writer has successfully created our HTML
newsletter that we going to be able to send to our subscribers and there is probably a better
way to show this than just a few printed text and the screen like this so what we're going to do
is download the HTML file and let's take a look at it okay just going to make it a little bit
shorter like this there we go so now we can see the results of uh I mean the results of
our automation uh we have a title that was generated uh by AI of of course and it is a
specialized a special title for this week's newsletter then we have the title for each
one of the stories which was also Rewritten by our chief editor the summary probably comes
directly from the researcher or maybe the editor um modified it a little bit and here is just a
quick um paragraph outlining why this article is relevant for our readers then we have the source
let's see that the source actually works so there seems to be working correctly this other one seems to be working correctly too this
one too so everything seems to be working okay amazing uh there we go so congratulations
we have successfully finished our newsletter Automation and now we can create our newsletter
for our subscribers in a few minutes so good job if you enjoyed this video be sure to subscribe
and like the video and of course share it with other people if you like it uh thank you very
much for watching and I will see you next time [Music] [Music] [Music] [Music]"
LHXujQ19Euo,2024-04-11T17:09:42.000000,Python: Automating a Marketing Team with AI Agents | Planning and Implementing CrewAI,yeah so hey everyone how's it going today welcome back to the channel and welcome to this video today we're going to be creating a team of AI autonomous agents who are going to be replacing a rudimentary marketing department in a small company this is going to be just like summoning a team of experts in basically anything you want who can collaborate who can talk to each other and who can interact with the real world through some of the tools that we're going to make available for them it's going to be just like having a part of your company completely run by AI agents I'm going to show you a workflow on how to create your own AI autonomous agents so that you can go from the idea to the actual implementation of your crew using crew AI how to monitor them to automate parts of your business and your workflow in this particular example we're going to be automating the marketing team of an Instagram page we're going to have a team comprised by a research Market analyst a visual artist a market strategist Etc and all of them working together so that we can create our own content calendar okay and by the end of this video you will have a deeper understanding of crei since this video Builds on top of the introductory course that I published a few days ago so without any further Ado let's get right into the [Music] video [Music] all right so before anything else I wanted to tell you a little bit more about crew AI which is the framework that we're going to be using to create this team of AI autonomous agents so crei basically is a framework that allows you to create this that you see right here so you're going to be here you're going to be asking a question to your AI crew you're going to give it an input and your AI crew is going to be comprised of several autonomous agents Each of which is going to be an expert in a different thing and Each of which is going to have a different task assigned to it and they are going to work together to complete all of those tasks they're going to communicate with each other and they're going to use tools and access the internet and do all sorts of things just like you like if you had your entire team of marketing for example or soft Ware development working for you and all of them are going to do that by themselves they're going to communicate and then by the end they're going to give you the result of whatever they created so in this case for example you can be asking them for an application and then you will have some project manager maybe you will have some senior developer you will have some designer Etc and by the end they will have worked together to create your entire product in this case we're going to be creating a crew that is a marketing strategy crew for Instagram so we're going to have probably an SEO strategist a copywriter a visual artist Etc so that is what we're going to be building and that is why this is so cool and revolutionary okay so first of all I want you to create your virtual environment for python now in short this is a place where all of your dependencies are going to live and your python version as well so you don't have any version conflicts or package conflicts or something like that um in order to do that I am going to be using cond but feel free to use whichever uh virtual environment system you want and if you do not have cond installed or you do not know how to install it there's a link in the description with instructions on how to do that now in order to create my cond environment I'm going to do cond create-- name then the name of my cond environment and then just assign the python that I'm going to be using I mean the python version hit enter now I had already created it so I'm not going to be recreating it but once it has been created all you have to do to activate it is do cond activate and then the name that you had given to your environment up here like that okay now once you do that if everything went smoothly um you will see somewhere in your terminal assign that your cond environment is activated and once you do that what I want you to do is to install crew AI so we're going to do pip install crew Ai and if you notice we haven't actually yet created a project folder for our project and that is normal because in this case we're going to be using the crei CLI to start off and to initialize our project in other words we're going to be using the command that CLI allows us to use in order to create all of the folder structure for us instead of us creating it ourselves and in order to do that once you have installed crei you're going to do crei create and we're just going to name our directory it's going to be called in my case Instagram and you can see that it has created this new folder called Instagram right here as you can see here you have it Instagram and with all of these files that you can use to start off your crew all right so that is how to use the CLI by the way CLI stands for command line interface and all you all you have to do is open it in code in vs code and we can start actually coding this okay so let me just tour you around the new directory that was created so here here this is the directory that was created Instagram like this right there and inside of here we have a source Instagram directory this is the name of our crew inside of it we have a config directory with our agents and our tasks in this case the agents are precisely the agents that we had defined in I mean this is where we're going to put the agents that we have defined right here and we have the tasks which is where we're going to put the tasks that we have right here if you remember the previous video we were creating the tasks and the Agents directly from the functions themselves but here it is pretty convenient to have all of the descriptions inside a yaml file to just load them and it just makes everything more efficient now you have this configuration here you also have a crew. py file which is the one that is going to contain your actual crew you have your crew Base Class which is going to contain everything you need here you have several methods some of them are agents if they are agents you're going to decorate them with the decorator agent here up here you have a couple of properties which are the locations of your configuration files your your crew framework is going to take care of loading this yaml file so you don't have to worry about it then you have the tasks um methods that are the ones that are going to return the tasks that your agents are going to perform and then finally you have your crew method which is going to programmatically initialize all of the agents and all of your tasks that were defined using the decorators right here okay so that is how you that is how this works and then by the end of course you have your main.py which will take your inputs and initialize your crew with the inputs okay so this is something else that we will have to be um modifying in a little bit so that is a tour you also have a uh directory for tests. tnv you ignore and then a RIT me that I invite you to read because it does contain some important information particularly about how to install this entire framework so as you can see let's actually just follow it real quick we have Instagram crew right here let me just show you so this is the readme.md so we have the Instagram crew introduction and then as you can see it uses poetry as a package manager for python so we're going to be needing to create uh to pip install poetry we're going to have to pip install uh poetry lock poetry install to install all the dependencies Poetry run in order to actually run our main method right here so there you go there was a problem with my condo environment that's okay because I have it active in the terminal end here so just is going to fix that in a moment but let's now actually start planning our crew okay okay so now that we have our environment setup let's actually start planning our crew that we're going to build okay because remember in CI we have several things that we have to prepare before actually starting to code and these things are the following we have to create a set of tasks that our crew is going to perform we're going to have to create a set of Agents that are going to perform the tasks and that we're going to define the set of tools that our agents are going to require in order to perform our tasks okay and usually the first step to do everything of this is to have a very clear idea of what your inputs are and what your outputs are for the entire crew okay so that's the first step so in my case we have defined that this the input that we're going to get is the page description of my Instagram account and the topic of the week and the output is the report for the content strategy of the week okay now going from this idea to the actual entire planning does require a little bit of time and I actually have a shortcut that I want to share with you that is what I what I recommend that you do in my case I recommend that you go to cre.com and you click right here on chat with our docs right here you're going to be able to access the GPT from crew Ai and what this does is basically it allows you to chat with a GPT that has access to the entire documentation of crei and also to its codebase so what you would probably want to do is to brainstorm your idea U at this assistant and then the assistant will return to you everything you need from the tasks to the agents and the tools okay so what I'm going to do right now is I'm going to record myself while I'm just brainstorming the idea and at the same time I am presenting it to you and I am going to record that and just send that to crei and in return I will get everything I need from the tasks to the agents and the tools from the assistant okay so um and also before I do that I just wanted to give a quick shout out to this guy Bren Wong who created this super cool extension called Whispering which is completely free you only need to add your API um key from open Ai and it will use the whisper API so that you can dictate directly your voice into chpd just like you would do in the mobile application okay so that's that's great so big shout out to Braden Wong so I'm going to record myself and I'm going to explain to you the entire thing so I'm going to click here and now I am going to brainstorm my crew idea okay so I would like to have a crew that takes as input the page description of my Instagram account the topic of the week and as output it will take I will get the content Str stry for the week this content strategy should contain the the hashtags the title and the publishing time for each publication for each day the hashtags the title and the publishing time should come from some research that my agents are going to perform so my agents should be able to perform some research about the latest trends in my niche in the topic of the week Etc and then incorporate that into the calendar um inside of the document I should also have the description or the caption of the post which is supposed to be SEO optimized which means that it would be good for Google and for Instagram and it should also contain the trending hashtags so it should also use the information received from the market research and apart from this I would also like to get the image descriptions now this is not the captions that I told you before before this is the image descriptions of the the images that I'm going to be posting because I am going to take these descriptions that should be very detailed and very Vivid and put them into an AI into an AI model that is going to be either di 3 or stable diffusion and this diffusion model is going to generate the image given the description that one of my agents give to me and after that I want everything to be compiled into a single into a single document that is going to contain all of what the information that I mentioned and this would be like my marketing team for Instagram in This Crew okay now please give me all of that in please give me all of that in a couple of yaml files because I am going to need a all of these configuration in yaml file so that I can put it into my codebase seamlessly these yaml files I'm going to give you examples of what they look like but they should be one agents. yaml and one tasks. yaml so now I stop recording and it's going to take a few seconds before it actually completes the the transcription there you go so now here is my brainstorming session and now I can give it the example of the yl file that I'm going to want so in my case I want the agents. yaml file example so that it knows what the yl file should look like and remember that the example I got it from visual code and here I have the agents. yaml just going to copy everything and go back to Google Chrome going to paste it right here and then I'm going to do the same with tasks do yaml example there you go just going to paste it like this copy all of this just paste it here and now this assistant will tell me everything that I need to know in order to create my crew okay now it will not always give the final version of the crew so you might have to tweak it a little bit but as you can see this is already a huge step and it's going to be saving you a ton of time because in reality when you're creating a crew or any piece of software for that matter one of the most time consuming parts of the entire process is going from the idea to the actual design of the software or of the framework that you're going to be creating okay so in this case just by brainstorming our idea to this GPT we got that we have four agents which is pretty much the same thing as I had right here and we got that we have four tasks so it didn't quite get the last task which would be the compile content task but it got pretty close so that's going to give get you way way closer to the actual final plan of your entire crew now let's wait a moment and see if it gives me the yamel files as well because I gave the example of the yaml files here so that it could follow my examples and let's see what it gets we have the image description creation for the tasks um it's going pretty good didn't give me the yaml files let's ask can you give me the yo files to there it is so here's the yaml file for my agents so Market researcher we have my role my goal and my backstory as well there you go I'm it's going to do the same thing with tasks so there you go that's how you bootstrap your entire project using the CLI and also their GPT all right so now it is time to actually start loading our configuration remember that I had already generated all of my agents I had to tweak them a little bit because they were not exactly as I required them so I'm just going to copy the agents that I have already created going to P them right here so as you can see I have a market researcher I had Define a role for it I have a goal for it and a backstory remember that this um properties have to be very detailed because they're going to go into the prompt and remember that the prompt has to be very detailed for your a agents to perform correctly I mean for any AI llm assistant to perform correctly we're going to do the same thing with the tasks I'm just going to copy them right here so as you can see I have my five tasks which are market research content strategy visual content creation copywriting and Report final content strategy Sur there is a problem with the naming here I'm just going to remove the task keyword right here there you go I have my tasks and my agents saved correctly now I can actually run them and initialize them inside of my crew class right here okay so now that we have loaded everything that we need to load we're going to actually start initializing our agents okay in order to do that you're going to want to come right here to crepy and in this file we're going to start about defining our agents and our tasks the first thing we're going to do is the agents so I'm just going to erase this right here I'm going to start them with coding them with you so the first thing that we're going to need is the agent decorator this agent decorator is going to tell our crei framework that this method right here is going to return an agent and here I'm going just going to define a new method and I'm going to name it the name of my agent I'm going to say that it returns an agent let's return an instance of an agent and this one right here remember that in the previous video where I showed you how to create your agent like this we initialized the agent like this directly like setting the role setting the description uh setting the goal the backstory Etc here since we already have the goal the role and the backstory in the yaml file which is right here all we have to do is load it in the config property in the config parameter like this and we're going to tap into the agents configuration object and open the market researcher key which is going to be this one right here and here we're going to be loading the role the goal and the backstory now there is something to consider right here because it might look a little counterintuitive is that here we are tapping in into the market researcher key of something that looks like a string so are we trying to Index this key from a string and I do understand that this this quite counterintuitive what is actually going on behind the scenes is that once we call the self agents config property right here which was initially a string once we call it right here it has already become a key value per object and that is happening behind the scenes inside the crew base decorator okay so just by adding this decorator right here it is taking the properties of the yaml files right here and it is loading them you is loading the yaml files as you can see right here so that when it gets to the actual method that you have right here this property is already a key value per object it is no longer a string with a path to your configuration file okay so that's how it goes and now we can actually just add the tools and in my case I have not defined any tools yet so I'm going to leave this empty I'm going to set the verbo setting to true so that we can see in the logs what is actually thinking our agent okay so there we go and there we go so that is the first agent now for the next agents I'm just going to copy and paste them from right here that I have on the side and there we go so we have loaded all of our agents we have the content strategist the visual Creator and the copywriter and all of them are pretty much the same you load the configuration and there you go there is only this single one parameter that changed for the visual Creator because remember that our visual Creator is this guy right here our visual artist and its own comp I mean all of its purpose in life is to create the description of the image of my Instagram post he doesn't really require needs to communicate with the other agents now remember that all the agents have by default the possibility to talk to other agents to delegate tasks or to ask questions in my case the visual artist didn't really I mean he's the visual artist he cannot really delegate the task of painting an image because he is the expert in that and he doesn't really require any additional research to create the image so I just disabled the delegation right here so that it does not have the possibility of talking to its other teammates when it's his time to perform his task that's just just shuts him up because in my testing I found that if they have the possibility of talking to their friends I mean to their colleagues they are going to talk more than you wanted to so if it's just a oneshot task you should probably set the allow delegation to false and also monitor your crew to see if someone is becoming too talkative because every time they talk they're making a call to the API and that can be come quite expensive if for no reason all right so there's the visual Creator and the copywriter and there we go those are our agents perfect so what you want to do right now is now that we have our agents we're going to want to create our tasks so we can delete these tasks and we can just initialize them from right here um go going to create the first task with you so that you see what's actually going on we just remember it's pretty much the same thing as with the agents I am going to take the same names for the from the keys in my configuration file and this is going to return a task now we did not import either the task or the agent types right here but we're importing them from crei all right so just keep that in mind we're importing everything from crei up here all right now that we are in in this one we're going going to be returning a task and I'm going to say that I'm going to return a task and just like before we're going to instead of loading the task description the expected outcome Etc we're going to set it as a configuration file so just like before self. tasks config which is this object right here remember here it looks as a string but once it gets to this method it has already become a a key value per object so here we're going to open the market research key and inside of here as well we're going to set the agent who is going to perform this task and in our case it's going to be the market researcher which we have initialized up here that's why it is important to create the agents first and then for this example as well we're going to create a output file and this is basically just going to say I mean here you're going to set the path to where you want this task to save its output so some tasks probably not all of them it might be a good idea to save the outcome in a file in our case this task is the market research task and it is quite an important task and you want to have the report from the the market research uh in a document so that's why it's probably a good idea to create a market research. MD saving it as MD because these language models by default return a string so we're going to be returning pure text and saving it as a markdown file so that's for the first task I'm going to copy and paste the other ones to not bore you with with all the repetitive task writing but here as you can see we have the content strategy task just like before we select the agent which is the content strategist and the key from the tasks configuration the same thing for visual content creation task our configuration and our agent same thing for copywriting and the final one just same thing as well but we are also adding an output file so in the end we're going to have two files which are the market research and the final report for with the content strategy which is the one that's supposed to contain all of the days the daily schedule the posting times the descriptions Etc okay and then by the end you just have this right here I am not going to change this because this is pretty much um exactly how we need it if you wanted to have a manager to be a language model who assigns the tasks you could set the process to hierarchical right here so you would have to uncomment this parameter right here but for now this is going programmatically very smoothly and we're going to be doing a sequential one a sequential process I mean and here just like I said before the agents are going to be automatically loaded because we have added the agent decorator from self. Agents and this of course is happening behind the scenes thanks to our crew decorator which is initializing all of our agents and our tasks behind the scenes for us so now when you call self. agents they are already defined and then the process just like we said sequential okay all right amazing you have successfully completed the creation of all of the tasks and of all of your agents now it is time to actually start creating the tools that your agents are going to need in order to to complete their tasks okay in our case if you remember correctly we had created we had designed a first tool set that one of our agents was going to require this tool set is the Search tool set and it contains three tools it contains search the internet which will allow our agent to search the internet with Google it's basically just a wrapper around an API that returns Google results we're going to have a tool that's going to allow the agent to search Instagram which is basically the same thing as search the internet but with a site colon instagram.com uh in front of the query okay and finally we're going to have an open page tool which is going to allow our agent to open the contents of the retrieved results from the other two uh tools okay so that's what we're going to do and just to be clear that we know what's actually going on remember that a tool in in an agent framework is basically just a function or a method of a class that our agent is able to call okay so our agent is going to be able to add an input to our function execute it and read the output and reincorporate it into its prompt this is essentially how a react agent works so a react agent agent what it does is basically it uses the language model to think then it chooses a tool that it's going to use it performs the action which is the calling the function reads the output and reincorporates the observation as context to its own language model call so next time it will know what the function returned that is essentially what we're doing and that is why you need to use a language model that allows function F calling so far we have for example open AI models which allow function calling clo which very recently um enabled function calling from the anthropic guys so there you go so that is what we're going to be doing so let's start actually by building these tools all right so to create these tools we're going to be requiring this API from serper dode in case you're not familiar with it let me just show you around what it actually does serper dode is essentially a wrapper around Google search okay and you get 2500 free queries so you can test it without without spending any money I don't remember putting my credit card details in it so uh that should be yeah no credit card required so there you go once you create it you're going to be able to create your API key and we're going to be using that in a moment and you're going to be able to create calls that will return this kind of results okay so in this example we're going to be quiring Apple Incorporated just to Showcase and you can see that the results contain several objects and in our case the one that we're interested in is the organic one which is essentially just the organic results from Google and we're going to be tapping into this into this object and we're going to be loading the first five results for this tool okay so let's create the function that we'll call this API and we have an example here by going to code and here we have an example using python so here they are actually using HTTP client I am going to be using requests myself but this should be good so now let's actually copy this and incorporate it into to our code what we're going to do remember that when we initialized our project that automatically created this folder right here that's called tools and inside of it we have custom tool with just some example of how a tool would look like I am going to delete this and I'm actually going to rename my file I'm going to call it search and in here I am going to create a class that is going to be called search tools like this and in here the first thing that I'm going to create is the the method that is going to return the search results so search I'm going to add a query and then I am also going to add a limit of we said that we want Five results right so right here is probably where we're going to start needing the code that we copied from their documentation dashboard so we're going to be importing I'm not going to be using HTTP client I'm going to be using requests and so we're going to want to First initialize the URL which is going to be API nope it's not API it is Google serper DOD like this then we're going to pass in the payload and the payload in our case is Json and Json object and the query is going to be just our query right here and then the maximum number of results is going to be number and limit and this one I get it from going to just modifying the number of results and you can see that it is num 20 so there you go number that becomes 20 then we have the headers and we have the content type application adjacent and here right here we have the API key which I am very conveniently leaking for you so I'm actually going to call it from OS and in order to do that I'm going to have to import OS and then we're going to actually just call this API and in order to do that I'm going to use requests and I'm going to save request I'm going to send a post request to the URL hand in the headers the data payload and there we go now remember that I told you that we were going to be tab into the organic object inside of it so I'm going to say that the results going to be equal to responsejson and inside of it remember that we're going to be tapping into organic because nope not organic results just organic because that is what we have right here in the example there we go and now once we have that we can actually just return a huge string with all of the results in it and this string is going to be just an empty array first when we start off and then for each one of the results we're going to append first of all the result title then in the second line the result result snippet and then in the third line the result not URL but link and there we go and here we're implementing title link and the snippet which is going to contain some information about our result that our agent knows if it wants to open this page or not so there we go that is for the string and then let's just return and F string search results for query and then we're just going to join everything in one single string there we go so now that we have created our search method this is the one that we're going to using inside of our tools okay so actually let me just add my API key right here so so serer API key and I'm going to go right here copy my API key going to paste it right here there we go and then now let's just finish off this two tools that we're going to require so remember that the first tool is going to be search the internet right this tool is going to be this one right here and in order to do that we're going to first of all initialize it with a tool decorator and this one takes the name of the tool so we're going to say search internet and the tool decorator actually comes from Lang chain so we're going to import it from Lang chain. tools we're going to import tool there you go and this decorator is going to decorate our function which is going to be search internet and it is going to take first of all the query which is going to be a string it's going to take the well no it's not going to take the limit because we're always going to be returning five so it's going to be returning this and return a string and this is very important you should always add a dock string for your for your tools because your agent is going to be able to read this dock string and it's going to be able to decide based on this description whether or not to use this tool for a given task okay so in this case I'm going to say use this tool to search the internet for information this tool returns this tool returns Five Five results from Google search there we go okay so that is our that is our doc string so now our agent is going to be able to read this and say okay so I have to research some information I want to research gole so I'm going to use this tool right here and that is also why it is very important to also um mention the type of the parameter because your I mean that is also information for your agent and in here we're going to just be returning search tools do search and we're going to be returning the search from this sare right here because we're calling this other method that we defined down here and let's do the same thing for search Instagram we're going to create a new tool that is going to be search search Instagram we're going to Define search Instagram it's also just going to take a query and it um outputs a query as well I say use this tool to search Instagram this tool returns Five results from Instagram Pages there we go and this one just like before it is going to return the search and the query and the limit of five but in order to limit the search to only Instagram results which is do the the neat little trick from Google I mean of course I repeat this is not a trick from this API in Google whenever you want to search for something in a specific site all you have to do is say site and then just type in the The Domain that you want so in my case it's instagram.com and then all of the results from Google are going to come from this domain and now there we go how about we just test this tools okay so in order to test all of this what we're going to do is basically just call the functions directly from our file because remember the tools are essentially just functions so what I'm going to do just going to say if name equals main I'm going to print how to make a cake for each one of them so here I'm using my search tools search internet method to look for how to print how to make a cake and same thing for Instagram and we should see the results however before doing that I'm going to have to from tnv import load. tnv I'm going to execute that because this function remember that it allows me to have access to my secrets in.nv and we're going to require the serer API key for this to work so now that that is done we can click on Save and execute this and let's see the results here so here's my call search results for how to make a cake and here we have 1 two 3 four five results each of them has the title The snippet and the link that we mentioned before and then the same thing for Instagram here search results for site Instagram how to make a cake then we have 1 2 3 4 only four results for Instagram also the title The snippet and the link pretty good so now before actually finishing the rest of the tests I would like to finish creating another tool which is the open open page tool because remember we're supposed to have um tools that are able to search the web but also a tool that is able to open the results so let's just do that we're going to create one that is called open web page like this we're going to Define open web page let's call it open page actually Define open page it takes one URL as a string remember then use this tool to open a web page and get the content and here we have actually for this one we're going to be using a loader from Lang chain we have used this loader before in the previous video of chat with a with a website basically just returns all of the all of the H tags and all the P tags of a of a page so let's import that one so from L chain we're going to be tapping into L chain Community because this is an third party integration we're going to go to document loaders we're going to import web base loader like that and this is very simple to use all you have to do is initialize your loader with the URL that is going to be passed right here and then once we have that we just have to return the results from the loader like this and this should be it let's actually just test that one as well in order toest test it we're going to do exactly the same as we did before going to come down here and do if name equals Main and we're going to try to open oops we're going to try to open Instagram well definitely not that's probably not going to work we're going to try to open python let's see how that works there we go we have the contents of the Python page seems to be correctly all right there we go working correctly our tools are working correctly now all that we have to do is add them to our crew okay so let's do that right now and in order to add this tools to our agent it's very easy all we have to do is like we did in the previous video we're going to go to crew. py and identify the agent where want to add those tools because remember in our diagram we have that the market researcher is going to have access to these three tools okay feel free to experiment adding the tools to other agents or maybe even using other providers for these tools and once we have that I am just going to add right here I'm going to import from instagram. tools. search of course I am adding it from Instagram because that is the name of my directory and then I'm going to go down here and just import search tools search internet search Instagram and open page now once that is saved I actually did want to mention something that is quite useful is that if you have several tasks like here we have five tasks the results from the first task are probably going to be lost by the end of the entire process that is normal it is just as though the agent in charge of making this had communicated the results to the next agent and then that agent is going to communicate the results to the next agent all the way till the final task you're probably going to have lost the findings from the first task that is why it is important that if you have a task for which you're interested in reading the results from the task for example the market re search one or the copyrighting one or the the visual creating descriptions you probably want to save those outputs in a file and that is very easily done all you have to do is go to the task that you're interested in uh creating a file for and then as a parameter you add the name of the file where you want that um results to be stored in my case just going to name it Market research. MD because it's going to be a markdown file and they just goes in the parameter output file and there you go now we are almost ready to run this we just have to add our inputs and that should be it okay so in order to run your groom remember you have to pass in some inputs right remember that we had defined that we requir the page description for your Instagram page and then the topic of the week so we're going to pass those inputs to our crew in order to do that we go back to vs code and right here we go to main.py here you have a function that was created automatically with our CLI and here you have an input dictionary and you also have this Instagram crew uh class that is being imported we're calling the static method crew and then we're calling kickoff on whatever this returns and just to be sure that you get what is going on behind the since here this one we're importing it from the crew that we just created which is this one right here we're calling the crew method which is returning an object of crew and this object has a kickoff method that basically just executes our crew so that is why we have crew and then Ki of and then we just passing the inputs and this inputs are the one who the ones who are going to be interpolated with whichever variables we specified in our prompts now what our where are our prompts our prompts are basically just the config files that we have right here in my case remember that we said that we were going to have these two variabl so here it is I mean for me I just added this to the first and Main task which is the market research so we have the description of the Instagram account that for which you're doing the research is then I just added some markup tags then the Instagram page description which can be as long as the user wants and then find the most relevant topics hashtags Etc and this is a topic for the current week topic of the week between markdown I mean this is not necessary just that some language models work better when you add this Tex and then I did also pass in the current date because language models doesn't the language model doesn't know by default what day is today so I'm just telling it the current day and in order to do that we're going to go back here and whatever we pass in here as our inputs is going to be interpolated it's going to be replaced with the value here of this variables so let's do that remember that the first one we have is current date and in order to set that one I'm going to set it right here and for the current date I'm going to be just call importing that from daytime going to say datetime datetime now the second one is going to be Instagram page description now enter the page description oh this is supposed to be an input because we're supposed to ask the user for this enter the page description here then we have lastly the topic of the week and here we have it whoops topic of the week and this one is going to be enter the topic of the week here and there we go now just so you remember what's going on here just going to open the terminal again and if we go back here to readme.md remember that in order to run all of this we had to First install poetry lock poetry install and then we can run poetry run Instagram and in case you're not familiar with how poetry runs it's just a package manager for python which allows you to Define some scripts that can be run using poetry run and then the name of your script in those scripts are are defined right here in PIP project. TL and they're here tool. po qu. scripts and you can see that the script called Instagram actually goes to instagram. main which is right here instagram. Main and then from Main it executes the function run which is the one that we had just finished tweaking so there you go and so let's actually just follow the steps from this rme file it says that first we have to install poetry I have already installed it so that's probably going to take a bit longer for you uh remember that in order to do this you have to be inside of your virtual environment that we created at the beginning of the video and after we do this we're going to do pip no sorry poetry lock which is following this instructions right here and then we're going to do poetry install once that's done just poetry run Instagram so let's do that that probably takes a few seconds then we do poetry install again to you it might take a little bit longer because I have already installed all of this just updating some of the dependencies and now we can do poetry run Instagram which is the script that I mentioned before and there you go remember to add your EnV uh your remember to add your API Keys Tov I have open Ai and I did specify the latest GPT 4 model you can specify that using open AI model name and then you can just select a model from Models open AI right here I just selected the latest GPT 4 which is this one right here um and there you go so we also have our server API I was testing grck I'm going to make a video about that later and also the linkchain tracing um API key and setting to be able to trace this using Langs Smith so now enter the page description here page going to say page about castles enter the topic of the week here castles in Germany and then let's see how our agents start working together and making research here's you can see that we have the the first one is the market researcher who started to make some queries the first query was searching the internet for popular Instagram hashtags and then it got some results then it's going to search Instagram it got some other results and he going to try to open a page Instagram going to call some going to mention some issues with Instagram later I mean with scraping using the length chain loader but seems to be working correctly and doing its job going to pause the video and come back once this is finished just to review the final results okay all right so our run has successfully been completed and here we have all the results as you can see here in the logs there are all the conversations of our agents among themselves so they of course were talking to each other trying to figure out how to solve our problem and at least with gp4 it turned out perfectly there were not errors there I mean the only thing that happened at some point was that when we were supposed to open some pages that some search results from the Instagram search our open page tool was not working because Facebook blocks regular scra scrapers like beautiful soup which is the one that we were using so in if that were the case you probably would want to you I mean if you wanted to craw those kinds of websites and to make sure that the website is correctly cwed you're probably want to use a more sophisticated way of scraping the website um like browser tools I think that's a very good service for that but other than that it turned out correct like perfectly here we have also I mean you can see all the conversations between our agents here for example here here is the Instagram visual Creator and here we have that he produced this file right here and then you have the Instagram copywriter and he also before crafting the Instagram story I need to ensure I have a clear understanding so he asked the question to the coworker Instagram content strategist and then the coworker answered something and then he found and then he used that answer to complete his his this response so everything seems to be working perfectly also if you might remember we added three output files for three different tasks the first one was for the market research so here is our market research report which is a markdown file and yeah as you can see you have everything that you require and it's basically a report as though a human had made it like your Chief Market researcher there you have have also the visual content description which was the one developed by the visual artist and these are the descriptions that you're supposed to enter into mid Journey or Del 3 and generate your image and then lastly you have the final content strategy which is also your complete strategy so yeah I mean you had a complete team working for you um let me just show you real quick here and lsmith what was going on behind the scenes as well here we have I mean here we have all of the runs from openai and in our case I wanted to show you for example how they open one of the websit right right so here for example you can see that the action that they chose was open page and they tried to open instagram.com however the observation was your browser you're using a web browser that isn't supported basically just blocking scrapers here we have another action that was taken here for example it is the chat open AI that I mean here it is the market researcher again who tried to open the page iqh tex.com and let's see what observation he got but the observation remember that it'll be appended to the next prompt in the chain of calls which would be here so let's go all the way down to find that call and here you see that the action was open page he tried to open this one and then you have here the observation which is Castle for Instagram Tik Tok YouTube and then you have all the contents from the page and we have successfully created everything that we wanted to create so congratulations for getting all the way here you have created a crew and now I mean we can totally just plug it into a user graphical user interface or something like that now um this is of course not the best crew the we can of course improve it a lot by updating the prompts and changing the tools to so that they are not blocked by scrape blockers or maybe even experimenting with uh adding the tools to other agents as well uh that's why it is important to be using lsmith or some monitoring system like this because it allows you to see exactly what your agents are thinking and what they're doing so if you see that maybe sometimes they're um entering a a useless Loop that is costing you like five or seven API calls that you shouldn't be making that's probably going to be saving you a lot of money if you're going to be sending this to production this is of course not ready for production yet but um agent orchestration systems and crew AI are both super new products and techniques so I'm very happy to see that it's starting to work pretty reliably and yeah well I'll be bringing you more news and updates about this I'll be making also a video about how Gro works I was testing this this week but um have didn't manage to make it work because of their I mean they only have a free tier so far and with agent orchestration system it is very easy to reach that uh rate limit very quickly so I'll be making a video about that be sure to subscribe and tune in uh every week for the latest updates in software development related to Ai and generative AI applications thank you very much for being here and I will see you next [Music] [Music] [Music] time
kBXYFaZ0EN0,2024-03-29T11:10:40.000000,CrewAI Step-by-Step | Complete Course for Beginners,good morning everyone how's it going today welcome back to the channel and welcome to this video tutorial today I'm going to be explaining you everything you need to know about crew Ai and how to start off with it how it works behind the scenes and yeah I mean we're going to be building our entire crew from scratch we're not going to be using their Builder so that you know exactly what is actually going on behind the scenes by the end of this video you will have this crew that is going to be able to think by itself you're going to be able to Def to design your own cruise and we're going to be looking at it with very nice diagrams that I have preferred prepared right here for you and to explain you the entire process behind all of crei so thank you very much for being here and let's start off with the [Music] video by the way uh there are a couple more things that I would like to tell you first of all that you will find the link to this article in the description which is the written version of this tutorial it contains not only the text but also the diagrams that I'm going to be using to explain all of this the code and the link to the GitHub repository and second thing is that I recently open a patron account so if you would consider becoming a patron and and supporting the channel you will get adree access and early access to my content whenever it's possible thank you very much if you're considering that you will allow me to continue doing this for free so thank you very much and without any further Ado let's get right on with the video okay so the first thing that I want to tell you is what actually is crei and why it is so revolutionary so crei is this new framework that allows you to build your own teams of autonomous agents all of these agents are going to be working for you to help you achieve your goal each agent is going to be an expert in a different task and they will all have this single goal in common to help you achieve it uh this goal can be either crafting an email based on some research creating a business plan writing a book creating a blog post or maybe even creating an entire application like you see right here the possibilities are basically infinite all we have to do is think of the process and the tasks that our agents have to complete and assign them to our crew of Agents they will do all of the work for us in this tutorial I am going to introduce you to the basics of the framework how it works behind the scenes and how to create your own crew using the sequential process I'm going to talk more about the process in a moment this is a completely Hands-On tutorial so by the end of the video you will have developed your own crew you will understand how it works and you will be capable of creating your own Crews from now on to create your own projects and be your own master of your own AI agent crew so let's start developing this so here's the diagram that we're going to be that represents the crew that we're going to be building today it is a crew that will take the participants the context and the goal of a meeting that you're going to have and it's going to return to you the brief for that meeting a brief that will include research about the participants the industry and the best talking points to cover during the meeting okay the idea is that you're going to have four autonomous agents A researcher which is going to be the one who's going to research the people and the companies an industry analyst which is going to be the one who's going to analyze the industry meeting strategist who's going to be the one who is going to plan the meeting itself and a brief or summary writer which is going to be the one who's going to write the clear and informative brief for the users okay these agents are going to perform this set of tasks the first one is going to be the research where they are going to research the participants and the context of the meeting then the analyze industry task which is going to be where they're going to analyze the industry trends the meeting strategy which is going to take whatever information was found during these previous two steps and it's going to develop the talking points about the about them involving the participants and the context of the meeting then lastly we're going to have a task which is summarizing and briefing which is going to involve all of the information that was returned from this three other tasks and will con constitute a brief for the meeting okay now our agents are going to have access to a set of tools as well so we have the EXA tool set I'm going to explain a little bit more about that in a moment but the idea is that they are going to be able to choose to search the web whenever they need to okay this is essential for two of our agents because they're going to have to find information about the people and the companies and the industries involved okay now I realized that this is probably not the most useful on a day-to-day basis example but the idea is that this example is complex enough that that it shows you how crei Works behind the scenes what are the components of of its process while at the same time being simple enough so that a beginner can understand it so that's why I chose this example from their documentation to build it and that is what we're going to be building today from scratch so that you see everything that is going on behind the scenes so let's talk a little bit about how to plan your crew before you actually start coding and at the same time I'm going to explain to you a little bit more about each of the main components of crew AI okay so there are four components in crew AI the first one is tasks which you see right here which can be considered the backbone of your crew the second one is the agents which are the ones who are going to be performing the tasks the tools is number three which are the ones who are going to be used by your agents in order to complete the tasks and four is the process okay in this case we're going to be covering the sequential process which is going to complete one task after another but know that there are other kinds of processes like hierarchical where you have a manager agent who is going to assign tasks to each one of its agents in its team uh depending on what it thinks that has to be done but we will cover that in another video I want to focus on the sequential one because it's a little bit easier to understand and to grasp the power of crew AI so when you're going to be planning your crew what you're going to want to have first is your input and your output the input is basically just the information that you want to give to your crew in order to achieve your output in this case our input is going to be the list of participants the context of the meeting and the goal of the meeting and we want our crew to be able to give us a brief of the meeting that will contain the industry analysis and the research of the participants in it by the end of the process okay so that is how you should plan your crew we're going to be covering it a little bit more in detail but just know that you should consider the tasks as the backbone of your crew you can consider this as once you have your input and your output the tasks are going to be the to-do list of things that you would have to complete in order to get to your task if you were to if you were the one who was performing this T this goal okay in our case if we had this information and we wanted to get a brief of the meeting we would probably need to research the participants analyze the industry create a meeting strategy and summarize everything so think about it as your to-do list all right then you can from your to-do list you can start creating and designing your agents and then your tools that your agents are going to need awesome so now that we have finished creating our plan we can effectively start coding now I'm going to tour you real quick around my setup right here I have my source file my source directory sorry where I have my main file which is going to be the place of my application I have my G ignore file and I have mymv file right here with a bunch of API keys that I'm going to explain to you in a moment okay but for now know that you're going to want to create a cond environment I I named myself crei tutor tutorial and you're going to want to use Python 3.10 upwards okay now once you have created your cond environment you're going to have to activate it going to activate mine right here and you're going to want to install crew AI now I already have it installed so for you it's probably going to take a little bit longer but once you have crew AI you're going to be able to follow through the rest of the tutorial now once you have this let's actually start building our tasks so now that we have our setup we can actually start creating our tasks because remember that our tasks are the backbone of our crew right so the first task that we're going to be creating is the research task and as you can see right here it comes with some properties it comes with a description which has to be very detailed because it is the description that is going to go to the language model in the prompt it has to have a very clear output so that the agent knows what to expect by the end of this task and it has to also Define an agent that is going to be the one who is going to be performing this task okay so let's do that first of all I am going to create a new file called tasks.py and in it I oops and in it I am going to initialize this new tasks class but first of all I'm going to just import from text trp I'm going to import detent just to make things look a little bit nicer I'm going to import from crew AI going to import task and let's just create our first class which is going to be called meeting prep tasks there you go and now this class is going to have several methods and each method is going to return an instance of a different task okay so the first method that I'm going to create is going to be called research task and this method is going to return a task okay now this method is going to take several several parameters the first one is going to be the agent that is going to be performing this task then it's going to take some context in this case it's going to be the meeting participants there might be a better way to organize the the context for a specific task in a dictionary or something like that but in this case we're just going to be sticking to how the how the tutorial is in the official documentation and the task that we're going to return is the this one right here that we're going to be initializing first of all with a description okay now remember that your description has to be very detailed because this is the one that is going to go into your into your language model as a prompt so here you have a very detailed description conduct comprehensive research on each of the individuals and companies involved in the upcoming meeting gather information of recent news achievements professional background and any relevant business activities and then we're passing as some variables this meeting context and the participants of the meeting okay then the second thing that we have to pass here is the expected output as we had right here okay I mean of course in the diagram I summarized everything in a few words but the idea is to have everything as as clear as possible when you're defining this so here let's also create this stent part right here and this one is going to return a detailed report summarizing the key findings about each participants and Company highlighting information that could be relevant for the meeting okay so that is the expected output and then we're going to assign an agent which is going to be the agent that we're going to pass into this method and another thing right here that we can set is async execution which means that this task is going to be run at the same time as this other task which is also a synchronous because they don't need the context of any other task before them they can be performed at the same time and this one on the other hand has to have async set to false because this one requires the two to have finished first because this one uses the results from research and analyze industry as context okay I'm going to show you how to set the context later but for now just consider that by setting the async setting to true we're going to allow these two tasks to perform simultaneously okay so there you go this is the first task and that's how you create a a method that is going to return your task now I'm going to copy the other tasks right here from the documentation and just explain them real quick there you go this is the industry analysis task which is another method that is going to return um another task and this one also very detailed description analyze the current industry Trends challenges Etc also passes in the participants I'm actually going to change the variable names right here because in the documentation they use context as um variable for the prompt and it is it can be confusing because it's not the same context as the context of the task I'm going to tell you a little bit more about that in a moment but just changing these names to make it a little bit easier to understand then we have the meeting strategy task which is this one right here here and this one just as the other ones is going to return just like the other one has a description and here we have the meeting objective as a variable for the prompt as well so develop strategic talking points Etc remember as detailed as possible and also a very detailed output and as you can see these two industry analysis and meeting strategy do not have async execution um sorry this one does because this is the the other async execution task but this one doesn't because async is set to false by default okay so you don't have to assign it there you go and then the last task that we're going to create is this last one right here which is the summarizing and briefing task and this one we have it right here it is going to to also take the meeting context the meeting objective and an agent that is going to perform the task so the description as well very detailed compile all the research findings industry analysis and strategic talking points into a concise comprehensive briefing document for the meeting okay so there you go these are the four tasks that we're going to be creating and they all have an agent that we're going to have to declare when we're calling these methods and these methods are going to return the task already um uh created so there you go that's how you organize and create your tasks once that we have our tasks finished we can actually start creating our agents okay and in order to do that I'm going to go back here and I'm going to create this new file called agents. py like that I'm going to put it right here inside the source file as well Source directory sorry and let's actually start coding our agents so first of all just like before we're going to uh import Dent from Textra to make this look a little bit nicer and then from crew AI we're going to be importing agent okay now now what we can do is we can create just as we did before a class for the agents we're going to call it meeting prep agents and this one just like task is going to contain several methods and each method is going to return a an agent in this case we have gith co-pilot giving us a recommendation although it is wrong so we're not going to take it the first thing that we're going to want here is the research agent method which is this one right here a researcher who is going to whose goal is going to be to research people and companies it's going to have a backstory and it's going to have a set of tools that it can use okay so let's actually create this like this we're going to be oh sorry this one is going to have self like that and right here this one is going to return an agent okay now this agent is going to have just like we said before a role and this one is going to be the research agent um we're going to call it research specialist actually then it's going to have a goal as well just like before remember that this has to be very detailed because all of this information is going to go into the prompt that we're going to send to the language model I'm going to show you how that prompt Works in a moment but just bear with me that you have to make this as clear as possible now in this case my goal is going to be conduct thorough research on people and companies involved in the meeting then we are going to have the tools that is going to have that it's going to have access to and this is going to be a list of all these tools right now in this case I'm going to leave the tools empty because we haven't created them yet but I'm going to show you how to do this in a moment and then something else that is pretty important is the back story okay now the backstory is a pretty interesting technique that you can use in prompt engineering and it comes built in with crei but the idea is that when you want your AI agent or your AI assistant to perform better you want to give it a backstory so for example if you want to give if you want it to perform good research you have to tell it that it that it is a research specialist and that it is very good at what it's doing and you have to create this sort of Personality for your agent for it to take that personality and give you the response that you expect so in this case we have I have this backstory written by the crew AI team as a research specialist your mission is to uncover detailed information about the individuals entities participating in the meeting your insights will lay the groundwork for strategic meeting preparation right now this is going to go into the prompt for the llm along with the description of the task so it has to to go well with the task that is going to perform right and then last but not least we're going to set this to verbos so that we can see in real time what the agent is thinking about okay and that is the first agent so we have effectively created the method that will return the researcher now I will copy from the documentation the industry analyst the meeting strategist and a brief summary writer to do this just going to copy this from here there you go as you can see it also has a very detailed backstory and it has some tools that we have not created yet so I'm going to delete them so we have the industry analyst whose goal is to analyze the current his industry Trends Etc and it also has a very detailed backstory same thing with the meeting strategist which is going to take which is going to perform the task the third task right here which is the meeting strategy task and this one is going to have also a backstory as a strategy advisor your expertise will guide development blah blah blah and then last but not least we're going to have this specialist in writing briefs for the meeting okay so here we have this specialist briefing coordinator his goal is to compile all gathered information into concise informative briefing document okay and I have deleted the tools from this to because I don't think they they actually need tools I'm going to give you more information about that in a moment but just know that we have effectively created our four agents right here we're going to create the tools that they're going to use to search the web in a moment but for now you know that we have this agents and we have the tasks awesome you have effectively created all of your tasks and all of your agents now what we're going to want to do is we're going to create the tools that our agents are going to use okay these agents are going to be able to decide whether or not to use a tool depending on their goal and they're going to be able to think about it using the language model I'm going to show you how that works behind the scenes in a little bit but for now just bear with me we're going to have to create the tools first okay now the tools that they're going to need are tools that are going to allow them to search the web in this case we have we're going to be using EXA which is a service that allows you that exposes an API that allows you to search the web using embeddings based search so basically you're going to create a few methods that are going to return results from the web and our agents are going to be able to use these functions on these methods and to get the results and to choose what to do depending on the results that they got okay in this case we're going to be creating a function or method called search which is going to search the websites based on a query find similar which is going to search for similar websites based on a URL and get contents which is going to get the contents from a websites giving the ID of that website because EXA works with IDs okay now know that these are very important properties of your tools they have to have a very clear description of what they do because your agent is going to read that description and it is based on that description that is going to decide whether or not it has to use that tool to perform its action or not okay so your description has to be very clear your input has to be very clear as well which means that you have to be very explicit into what kind of uh data your agent is supposed to to use when it's going to be using this tool and what it can expect from it so in the case of the search and Def find similar tools we're going to have that they return three results okay so let's build these tools right so as mentioned before we're going to be using EXA to create our tools and EXA actually gives you a thousand requests per month for free so it's pretty good for testing and now you can go right here in EXA documentation and we can see how we can use this so we are going to install EXA using pip install xpy so I'm going to come right here going to do not here I'm going to come where my environment is active and once that XI is installed I'm going to be able to come right here to create a tools. py file and I'm going to put this file into my source directory and inside of here I'm going to actually start coding my tools so the first thing that I'm going to do is I'm going to import OS because we're going to want to use the API key from EXA that we're going to get in a moment then we're going to import from EXA py we're going to import the EXA client just like they say right here and then we're going to initialize our client like this right here but before doing that we're going to create a class that is going to wrap it all and make it a little bit more organized we're going to call this XA Search tool set and here we're going to define a method we're going to define a method that is going to return the initialized instance of XA okay so this method is going to call be called like this and it's going to return an instance of X like this this and remember that in order to initialize it we have to pass in the API key so we're going to pass in the API key like this right here OS Environ we're going to get xipi key so there we go now we can actually start coding our tools and in order to code our tools we're going to use the decorator from Lang chain okay remember that crew AI is built using Lang chain so everything that you have in Lang chain is compatible with crei so from Lang chain. agents we're going to import the tool decorator and that's the one that we're going to be using right here to create our first method that is going to be this first tool search Okay so the method is going to be called search remember to name them with um with a name that that show shows what this method does because the agent is going to have access to the name of the function as well it's also going to have access to the name of the input variable and it's important to add the type right here so that the agent knows what kind of um input this method expects okay and here we're also going to need this documentation string that is also going to be available for the agent to know what this tool is for so here we have the tool is for searching for a web page based on the query okay and this one is going to return the results from EXA and in order to call the results remember that here in the exit documentation we have to do excess search our query and then use Auto prompt true so let's return first of all we we're going to have to call this function to get our client so we're going to call it from the current class we're going to call EXA we're going to call search and here we're going to pass in the query now for some reason in the documentation they use an F string to wrap the query like this so I'm going to do it like they do but know that uh I mean apparently you can just pass in the query like that but let's just follow what the guys from cow I did then we're going to set the use Auto prompt to true and last but not least let's set the number of results to three right there you go so that is the first tool that we have and the second tool remember it is find similar which is going to be uh I mean the description of which is going to be search for similar websites based on a URL so I have it right here let me copy it for you there we go like that so again a very clear description of what this function does which is the tool that our agent is going to be able to use search for web pages similar to a given URL the URL is the input parameter right here the URL p in should be a URL returned from search and here we're going to just correct the name of the class there you go and the method is fine similar of course you can find the methods in the exit documentation but I'm just going over like this to make it a little bit clearer and faster and then last but not least we have the get contents tool which is going to explore the contents of a given website web page I mean so get contents it gets the IDS of your of your retrieved web pages and here's the description get the contents of the web page the IDS must be passed in as a list and the list should have been the one returned from search and here we're going to I was just making some tests here we're going to copy the EV I we're going to first convert the this string into an actual object right here then we're going to call EXA to get the contents and then you go this is going to return the contents in a string so there you go and now last but not least actually what we can do is we're going to create a function called tools that is actually all it's going to do is going to return a list of all of these tools right because this is the function that we're going to want to use to assign these tools to our agents right here okay so in order to do that remember that all right so for now just know that our tools are completely coded they're finished and these are the tools that our agents are going to be able to use now that the tools are finished we're going to have to assign the tools to the agents because remember that we have these two agents that are going to have access to these other tools right so in order to do that what we're going to do is we're going to come back to our agents and here in tools what we're going to do is first of all we're going to import from tools import EXA Search tool set and remember that we defined this method called tools that effectively returns a list of our Tools in this class so there we go we're going to do the same thing with our industry analyst because it will also have access to these tools and there you go so now we have effectively created our tools and we have effectively assign them to the agents that are going to be using them now let's talk a little bit about how agents use these tools and how agents think and then we're going to see how they interact with each other okay so let's talk a little bit about how agents work and how they think by themselves in order to choose tools that will help them to complete their tasks okay in order to do this we have to understand a couple of Concepts um which is that crew AI actually implements Lang chain agents and they Implement a type of agent called react agent this is knocked to JavaScript framework these are agents that actually work in a loop of chain of thoughts in which they enter this Loop until and they think about the task and execute actions about it until they find that they have found the actual answer to the question okay so let me show you real quick how this looks like so what is actually happening is that we're passing in some context to the agent the agent is sending that context to the language model and it is using the language model to think okay so the agent is going to be saying something like given the following context what action would you take and then it's going to think about it it's going to present present a thought so for example for our first task which is research the participants the thought is going to be something like now I have to use a tool to search about the participants and the companies involved in the meeting now it's going after that it is going to choose a tool and out of a set of defin defined actions that it's going to have inside the prompt it is going to choose one action okay and each action is going to have specified with with input it can it can accept in our case each action is going to be using each one of our tools that why it was that's why it was so important to give a description to our tools because that way the agent is going to know what each tool does and decide what action to take with these tools and it is going to also return to us the the input that is going to input to this tool then once you get that tool it is going to execute the tool and whatever the tool or the function returned it is going to be called the observation and this observation is going to be appended into the context so now the context is the task the description of the task the thought the action and the observation of the first action and then it can enter the thought again and think okay so now I have information about this now maybe I have to research information about this other thing and it is going to use the search tool again and it is going to have another observation that is going to be appended and notice that we're making several language model calls here so we're making a language model every time the agent thinks and maybe also every time the agent h executes a tool depending on our tool and we're appending that into the observation let me show you how that looks like in in your actual prompt so this is how the prompt looks like in O in crew AI so the prompt that you're actually going to be sending to the language model looks something like this youur are a then the role of the agent that is assigned to the task in our case we're going to be dealing with the first task which is research the participants and so here it would be something like you are a research specialist and then you have here the backstory that's why the backstory was so important because it's going to allow you to give this backstory to your agent that will give you more probabilities of getting a good answer from your language model so you're a research specialist and then the backstory of this one as a research research specialist your mission is to uncover detailed information blah blah blah and then your goal is and then the task agent goal I mean the goal of your agent assigned to this Tas task because remember that when defining our agent we also set the goal right here conduct th of research on people companies involved in the meeting and that is what we have right here your goal is to conduct tho research and people and companies involved in the meeting right after that you have the following tools at your disposal and here you have the following tools at your disposal and as you can see we're also taking the tools from the that is assigned to the task so we're going to be listing these tools right here and as you can see in our prompt we have them right here we have the Search tool the find similar tool and the get contents tool and here you have how you call the function which input it takes and also the description that we gave to it in the documentation comment right now something interesting to note right here is that we have a couple other tools that we didn't add ourselves these tools come by default in all of the crei agents and if you want to to disable them you would have to disable them manually but for now know that by default all of the agents can actually delegate work to a coworker which means that they are going to call this function called um delegate work to cooworker and it is going to take the coworker the task and the contexts and it is going to send the task to them and it is going to also um give them all the context necessary to perform that task okay and they also have the possibility of asking a question to a coworker and by asking a question to a coworker also I mean it's pretty much the same thing but they actually expect a result um in return and the task to conduct comprehensive research da da and then you have the description of the task okay and consider that they do this using this other method right here that we have which is how agents think which is what I was talking to you about so we have the thought which is that given some context they use the llm to think what they're going to be doing afterwards so after they get the results from that prompt that I showed you they're going to append the results to the end of that prompt then the action which is the one that they're going to choose from the list that you just saw the action input and the observation which is the one that is going to be appended so that they can think again until they think that I now have all the information required to complete this task and they are going to just return the information required okay this is a very high level overview of how this works but it's just to show you how this is actually going on behind the scenes okay so there you go that is how agents work and also as you may have noticed now they can ask questions to each other so that's why the diagram I showed you at the beginning was kind of an oversimplification so here's another diagram that exemplifies in a little bit more realistic way how these Crews work at least in a sequential process okay so here we have the two tasks that were defined using async set to True which means that they are being executed at the same time and then the context from these tasks is going to be passed into the meeting strategy it's going to be appended into the prompt and then once the meeting strategy is done we're going to pass all of the context from these three into the summarizing and briefing task which is going to give us our result and the part of the agents also looks a little bit more different because now we don't have just one agent doing one thing we actually have the agents asking questions to each other to find the right answer to your tasks okay that is the reason why I decided that the brief and summary writer and the meeting strategist did not necessarily have to have access to the tools um of EXA to search the web because they are only supposed to be working on the information that the specialized researcher and Industry analyst got for them okay so that is why we did this and that is why we're using that's why I took the tools from them because in the documentation they actually have the tools I figured that if they want to find more information they can use the delegate tool or the ask question tool to actually get information what the information that they need from the researcher or the industry analyst okay so that is how agents work and that is that is a more reliable a more realistic overview of what is going on behind the scenes in cre AI so I hope this makes it a little bit clearer awesome so first of all congratulations because I mean by getting all the way to here you have successfully completed all of the small components that are going to be used to create our crew so you have made the already the most difficult part now from now on it is only just putting everything together and seeing the magic develop in front of our eyes so congratulations for that now what we're going to be doing actually is to put everything together I'm going to go to main.py and in here well first of all I am actually just going to create my main function just to make this a little bit more organized and first of all let's import from tnv we're going to import load. tnv and we're going to call it right here there you go and this is just to make this more organized and to be sure that this is only executed if the file is executed directly right now right here we're going to import from crew AI we're going to import crew which is the class that we're going to use to create our crew now from tasks we're going to import meting prep tasks and from Agents we're going to import meting prep agents now to be clear what we're importing from tasks and agents is actually from these two files the the tasks and the Agents that we previously uh defined okay so that's what we're importing right here now the first thing that I'm going to do is I am going to set up my input right because remember that right here we had the user inputs so we have to ask the user for these inputs first of all I'm going to I mean this is not going to have a graphical user interface it's going to be in the terminal so we're going to print welcome to meeting prep crew some dashes and let's just refact to these meeting participants is going to be input by the user what are the emails of the participants in the meeting then we're going to have meeting context which is going to be the context of the meeting and the meeting objective which is the meeting goal that we have right here okay now once that we have that now we're going to start initializing our agents and our tasks okay so first of all I'm going to initialize the tasks object and the Agents object with the classes that I imported from Agents and from tasks and this two I am going to use them to create my agents first of all okay so the agents are going to be my research agent first of all and then we're going to add my then the second one which one was it the industry analyst industry analysis agent agents industry analysis and what we're doing here is actually calling the method from the agents from the meeting prep agents class right so here I'm calling the research agent method which if you remember correctly when we go to agents research agent it actually Returns the agent from crew AI with all the roles goals and backstory that we defined before so that's what we're doing right here now we're doing the same thing with the other agents right here which are the meeting strategy agent and the summary and briefing agent then after that we're going to create our tasks the tasks are going to be just like we defined before right here first of all research and analyze industry we're going to do the research task which just like we saw before remember we're calling the method from the tasks meeting prep tasks class okay and this method if you remember correctly it takes an agent the meeting participants and the meeting context so we're going to pass in the research agent which is the one in charge of the research task the meeting participants and the meeting context we're going to do the same thing with all of the other tasks which are going to be the industry analysis task the meeting strategy the meeting strategy task so let's call let's create this one called industry industry analysis task I was hoping GitHub would give me an autocomplete there you go and a summary and briefing task okay so we are creating our three our four tasks each one with its own agent research agent industry analysis agent meeting strategy agent and summary and briefing agent and each of them with the context required in which case for the first two it is the meeting participants and context and for the um third and fourth it is the meeting context and the meeting objective okay now something to consider right here is that these tasks require context okay as you can see right here the research and the analyze industry tasks they don't have a context property right here but the meeting strategy and the summarizing and briefing uh tasks they do have a context property and their context is supposed to be for as I mean for the meeting strategy it is supposed to be the results from the research um from the research task and for the analyze industry task and for the summarizing and briefing task the context is supposed to be the results from the research task the analyze industry task and the meeting strategy so this one takes the context from this two and this one from this three so let's actually set that right now in order to do that all you have to do is to call your call your task and add the context like this we're going to say that the context is going to be equal to and we're going to pass in just a list and each one of these objects actually conect contains the results from that task so here we have the results from the research task the resch from the industry analysis task and these results are going to be appended to the end of The Prompt when we send the prompt for the meeting strategy task and this last one is going to be the summary and briefing task and this one also takes some context and this one takes the context from the other three so there you go now we have successfully created all of our agents and our task it's time to actually create the crew using all of this so to create the crew this is very simple we're going to be using this class that we imported from crew Ai and what we're going to do is just going to say crew equals we're going to initialize our crew and this one takes several parameters the first one is the agents and this is basically just a list of all of our agents that we have defined up here so there go and then it is going to take the tasks and these ones are just going to be a list of all the tasks that we defined up here and there you go now by default your process is going to be sequential okay so here you see process sequential but I mean that's that's the default so we're not going to touch it we're just going to leave it at sequential but know that if you wanted a hierarchical uh hierarchical process this is where you would have to add it in process hierarchical okay so now that we have created our crew we can effectively execute it and in order to run it what we're going to do is we're going to say result crew. kickoff and this is going to this is going to execute your crew and return the final result from the final task which is going to be your final goal of your entire crew okay now I wanted to mention something a little bit important about the costs of this so let's talk about that now so let's talk a little bit about the costs of all of this okay you have to consider that of course we are making calls to our language models and that is expensive and you also have to consider the API calls to your tools that might be expensive as well I mean in our case EXA is free for the first thousand uh request so you don't have to worry about that but you have to remember that agents are using the reactive model which is this one right here remember that this means that they can perform a Chain of Thought prompt in a loop until they find until they think that they have completed the task so every time they think about anything right here they are making an API call to your language model model and this can become quite expensive especially because crew AI works with gp4 by default you can change that uh but by default it works with gp4 and actually gp4 is the one that works the best with what I have tested so when you are designing your crew I would recommend that you make sure that you have a clear monitoring setup in place and that you know how much this is costing you so for example to give you just a quick example about this these tasks in what I have tested each one of these um each one of these tasks uh turned out to be about five five to nine iterations of this cycle until they each I mean for each task until each agent decided that it has the answer to the task so in the end all of this ended up costing me something like $7 to $9 for just a single execution of the crew okay so bear that in mind um so what I'm going to do now is I'm going to show you how to monitor this using Lang chain just I mean this is kind of a bonus so that you know how much you're you're spending and you can visualize how this works okay so let's actually do that so let's start by setting up some of our API Keys as you can see you can come to platform open.com to create your API ke keys and you're going to want to add a building method in act in order to actually use these language models okay then you're going to go to EXA dashboard. xa. and you're also going to generate your API key right here remember that EXA is free for the first thousand requests and I don't remember actually adding my credit card account so that one's for free then what I'm going to do is I'm going to be using Langs Smith which is a monitoring method meod a monitoring platform that allows you to check exactly which requests are being sent to your language model what the responses are for each one of the requests and how much this is costing you and in order to do that you just have to set this two this two environment variables Lang chain tracing and Lang chain API key which you will get I mean the API key you get it in lsmith and the tracing you just set it to true and that is what I have done right here I mean of course I will delete all of these API Keys before publishing this video but this is how this should work now what we're going to do right here is we're actually just going to execute this and see how this works and just by adding these API Keys Langs Smith is going to be able to log everything that happens just by adding this okay so let's do that right now and actually another thing that I wanted to show you is how to test this with gpt3 instead of GPT 4 because remember that crew AI works by default with gp4 so here they tell you which environment variable you have to update if what you want to use is another language from open AI so I'm going to come right here and instead of GPT 4 we're going to be using the latest GPT 3.5 turbo which has a context window of 16 000 tokens which should be enough for our Chain of Thought hopefully so oops this one is supposed to be GPT 3.5 turbo like this now if I save this I should be able to run this there we go so we can actually start executing this in order to do that what I'm going to have to do is just go python and then execute the main file which is going to create my crew and then execute the crew kof actually I forgot to print the results so let's print the results here like that there you go so now I save it and I'm going to execute it right here as we have defined it is going to ask me for the participants of our meeting who are the what are the emails of the participants and my meeting is going to have Sam Alman from open aai Tim Cook from Apple and S Pai from Google these are of course not the actual emails because I don't have them and if I had them I would not share them like this what is the context of the meeting the participants of the meeting have decided that they want to find a new industry to invest in they have lost faith in artificial intelligence so they want to start investing in cat coffee shops cat coffee shops are cafes where people come to drink soft drinks with cats walking around the clients are allowed to pet the cats so let's see and the goal of the meeting is to find a way to enter this new market and make it profitable ideally the participants should be able to find a location to open their first cat coffee shop so let's see what gpt3 is able to get for us so I'm going to hit enter here and we have entering new crew agent executor all right so the first action was search and it's starting to search it's also loging some errors well the crew seems to be working correctly this is going to take a few minutes so I'm going to pause this and show you how this looks once this is finished so the execution is finished and as you can see here is what the agents were thinking thinking all the time I mean it took a few minutes um it always thinks I mean as I told you before it starts all with a thought I need to further analyze the content of the Articles to extract insights then the action it shows defin similar action in this case action input sent in a URL Etc okay and sometimes it would encounter some errors and here is the end result now we are talking with GPT 3.5 and and it did make some mistakes apparently we didn't even get the bias from the participants this doesn't happen with gp4 I'm going to run this with gp4 in a moment just to show you how this works but you can see here we have the industry overview the talking points and the Strategic recommendations looks pretty good now how about we take a look at how this works in Lang in Langs Smith and what was actually going on behind the scenes so what I'm going to do going to go to my projects and here is my default project where every everything was logged in and here is my recent my recent execution so here we have the first one for example here we have that this is the crew agent executor and here we see all the prompts that were sent to open Ai and you can see you're an industry analyst and Industry analyst your analysis will identify key TRS blah blah blah which is what we wrote then the list of the tools that we selected here search find similar get contents and as I mentioned before delegate work or ask a question to a coworker we also have the following format thought action input on observation just to prompt the the agent that this is the way that it has to think to prompt the react Loop and then the current task which is analyze the current market industry Etc and the participants the meeting cont text Etc and then we just prompted to get the next thought and here you have the output and you can see that this particular agent went through 1 2 3 4 5 6 7 8 9 10 11 12 14 Loops in this react cycle so it made 14 calls before actually completing this task which is huge if you're using gp4 um I'm going to show you the results of this same crew using gp4 I mean gp4 I've tasted it and it doesn't make this kind of mistakes but it does become much more expensive so as you can see here using gpt3 this costed me not too much actually yeah that was all right but if I had been going with GPT 4 let me show you um yeah I think last time I executed this was like four years something like that so just keep that in mind um when you're executing this kind of change I'm going to run this in gp4 to show you how this works all right so let's do this again but this time we're going to be using gp4 and in order to do that I am just going to go back here and select the latest gp4 model and just complete this right here so now we're going to be using gp4 and I am going to test exactly the same chain I'm actually going to open a new terminal so that we can so that we can compare both of them so here I'm going to remember cond activate crew tutorial and then I'm going to just execute this python main file again the emails of the participants the context of the meeting which is that they have decided that they want to abandon Ai and go for creating cat coffee shops and the objective which is finding the next location and now we're entering the crew executor chain and let me just show you this in real time in here so you can see it has started two agent executors and this is of course because the first two tasks are asynchronous which it means that they are executing themselves simultaneously that's why we have two agent executors here so let's see as you can see init I mean from the that we're starting with much higher costs this never went above 1 cent I mean once yeah but here just it just started and it's already at 1 cent so let's see how this goes let's open this start seeing there you go we have an exception here and you can start seeing the prompts that this is sending you are a research specialist blah blah blah and then you have the thought to conduct comprehensive research blah blah blah so let's come back here and I am going to show you I'm going to pause the video I'm going to show you the results in a moment so there we go it has finished with all of the chains and all of the agents right here executions so here we have the finished chain The Briefing document for the Cat Coffee Shop investment meeting we have the introduction this briefing document aims to equip meeting participants with Comprehensive insights BL with we have the participant bios which which are correctly set up here CE of Google Apple and open aai industry overview the Cat Coffee Shop industry looks great key talking points strategic recommendations discussion angles and the conclusion and yeah I mean you can see that gp4 does a much better job at this and you can see that it also managed to finish the tasks in way less calls actually so that's actually good news we had 1 2 3 four calls in this agent one call for this one and one call for this other one because we didn't allow them to use the tools for the web so yeah I mean actually this one wasn't that expensive because we removed the tools um the the research tools from the last two agents so I've apparently gp4 is much more powerful so there you go so that was your introduction to crew AI we saw all the components that involve the creation of a crew including the tasks the agents and the tools and everything inside of a sequential process we also saw how this works behind the scenes how the agents think behind the scenes and we tested the whole thing with GP 3 and gp4 let me know what kind of other videos you would like to see in the future don't forget to subscribe and please support me on patreon I recently opened this patreon account and this will allow me to continue doing this for free for you so thank you very much for watching and I will see you next [Music] time [Music] [Music]
8E6uPB4U0E8,2024-03-25T11:37:45.000000,Harrison Chase: LangChain and The Future of LLM Applications | Alejandro AO,[Music] all right welcome everyone how's it going welcome to the first episode of our podcast where we explore the minds of the people who are shaping the future of artificial intelligence technology and Beyond I am your host and today we have the privilege of sitting down with a guest who is at the Forefront of integrating large language models like gp4 mestral Gemini into our everyday lives his name is Harrison Chase if you haven't heard about him he is the Visionary co-founder and CEO of Lang chain now Lang chain is probably the most popular framework that allows software engineers and developers to integrate large language models into the new generation of applications these applications range from assistants that can chat with you over your private data like how we have shown here in the channel and to all the way to autonomous agents that can reason and take action by themselves depending on your instructions and much more today we will dive deep into Harrison SP for the future of AI the challenges and triumphs of building Lang chain and his insights on the evolving landscape of large language models and generative AI so without any further Ado I bring you haris and [Music] [Music] Chase all right there we go great well Harrison thank you for thank you for being here uh it's an honor thanks for having me great it's an honor thank you very much for for coming and um yeah I'll be asking you some some questions about on Lang chain and about your your career and uh your Insight about the entire AI industry and what you see coming the future so um very happy great so well let's start off with um having you describe uh what you do in a few words I mean Lang chain and in general what you have have been uh working on it's been more than a year already that you have been on this so um why don't you start with that yeah it's been a little over a year so Lang chain started as an open source project to make it easy to build llm applications um so uh yeah launched in late October early November of 2022 um as a side project just a python package uh that yeah had a bunch of like Integrations with various components that are common for building Alama applications and then a few specific ways to construct these into what we called chains um hence the name kind of Lang chain language chain um and since then uh it's turned into a company so we started a company around it in uh late January of 2023 so a little over a year ago and now we have python package which is a big Focus we have a JavaScript package which is also a big focus and then we also have laying Smith which is a platform um for logging observability testing eval of uh llm applications in general um so yeah at a high level that's uh that that's what Lang chain is as the company and then I'm sure we'll dive into all the components in more detail yeah I mean it's amazing that um you have managed to go from one package to this entire ecosystem of uh tools that are capable of building this very cool applications I mean I think it speaks to the early nature of like it's just so early in the space right so like I I start I didn't start lingin with the intent of starting a but when I when I um you know after playing around in the space more and after building with it more it became pretty quickly apparent that one like you know llms are going to be a big deal um and and change a lot of things and two it's just like so early on in the space and so because of that there's just so many tools and helpful things that need to be built that are you know Lang train the orch rtion layer that is just one part of what's needed to build llm apps and then the second big part which we saw was basically these apps were you know really hard to get reliable they have these like random non-deterministic things at the center of them and so we recognize that pretty early on built Lan SP pretty early on and you know I'm sure there's going to be more tooling that's needed but yeah I think it just speaks to the fact that it's super early on and so there's a lot of ways to provide value a lot of uh new tools coming on in on the Ling side um I mean you know I think definitely a lot of like changes and improvements to Lane chain and Link Smith like Lan chain right now is very different than L chain when it first launched right it has to be um and so I we'll continue to push it we'll continue to focus on specific areas that we see being kind of like focuses and add more tooling around that for sure and then On LAN Smith there's uh uh yeah there's a lot more features we we are going to add there we we want to add there um again it's just so early that you know observability and testing is a great start but there's just a lot more to be built in this area yeah um about that like Lang chain how how did the idea come to you did I mean was it some some sort of a realization like one day you were like I wish this existed or was it more gradual uh that you started building it how did it go yeah it wasn't um basically I was going to a bunch of hackathons um and meetups in the space talking to folks I knew I was going to leave my previous job but I didn't know what I was going to do um and so I was just exploring um and as part of that exploration you know talk to a bunch of folks who were building early applications and saw them doing similar things that Ling chain would would end up helping enable um and so I think the thought process thought process wasn't really too grandiose it was like hey there's some common abstractions in terms of how people are doing things wouldn't it be cool as a as a weak side project to pull these out into a package and put it out in the world and that's really how it started right yeah I mean it's it's definitely become I mean since then it's become a very mature product I would say um more mature at least I constantly only getting more and more mature I mean after over a year how would you say that your vision of uh Lang chain has changed because I mean I suppose that it's not the same as it was like a few months after you founded a company yeah vision of the open source or vision of the company I mean in general um in general yeah yeah you know I think there are a few like specific areas that we have more confidence in as being like high value like I think like right after we started the company the main thing that we knew is that it was really early on in the space um and so there was a lot of hypotheses we had um and and I think now we know a little bit more about what it means to be able to build reliable app in the space so like on the L train side you know we've been really focused on kind of like structured output so so uh making it really easy to use all LS to Output structur data we see this being a huge use case um especially where Lang chain plays which is like using language models to call other things and do other things you need to Output it in some structured format so that's been a huge focus of ours um we've we've uh added a bunch of stuff around streaming um so we think streaming not just of but of the inter immediate results as well is really important as you have longer running applications so like that's you know something we've updated our belief is is really important and um uh retrieval is really important um I think if you asked me that last year I'd probably say that as well some updated believe you know now now uh one aspect of that that we're really focused on is the query analysis part um so we think like basically taking a raw user query and then converting it into a more like optimized query in some way um we think big piece and likely to be here for a while so we're really focused on that right right can you give an example of what that what that means a little bit more in detail yeah yeah absolutely so I think maybe um the easiest example to understand is so a lot of rag applications take a user query um and then they basically the the you know the typical method is to look it look up against documents that are in a vector store so you have a numerical representation for each document you create a numerical representation for the user query you find the ones that are most similar right uh but often times queries can in and backing up like that embedding similarities really good for kind of like comparing the semantic uh nature of two documents against each other um but oftentimes queries contain information that is not really semantic but rather more precise so an example could be um like you know what are movies about aliens in the Year 1980 so 1980 isn't like a semantic bit you want like you know you're asking for a specific filter and so like a query analysis step would basically take in that query and then spit out uh assuming that in our database we're able to filter on year of of publication for a movie it would spit out an optimized sarey where it would have like a query search string which maybe be like movies about aliens or if you have it's a movie database maybe it's just aliens um and then it has another filter that's uh uh you know release date equals 2010 and then you can pass that optimized query into the into the you know Vector store filtering on the release date and and get back results that are guaranteed to be that release date 201 right okay that's pretty cool at at some point in the I mean I had seen some interviews with you before and you were talking about some of the implementations of um Lang chain some really cool projects that you had seen in the past I heard you mention one say Dungeons and Dragons um master or something yeah um in I mean it's been a while since Lang's been out has your I mean have you encountered new or cool projects that have used langing to create their application or something yeah I mean I think there's a lot of cool projects and cool and different ways um so so I I I think the Dungeons and Dragons one is still one of my favorite for a few reasons like I think like one like uh you know is a creative application right and so I think creative applications are really good for llms because they're not perfect and they can mess up and in Creative applications that's totally okay and it can even sometimes be like a feature um but but I also think there's a lot of um there's a there's a lot of really tricky technical challenges to build a really good kind of like Dungeons and dragon Str Master mainly you need to kind of like maintain like the state of the world and keep track of that over time um and so I think that gets to like the idea of like long-term memory which is something we're really excited about and so so I think that's really interesting um you know I I think another example of kind of like cool applications for a different reason um are some of uh kind of like these are they're kind of like more complex one example would be a more complex kind of like customer support chatbot and that sounds really boring on face value right um and and and much less exciting than Dungeons and Dragons but but I think the reason why it's cool is that you know it's really easy to build a chat bot that's kind of like answering questions about documentation and so if that's what you have as a support bot right that's that's a little bit less exciting but oftentimes um you want your customer support bot to be able to do a multitude of different things it needs to know about the user that it's interacting with and it needs to like only be able to you know if you're if you're asking about like previous transactions you should only have access to data that to your transactions you shouldn't be able to ask questions about my transactions so there's so it's a bit more narrowly scoped in that way and and the way that we see people building these more complex Bots is often as kind of like more complex graphs or state machines kind of um so there's a lot of really uh cool kind of like flow engineering work that goes into creating these basically like State machines where you have a customer support bot that you know maybe you you you enter um and you're talking to like a generalist customer support bot but then you ask a question about a purchase order and it routes you to different one that knows how to deal with kind of like your previous order and then you ask a question about the current inventory and it routes you to a separate run right so you have these multiactor systems with some like flow set up between them and so there's some really complex engineering that goes in there and so well may not be as cool or sexy as a Dungeons and dragon thing um it uh I think it's still a pretty cool example of uh some complex engineering Plus llms have you seen some of those in production already yeah yeah cool uh they're using Lang chain some are yeah you know unfortunately not are but some definitely are yeah cuz I I saw like um on the previous information that you shared in previous interviews that most of these projects had not reached production level yet um so that has changed apparently since uh last year well so you know most uh so okay maybe a few things like uh I would say most still probably haven't reached production level but there definitely are some that are and so we're starting to see like what it takes to get successful and what success looks like um and then more generally yeah we're seeing we're seeing more and more of that recently so my my take on the both space is like you know chat gbd came out like November 2022 right um and so maybe from then until kind of like the summer there's like a massive kind of like rush in people exploring and trying out new things and tons of interests and people like trying all these wacky agent multi-agent type things um and and then around last summer I think people um you know became more focused on like okay so can any of these actually go to production like what are we putting that's in production and you know there were a few right away but those were more like simple single llm calls um and and so yeah I think from the summer so so I'd say like from the summer to maybe like o October November I would say uh uh yeah maybe like from the summer to November the space I think was a little bit quieter as people were trying to like figure this out and then roughly from like November till now I think there's been more and more companies that are putting things in in production so we did a case study with elastic um who launched kind of like a a chatbot answer questions like an an assistant style chatbot um and that's using link chain and I think that launched I forget the exact date but I think that was maybe like December January um right so we see a lot of these applications starting to come to fruition and and finally yeah finally that's awesome um and you mentioned that you're we're starting to see what kind of things um are required for this kind of applications to actually go to production what would you say that are the main challenges for this applications to actually make it to production level yeah great question um I think there's a few one is like what is the right like ux for these applications um so you know chat and I mean that in a few ways one like chat is a fine ux um and so a lot use that but a lot are experimenting with kind of like other uxs as well I'd say most have gone to production have still been chat um but people have been experimenting and trying to figure it out but even within chat um you know interacting with llms is different than interacting with traditional software or with humans and so people kind of like need to figure out how to interact with these things um and so you know there's there's we did we did an article uh with uh folks from Norwegian Cruise Line where they talked about their chatbot and and some of the UI things that they're doing like you can give people example questions they can ask right um so that they know how to use it um you can uh I mean you need to stream tokens so it doesn't seem like it's waiting forever kind of like basic stuff um but yeah there's there's uh some figuring out of that um and and then uh I think probably the biggest blocker is these applications like you can build a prototype really quickly but it's not kind of like at the level of accuracy where it's where that's good enough to send a production and so there's actually a lot of work that goes in to to tightening um that Gap and and improving the application um and so a lot of that is basically prompt engineering and flow engineering making sure you have the right context making sure the prompts are keep on improving maybe making sure you have the right few shot examples and and this is where Lang Smith um building comes in real Handy you can see exactly what's going on you can see the input and output at each step um uh you can you can enter into a playground play around with the prompt mess around with it from there um and and so you can you can create test sets which then allows you to like iterate with confidence as you kind of like uh change a prompt you can see whether it's improving or depring or sorry not improving um and yeah this type of like visibility um I think really provides you know it's still a lot of work don't get me wrong like it's not and that's why it's taking you know that's why it takes a while and but we see the best engineering teams kind of like get more rigorous about how they're testing get more rigorous about how they're debugging issues um and uh launch into production get feedback improve from there have this like tight feedback loop and and that that gets them to a point where they can say launch into production right um for those who are not familiar with it would you mind just giving a um a quick explanation of what Langs Smith is and how it works yeah absolutely so so Lang Smith is a platform that we're building it's independent of Lang chain so it works with or without L chain all right um uh one yeah a lot of people don't know that um but it's yeah it's completely API first so we we have a nice kind of like Python and typescript um sdks for it that uh you we have some methods for like you know patching the open AI client really easily so if you're using open AI directly and not using linkchain you can just use that or you can just log things directly um so basically what it is it's a loging platform you log you log kind of like runs and results there so runs from production you log there um runs from kind of like evaluation runs uh you log there and then you can easily inspect the results and so you can see exactly what's going on you can see the inputs and outputs at each step um you can track kind of like uh you can collect feedback there you can track feedback over time uh you can you can monitor kind of like the latency of your applications you can check it for errors um we also have uh other things like a prompt Hub where you can store inversion prompts um and then also an annotation Quee um where you can easily label some of this data that's coming in so we say that human label human annotation is is pretty needed useful for collect you a lot of the feedback on these data points right sounds like that's kind of a most for uh production application are you the the I mean I I really don't know is this the only application that does this in the market or are there on any other because I I don't really know about that there there so there are a lot of other similar ones I'd say that ours is the most complete in the sense that it does all these things that I just mentioned um I think you have other tools that are really focused on just kind of like the logging of single data points or just the monitoring of of like latency or just the testing of uh data sets um and and I think ours is unique and that it brings all these things together um or our this unique in two ways i' say one it brings all these things together and I think that's really important because I think this like flywheel between logging testing experimenting like all of that is super important to to get really tight and crisp um and then two ours is really focused on like multi-step applications so a lot of other um ones are focused on like like single llm calls right um but you know we're L chain so you know we need to build this to work with L chain um and L chain is a lot of like multi-step applications um and so I think we have by far the best support for that just given the nature of kind of like our Focus right okay that's uh yeah it sounds pretty much like it's a something that you would need for for production definitely I think it's a I think it's a very very good product it's a probably a better product than linkchain um it came we launched it it was in public data for a while but it's now generally available so everyone everyone just sign up and try it cool and um are do you have any other any other products that are in the works right now or is that your main focus for the moment that's the main focus for the moment right um okay continuing about the about the Lang chain ecosystem you have an immense number of um Integrations with super cool providers which one would you say that has uh brought the most value to the Lang chain ecosystem or which which Integrations like you can name a few that are the most interesting to use um I mean this okay a little bit self- serving but I think the one that's brought the most value is the laying Smith integration um but let's I I'll put that aside we already talked about about that um I mean I think the most you know the main new thing here are language models right so like all the Integrations with language models are probably the most important things there and we've invested we've invested a lot of work in our integration ecosystem so Eric on our team has done a fantastic job of you know we now have like integration packages with specific providers so they're like more reliable and more maintained um and so we've invested a lot of work in this particularly around the language models um and so you know probably the most used one is the open AI integration for sure um and so by that measure like you know that that we we actually do have a list of the most uh kind of like downloaded integration packages um openi is number one by far um but I think you know like uh any of the language M providers anthropic Google Nvidia Kier Azure like all of those have got to be up there um some of the more cool ones I think are the local model integration so like AMA is a a thing that can run models locally our integration with them I think is really popular and it's also really cool because it lets you run stuff locally and that's awesome right so I'd shout out them as being one of the more cool ones that people should check out cool and I mean there language models when you're within the langu framework um the idea is to make them interact with other providers not only for language models but for data store for stores for other tools which ones would you say that are the tools that have had the most success within the echosystem like which ones have attracted more people yeah so uh number one by far has got to be all kind of like the vector store tools um so one of the main things we see people building is chat over their documents right and so to do that Vector stores have emerged as the or or or databases that support Vector uh Vector Technology have emerged as kind of like the main way to do that um and so pine cone weeva troma redis like all of these whether they're Vector native or have added in Vector functionality um you know uh uh those have got to be the main class of tools that are used I'll I'll shout out a second one which is also search related tools um so we see applications that can interact with the web being really popular and so uh tavil AI is a great integration partner um and they have a great kind of like a web action same with EXA same with u.com and so those types of tools have have also been really popular um I I'll also say though that for um you know when we see people going into production often times the tools that they use are custom tools that they write um right because you know we have a bunch of generic tools like Google Maps and stuff like that but oftentimes we see people building custom applications with their data and so we've made it really easy to write your own custom tools and so that's often times that's by far what we see people using most in production with with the exception of like these Vector databases because those are there are a few people that maybe right there on Vector databases but for the most part people use ones that are yeah shelves yeah so you mentioned that apart from rag uh from yeah apart from rag you have web like searching the web applications do you see any other kind of applications where Lang chain um is useful for or are those the main two ones um I mean like I think the main so so I'd say the two main things that people build are and they you can think of them in the same way if if you really want to but one's kind of like rad style chop Bots and then the other kind of like assistants that can interact with various things um those things can be apis to search the web um right or to search their own data but there there are a long tale of other tools um but there it's it's like a long taale like a few people use this tool a few people use this other tool um but the the things that they're building are these kind of like assistant co-pilot like things where you say something then thinks about what to do do it takes some action it gets the response back it thinks about what to do again it gets the response back and then it returns to the user and so that that type of architecture um I think we've spent a lot of time making easy to build with Lang chain and Lang graph um and so you know the that that would be the main thing that people are building but there's so many different use cases for it like you can use it to do SQL question answering you can use it to do CSV question answering you can use it to do question answering over your documents you can use it to interact with an API um and then you know interacting with an API is incredibly horizontal and so there's all different types of apis so you know it's it's tough to but but and it's tough to come up with something more specific than that because people are using LMS for everything so I mean just just to to be sure that everyone understands what we're talking about here when you when we say rag would you mind explaining what rag is in simple terms Place yeah absolutely so rag stands for retrieval augmented generation the basic idea is that um when when you're chatting with an llm and you send a message in it responds based on stuff that it knows it's been trained on that's in its weights um and so that's great if it's been trained on data that's relevant it's not great if you're asking questions about data that model has not been trained on and so the most common way to overcome this issue is to use rag retrieval augmented generation which is where you first do a retrieval step and you fetch relevant documents um or relevant data I should say um and then basically you augment the generation of the llm which basically means you pass in these documents as part of the prompt to the llm and you say something like answer this question based only on the data below right so that allows you to chat with your private data and pretty much any data available yeah exactly and I think most people immediately think of chatting with like unstructured data but you could view SQL as a chatting with a SQL database as a type of rag um you could you know then then there's also uh like when I was talking about the assistance earlier you could also view the assistance as a type of rag and and you know I would say that's not the most common way that people do it there's and this gets to um you know probably like the main point of laying chain is that there's all these different architectures that your applications can take on they can take on like I'd say like assistants are specific type of architecture there's also another like the most common architecture is a much more simpler one for rag the most common rag architecture is a much more simpler one where you you don't have this assistant thing you just like look up data pass it to a prompt that's your final answer right and so that's really fast that's really simple but it doesn't handle like it doesn't handle edge cases well and things like that and so then basically people are people are experimenting with all these different architectures and that's what L chain and Lan graph make it easy to do they make it easy to build all these different architectures and and and use examples of these different architectures awesome all right at some point also you mentioned um that you had seen some applications that I mean the most oftenly used interface for these applications was chat what other interfaces do you see or have you seen either in production or in prototyping yeah I mean the the other most common one besides chat is just like there's a single text input and then you get back a response um so like a single turn chat or something like that but then you can like you can populate it with um any information um then there's also some that just like they they weave it into their application UI so they're not actually maybe changing their UI they're just surfacing things so they could be using it to like generate uh uh like summaries of a document and they show those generated summaries in the UI but like they were already showing the document anyway so it's just adding like another bar under it um and other than that like uh yeah chat's by far the most common right I wish there was more I wish there was more um good ones Rell recently announced like uh or they they shared something around like generative UI where you use an llm to generate the UI um but I still think that's pretty new I haven't seen that like actually in production um very cool but everything that most of the things we see in production are the chat right um I would like to know a little bit more about as well about your career and what you what you have done because I I wasn't able to find much information about that um mostly most most of the information online about you is about Lang chain but I would like to know how you got to to where you are today and um and yeah I mean some advice that you may have to people that would like to to go into the same field as you and yeah so if you would mind just sharing a little bit about your academic history or professional history uh what you have been doing before Lang chain yeah absolutely I studied stats and computer science in college um and really started actually doing stuff in uh because of sports analytics so I really liked Sports and I liked math and stats and so I started doing stuff with sports analytics that led to like uh learning uh how to code to do that and things like that um so uh studied stats in cassin college did a bunch of sports analytics um after graduating did not do Sports analytics but instead went to Keno um a fintech startup um was on the machine learning team there for about two and a half years um did some stuff in time series then uh led the entity linking team so some some NLP related stuff um around entity linking uh we were that was like a 60 person startup when I joined we then got acquired by S&P Global after about a year um stayed there for like another year and a half S&P Global very big company um and so you know after after that I knew I wanted to go someplace smaller so joined robust intelligence um as the second employee there my current co-founder anush was actually the third uh employee there so that's how we met each other um and yeah it was there for about three and a half years um by the time I left we were about six people and it's it was a company in the mlop space so basically we worked on like testing and validation of machine learning models um it was really cool the first year you know uh super early on we were interacting with a lot of like R&D Departments of of other companies we spent a lot of time doing like adversarial machine learning um so some some really cool stuff there um then we started building out a platform um so got to got to see that um that that was really fun in in the mlop space on on testing and validation of machine learning models um and yeah I don't know like you know I think I've always just done things that I've I think I've always done things that I enjoyed right like I got into this because Sports analytics and I really enjoyed that you still do some of that uh not really like I follow it Loosely for for a few years after college I did some stuff on the side um but not really anymore um and so I I don't know I'd say like uh do stuff that you like and then you'll you'll work hard at it more naturally and then if if you work hard at something for enough time you'll you'll get pretty good at it then you can you can get good enough to be dangerous and then you can start ACC company in the space or something like that so you've you've always been in in the machine on the machine learning side of uh of these products right yep yep you learning and ml op so more so on like the applied side of that I was I was never I was never like a good researcher or anything like right and would you say that your degree prepared you more for for that kind of job or more for the development software engineering side um so I think I think my degree was very helpful for a lot like the machine learning stuff um but I learned everything I know about software engineering at my first job like you know i' obviously coded before that but like never seriously and so um yeah learn learned everything um for Real about that um out of college right and I had one question here about um becoming an AI engineer like I mean this these new terms like they're since they're new they can mean so many different things depending on the company that's posting the job ad so so how would you define a job engineer and sorry an AI engineer and what they do yeah um I definitely don't have a very good description of that you know I think it's probably been like under a year since people started using that term I I would say like um it probably involves working with language models and integrating them into uh in an application um and so I think like you know the require skills are are probably good engineering skills um and as well as like good problem solving skills because I think working with llms is a lot like solving hard problems they it's it's you you like the space is just moving so fast you need to be able to like pick up new things quickly um debug things quickly and so yeah just like solid engineering skills and then good problem solving skills to to stay up to date with all the llm advances would you say that would you say that you have to stud computer science in order to actually participate in this new industry or what do you what is I don't think so I don't think so I think like um and there's also flavor like you know there there like I think there's some debate around like will prompt engineering alone kind of like be be be a job and I think if if there's a job engineer for or if there's a job wreck for prompt engineer like I don't even know if need to be able to code um but I think if we're talking about AI engineer you need to be able to code but you don't need to have like you can you can learn that without a degree right um and then yeah you you you need to figure out how to work with language models I don't want to say like you need to know how to work with language models because no one really knows how to work with language models and it's constantly changing um so I would not get intimidated by that so I think like I think probably in my mind the requirement is more about kind of like being a solid engineer and having good problem solving skills right and about that like how would you like where would you go to learn all of those those things like would you uh I mean is what I I guess what I'm trying to get to is is studying by yourself enough to get into the industry or do you need some sort of a an official diploma or something like that um yeah I mean I think uh so so for the kind of like understanding how to work with language models kind of things um like just play around with language models work with language models put stuff out on Twitter put stuff out in the open source like all a lot of the most interesting stuff with working with like language models is being done out in the open by random people on Twitter um for the engineering side of things um maybe maybe this is a bit of a uh uh an oldfashioned take but like I think you just need to work in the industry and and start start in a you know in in an entry-level position work with some really strong people get feedback constantly kind of like improve I think there is you know I think there's some stuff in engineering that you can only learn by doing and so I think it's just experience there and you know there's nothing there's no there's no kind of like shortcuts there yeah I totally agree with that totally and yeah I mean studying in college can take you somewhere but it's only by doing that you will learn yeah exactly yeah like that's why I said I really didn't know anything about engineering until I started actually like working full-time in in your journey as a like as an engineer um do have you had any mentors or role models that have shaped the way that you work today in like in engineering's part or like in general yeah yeah absolutely I think I think both of my first bosses at uh Keno were amazing and I look up to them a lot um uh Sam schlier is one of them he's now like he I think he's like founding uh member of the character team so they're doing awesome stuff he's I think he uh him him and and Mikey um Mikey scholman who's the CEO of suo Al another company in the geni space but both of them were like you know I I learned so much from them not only like the obviously like skills of engineering but also like mental models of how to think about engineering and how to think about leading engineering teams um and Lead engineering projects and stuff like that I think probably the biggest thing um that uh I think it was probably Sam mostly but but Mikey as well um I think really important it is this idea of like just like figuring out what the blockers are and doing just the blockers um like I think oftentimes you can over complicate things in engineering a lot um and especially in a space like AI engineering today where it's just so fast moving and you need to just like ship stuff get feedback iterate you really need to focus like okay what's actually the blockies here and what are we just like bike shedding is a complete waste of time um and so I think Sam and Mikey were both I I think that's probably like the strongest mental model that I took from them W yeah it's always I mean you always take from from people you've worked with yeah you want to borrow like death parts from everyone right then try to do that so I should work with people who are like better than you at at something and try to learn from them 100% yeah that would yeah that would for anyone like just like any new grads or anyone just getting into this field like 100% my advice would be like find really good people and just work with them and just focus on that and don't worry about uh you know don't worry about title don't worry about um you know with within reasons don't worry about title don't worry about uh comp work worry about working with really good people and learning and that will pay off like few years on the line yeah totally do you have any advice for like people who want like they know how to code they are starting off um with these new technologies they're creating these new products there prototypes and they want to build a company around it um do you have any advice to PE to people I mean for people who are kind of in this situation yeah I mean I I don't um I don't know if I have any good advice like my my story and I could share that um you know like I don't know how typical my story is I I can share it and the lessons I learned there but like any advice I have would be you know with that context in mind um and what I did was basically you know I I I built something that I enjoyed working on um and thought was useful um and then I shared it with the world you know I put it out on Twitter um I iterated on it quickly I I made like a release every day right um and eventually enough people started using it where it was feasible to start a company around it um and so um you know I I was in a fortunate position where I was you know uh still at another job at the time but I knew I was going to leave so I kind of like had had a a safety net but I also had the freedom to um you know before that I was I I worked a lot I worked hard right so I wasn't doing a lot of like side projects so I I was in a you know definitely unfortunate position I don't know how replicable that is but yeah the takeaways would probably be like ship it like right you got to you got to put it out there um iterate quickly like get feedback and iterate L really seek out feedback like I think I was pretty proactive about seeking out feedback and I think I think that helped improve it um and then yeah if if you build something that people want as cliche or you know much easier much easier said than done but if if if you do that I think um I think that helps yeah I I mean to me it's just uh impressive how so many stories start with uh the first tweet came out like on this day um I mean from the top of my head I can't actually remember a single one but um like it just comes so often in conversations that yeah it all started with the Tweet did you have like many followers or how did how did that like actually took take traction I had like 200 followers 250 um they were mostly from the sports analytics days um so it's actually funny when I look at the people that I follow like you know it's it's mostly AI people now but there's like some Rand Sports analytics people from way back in the day um and yeah I think what I you know I think the first thread I did was like 13 tweets or something right so it was pretty long and detailed um and I tagged a bunch of people in it it was you know I I think I'd implemented like three different papers and like seven different Integrations or something like that so I tagged all the authors I tagged the integration things um and yeah I guess that helped get enough people to see it and enough people liked it and and and retweeted it I think that it it got got some followers from that and then kept on follow uping follow following reading about it and yeah yeah but it was just like consistent right like you got to do something every day you got to make progress like I mean it's it's it's still impressive the thing I mean the open source part right because I mean it's not obvious to me how you turn open source into a into a business has it been like very difficult or how how's that been um you know we knew we were going to build Lang Smith from the beginning and I think Lang Smith has turned out to be a correct bet like I think there's definitely a market there um and I think the you know but but it is difficult because it's not Lan chain right it's a separate thing like we basically have two teams internally and we basically twice the number of competitors right because there's some competitors for the open source some competitors for link Smith um but luckily we have a very good team that moves very quickly and I think we're able to ship and and and so I think we have the best product in both um but yeah you really I I remember talking with the data bricks people early on um and and they did a similar thing where they had they had spark and then they had their datab break platform um and the way they kind of um framed it was you had to you had to hit a home run in each right so like by the time we started the company you know would gotten a hit with l TBD like you know what's a home run versus what's a single but we got in a hit and yeah with doing that with Lang Smith we had to do that again and I do think we've done it again um you know obviously I I don't know if it's single or home run but like I think think um but yeah you have to do it with both and they're different skills one's Source one's a platform um different set of competitors different set of considerations uh at least one kind of takes the the users to the other one right yeah yeah oh I mean I I would actually say both um both like lane lane chain takes people to Lang Smith but then Lange Smith also makes L chain a better experience so there absolutely is like a flywheel there um and that was intentional as well we didn't want to do something like completely separate um we wanted to do something where there was a strong flywheel um but it is still different skill sets and different product right and if it were only the open source part uh do you have like um like a monetization side of it or is it like completely I mean I really don't know how how to monetize open source so just enlighten me here yeah I mean I think a lot of traditional open source is kind of you know we spent a lot of time looking at kind of like comparables so so like a lot of Open Source databases for example monetize a hosted version of that database um but link chain is not a database and so it would be unclear what that would be but if we were to do that that would probably look like a hosted Lang chain experience maybe like a low codee no code version or something like that um and we didn't want to do that because well we we haven't done that yet because we think it's still really early on really fast moving and that wasn't like the blocker for people we saw the blocker being the problems that Lang Smith solves um so that's why we didn't do it but if you're saying like Okay you can't build Lang Smith then like yeah we probably would invest more in like a hosted experience of sorts um I think another like reasonable analogy is kind of like nextjs and versel um and you know we're starting to build some of that with like langing serve and hosted langing serve so like really easy way to deploy Lang chain applications uh but again we we we see the Lang Smith being a bit more blocker for folks and at this point we just want to create as much value for people um as opposed to try to capture awesome great um all right I wanted to talk to you a little bit about what you see in the future of the industry and in AI in general how would you see the this future of large language model applications um do you think that it will look a little bit similar to how it's being done today with the rag applications or do you do you see something completely new coming on yeah it's a really good question and any any predictions I make are probably going to be wrong um I think like I think we'll see more and more multimodal applications I think we'll see more and more um like complex applications um so like multistep the language models deciding what to do and then taking that action um and and more and more steps um and and I think we'll see that for a variet of the reasons the models will get better people will figure out how to work with them they'll get cheaper and faster um and yeah so so so I think uh the and then multimodal I think we just see so much excitement about that the models aren't currently there um but when they get there I I do think that'll be big um and so those are two pretty kind of like easy bets um one thing that I'm really interested in is the role of kind of like long-term memory in all these applications like like what does that look like and I think I think I think that will be needed for a lot of applications to get uh like personalized experiences for users and so so what exactly does that look like you know open AI added it into chat GPT and they added it a specific way right um uh we have some memory modules in Lane chain that think about it in a slightly different way um how how is it different though yeah so so open AI um they basically use uh they let the llm decide when it wants to remember things um and then a bunch of memory modules in linkchain kind of like do the remembering automatically and I think there are pros and cons to both um but it's it's like it's kind of like you know active memory versus kind of like background memory um and uh yeah they're are pros and cons to each um very interested by memory I think I think I don't think it's like the thing holding applications back now I think people are still trying to figure out how to get simpler applications to work but if we're talking long-term I think that'll be a big part of it memory Yeah Yeah you mentioned as well multimodel um multimodel models uh can you can you develop a little bit on what that means and how that would be uh like important for the industry yeah so multimodal working with different modalities so like speech text image so like right now uh gp4 um has a vision variant where you can pass in images and then get back a response and so I think this is important because there's all you can like you know previously if I wanted to uh try to build an application that would look at an image and decide what to do I would have to like convert like if it's just text I have to like convert it into some description of it's kind of janky right and so now you like pass in an image and you can be like okay based on this like what action should that's how like we're mostly interested in it in terms of like input is image video audio but then it returns like what an action to take because you know Lang change just interested in like the action taking aspect of it right or that that's a lot of what we're interested in um and yeah so I think be able to pass in an image and ask for the next button to press if you're looking at like a computer screen or something like that or pass in a video and ask for a summary of it or something like that is is really powerful do you see a future where you have like for different language models interacting with each other from different applications like for example today most of the Integrations that we have within different applications I mean all of them are made through apis like one application exposes one part of its logic to the other application and then they connect each other do you see a world where these kind of connections happen with natural with with human language even within applications or does that seem like not realistic in the industry no I I think that's pretty realistic yeah I can totally see that I think I think the main reason that's realistic is it's very valuable to create agents or applications that are more narrowly scoped um right so you you might have uh I mean even back to the customer support bot case that we were talking about earlier where you have one person that's responsible for talking about their their previous orders another for the inventory those can be two separate you know llms chatting with each other yeah that's what I was thinking when you were saying that I was like like what if the person is an llm as well yeah exactly so from that point of view 100% I think that that'll that so you would have something like one person asking their language model assistant hey do this for me and the language model assistant will communicate with the language model assistant from another person exactly yeah I mean I don't know if that's coming soon but that would definitely be very crazy for the for the world um about um AI what what do you see in the open source sphere of language models because I mean we have seen some amazing language models in the open source scene um do you think that I mean how's your what's your position about that and has it changed uh recently with the newer models um I think my position is that they're still not used as much and they're still not as good as the closed Source models um but I think a lot of people are really interested in them I think the interest yeah I mean the you know I I think the interest for a few reasons one they can run locally and so your data doesn't leave the premises two they're often um if if you host them right and there's a few good providers like together Ai and fireworks they can be like really fast especially because they're smaller um right so so I think there's a few different considerations which is like okay like are the open source models like how good are they um like are they going to would I like would I rather use just purely based on how good they are like and open source model or or gbd4 or something like that and right now like if I just want it for how good it is I'm going to be using gbd4 and because it's early in the industry um we see that people are just using gbd4 because they're still trying to figure out what to build and if you can't build it with the best model you're not going to be able to build it with a weaker model but I do think it's possible that it'll start to change as these things go to production and then you carry about cost and latency and all of that and so that maybe more appealing to look towards the smaller model um and you know there's a lot of good capable smaller models out there that you could fine-tune if if if you wanted to if you have this really high production um and so I think that's really interesting to think about and and that's an area we're very interested in exploring well I wanted to ask you a little bit as well about I mean real quick about the security side side of it because I mean what Lang chain is doing I mean at some degree is fac facilitating the creation of autonomous agents and just that word autonomous agent uh might freak out a lot of people um do what what is your your position or your thoughts about this security issues with programs that can reason and act in the real world yeah it it's a good question uh I I have a few thoughts I mean one like I don't think the current systems are that good right now like I think they're still very narrow focused right and so you know they can and they can be very good at there was narrow focused but I don't think it's like it don't think it's it there like I don't think there at a position where they're gonna run off and cause a lot of harm um I do think though that you absolutely need to be careful when you hook up various things to a language model mod and so there are a lot of things in linkchain like we have a we have a python reppel where you can run python code but if you're running L generated python code that could be unsafe and so we have a lot of warnings like hey this is experimental you probably like want to be careful about this um and so yeah I'd say those are my two main thoughts like yes you I think I think we're we're mostly like encouraging people to be really thoughtful about the types of thing like I think I I I think there's like two separate things when you talk about safety there's like okay the models are getting better and better and so like will they allow people to you know will will will will anyone be able to like learn how to like build a bomb or something right like that would be terrible right and so I think there's a lot of like safety work going into like that um and and that's a little separate from linkchain and so I view that as separate then there's like okay like are people putting these things as a reasoning the engine and creating these systems that could be dangerous and I think that really boils down to like are people giving it like um like what types of tools are people giving it access to then and and they letting it operate and so yeah we you know I I think we try to put a lot of warning around dangerous Tools in L chain and and try to bring attention on that note would you support a more strict regulations of this kind of um uh companies that deal with language models given that probably in the future most companies will be Dev I mean most software companies will be developing their own llm applications at this point no I'm generally not really in favor of Regulation um I Al to be honest I also don't spend a ton of time thinking about it um I For Better or Worse that's right yeah because I mean the what one of the things that shocked me uh the most about Sam Sam Alman when he was in his interview with I think it was with Lex fredman that he I mean he has always been openly open about his position that regulation is required and that's why he's doing this and he wants to be regulated and things like that so that's that's kind of that was kind of a new thing for me especially in in in the software industry and Industry in general right but yeah so I think they're not many people uh leading companies uh thinking like that I suppose yeah I I think uh you know he also probably has a much more nuanced and and detailed view on this than than I do and so I'm I'm I'm I don't think I'm incredibly qualified to speak on let's just take care of our applications and try to be responsible with how we use them right all right um do you have um I mean we're coming to the end of the of the conversation do you have like some other new projects that you would like to share or some other new advances in AI that you're excited about that you see coming in the future something I don't know yeah I mean I mean very short term um a few few of the things that we're working on um one on the open source we're putting a lot of effort into like query analysis like I think the query analysis bit can be really helpful when improving rag applications I think it takes advantage of a lot of things that Lang chain is good at like structured outputs and things like that um and so we'll be putting out a lot of content around retrieval but specifically around query analysis um and then on L Smith we we're doing a big push on kind of like online evaluation and like automatic kind of like f shot example data set curation and stuff like that um and uh so that should we should hopefully have some stuff to share there in a month or so um but but those are kind of like the two very short-term things that we're thinking about right that's about Lang chain in particular and in the world in general do you have like some like some new developments that you are like yeah I hope this comes soon uh we'll hopefully be able to use it in Lang chain or something like that yeah I mean all the model advancements are super exciting like Gemini 1.5 with their million context window length is really exciting Straw's new model that they just released um you know I'm sure others will putting out new models as well and so I think uh I think yeah just very excited for better models which seems to be happening yeah about that actually I forgot to ask you about that um about the huge context windows that these models are starting to have do you think that that's going to uh make obsoletes some of the rag applications or how do you see that happening some of them probably yeah yeah um I think it will become less and less important how you chunk things and split things up for example um I think the parts of rag we we spent a lot of time thinking about rag I think there's three main components of rag that I don't think are going anywhere in some form um so one's indexing so this is just like taking documents and putting them into some sort of data structure some sort of index um and I think long condex will probably change what those data structures are right you may not need like as many small chunks you may not need to be as clever about it but you still need to fetch doents from somewhere whether it be like elastic search traditional elastic search or something like that so I think there's an indexing step then there's a query analysis stuff so like figuring out what documents to fetch still think that's going to be needed um I think like when you deal with large col well so so there is a difference between if you're doing rag over like a single document or rag over a large collection of documents and so rag over a single document like yeah most of the stuff will go away rag over lots of documents all this stuff will stay around and so the quer and the stuff I think is is really important there and then there's a reranking step and I think that'll be important but yeah rag over single document you're just going to pass the document into the C response yeah yeah I can see that happening too all right okay well uh I don't know if you have any extra comments that you would like to make some extra message that you would like to pass to the community or some or something you would like to say check out all Andre's YouTube he does awesome stuff uh and yeah more people should be like all hund and building awesome things and teaching people how to thank you man I appreciate it um yeah well thank you thank you very much Harrison for for being here for coming to talk with me and it's been an amazing time having this conversation with you I've really enjoyed it thanks for having me great thank you see [Music] you [Music]
YqqRkuizNN4,2024-03-18T21:03:02.000000,Chat with MySQL Database using GPT-4 and Mistral AI | Python GUI App,good morning everyone how's it going today welcome back to the channel and welcome to this new video tutorial in which I'm going to be showing you how to build the application that you see right in front of you okay it is a chat but that allows you to chat with a SQL database in natural language which means that it is going to first uh generate a SQL query by itself given your query and then it's going to read the results from that query and it's going to give read the result interpret the results to you and give you an answer in natural language okay so just to show you how this works I'm going to connect here to this database that I have in my local host which is called shinuk I'm going to connect and this is a database that has some um artists and albums and tracks and it's supposed to be the database from a music store so I'm going to ask a question something like which artist has the most tracks and now as you will and as I will show you later in the video this is generating the SQL query and reading the results so here you can see that the artist with the most tracks in the database is Iron Maiden with a total of 213 tracks and as you can see it also has conversational memory so I can ask a follow-up question something like which one is second and it's supposed to be able to know that I'm referring to the artist that has the second most tracks so the artist with the second highest number of tracks is the in the database is You2 with a total of 135 tracks seems to be working correctly so let's get to actually building it and something that I wanted to tell you as well is that thank you very much for waiting for me last week I was not able to publish a video because I was very busy actually getting my diploma so now that that is done we can go back to focusing on making super cool tutorials for you to build super cool project s to Showcase to your clients uh future employers and your friends okay so without any further Ado let's get right into [Music] [Music] it okay so let's actually start off with this super quick tutorial I'm going to try to make it as short and concise as possible but also making it as clear as possible so that you don't have any problems here um as you can see I have created my root repository sorry my root directory called Chad my SQL GUI I have my source directory with my app.py file which is where my application is going to live I have mydmv file with all these secrets right here that of course I am going to be deleting before I upload a video but as you can see I have my open AI API key because we're going to be using gp4 for this um this chat putut and I also have my Gro API key because we're also going to be using mistol I'm going to show you how to use Gro in this video to interact as well with the my SQL database and this other two you can ignore them this is just to use lsmith which is good for logging I'm probably going to show you a little bit about how that works in the end of the video if it's not too long okay so yeah about the the development environment also we have our virtual environment with a with a cond environment in case you want to create your own using cond which is what I recommend you can create it using cond create-- name and then you name your environment and then you give a python version that you want to use in this case I am using python 3.10 okay once you have done that all of the dependencies that you install using pip are going to be contained within this environment and it's just going to make it super easy to manage your dependencies okay so there you go now first of all we are going to have to install the dependencies that we're going to be needing in my case I'm going to be pip installing streamlit because we're going to be building the front end of the application using streamlit I am going to be using Lang chain for this as well I am going to be using Lang chain open AI because remember that open AI now now has its own package for the Lang chain integration I am also going to be using Lang chain Gro Gro because also Gro also has its own package for its integration um since we're going to be using a MySQL um database we're going to need a my SQL driver for for SQL Alchemy which is the package that we're going to that I mean that Lang chain uses behind the scenes so we're going to use my my SQL connector for python like this and finally we are going to use python. tnv to be able to actually connect and to use ourv file okay so I'm going to run this of course that was super fast because I already have it installed but to you it might take a little bit of time um once you have all of it installed we can actually jump into app.py and start coding our application great so the first thing that you're going to want to do is load the tnv file okay so we're going to first of all we're going to do load dot. EnV which is the function that is going to allow us to use all of ourv Secrets okay and and in order to actually be able to use it you first have to import it so you have to do from. tnv import load. tnv there you go and second of all we're actually going to just start using uh uh creating our stream lad page so first of all we're going to do from uh sorry now import going to do import stream lit s St and then we're going to just first set up the configuration for the Page by doing set I think it was set page config and here you can just specify the title of the page we're going to call it chat with my SQL and the layout we're going to set it to just leave it as is uh let's add a it's not supposed to be title it's supposed to be page title and here we're going to call this page icon let's call it a speech balloon and let layout we're going to leave it as is there you go um now remember that in order to run your streamlit application you're going to want to do streamlet run sort and then the path to your file and let's see how this is working we have our application let's actually just add a quick title chat with my SQL let's see how that works chat with my SQL there we go so now that the layout is a little bit set up let's actually just add our side bar with the where we're going to set up the information for the database okay so in this case we're going to want to in order to create a sidebar we're going to do with st. sidebar we're going to add a subheader for settings and this is simple chat application using my SQL and connect to the database and start chatting so first of all we're going to do an st. text input and this is going to be the host first of all the default value we're going to set it to Local Host just so that I don't have to retype the name of the of the host post by hand every single time I want to test it let's also add the port uh we're going to going to we're also going to set a default value of 3306 which is the default value for most of my SQL databases we're also going to add a user um default set it as root then we're going to add an input for password and in my case I'm going to add also uh default value of admin because that's what I set my password to to be for my local instance of my SQL yes I know I am very good at um at security um and last but not least we're going to add the name of our database right so database and the value is going to be shinuk there you go all right so so and then of course let's just add a button sd. button connect so let's see how that looks now there you go so we have our settings we have our host Port user password and this of course you can update it I mean you can change the port to be whatever you want but I just set a default one because this is the values for the ones that I have here in my terminal let me just show you if I do if I do Brew Services I think it's list I think yeah I have my SQL that started and as you can see I have my SQL rude and as I told you before my password is admin so show databases I have shinuk right here and if I want to use shinuk I can see that I have 11 tables right here and yeah I mean it's supposed to represent a media store which is a which sells albums and each album has a has an artist and each art I mean each album is comprised of tracks we also have invoices employees and customers that have bought albums Etc okay so that's how that's what we're going to be dealing with so now what we're going to be doing is let's just add our chat interface as well okay so actually right now what I'm going to do is I'm just going to add the St chat chat input right here chat input type a message let's see how that looks there you go type a message and actually before creating the whole message interaction and stuff like that let's actually connect to the database that we're going to be connecting to so in this case as I told you before I'm going to be using my local host and these are the this is the credentials that I'm going to be using to connect to the database but the thing right here is that I want to do that whenever I click on this button connect right so whenever I click here I want my computer my application to be connected to the database you in order to do that I am going to create a new function right here that is going to be called um let's call it initialize init database like that and we already run load. tnv so what we're going to do is we're going to remember that we're going to be using a SQL Alchemy wrapper from Lang chain and this one actually comes in their package from Lang Ching Community because remember that the Integrations from Lang chain come in the package Lang chain community so from blanching community. utilities I'm going to import SQL data base I don't know what I don't have auto complete here um let's hope this works and um so we're initializing the database right here and and this one right here takes a URI of the database so I'm just going to initialize my URI and I'm going to say that this one is going to be a F string my SQL we're going to have the user the password at the host going to have the port and the name of the database and well of course here we're going to need also this all of this all right we're going to need all of this there you go all right sounds good and then we're going to return our SQL database in order to initialize it we're going to call from URI and we're going to pass in our database URI that we initialized right here okay so there we have it here is our function that's supposed to initialize with the connection to our database and let's add actually initialize it when we click on the button connect okay so let's say if the button is clicked what we're going to do is we're going to say let's just add a spinner right here with st. spinner remember that a spinner in langin allows you in Lang in streamlet allows you to connect I mean to show the user uh real time that you're working that the application is thinking on something it's just like this little Roundy thing that shows like just user user experience wise it's pretty convenient so with the spinner we're going to say that we're going to show the message connecting to the database and then after that we're going to initialize our database by passing the user password host port and then the database and then let's just set the database to the database and then just show a success um message right here however here we're using session State variables and we did not include them right here so let's just add a key right here to each one of these so that they are stored in our session state so hopefully this is going to work let's see how that goes if I reload this thing and remember that my my SQL database is running so if I click on connect I am supposed to be able to connect however no module named my SQL database all right here's a here we we made a mistake right here I mean I made a mistake uh in order to use a my SQL database you actually need to use uh the driver that I was telling you about before so in order to do this you're going to need to add here the driver and since we're using a my SQL database I'm going to use my SQL connector like that just going to save this let's see if this runs now so if I click connect can't load plug-in dialects my SQL connector we have a problem here let's see what's going on um um Runner script from URI host [Music] password oh I missed here my SQL not my there you go so maybe this is going to work now if I click on connect streamlet API exception session State database cannot be modified after which it with key databases initiated what's going on here oh yeah we update we we set it to the same name this is not supposed to be this let's just call it let's just call it DB like this DB like that now it's supposed to work there we go we're connected to the database and now everything seems to be working correctly there you go so now that we're connected to the database we can actually start quering it and creating our two chains the SQL chain and the get response chain and let me just show you actually a diagram with what's actually going to be happening behind the scenes here great so if you watch the previous video of how to do the mySQL database chain you probably already know what I'm talking about but in case you haven't watched that video let me just tour you again through what's actually going to be happening behind the scenes in this program so the idea right here as I told you before is we're going to have a user question in natural language I mean in English and then by the end we're going to get a natural language answer from this chain okay just to be clear this is not an agent not yet we're going to be working only with chains for now and the idea here is that the user question is going to enter a SQL chain which is the first chain that we're going to be building this chain is going to take the database schema which is pretty much just a list of all the table names and all the table uh column names and the types data types for each column and we're going to pass into the language model and we're going to be asking the question something like so given this schema and this user question what is a usel what is a SQL query that is going to answer that question and then it's going to return a SQL query then we're going to run that query towards the database and then we're going to take everything to a to the language model again and be like all right so we have this user question we have this database schema we have this user query uh SQL query and we have this response I mean this uh response from this SQL query uh now give us a give me a natural language answer to the user question and that's when when the full chain is going to be returning a natural language answer or something like uh so if we ask something like which artist has the most tracks this one is uh this one is going to get select blah blah blah limit one then we're going to run it then it's going to get the response and then this one's going to be like all right so the artist that has the most tracks is I don't remember I think it was Iron Maiden so there you go and that's what's actually going to be happening behind the scenes okay um I mean of course here is pretty much everything explained more in detail about how this is actually working also if you want to uh check more like The Notebook on what we're doing here I recommend that you watch this other video I'll put a link somewhere up here uh which is the video that actually shows a little bit more in detail what's going on behind the scenes in a Jupiter notebooks okay so now let's actually start building this first chain right here this SQL chain let's do that okay so actually before creating all of this um before creating the SQL chain uh let's just create the chat chat interactivity part I mean the interactive chat part um in order to actually be able to pass in the chat history to our SQL chain okay so in order to do that the first thing that I am going to do is I'm going to initialize a persistent variable that is going to be in the session state for the chat history okay now in order to do that we're going to do if chat history if chat history is not in the session stage we're just going to initialize it here as you can see they are I mean we could initialize it with an empty array like that however I am going to initialize it with an AI message now actually I did this off camera so let's do this again um remember that in Lang chain you can use schemas for the messages that is is going to allow you to do to organize your conversations a little bit more uh neatly and the idea is that you have different classes for the AI message for human message and for system message as well in this case I'm just going to be using the AI and human message so in order to do that we're going to do from L chain core and we're going to tap into the messages module we're going to import AI message like that and and we're also going to import human message like that and here we're going to initialize this message with an AI message and let's just say something like hello I am a SQL assistant um ask me anything about your database okay and oops and this one right here is supposed to be the entire the entire chat history actually I'm not sure if this does this by default um but actually this is supposed to be the content of the message okay so there you go now what we're going to do is actually create I mean display display this messages in the on top of the chat input right so what we want to do is we're going to we're going to want to display the messages up here so in order to do that we're going to first of all up here on top of chat input we're going to do for message in session State chat history If the message is an instance of AI message I'm going to do with st. chat message and it's going to be an AI message I'm going to St write the message content this St and actually I'm not going to use write I'm going to use markdown because remember that sometimes we're going to be displaying lists we want to be able to to use mark down inside of the message right and that is if this is an AI message if not and if it's a human message we're going to do pretty much the same thing but with the human Okay so let's just save this and let's see how this looks so here we have hello I am an I'm a SQL assistant ask me anything about your database so there you go now actually let's add the interactivity here so when a user asks a question we're going to add it to our history so to do um let's just store whatever the user um writes in the chat input into its own variable we're going to do something like we're going to store this in the user query variable like this and so here we have the chat input so if the user query is not is not none and it is not [Music] empty we're going to first of all we're going to take the user query and we're going to add it to the history of the conversation right so we're going to take the st. chat history and we're going to append the human message with the content of the user query that's the first thing we're going to do secondly we're going to show that message in the conversation so we're going to do St chat message and this one is going to be the human message message and remember that in order to use this you have to do with st markdown and we're just going to show the user message right here okay so let's see how this works so far if I do this I reload I say hello there you have my message now let's pretend that we're getting the response okay we're not getting the response yet but let's just pretend that we are we're going to do that with St ch chat message and this is going to be the AI the response is going to be so far here we're going to add the function get response but so far we're just going to return I don't know every single time I don't know I don't know how to respond to that let's go and let's just st. markdown response like that okay and then what we're going to do is after showing the message we're just going to append it to the chat history like that so now chat history we also have the AI message there we go so now let's see how this is going hello I don't know how are you there there we go so now we have a chat message and we have our message history right here and we're going to be able to use it inside of our SQL chain okay this is a step up from the previous time we did we dealt with SQL databases because I mean with with with the pre from the previous video which is this one because in the previous video we were actually not taking into account the history of the conversation in the SQL chain in this video we are and and so we're going to be seeing how it actually works so now let's actually build that SQL uh chain let's do that now okay so in order to create first this SQL chain I am going to create a new function up here called get SQL chain okay so this one is going to be called get SQL SQL chain like this that and this one is actually going to take the database object that we're going to be returning from this one so I'm just going to call it DB for now and right here actually we have a few things that we want to we're going to want to do the first thing that we're going to want to do is create a template for our prompt okay because remember that we are going to be sending a prompt to our language model and the prompt is going to include something like so given this database schema and given this user question um and given this user conversation history give me a SQL query that is going to respond to the user question and actually that's quite a complex uh template a complex prompt so I I prepared it here for you let me tell let just tell me what you think about it so I'm going to create a template and here's my prompt uh I mean it's let let let me just tell me what you think about it uh here you have you are a data analyst at a company you are interacted with a user who is asking you questions about the company's database based on the table schema below and we're going to pass in the schema write a SQL query that would answer the user's question take the conversation history into account okay and here we're going to pass in the schema here we're going to pass in the conversation history and then actually I was having trouble when doing some tests for this application because in the language model would respond something like certainly here is your SQL query and actually we want we want to have only the SQL query we don't have to have any certainly or yes of course or any comment beside it we only want the SQL query so I sent it a few examples um uh we I sent it uh two short examples here so we have um here here I I mean just to show it what I expect from it to respond okay this is called fuse fuse shot learning so here we have the question which three artists have the most tracks and then here we have the SQL query of some like giving me the actual query for this but here as you can see I am showing it what I want I want only the SQL query here I have another example and here I also have the response with only the SQL query okay and now I tell it your turn here's the question and then I just give it the the prompt right here so that it only completes the usql query okay some language models did better than others in this case but I mean these few short examples are very much to to make the language model work on this part of the this part of the debugging of the application okay so this this template does the job for me let me know if you have a better idea of how to create this prompt and let's actually just create it so in order to do this we're going to do prompt we're going to initialize it from chat prompt template okay so from from Lang chain core prompts we're going to import chat prom template and here we're going to do The Prompt is going to be equal to chat promp template and here in order to initialize it we'll have to say that we're going to initialize it from a template and here just pass this template right here and there you go let's just initialize our language model now the first thing that I'm going to show you is I'm going to be using open Ai and I am going to be using gp4 so the gp4 model as at the time of writing the latest one is this one and then we are going to need a tool oh this is supposed to be chat open Ai and we actually have not imported it so let's say from L chain open AI we're going to import shat open AI like that I'm not sure if I have actually installed shatow open AI uh let's see in case you haven't remember that what you have to do if you're going to I mean first be sure that you're using your your environment so I'm going to activate chat with my SQL and I'm going to see is that actually the environment that I'm using here chat with my SQL yeah and I am going to be using I'm going to be installing lank chain open AI yeah it was already installed I don't know why this is not autocomplete so there you go so from lch we're going to import chat open AI so chat open AI seems to be a problem with the indentation here so now we have our language model we have our prompt now we need the tool that we're going to be using the tool is going to be get schema because this is the function that we're going to be executing in order to get the schema from the from the database this remember D DB is the database W the database return from this function right here which is a wrapper around SQL Alchemy and this is this actually allows us to get the to this is not the function it's not get the schema it's get table info get table get table info and this one actually will return the schema of the of the database okay so there we go this is the tool that we're going to be using the language model The Prompt and now we can actually just return our our chain so let's return the chain remember that in order to return the chain the first thing that you got to do is we're going to pass in a runnable and actually to uh import the runnable I'm going to have to import it from Lang chain core from Lang chain core do runnables we're going to import a runnable pass through that's going to allow us to pass in this function right here as a runnable runable pass through and this one is going to be the AL sorry actually here we going to have to assign one of the variables in my in my prompt okay so in this case we want to assign schema and we want this one to be the result from this function right here so there you go now the second part of this is going to be the prompt the third part is going to be my language model and then let's just add an output parser from L chain core. output parsers I'm going to import a string output poer this is because we want to make sure that whatever this chain returns is only going to be a string okay I mean of course you can just tap into the property returned by the chain that is the string which is probably going to be the content property but let's just leave the let's just let the live leave that to the output parsers they just make the world the work a little bit easier and here we're going to initialize the string output parser okay so this seems to be working here we have the chat history the question so I mean just to be clear this chain is going to take as input it's going to take the question it's going to take the chat history and not the schema because we already have the schema right here that is that is um executed from the get schema function okay I mean that is returned from the get schema function so there we go now how about we actually test this function all right uh sorry this uh chain so in order to do that I am going to say that the response is going to [Music] be first of all I'm just going to create the chain right here um SQL chain get SQL chain I'm going to pass into database like that then the response I'm going to say that it's the SQL chain and I'm going to invoke it and here remember that it take it it takes an uh a dictionary with all of the variables that you want to populate from The Prompt so in this case the first one that I want to populate is chat history with my session State chat history and the other one is the question which is the user query and there we go so let's actually I mean I'm not sure this is actually going to work so let's see how this is see how this works so first of all we're going to have to connect to our database in order to actually initialize this database object and now we can ask a question something like how many artists are there and let's see what it returns it's probably not going to get it right oh there you go so select count from artist so there you go this apparently seems to be working uh the chain is actually returning our SQL query perfect so now what we want to do is put this chain inside of another chain that will return I mean that will execute this chain in the database will read the uh that will exit this query in the database sorry we'll read the results from the database and then we'll um uh report to us in natural language what the results are okay so let's do that right now okay so I mean just to be clear what we're going to be doing right now is we have this SQL chain that we just be that we just finished building and now we're just going to put it inside of a bigger chain that is going to take whatever this chain returns which is the SQL query run it towards the database and feed it back to the language model so that the language model can return a natural language answer okay so in order to do that what I'm going to do is I'm going to create a new function that is going to be called get response okay so I'm going to do this function called get response and this function is going to take a few parameters it's going to take first of all it is going to take a user query then it's going to take the database and it is going to take also the chat history okay now this is of course not complete we want the SQL chain to be to be initialized right here but we also want to create a new chain that is going to use that chain inside of it so the first thing to do is to create a template uh just like we did before up here uh we're going to create a similar template but this time it's going to return the actual the actual natural language response that we're supposed to get at the end so you're we're going to be saying you're a data analyst at a company you're interacting with a user who's asking you questions about the company's database and here we actually are supposed to already have all of this information to send back to the language model so we have based on the table schema below the question the SQL query which is this one the SQL response which is the response that the database returned from running the SQL query on it write a natural language response to to this question okay so let's just put this here user question so that it knows that this is the actual user question um so there we go now now what we're going to do is we're going to to initialize the prompt from this template so the prompt is going to equal chat prompt template we're going to initialize it from a template like that then I'm going to initialize my language model again um just going to continue it open AI but I'm going to show you in a moment because a lot of you have been asking how to do this with free with with free models I'm going to show you how to do this with frock um and mistol which is completely free at least for now and um and once that we have this actually you can pretty much just start doing the chain as far as I remember so we can do chain equal and the first thing that we're going to do is we're going to run a pass in a runnable which is going to be our SQL chain and we're going to first assign the doesn't it's not supposed to take the schema it is supposed to take the query you know to populate this variable right here and the query is actually going to be returned from our SQL chain okay now this itself is going to return another runnable that we can also use to assign other variables and here is where things can get a little tricky runnables are H not probably not the best I mean the most beautiful design here um maybe they will change at they will change at some future version of L chain at least I don't find them super easy to use but um just stick with me and follow along with this code I am going to explain a little bit later in the video in more detail what's actually going on behind the scenes here so I just want to show you that it works and then I'm going to show you an intermediate step to make it easier to understand okay so don't um don't give up if you don't understand this in the next three M three minutes I'm going to explain this again um before the end of the video so stick to the end um all right so here what we're going to do is we're going to assign other variables the first one is going to be the schema the schema and for the schema what we're going to do is instead of actually recreating this function right here I'm just going to do what GitHub what GitHub co-pilot is suggesting I'm going to use the Lambda function that just takes the database and just Returns the DB uh get T table info just like we did with this wrapper right here and the second thing that we're going to want to populate is the response because here we have the response uh here we have the response and we want to populate it so the response is going to equal Lambda here I'm going to call it vars and I am going to run I think it's is run like that yeah I'm going to run from the variables returned I'm going to return the query okay so there you go this is supposed to work if I'm not mistaken once we have the runnable finished we can which was the harder the harder part we can do just passing the prompt the language model and just like we did before the string output parser and then just close the chain and then return whatever chain return whatever the chain um uh returns okay so in this case we're going to return remember that in order to invoke a chain we're going to want to pass in the variables that we want to populate from The Prompt and in this case as you might have as you might remember from this runnables we have already populated the query we have already populated the response and we have already populated the schema so all that we need is is the question and the chat history so let's do that so the question is going to be the user query that we passed right here and the chat history oops and the chat history is going to be the chat history variable that we also passed in as a parameter okay so there you go um then we save this and of course there are much more efficient ways to do this here for example we are uh querying the database to get the schema every single time the user asks a question that's absolutely a terrible design just trying to show you how this works real quick uh this is of course not supposed to be production ready um so here what we're going to want to do is instead of calling the SQL chain directly bom we're just going to get the response from get response and remember that this takes the user query the database and the chat history and then we're just going to showcase the response like that now if I'm not mistaken this is supposed to be working um so how about we just test it right here let's see let's go back here and say first of all remember that we have to connect in order to actually have our DB object uh initialized and here we're going to do something like um how many artists are there so now it's thinking I haven't haded streaming yet so based on the information from the database there are 275 artists in total and I mean if you want to see what's actually going on we can see the lsmith um the lsmith trace back right here and as you can see the first here we have it the for the first runnable which is the first chain that we run we were we asked it how many ARS are there and here is the history and the output was correctly our select count from artist which is the name of the table let's see what the prompt was so the prompt returned you are data analyst at a company you're interacting with the user who's asking you questions here we have the schema of the entire database then at the end just like we saw we have the conversation history which has been correctly populated with AI message hello I am an SQL assistant and then our message which is how many artists are there then we have the SQL query for not uh right only the SQL query and nothing else blah blah blah and then we have our prompt our question and the response was of course select count from artist and then same thing happened up here in the second chain in which we sent as input our question and the query remember which is what we did right somewhere right here the query and the question which was which was here the query and the question and there we go seems to be correctly the output was correct the schema and here we have the chat PR template you are data analyst at a company based on the table schema question SQL query and response write a natural language response here we have the schema which goes all the way to the bottom which is pretty long which really should be storing that in a variable or something instead of querying it every single time um we have the conversation history we have the SQL query which was select count from artist we have the user question which is how many artists are there and we have the response and then of course we have the response from the language model which was based on the information from the database there are 275 artists in total um I mean just to let you know what is going on here this is is uh lsmith which allows you just to see uh every single step of your chains and what is actually happening behind the scenes uh it's pretty useful it's like super cool um and uh I think it's free for now uh if you want to use it for your personal projects um but yeah I mean totally recommend and um so there you go that's that's how to do that let me just explain to you what actually happened right here um and also maybe we can oh and add Mist all right let's do that now okay so let me show you what's actually going behind the scenes in this part right here so now that you saw that it actually works um this part right here was a little sketchy um and I mean I understand why it's weird because I mean runnables um this interface for the runnables is probably not the most user friendly so let me show you what's actually going on behind the scenes we have this runnable right here where we passed in the SQL chain in order to get the query okay so that's the first runnable and that runnable is going to return some variables as an output and those variables uh we can use them in in in this other method okay so here we have the vars which is where these output is stored and actually to show you what's going on behind the scenes I'm just going to comment out the place where we run the query towards the database and I'm going to show you what's happening here so what we're going to do is here I'm going to comment this out and instead of using it I am going to print it so let's let's say the variables and let's just let's just pass in the vars that we got from here okay now this is of course going to break the application um because we're not going to be running the query towards the the database but this will probably this will hopefully show you what's actually going on um behind the scenes here so now that this is saved I'm going to go back here remember to connect before running and now let's do well how many artists are there now of course this going to say that there was an error um let's see what happens here um it's trying to retrieve the data but I mean we're not we never generated the database we never generated it so it looks like there was an issue rriv the data yes of course and now what we can do is we can see here that we have the variables um here here is the variables that I locked with the print method and here we have the question how many artist are there the chat history and here we have the query that was generated from my the query that was generated from my previous pass through so this is the one that we want to use to run on the database okay so that's why I did DB DB run vars query because I want to tap into this this variable right here that was returned from the runnable so that's that's why this is um that's why we did it like this now if we save it it works again how many artists are there uh yeah have to connect first how many artists are there and now it Returns the actual answer uh what I'm going to do now is I'm going to show you how to stream that because I mean we did that in the previous video so why not implement it here as well and let's also use Grog from mistol so let's let's do those two bonus things now great all right so now let me show you how to do pretty much the same thing but instead of using the paid model of open AI we we can use um we can use Mixr which is free and we're going to be using uh Gro in rock in order to to use Mixr okay so in case you're not familiar with rock it is a very I mean it's a new A New Concept I mean they they provide an interface that allows you to run some language models in a much much faster way they just have a different way to to process the the completions uh which they call lpu I'm not going to go into details about how this works but just know that it supposed to be I mean it is much faster than calling the API directly of any of these models um so yeah I mean if you haven't heard of rock just take a look at it and it's pretty good it does have a bit of a latency problem at the beginning but uh it's super fast so what we're going to be doing in order to use frog with mixol what we're going to do is I'm going to go back here and remember that at the beginning we installed this package called lunching Rock and that is very that is that's going to install everything that you need to to use Rock here so what we're going to do is we're going to do from L chain from L chain grck we're going to import chat GR like that and then we're just going to replace the language model every time we initialize it right here so here instead of calling the Lang instead of calling the language model from open AI we're going to call it from Rock and then just rock you you're going to want to pass in the name of the model that you want to use so in my case I want to use mix strol this one right here so I'm just going to populate the parameter right here saying that the the model that I want is mixt dral and I'm just going to set the temperature to zero as well just to be sure that it's not getting too creative with the SQL queries so that's for this one and here is the SQL chain so we're going to do the same thing with the get response chain right here let's comment out open AI add in Rock and just save this and let's see how this is behaving um I mean in in your case you probably want to test a few models see which one is actually doing better with the SQL queries that you're using and with SQL queries in general um it doesn't matter I mean it's it's difficult to to know in advance which language model is going to behave best in a particular uh in a in a given task so I encourage you to test uh several of these of course if this was going to go to production I would probably find tuna model to do well with my SQL chain with my SQL uh query generation because here we're using a general model and which is probably an Overkill and it's probably not as sufficient as fine tuning model for my SQL queries but let's see how how mix does let's ask a question of something like which artists have which artists yeah which artists have the most albums let's say which three artists have the most albums um It's thinking the three artists with the most albums are the ones with I is 90 22 and 58 so apparently it it looked for the artists by ID so let's see uh so this is what the prompt was what was returned as a query so select artist IDs yeah so it's it's selecting for artist ID which I mean it's okay but it's probably not what we want we want the actual names of the artists um well at least it identify that these are the IDS and not the names of the artists so let's just ask it a follow-up question right let's do something like which artists artist names correspond to those IDs let's see if it gets it right mixol come on do don't all right so the artist with ID is 1922 and 58 let zein purple and item Maiden respectively okay so seems to be working correctly great all right so let's see the prompt here let's see the prompt right here um the output the r2r blah blah and did the select name from artist Vari is yeah so I mean it actually did it correctly great uh very surprised um because this is not an agent this is just a chain and this is a quite sophisticated quite a sophisticated uh application of a chain in real life you would probably use an agent instead of a chain for this kind of uh applications but wow works pretty good so yeah I mean I'll I'll add a link to this article in the description in case you want to go deeper into how this works uh behind the scenes and yeah congratulations for following all the way up to here in this tutorial and yeah as homework for you I encourage you to try to implement streaming into this chatbot uh my previous video shows you how to do that so uh hopefully that's going to be useful for you too so thank you very much for watching this video and thank you very much for being here part of the channel it's amazing join the Discord Community if you're free I'll be more active now that I have finally gotten my diploma and um thank you very much again I will see you next [Music] [Music] [Music] time [Music]
zKGeRWjJlTU,2024-03-01T12:07:00.000000,Stream LLMs with LangChain + Streamlit | Tutorial,good morning everyone how is it going today welcome back to the channel and welcome to this new video in which I'm going to be showing you how to build a chat that does pretty much what you see on the screen it streams the generation as it is being generated this is great for user experience um just to be clear I am going to be building the entire chatut here for the newcomer so you see how this is all working but if you already know how to build your chat but in streamlet and Lang chain you can just jump to the section where I show you how to use the streaming part okay so without any further Ado let's get right into the [Music] video okay so just a quick note right here uh in the description of the video you will find a link to this article that you see right here which is pretty much an article that accompanies the video here you will find all the written explanations and you will also find the quick links to both the GitHub repository and I will add a link right here also to the Google collab notebook so that you can check that out as well and everything is centralized in this article right here okay so let's take a quick look at what we're actually going to be building here first of all we're going to take a look at how the streaming generation works we will make a chatbot that we will stream the response from the language model as it is being generated we're going to use Lang chain to interact with the language model we're going to use streamlit to create the front end of the application and we're going to have the chatbot remember the chat history and show it to the user okay so let's create all of that great so let me just tour you around of this very quick uh project that we're going to be setting up okay so as as you can see I have already set up the project we have myv file with my open AI key we have my G ignore and we have my app.py inside of here of my source directory okay and also let me show you what's going on here I have already enabled my environment called streaming bot I am using cond environments if you're interested you you can just create it doing cond create create and then you just call then you just call name your environment and then you specify the python version that you want okay my case I'm not going to do it because I have already done it let you just activate it activated by calling the name of your of your environment okay so as I showed you before we have already installed Lang chain and Lang chain opening I but I also did pep installed stream lid and python. EnV to be able to use my secrets which are right here okay um if you want to see more details into how to initialize or set up your project I'll link a video up here so that you can take a look at that but for now let's actually focus on building the application okay so the first thing that we're going to do is we're going to set up the user interface for the chat but okay in this case remember that in order to run our application in streamlit we can do streamlit run and then the path to our application so there you go it started off this application that you see right here and as you can see it only has this title because that's the only thing that I have added right here so what we're going to do is right now we're going to add the part where the user adds an input okay so let's actually create the entire chat interface let's do that right now so I moved myself up here so that you can see both the chat but up right here as it's being built in real time while we code up here okay so what we're going to do right now is we're going to initialize the entire chat interface now in order to do that remember that uh stream lid actually comes with a very convenient uh chat uh module that you can use so in this case we're going to use chat input and here it takes whatever placeholder you want so I'm going to say your message there you go and let's say that this is the user query like that if I save and up here I mean you don't see it because there's my face but there is an always run rerun and now we're seeing the changes life so now once that we have this what I want you to do is we want to initialize our chat history variable okay and that's what we're going to initialize let's initialize it up here so let's say if chat history not in SD session State because the SD session state is the um the object that is going to keep all of our variables all of our variables persist throughout the stream L session we're going to put it right here and if it's not being initialized we're just going to initialize it as an empty array like this okay and then from the Mt array we're going to actually log our messages but now that we have this user query and the chat input what we're going to do is we're going to deal handle whenever a user enters a user query so let's say that if user query is not none and and if it is not an empty string what we're going to do is we're going to first of all take the chat history and we're going to append we're going to append the user query however we're not going to append it just like that we're going to use l chains schema for a message okay so from L chain core. messages we're going to import human message and oops and we're also going to import AI message and since this one right here is a human message we're going to import it as a human message like that and after that we're going to get um we're going to show it in the in the application so let's do with st do chat m message and here you say who is actually talking in our case this one can be a human so if you write human and let's just type here the mark down and let's say that it is the user query okay so let me just show you what this is actually doing if I type right here hello and I hit enter you will see the message from the human up here okay and then after we do that we're going to want to actually create a generation for the uh chat message okay so let's do for St do chat message and we're going to say that this is the AI we're going to say that the AI response is going to be I don't know and right here we're going to just add the markdown for the AI response and there we go so hello hello how are you seems to be working correctly okay but so far it's only showing one one part of the message what we're going to do right now is well first we're going to append that AI message to our session stage just like we did with the human but now with an AI message schema and now let's actually just show the conversation right here [Music] conversation there you go so the conversation we're going to say that for message in s session stage CH history If the message is an instance of human message we're going to do chat message human and we're just going to show the content of the message and we're going to say else I mean if it's not a human that means it's the AI so we're going to show the hum the AI message like that seems to be working correctly and we seem to be appending the thing correctly um [Music] else there we go so let's see how this looks hola I don't know how are you I don't know perfect now the conversation seems to be running smoothly and the user interface seems to be running smoothly as well okay now let's actually just create the get response function which is actually going to generate the response using um a language model okay and we're going to create a very quick chain using langin for this so stick with me for that all right so let's just add some comments right here here is the user input and here let's let's just create the get response from the chat from the language model okay so we're going to define a function and we're going to call it get response and this one is going to take the query and it is also going to take the chat history okay now the first thing that we want is we want to create a template for our for our prompt because we're going to be using a prompt here and I have my template prepared up right here let's say you are a helpful assistant answer the following questions considering the history of the conversation we're going to we're going to pass in the history as say variable right here and we're going to pass in the user question as another variable right here okay now second thing we're going to do is we're going to initialize our prompt from this template um however for to do this we're going to have to import another thing right here let's say we're going to import from lank chain core because this is a core module we're going to import from the prompts module we're going to import chat prom template okay so that's what we're going to be importing here chat prom template and let's say from template and we're just going to pass in the template that we just created okay now that promt um the second thing we're going to need to for our chain is we're going to need a language model remember we're going to be using open a just to keep things simple so from longchain open AI we're going to import chat open AI like that so our llm is going to equal chat open AI like that and last but not least we're going to add a string output parser and that also comes within Lang chain core so from Lang chain core dot output parsers we're going to import a string output parser there you go so now we can actually create our actually this is not correctly indented there you go now we can actually create our chain that is going to I mean remember that we're going to be using L cell so remember that the chain is first of all we put the prompt prompt then we're going to add the language model and then we're going to add our string output parser right here and now we can actually use the chain. invoke as we said before and this one right here takes an object with the variables that we have right here okay in this case remember that our variables as as you can see up here is chat history and actually this is supposed to be like this and this one is going to be the chat history that you see right that we are passing to our function like that and the user question is going to be the query that we're passing right here and let's just return whatever this is okay so save and we can actually instead of saying I don't know every single time we can say get response or we can pass the user query first of all and second of all we're going to pass in the St session State chat history because remember that the second parameter right here has to be our our chat history and that chat history is stored in this session state that we have right here so let's save this let's rerun this and let's see how this works hello how are you now it as you can see it's actually thinking before it sends the the response so that's not what we want but let's just continue testing it I am Alejandro and let's see if its memory is working what is my name there you go my name is Alejandra so the memory is working the chat is working everything seems to be working now it is time to actually create the streaming feature so let's do that right now okay so now let's actually use the this new feature from streamlit that allows you to display whatever a generator is returning okay so let's go back to our get response function right here and remember that so far we're returning a chain do invoke uh whatever the chain. invoke method returns and as you remember from The Notebook this one Returns the actual completion what we want to do is return just the generator okay so in order to do that remember that since chain is a rable we can do chain dot stream or we could also do a stream if we were using a synchronous functions and in this case this is going to return a generator okay so here if instead of doing this we if if we do if we leave it like this let me show you how it what it actually does how are you and then as you can see it returns a generator it doesn't return the actual response and that is what we want but we actually want to yield each generated token by this generator so let's see how that works in order to do that I am actually going to put this thing right here inside the STD markdown like that and right here that here you could do what we did in the notebook do a for Loop for each part of the generation however streamlet recently introduced a very nice module that allows you to do this with a single with a single line of code so let's use their new module called write stream like this so if I save this and I hit I mean of course I need to I need to redefine my AI response like that and now if I reload this let's see tell me a story all right what is kubernetes and there you have it it is streaming the contents now as you can see let's see if the memory is still working let's do tell me a poem about that so in a b digital C kubernetes sales Etc so it seems to be working the streaming seems to be working just remember to use right stream if you're using streamlet and remember that you have to run the generator inside of this right stream for it to actually work okay so there you go that is how to use a generator and how to display the streamed contents from your language model using Lang chain and streamlit I hope that this was a useful tutorial for you I hope that you have learned a lot and I'm very happy to see you here please subscribe join the Discord Community to actually have um a closer uh relationship with the community and I will see you next time [Music] [Music] [Music]
9ccl1_Wu24Q,2024-02-23T10:07:00.000000,Chat with MySQL Database with Python | LangChain Tutorial,good morning everyone how's it going today welcome back to the channel it's so great to see you here again uh in today's video I'm going to be showing you how to chat with a mySQL database using Python and Lang chain okay we're going to be going through all of what is going on behind the scenes we're going to be creating our own lank chain chain and I'm going to be explaining all the details of what is going on here with a very nice diagram also all the code for this tutorial is going to be available in this article right here that is in my in my website you will find it um for free in the description below okay so make sure to open that link to follow along here you also have the explan the written explanations if you prefer to read rather than watch and yeah without any further Ado let's get right into the [Music] video [Music] okay so first of all I want to show you what is actually going to be happening behind the scenes in this notebook the thing is that we're going to be creating a full chain that is going to take as input the user question about the database so let's say a user asks something like how many users are there in this database and the result of the entire chain is going to be the answer in natural language something like there are four 48 users in this database okay now under the hood inside of this chain we're going to be having another chain and a tool that we're going to be using so the other chain is this one is the SQL chain and this one is going to take the user question and the database schema and it's going to put them in a prompt okay if you don't know what a database schema is it is basically just the list of all of the table names and all of The Columns of each table in your mySQL database okay so this this chain is going to take a prompt that is going to go something like given the following database schema and the following user question create a SQL query that is going to answer that question and then we're going to get just a SQL query as a result then we're going to run the query using a tool by Lang chain and we're going to run the results of the query through another language model and we're going to ask the final question something like um given the following question and the following result from this SQL query give an answer and that is only when we're going to get the actual response that is going to be there are 48 users in the database okay so that's actually what's going to be happening behind the scenes we're going to be coming back to this to this diagram as we go but just that you have like a clear idea of what is going to be happening during this tutorial okay so let's start this off in the article that I have uh right here I show you how to do this with both uh sqlite and MySQL but I figured that for this video it the most important thing is to show you how to do it using MySQL because even though sqlite is very useful as well it's mainly only used for testing purposes and that's also the database that they use to Showcase this in the Lang chain official documentation so I figured that using my SQL uh was something that's going to be useful for you because that's the actual database that people use in production and as for the contents of the database that we're going to be using we're going to be using the chinuk sorry shinuk database I made a typo here and this database is basically a sample database which means it's not from a real um application but it's a sample database that contains a lot of data that looks real and and it represents a digital media store okay it includes tables for artists albums media tracks invoices and customers so we're going to be able to import the SQL um database into our MySQL instance and we're going to be able to query it using our chain that we're going to be building okay um if you I mean in order to follow the tutorial you're going to have to go to latest release and download the appropriate release for my SQL or to make it easier for you I also added this quick link right here that links directly to the version that we're going to be using so if you don't want to go to their GitHub and go through the release list you can just come right here to the article and Link and and click on this link right here uh so let's go to the MySQL part right here and let's import this SQL file into our database let's let's now download our database right here that I told you from this link right here so now that downloaded the database and now what I'm going to do is I'm going to run a MySQL instance okay so in order to do that I already have my SQL installed so I'm going to do my SQL I'm going to connect this root and there you go now I'm inside a my SQL in my computer let me just show you that I don't have um databases I don't have the shinuk database so what I'm going to do is I'm just going to create it real quick so let's do that right here we're going to do create database we're going to use shinuk we're going to name it shinuk let's just use it and now what we're going to have to do is we're going to load the database that we are using so we're going to do source and I'm going to say that I want to Source from this file that I just downloaded and there you go now if I do select everything from let's say artist I'm going to limit that to 10 artists there you go I have my artist ID and my name which are the The Columns from this table that you see right here so now I have my database installed in my local computer and now I can actually start coding my chain to talk with this my SQL database okay so let's do that okay so what we're going to be doing here is we're going to be using a local notebook uh for python I am not going to be using cab for this video because I am going to be communicating with my local instance of my SQL which just makes it easier to do if I am running a local notebook um in order to run my notebook in my vs code I had to initialize a virtual environment I used cond for that so I just did cond create then I named it chat with my SQL and I specified that the version of python that I wanted to use is python 3.10 okay not going to run this because I already did that and then I just activated my my environment using chat with my SQL okay so that's what you're going to have to do if you want to run your notebook locally I already have it active as you can see right here and now I can actually start I can actually start coding my chain all right now the first thing that we're going to have to do is I'm going to import the AP AP keys from the language model that I'm going to be using uh as it's usual I'm going to be just showcasing this with open AI because the API is very simple but you feel free to use any language model that you want okay so in this case I'm going to do import OS and I'm going to do OS Environ oops OS Environ and I'm going to set the API key for open Ai and and my API key I have it stored here on the side so let me just paste it right here of course I'm going to disable this API key before you before I upload this video when I hit run in vs code it's going to ask me to select the python environment that I want to use to execute this so I'm going to show the cond environment that I that I just created this is of only because I am using Jupiter notebooks right um so here we have a problem appar OS Environ opening a key equals yeah I use single quote here there you go what's the problem here there you go so now now I initialize my API key now it's time to actually start creating the first prompt that we're going to be using for our SQL query let's do that okay so what we're going to be doing right now is we're going to do this part right here we're going to be creating a SQL chain that is going to take our user question and it's going to take a database schema and it's going to combine them together to give us the SQL query okay so first of all we need a prompt that will take our user question and the database schema so let's create that prompt right now uh in order to do this we're going to be using Lang chain so we're going to do pip install Lang chain now I already have it installed so that was faster than it might be for you but um just for reference what I wanted to do is I wanted to show you which version of Lang chain I'm using here so let's say freeze um no peep freeze and grab L chain so just for reference I'm using L chain 0.1.7 okay all right so now that we have L chain installed what we're going to do is we're going to import from Lang chain core and we're going to tap into the prompts module we're going to import the we're going to import the class chat prompt template like that and now we're can create our template now the template is just a string so let's just create our string like this and the string I I mean the template I have it called copy it right here let me just copy it for you so the template for our prompt is going to be based on the table schema below write a SQL query that would answer the user's question and then we pass in the schema which is going to be the the schema for this database right here and then we're going to pass in the question from the user okay and then we're going to create our prompt so we're going to create our prompt for using the class that we created and actually this is wrong we're going to do from template and then we're going to pass in the template that we just created right here just going to execute this and as you can see let me just show you how that works I'm going to format this prompt and let's say we're we have the schema so I'm just going to pass we're just going to say that the schema is going to be um my schema my schema and then the question is going to be how are you I mean how many uses are there so there you go we have our prompt formatted right here so we have based on the table schema below right SQL quer that would answer the question and now we have my schema which was this variable that was um replaced and then in the end we have the uh question how many uses are there so that's that's convenient let's just add a double a colon right here so to [Music] prompt our language model to actually complete the SQL query so there we have it now the prompt is ready what we're going to have to do is actually create the chain that uses this prompt and we're going to be using a to tool for that so let's do that okay so now what we're going to have to do is we're going to have to create our python object for our SQL database okay uh we're going to be doing this using Lang chain wrapper of SQL Alchemy and this integration whoops this integration comes inside of the langin community package so from Lang chain Community because it's a third party integration remember that as of the latest version of Lang chain the third party Integrations are contained within Lang chain Community we're going to tap into the utilities module right here and from here we're going to import SQL database like that now first of all in order to initialize our SQL database we're going to need a database URI so I'm going to initialize it like this and I'm going going to create my URI in my case since we are using MySQL it is MySQL and in order to run my SQL in my local machine I needed to install this driver called uh MySQL connector in order to use this let me just show you real quick what you're going to have to install is this thing right here MySQL connector Das python so let me just copy it and let me just show you so you do pip install MySQL connector d python now to me it's already installed but to you it might take a little bit longer once that's installed you can run this like this my SQL plus my SQL connector and inside of here I'm just going to pass in the path to my SQL database okay so in my case my username is root my password is admin and and this is of course running in my local host and I am running this in the default host Port which is 3306 but in your case if you want to check in which Local Host this is running what you can do is go back to your MySQL instance I'm going to top in here and now that I am inside uh my SQL I'm going to say show variables like P Port let's see so there I have it so I'm running Port 3306 which is the standard port for uh my SQL it wouldn't change I mean the only reason why you might have another one is that it was changed manually on installation okay and then right here I'm going to finally tap into the name of my database remember that the database that I created is called shinuk if I'm not mistaken yep shinuk like this so I'm going to copy this and I'm going to say here so there you go that is my database URI and now I can initialize my database object using the class which is the wrapper from lch chain and actually right here I have to specify that I want to do this from your ey there you go so now I execute this and there you go so now it is running um to show you to show you real quick that it works let me just do db. run and let's say select everything from album let's limit that to five and there you have it we have our five albums in topples which is very convenient so now our database is inside our python code and we can query it and we we can add it to our chain right remember that we are building this chain right here so we're building an SQL chain that is going to take the user question it's going to construct the schema of the database that we just loaded and load both into a prompt to send the language model in order to get only the SQL query okay in order to actually do this we have to first create a function that is going to return the schema of this database object that we initialized so in order to do that I'm going to just create a function called get schema and it's going to look something like what copilot is is suggesting me but here we have to pass in an underscore which means that this is an empty parameter but since we're going to be using this as a runnable we need to pass in an argument just to um just so that the runnable accepts this okay I'm going to show you how that works in just a little bit and we're going to return the database object and we're going to get table info like that all right just to show you how that works I'm just going to call it um let's just call it like that so there you go here you have that this returned my actual schema for the shinuk database that we have uh downloaded so there you have all the schema which is the names of the tables and all the names of all the columns okay that's pretty much all the information our language model needs to actually create the SQL query once that we have created this function right here we can focus on creating the actual SQL chain um in order to do that we're going to have to import a few other classes right here so from L chain core we're going to first uh tap into the output part module and from here we're going to import oops we're going to import the string output pass because remember that we're we're supposed to get a SQL query and this SQL query we're going to be running it inside of the the we're going to be running it uh to uh in our database so it needs to be always a string so that's why we're going to be using a string output parser and then we're also going to need to use from also from lunch and core we're going to tap into the runnables okay and right here we're going to from right here we're going to import the runnable pass through this one is going to allow us to pass in this function right here as a runnable so that our chain can use it okay and last but not least we're going to use L chain open AI models and we're going to just use chat open AI now if you don't have I mean if that line is causing you trouble right here that might be because this of the latest version of Lang chain remember that you're going to be needing to install open Package separately from langin so you're going to have if this doesn't work you're going to have to do biip install open a sorry pip install L chain D openai like this remember to be inside of your virtual environment and once that is installed you should be able to use this okay so now let's create our chain first of all we're going to create our language model and we're going to initialize it from chat open AI I'm just going to initialize it like that and second of all let's just actually create our SQL chain okay now the first element in our chain all right so I mean just uh so you know we're going to be using L cell which is Lang chain expression language which allows us to create our own custom chains but using um a more pipeline like synx okay so here the first step of the pipeline is going to be our runnable pass through and this one we're going to use it to assign a value to one of the variables okay which Vari is going to take this new V this new value it's going to be the variable schema all right and oops schema because remember that schema is the variable that we want to replace right here in our prompt and this one right here is going to take the value that is returned by our function called get schema okay this is also one of the reasons why we need this underscore right here because if even though we don't need um um we don't need to pass in any parameters uh this pass through requires that whatever we pass in has one at least one parameter so that's why we get this um underscore right there let's now focus on the following steps this step is going to assign this the schema value to this variable then the second step we write this vertical line like this and the second step is going to be our prompt that we initialized before up here the third step is going to be to pass that to our model and right here actually what the guys of Lang chain do is they tell you to add a to bind a stop sign stop parameter to your language model this is uh good practice I suppose because what this allows you to do I mean let me just write it down right here um we're going to add a stop parameter here that is going to be SQL result okay now what this does is basically tells your language model to stop generating more text as soon as it sees that it has already generated this right here this is basically just um security concern or yeah a kind of observability concern so that your language model does not hallucinate a result for your query as well right because remember that our prompt looks like this there is our schema question SQL query and we want to make sure that if for some reason our language model gets a our language model the completion from our language model includes the next line which would be s SQL query uh SQL result we want it to stop because we don't want it to hallucinate the response okay the result um I mean you can also you can also delete this this could this would also work but this is what they did in their example so I'm just going to keep it right there and lastly but not least we're going to add our string output parser to be sure that the result that we get from this chain is just the string containing the SQL query okay okay now that has created our chain now how about we test it let's run the chain remember that using Lang Chain's uh latest version using uh Lang chain expression language we can call a chain calling the method invoke and passing in an object with all the key value pairs of all the variables in its prompts in our case in our case remember that we already have populated variable schema within the pipeline now the only variable that we need to populate is question so I'm going to add right here a value question and I'm going to say oops not like that I'm going to say how many artists are there going to execute this and there you go select count as title artist from artist there you go so that is the SQL query that we're going to be running um in our database uh in the full chain so now this SQL chain is ready it takes the user question it generates the schema from the database object that we defined up here and it returns SQL query now let's create a full chain that is going to include this chain and run the query towards um run the query with another language model and return the final result so let's do that right now perfect so actually creating this new uh chain that is going to be the full chain that contains the SQL chain is going to be very very similar to the all the chain that we have already built right here okay the only difference is that we're going to be passing in another function as runnable which is going to be the function that is going to run our SQL query and we're also going to be passing this SQL chain as runnable okay so let's do that right now it's actually very simple um the first thing that we're going to have to do is we're going to have to create a new template a new prompt and this prompt is going to look something like this let's first create a template just like we did before we're going to create a template like this I have the template already prepared right here so let me just paste it so it's going to say based on the schema below question SQL query and SQL response write the natural language response so we're going to pass in the schema that we have already got from running this uh get schema runnable right here we're going to pass in the question from the user we're going to pass in the SQL query that was generated by our SQL chain and we're going to pass in the SQL response which is whatever this um this return when it's run in the in the database okay so that is a template now actually now let's actually create the prompt um and this prompt is going to be just as before we're going to initialize it for from chat prom template and let's say that from template as well and we're going to initialize it from this template that we created right here okay so let's run that there you go so now we have this prompt and now let's actually use it to create the chain the full chain all right but actually before we create this full chain we I forgot that we need to do something else remember that with our SQL chain we had to create a function that would get the database schema and we would use that function as a runnable in this case we have to do the same but this function is going to run the query so let's create that it's going to called run query like this there you go and this one is going to take in the query which is going to be a string and this one is basically just going to return whatever the execution of the query in the database is however here in our database object the method to do this is run and we're going to run the query like that okay let me just show you how this works so I'm going to oops I'm going to run this query right here just to show you how it works and I am going to run just a sample query just to show you I'm going to run this query right here that was generated before there you go there you go so now we're going to run this query and let's see what it returns there you go so we have 275 which means that there are 275 artists in the entire database so there we go now we have our function that works we have our prompt that works now it's time to actually create the chain that is going to put everything together okay so let's do that now all right so just as a reminder of where we are so far let me just go back here to the article that you have Linked In the description and just as a reminder we have already successfully built the SQL chain we have already successfully got our SQL query from this chain we have created a run query method that is going to allow us to run whatever we get from this chain and now we have to put everything together what we're going to have to do now is create this full chain that you have right here and just as a reminder you have all of the codes um that I wrote here in the video right here in the article with all of the explanations and everything and all of the prompts and everything is inside of here as well so just be sure to to open this and yeah so now what we're going to do is create a chain so the first thing that I'm going to do is initialize it as full chain going to be using L cell as well which is Lang chain expression language and the first thing I'm going to do is I'm going to pass in the SQL chain as a runnable okay now in order to do this just like we did before we're going to assign um a value to one of the variables that we have in our prompt in our case because we're going to be passing in the SQL chain we're going to be uh populating this oh no which variable is it yeah this variable right here which is the query all right so that's the first thing the query is going to equal whatever our SQL chain is able to return okay and here let's actually just pipeline this a little bit more and whatever this returns we're going to pass in to another as another runnable and this one is going to populate our schema which just going to get it from the get schema function that we just created and the second variable that we want to to populate is the one response okay now here we cannot actually just do like this because we need to know which which um parameter we're going to pass as argument right so if we just pass run query it's not going to know what to put inside this parameter right here so what we're going to do is we're going to tap into the V the the variables returned by this runnable and we're going to choose the query that has been returned by the runnable already right remember that the runnable is the SQL chain I hope this is clear um just buckle up it's going to be very simple actually I'm going to let me just print it so that you see what's actually going on uh we're going to create a Lambda function that is going to uh I'm just going to call this variables and right here let me just print this let's just print all the variables all right and and let me just close close everything okay of course this is not the full chain but I just want to show you what is going to actually be going on so we create this chain and let's just execute it it's invoke it saying that the question is going to be how many artists out there okay let's execute [Music] this so there you go you have that the print variables are first are the questions and everything and once that is executed we have the question we have the query that has been already been returned by our SQL chain we have our schema which was returned by our get schema and the response of course since the print method returns none is none okay so what we want to do is we want to run whatever is inside the query with our run query uh function okay so let's do that we're going to have to use this Lambda function right here and we're going to do um run query variables query like that uh hopefully this is going to work let's see how that looks second like I mean that was the the hard part right here after that we're just going to pass that into our prompt and lastly we're going to pass in our model that we have previously designed previously created um here well copilot is recommended me to bind another stop sign for the natural language response I mean you can add it I don't think we need it um so let's just run this and let's run the second one and see what it returns there you go so it returns an AI message saying that there are a total of 275 artists in the database which is exactly the result that we got from our query area right here so our full chain is working and it seems to be going correctly now just going to modify this right here just going to say vars or I don't know variables just seems too long but yeah I mean there you have it that's the full chain just remember that we are passing first the SQL chain as runnable and then whatever that returns is we're going to be using it to populate the we're going the second runable which is going to include the the schema and also the the response from the query okay so there you go that's I mean if you want you can even add uh last string output parser which is going to return only the string of the message that I mean that's optional so there you go that's how to create a SQL chain in the next video I'm going to show you how to implement this in a graphical user interface but I figure that it was very important that you see how this works in an actual notebook um because I mean in order to actually implement this in a in a graphical user interface you have to kind of be aware of what's going on behind the scenes with this diagram so I hope that that was clear I hope that I hope that you have learned a lot from this video and it has been a pleasure having you here again remember to subscribe remember to sign up to the Discord to the Discord Community to see all the news about the community and to participate a little bit more in the future of the channel and thank you very much for being here and I will see you next [Music] time [Music] l
6ciD6KXq3MY,2024-02-17T00:54:14.000000,What is Google's Gemini 1.5 Pro | 10 Million Token Window,"good morning everyone how is it going today welcome back to this video and welcome back to the channel where we talk about everything about software engineering and Ai and how to implement the new AI Technologies and libraries and models into your super cool applications in the today's video we're going to be covering a pretty groundbreaking news which is the release of Gemini 1.5 by Google a model that is pushing the boundaries of what we thought possible in Ai and we're going to be going over the official release post and summarizing it and explaining to you what actually each part of it means and we're also going to be delving a little bit into the more technical report and explaining how this new model compares to other models in the market so without any further Ado let's get right into [Music] it [Music] so according to Google this new language model is really a groundbreaking leap into the future of multimodel machine learning okay so it delivers dramatically enhanced performance we're going to see how that works it does that with a multimodel model I'm going to tell you a little bit more about what that means and it does that using the mixture of experts architecture I'm going to tell you a little bit about that as well the thing that is the most impressive probably and the thing that is making the most fuzz in the internet is the their ridiculously large context window in the standard version version they have 128,000 tokens however for production they can go up to even 1 million tokens and in the official report they say that they have even tested up to 10 10 million tokens which is ridiculous I'm going to tell you a little bit more about that and show you how impressive that is but let me just explain to you first what multimodel means so what a multimodel model means is that it can take several kinds of formats as input not only text okay so to show this let me let's imagine that you have a model like gp4 or Gemini 1.0 or something like that and you want to feed it a video or an image or an audio file what you would have to do is first extract the text from that video or from that audio file and then feed the text to the language model what makes a multimodel language model different is that it is capable of taking as input natively the video or the audio files and tokenizing them and indexing them without having to rely on other services such as the whisper API or something like that to convert the audio into text so that is pretty impressive and it comes by default with Gemini 1.5 now some other interesting part about the model is their architecture Google says openly that the architecture that they are using is the mixture of experts architecture which is described in this paper right here now I'm not going to guide you through the entire technical paper right here but just so you know what a mixture of expert architecture means is the same architecture that mistal and probably gp4 are using which means that the whole language model is actually several language models working together under the hoot so what a mixture of experts design is is a machine learning strategy where multiple specialized models so-called experts are trained to perform very well in different very specific tasks okay so for example you will have one model that is very good at mathematical reasoning another model that is very good at varable communication and copywriting and narration another model that is very good at debugging code another model that is very good at software design for example things like that and what the mixture of expert architecture does is it takes all of these models that are very good in each in their specific task and put them under a single hoood and whenever the user sends a query the model chooses which expert to use for the specific task so if the user is talking about mathematics is going to use the expert in mathematical reasoning if the user sends a query about code and debugging it's going to use an expert in debugging so what you get in the end with this architecture is a system that is very good at handling very different tasks by averaging the strengths of different experts leading to very improved performance and flexibility of your model as well so that's the architecture that they are using now something else that we have to talk about is its ridiculously long context window okay as we mentioned before the context window can take up to 1 hour video 11 hours of audio or 700,000 words with the 1 million token uh version okay that is just ridiculous just to put it in perspective 700,000 words is pretty much all of the works of the har Potter series minus one book I think all of that sent at once in a single prompt to your language model just think about how revolutionary that is if it actually works as they say it does and that is only with the 1 million token window that is available in their API however according to their reports they have tested up to 10 million token windows in their research with pretty good results we're going to take a look at how that looks in a moment but yeah pretty impressive now let's take a look at the performance right here for a moment and apparently it is very very impressive so what we're going to have to see is their actual official report that he published alongside with the blog post and here we have some results right here the results show the plots for the test needle in the Hy stack okay I'm going to explain to you real quick what needling the Hast stack is with the text Hast stack so let's go to page nine first of all which is where they make the comparison with gp4 and here we have it so let's see how needle in the hstack works um needling the Hast is a technique is a test to evaluate a language model ability to find specific information which would be the needle in a very large context which would be the Hast stack in this case what they do is they take this this piece of information right here this short sentence which says the special Magic City number is and then the given a number okay and they hide this information somewhere in the prompt and then at the end they ask the question or they ask which is the magic number and they evaluate if the model returned that correctly or not so how this plot works here in the vertical axis you have the depth which means where in the context the hidden sentence is positioned 0% means at the beginning of the context 100% means at the end of your context and the vertical axis right here is basically just the context window okay so here you have 32,000 tokens up to 10 million tokens okay so let's just consider for example this point right here means that they sent a 128,000 prompt which is somewhere about uh 30,000 uh words s and they hit this piece of information special Magic City number is let's say seven at 43% of the prompt okay so somewhere along the middle and then they asked the question what is the final the magic number and then apparently it responded correctly because we have a green square okay so that's how this works and so you can see the comparison between Gemini 1.5 Pro and GPT 4 Turbo uh as you can see the Contex window for G 1.5 Pro is ridiculously large here you have up until 1 million and you can see that GPT 4 Turbo goes only up to 128,000 tokens so GPT 4 Turbo has a 100% recall and apparently Gemini 1.5 pro has a staggering 100% recall up to 530,000 tokens which is just ridiculous and then it and then they say that it has almost 100% up to 1 million tokens which means that in the test that they made the language model was capable of finding hidden information inside a huge context of 1 million tokens 99.7% of the time ridiculous the second performance test that I wanted to show you is the one that they do with video okay for this one they use gp4 Vision as a benchmark and as you can see well according to them they do ridiculously well all right um what I did here is I needle in the Hast stack test just as with the text however this is a little different because it is multimodel in the sense that the question that they ask in the end is in text of course and they are asking the model to retrieve information from a video okay so that that itself is already quite impressive and the thing here how they do it is that they overlay the test the secret word is whatever on a single randomly sampled video frame so for example they have a video and they put this text in the first frame or in the frame at the 12 20th second Etc and they ask in the end a question to the language model what is the secret word and the language model has to find whatever the secret word they overlaid in that specific frame okay just as with the text the xais is the context window in this case it is in minutes because we're we're measuring a video and the depth is the place in the video where the overlay was okay so we have Z from 0% which means at the beginning of the video to all the way to 100% which means by the end of the video and as you can see well gp4 Vision was pretty good 100% recall for all of their context window which goes all the way to apparently 5 minutes 4 minutes and Gemini 1.5 Pro goes to 100% as well but up to 3 hours well 3 hours is what they test in research and up to 1 hour which is what they have in production okay so that in itself is quite impressive last but not least we have the a Hast stack test which is pretty much the same thing as the one that we saw in video also we have in this case a multimodal test and what they do is they hide a very short clip of audio lasting a few word a few words where the speaker says the secret keyword is whatever within the audio uh signal and they hide that in a corpus of a a very big audio right so they use the Vox popular data set with multiple speakers to make it harder for the language model and then they experiment when they input audio ranges from 12 minutes to 22 hours or 2 million tokens okay they insert this needle which is this phrase right here in different positions across the signal and they test whether or not the language model is capable to find the secret word okay in this case apparently Gemini 1.5 Pro was pretty much perfect all the way to 22 hours that means that they gave it a 22-hour audio file with this needle secretly placed somewhere in the file and it was always able to find information directly pretty impressive and they test this against gp4 turbo plus whisper because of course this gp4 is not a multimodel model so what they do is they take this same data set they pass it through whisper which is the API by open AI that allows you to convert audio to text and then they pass whatever that had whatever the text they got from whisper to gp4 Turbo and they ask the final question for the secret keyword and as you can see gp4 turbo had a much less accuracy and recall than GP than Gemini 1.5 Pro so that's it for the audio performance and then in the end we have this bit more sopis icated test which tests multiple needles in the hch which is a little bit more realistic this basically means that they put several needles in the entire Corpus that is being tested and then they evaluate how many of those needles were actually retrieved which is much more realistic and as you can see well in this test also Gemini 1.5 Pro seems to be doing way better than GPT 4 Turbo so those are the performance results for Gemini 1.5 Pro published by Google and they actually do look very very groundbreaking let me know what you think about this in the comments but I I can't wait to use this model to build some applications finally let's talk about this pretty amazing feat that they were able to do with gini 1.5 Pro uh apparently they were able to teach gini 1.5 Pro a completely new language that it had never been exposed to all within a single context window which is just amazing if you think about it what they did is they took a 500 page grammar book and dictionary of this very rare language called calang that is spoken by fewer than 200 speakers in West Kia and they sent that document as context to the language model okay so they sent it within a single prompt and then they asked the language model to make some translations from English to caling and they found that the quality of these translations was comparable to that of a person who had learned from the same materials to me that is just impressive and the fact that this is made possible by this insanely large context window means that probably the next generation of language model applications are going to be very very different to the ones that we do today so that is pretty much how the model performs and the amazing feats that it's able to do now that wraps up our dive into Gemini 1.5 let me know what you think in the comments I'm very excited to see what you have to say and yeah be sure to stay tuned here in the channel because we are very soon going to be building very nice applications with Gemini 1.5 here using python so be sure not to miss that so yeah thank you very much for watching don't forget to subscribe and I will see you next [Music] [Music] time"
74c3KaAXPvk,2024-02-14T12:07:00.000000,Deploy Your AI Streamlit App for FREE | Step-by-Step (Heroku Alternative),good morning everyone how is it going today welcome back to the channel and welcome to this new video tutorial um here we're going to be seeing how to deploy pretty much any of the applications that we have been building here in the channel uh these are applications developed in Python and using stream Le for the front end so yeah I have seen that some of you guys have been building amazing applications you have been creating beautiful projects uh that you have either Creed completely yourself from scratch or you have modified from the tutorials that we have been putting up here in the channel so it would be a great pity if you didn't have a way to share those products with either your clients your co-workers your friends or your employers um so by the end of this video the idea is to give you pretty much just that a way to deploy any of the applications that we have been building here for free and in a very easy way okay um on on another note we have recently opened a Discord server so it is completely free and it is a way for you to participate in the community to meet really cool people and to also participate in the direction that the channel takes and have a word in about future future YouTube tutorials and also to get notifications whenever we have new free learning material uh this is also a good way for you to participate in the coming events that are coming very soon uh also great opportunities for you to learn about uh about these Technologies by meeting very cool people and also a very nice way to get friend to get um uh support and help if you get stuck at some tutorial or something like that we have a private Forum right here that where you can just post your questions and the community is here to help or myself itself as well um it's more convenient than the YouTube comments for technical questions so yeah I'll leave a link in the description it's completely free and feel free to just hop in there and send me a message all right um also so now without any further Ado let's get to deploying this application that we have built in the previous video in a very simple and free way okay so let's do that [Music] all right so the first thing that we're going to need in order to deploy our application is we're going to have to have our code in a GitHub repository okay this is very simple you just got to go to github.com create an account and add a new repository and push your code right here okay um something important to keep in mind when pushing your code is to have of course your git ignore file so that you don't push your secrets to GitHub and you don't make them public to everyone and secondly you're going to want to have your requirements that txt file generated now what is the requirements.txt file it's pretty simple it's just a list of all of the dependencies that you were using when you developed your application and the your application needs to run okay so everything that you installed using pip install you're going to have to add it here so Lang chain langin Community langin open AI python. streamlit since we're going to be deploying the application that we built in the previous video this should not come as a surprise to you because these are exactly the dependencies that we deploy that we required using pip install okay so in case you don't have the requirements that txt T file what you're going to want to do is you're going to want to come right here to your to your product to your project sorry and let's see how to generate the requirements.txt right so in order to generate your requirements.txt file the first thing that we're going to want to do is we're going to want to come to our terminal right here um and first of all we're going to want to act activate our virtual environment okay um actually going to do this in on the site terminal like this we're exactly in the same spot chat with website project and chat with website project I'm just going to activate my my virtual environment like that there you go and now inside of here what I'm going to do is uh uh remember that the requirements of dxt file is a file that contains all of your pip installed requirements so we're well A good rule of thumb is that every time you install something using pip install stream pip install whatever um after installing it so for let's say I install I install streamlit a good rule of thumb is that after doing this you're going to do you're going to do pip freeze then this vertical bar and you're going to do rep and whichever dependency you installed at that point so you're going to you can do um streamlit in this case streamlit and then double Chevron requirements.txt and what this is going to do is it's going to append to the end of your requirements.txt file the dependency that you are specifying here in this case it is uh streamlet all right so let's see if I run this here you have it streamlet and the right version that I am using I already had it up here so there is no real reason for me to add it again but that's how you do it um just to show you exactly what is going on behind the scenes uh peep freeze pip Friz is actually just printing all of the dependencies that are installed in my virtual environment then you have then you have rep which takes all of whatever this command returned and it filters only the lines that contain this word right here so in our case we're filtering only the lines that contain streamlet and then the double Chevon requirements .txt is taking whatever this command returned and appending it to the end of requirements at txt so that's actually what why this went like that um another way to do this if you have already created your if you have already created your project and you don't have and you forgot to do this for every single pip requirement that you had what you can do is you can pip install pip Rex and this is going to install a command that you can call called PX and this is only going to work if you don't have your requirements at dxt or else you will have to force it through so I'm just going to delete it I'm going to run pip Rex and as you can see this is going to generate my new requirements the txt with all of my dependencies however be a little careful when relying on P you're probably going to run into some errors because it for some reason it doesn't um pick up every single dependency that you need so in this case as you can see this is not exactly what I had before let me just show you the comparison as you can see it It upgraded the dependencies it added like the supposedly non-breaking patches to to all of my dependencies and it forgot to include two of them so it forgot to include chroma and beautiful soup so my application when once I deploy it it's not going to work if I don't have chroma and beautiful soup then you will have to debug it and you'll be like so what am I missing and you will be like oh I am missing the chroma um package so you're going to come back to your requirements of txt see that your chroma is not included and then you're going to have to manually do peep freeze um rep Etc okay so so yeah I mean just keep that in mind and this is how you um how you generate your requirements the txt file so now once you have your requirements at dxt file and you have all of the other files in your GitHub um in your GitHub repository we are ready to actually deploy this using our services great so now you have your repository already set up with your requirements.txt what we're going to do now is we're going to deploy it your using a platform um that offers this service okay uh we're going to start off with streamlet Community Cloud which is a free service provided by the commun the streamlet guys um and it's very convenient first of all it is free second of all it's very easy to use you can have your custom subdomain which means that you can have your application. stly doio which I mean you can always change the subdomain um and and you can use it with private GitHub repositories okay uh now the limitations are that there are no custom domains like it will always beam. um it you can only have one private application all of them all of the other ones will be indexed by Google and accessed by anyone you anyone on the internet and also you have very limited resources I mean of course since this is a free service um your application at some point if if you receive too many visitors your application will shut down and also if many visitors visit your application on streamly on the stream Community Cloud um if some if no one visits your application for a long time they are going to shut down your application and then you will have to reboot it when someone else wants to to to access it so I mean those are the kind of limitations and also something that's not very nice is that they don't have a paid tier they only have a free tier okay okay so if at some point you go beyond what the free what they can uh do for you they're not going to be able to sell you a a bigger uh package all you have is what you you get all all they get all they have so yeah I mean but it's on the on the upside it's very easy to use and very fast so let me just show you real quick you're going to go to share. stream.io I suggest that you continue with GitHub because we're going to be um uh connecting GitHub together um of course this should be the same GitHub account where you have your repository and once you're there you're going to get to the dashboard like this all you have to do is create a new application you can and then I inan here they're going to ask you to select which repository you're going to deploy I'm going to deploy chat with websites which is the the one that I was mentioning before um select the branch to deploy the main file we're going to we're going to give the path to my main file of my application which was source. app source app.py and then here as I told you you have your custom uh soap domain so let's say website chat with websites. stly doapp and here you have some advanced settings and these right here are your secrets which are of course your API keys in this sense now if if you remember correctly this application needed the open AI API keys and this is pretty much the same contents that you would write in your in your EnV file but here is another format here is a tunnel format so you should add the the double quotes right there uh let me just remember which uh to add some API keys right here let's just create this one and here it is there you go there it has my open a I key and be sure to choose the exact python version that you were using when you were developing your application in my case I'm going to come right here and check it let's say python for version python 3.10 is the one that I'm using so I'm going to select that one to be sure that everything's running smoothly and then I'm just going to click on deploy and this is basically going to deploy my application um you get a real nice animation right here you can see all the logging happening on the side right here and um yeah I'm going to pause the video for a little bit because it's probably going to take a few minutes but I'll be back when when it's um when it's already deployed okay so actually we had a problem while we were installing the dependencies and let me just show you I think this is very useful so that you can debug this yourself as well the thing is that here if you if there's an error while you're deploying your application you're going to have an error message a warning and then you're going to have all sorts of error codes here in this case we have that the error is an invalid requirement beautiful soup for and this not working did you mean there is a hint as well so I mean there's a problem here let's just try to figure out what's what's going on um here let's just Google what's going on so apparently there is a problem with beautiful soup beautiful soup and the problems with the requirements.txt file so let's see how to use beautiful soup for in Heroku and this is very convenient because Haku is pretty much the same kind of service that we're kind of that we're trying to use but the problem with hiraku is that they don't offer a free tier anymore so we're using alternatives to Heroku um here we have that they have beautiful soup 4.9 and they have this her and some some one says that you should include bs4 itself because when we install it we do pip install bs4 not beautiful soup okay so let's see the releases 0.0.2 all right so let's let's correct that so instead of first of all let's just go back to the actual one that we're going to try to be deploying and instead of doing that let's do beautiful soup 0.0.2 which is the latest one as of January 17 and let's just save this again I'm just going to get add requirements I'm going to get um commit and just going to add a very quick message right here saying that I'm commit say that I'm committing the requirements and let's just push it back let's see yes I am connected to GitHub so let's just let's just push it there you go now it's pushed all right and now that we have pushed it here it LO it saw that we had updated the appc application so let's see if it's going to try to re process it let's see all right so apparently it's not doing that alone so let's go back to Shar stream.io to our list of applications and here you have chat with websites and you can see that we have this error right here um so what we're going to do is we're going to reboot it now that we have updated the requirements that the file and now we can just go back and see it again and see the log again now I'm going to pause the video again while this loads and let's see what happens so everything's finished installing and loading so now the application seems to be live here in chatw websites. stly doapp now let's just test it real quick for this I use I'm going to use this blog from Lama index where they um talk about the newest release the version 0.10 and of course our language model has no idea what that is so as as you remember this application pretty much allows you to talk with any website so let's see what it does uh what are the latest um the main points of the latest llama index release let's see if it is able to reply still thinking there you go so the main points of the latest release version 0.10 are as follows all right so seems to be working correctly everything seems okay in the application and the application is correctly deployed and it is live and anyone can access it here at chatw websites. shml it.app so there you go that's the first deployment system that you can have uh just to show you real quick if you want to edit this you're going to have to go to settings you can change the url I mean the subdomain you can set up this application as a private application which means only the people that you sh that you specify the email here are going to be able to access the application however you only have the right to have one private application per account all the other ones will have to be set as public which means that they're going to be indexed by Google and they're going to be accessible by anyone on the internet so that's kind of a downside if you want to if you want to use this service and of course your secrets which is where you want to keep your enironment variables which are going to be mainly your API keys and other configs okay so there you go let's now see a second platform as a service that allows you to deploy your applications for free the second platform as a service that I wanted to introduce to you today is a good way to think about it is like a hiroku replacement in case you're not familiar with Hoku both hiroku and render are platforms of service that allow you to deploy any application you want directly from GitHub in a very simple and easy way uh however Hoku became very popular a few years ago basically because they had a free tier that allowed students to deploy their recently developed applications and showcase to their um co-workers to their employers Etc um now I think it was in 2022 that they disabled the free tier and now it is render which has taken that that Spotlight because they do offer a very generous free tier uh let me just show you real quick they have uh 500 minutes of free pipeline I mean 500 free pipeline minutes and free bandwidth of 100 GB which sounds pretty good and here you can deploy your static websites and also your web services which is what we're going to do right now so in order to deploy your streamlit application to render what you're going to want to do is you're going to sign up and connect your GitHub account to to your render uh account and then right here you're going to click on new and click on new web service you're going to select that you want to deploy from a g repository and here you will see a list of all of the repositories that you have allowed access to from your GitHub or your gitlab account because you can also create an account using gitlab um in my case I have only um access uh given access to this two which is chat with websites and another one right here but we're going to deploy the same one as we did with streamlet Community cloud I'm just going to select that one right here and let's just fill in this form uh so the first thing is the name I'm going to call it chat with websites um then we have the branch that we want to deploy from which is going to be master and here is the runtime I recommend that if you know how to use Docker and how to dockerize your application I recommend that you dockerize it create a Docker uh Docker file in your repository and you deploy it using a Docker runtime however if you don't know what Docker is and you don't know how that works that's completely okay um the python should work pretty well for you too now we have the build command which is the one that is going to be run to install all of our requirements all of our dependencies in our case since we're going to be dealing with a python application it's going to be pip install dasr requirements.txt see these are things that streamlit Community cloud is doing in the background so um that's why in streamlit community Cloud you did not have to do this and then we're going to have to add our start command in this case remember that in order to start to start our streamlit application we have to do streamlit run and then we add the path to our application which if you remember correctly it was in source app.py like that okay now a good thing to do uh in this case is to say in which Port you're going to be deploying your application because what render does is it tries to scan all of the ports that you have that you have um exposed in your internal server and it uh one it finds one it exposes it okay so it's usually easier I mean it's it's better to make it easier for them uh by by specifying a common Port which is the port 80 um let me just remember how to how to run streamlet in a specific Port as far as I remember it is server Port like this there you go so now what we're going to have want to do is add like that-- server. port and then we specify at80 that is just going to make it a little bit easier for um the render uh platform to detect that we're running the server the service in the port 80 and then finally we're going to have to add our environment variables in our case it's our open a key the only environment variable that we need for our application I'm going to come get get it here from my chat with websites application that I that I created just a moment ago copy this and put it right here like that now everything seems to be running smoothly I click on create web service and a good thing about this as I mentioned before is that if at some point you receive this one has pretty much the same limitations as stream L Community Cloud however if at some point you receive uh a lot of users and you need to provide a better service it is possible to just upgrade your plan to a paid instance and then you will be able to to serve as many users as you as you require okay as you can see here you have the log and I'm going to pause a little bit while all of the dependencies are installed and I'll be back in just one second there you go all right just uh uh quick note right here just to make sure that you don't uh cancel this before it's actually finished as you can see here all of the installment all of the dependencies were installed and everything happened correctly it got to this step of running streamlet run um app.py in the server that we specified and then you have a message saying you can now view your streamlet application in your browser and that's okay that that's that means that everything's going smoothly however this is not true yet okay this is all running inside of the container of render and it is not it was not deployed just yet now as you can see it detected a running service on port 8080 and now it is routing that port to an actual Port that we're going to be able to access so as you can see even though we had this message if I try to open the any of this this URLs that it gave me I'm not going to see anything because it's not live it's not actually live yet okay uh what we're going to do is we're going to want to wait for it to actually uh once it has detected the port we want to have there you go we want to have this message your service is live Etc and now you have the green flag right here saying live and now you have your your url right here which you can click and now here you have your actual application that seems to be running let's just test it again with our Lama index blog post let's just paste it right here and um uh it's index in the entire post when was the latest version of Lama index released and our application seems to be working correctly in February 2024 Perfect all right so that is how to deploy on render all right so that is how to deploy your application uh your streamlit application into different web in two different uh platforms as a service we have seen streamlit do uh streamlit Community cloud and render.png this was useful for you I hope to see your applications deployed very soon be sure to share them to the community in the Discord server or here in the comments and I hope you learned a lot and thank you very much for watching I'll see you next [Music] time [Music]
bupx08ZgSFg,2024-01-31T14:52:47.000000,Tutorial | Chat with any Website using Python and Langchain (LATEST VERSION),good morning everyone how's it going today welcome back to the channel and welcome to this new video tutorial in which I'm going to show you exactly how to build this application that you see right here now this is a chatbot built completely using Python and using the latest version of Lang chain and it allows you to chat with pretty much any website so let's say for example we're going to talk about langra which is the latest product released by Lang chain I'm going to paste the URL right here here and now I'm going to be able to ask my language model about the information inside of this website for example what is Lang graph now this is interesting because langra since it's such a new product um no language model is going to know anything about this however here we see that we have um our chat B is answering questions about it so we're using the information inside of this website as a context okay uh um I understand that this may look a little daunting at the beginning but believe me it is simpler than it looks and I promise that by the end of the video you will have a product working that you will be able to Showcase to your clients to your colleagues to your co-workers to your employers Etc and maybe even deploy it for your team to use okay uh if you like videos about Ai and software don't forget to subscribe and yeah let's get right into the video [Music] okay so the first thing that we're going to want to do is we're going to want to create a virtual environment for our application okay here as you can see I am already in visual in vs code and I already created a repository a git repository for this web for for this project in this case I now I'm going to create a virtual environment remember that a virtual environment is important for you to be able to install your python dependencies only for this project and so that they don't overlap with other projects that you might be working on the side okay uh in order to do this I am going to use cond if you want to use cond don't forget to install anaconda or miniconda so I'm going to be doing cond create D- name to name my environment I'm going to call it chat with website and I'm going to also specify the python version that I want I want to work with python 3.10 I'm going to hit enter okay now if I hit enter there you go it's going to start creating my virtual environment feel free to use whichever virtual environment technique you want you can also use VN for example but lately I've been using cond a little bit more than vmf and here you have it that if you want to activate it all you have to do is say cond activate and the name of your environment and there you go now everything that I install inside of here be it using cond or pip it's going to be installed only in my virtual environment okay so now we're ready to start the development all right so the first thing that we're going to do right here is we're going to create a Source directory and inside of here I'm going to create my app.py file which is going to contain my application and also right here I want to start installing the packages that I'm going to be using for my application to work okay um remember that I told you that we're going to be building the front end using python um in order to do this we're going to be using a library called streamlit which allows you to create graphical users user interfaces in just a few lines I'm going to show you how it works in just a moment so you're going to do pip install streamlit and also for our application to work we're going to be using Lang chain and Lang chain open AI which is the third party package for open AI okay you hit enter for you it's probably going to take a little bit longer than that because I already had them installed before recording but there you go now we're ready to start coding wait I just realized that just a moment ago my fa my head was on the way so you couldn't see what I was typing uh so I'm just going to paste this like this right here and it's going to be available anyways in the GitHub repository that is going to be linked in the description okay so we installed stream lead Lang chain and Lang chain open AI now what we're going to do do is we're going to import streamlit as St and we are going to initialize the applicate the front end of the application doing St set page config and this method takes a few par few arguments the first one is the page title and this is the what is going to show in the tab okay of your of your of your browser in this case I'm going to call it chat with websites and the second one is going to be the page HIC and I'm just going to leave it as a robote head like that just going to close this right here now let's just add a title for example to do that you just say h St title like this if I'm not mistaken St title yeah St title not page title just title like that and we're going to say chat with websites and if you want to add a a sidebar like we did like we had in the in the app that I showed you just a moment ago all you have to do is s sidebar and actually you have to say with st sidebar and anything that is inside of here is going to be put inside of your sidebar I'm going to say the I'm going to add a header there there's going to be heading settings and right here let's add the text input that is going to take your website URL okay so let's add that st. text input and here we're going to say website URL there you go and we're going to store whichever value the user adds here in a variable called website URL like that let's see how that's looking so far in order to run your streamlet application remember that you cannot do Python and then run your application from like this python SRC app.py this is going to return an error because stream lid is supposed to be um oh we got out of we got out of my environment so I'm going to do cond activate chat with website there you go remember that if I do python SRC app.py that's going to give me an error because streamlit applications have to be run using streamlit run so I'm going to do stream L run and then the path to my application and and here I have it let me show you it appeared here on my other screen and here I have my sidebar with the settings the website URL and my title right here let me show you now how to add the chat components for the front end so in previous videos what we did is we had we were creating our own element to display messages right and that is a that is a good method and it allows you to to bend the possibili of what streamlit can to right out out of the box but since then actually streamlit has introduced a new component to their component list and now you can actually create chatbots that like chat GPT natively inside of stream lit so let me show you how to do that in order to create a an input bar for your dialogues you you can you do St dot chat input okay and here you just write like the prompt type your message here for example if I save this let me just open the application right here I'm going to say always rerun and here you see that we have our text input right here for our chat putut right now what we want to do as well is we want to add the messages and the nice thing right here is that you can add the messages after the chat input right here and they are still going to show on top so let's do that right now in order to add a message you have to say with st. chat message and between parenthesis you're going to have to say who is sending this message uh in this case I'm going to say that this one is the the human and you have to add semicolons right here and go um st. fright and then you just say whichever your message is so hello um let's say actually the first one is the AI and then we're going to add another message with st message chat message and this one is going to be human and we're also going to add St ride and let's say I want to know about um about Lang Ching for example there you go now if I save this you can see that here are the messages that are being sent here I mean my sidebar is still there and you can see that here is my my input right here and all of the messages that I add right here with using with st chat message are going to show like this so here I can for example add a third one one I'm just going to copy this one right here for AI nah so there you go here hello how can I help you I want to know no all right so that's not very helpful but now you now you you can see how to how to start creating these chat BS okay so for now we have only Built the front end what we're going to be doing right now is we're going to actually start giving it the capabilities and the possibilities to chat with your data from the website all right so let's do that now okay so the first thing we're going to want to do is we're going to add some functionality right here let's add some interactivity okay so what we're going to do is so that when the user types something right here we're going to reply something automatically okay so first things the first thing to do is to store the value of whatever the user writes here in a variable so let's do that let's say user query is going to equal this and then if user query is not known and also if it's not equal to an empty string what we're going to do is we're going to write our messages right here so if it's not none we're going to write a human message with the user query like that and we're then going to add a response from the AI and the response is going to be an automatic I don't know like this there you go and we can just erase this one right here now if we save this let's see what happens hello and it replies I don't know how are you I don't know okay so so far there is some interactivity right here but we don't have a history yet so let's add a history but before actually creating our history object what we're going to have to do is we're going to emulate our response from our language model OKAY in order to do that we're going to create a function called get resp response that is going to emulate that we it's going to simulate that we already have the logic behind our chatut okay so let's just create that function right here it's going to be get response it's going to take the user input and it's going to return just a very generic I don't know now let me just add some comments right here this one is going to be the app config right here is going to be the sidebar this right here is going to be the user input there you go now right here inside of the logic that is going to handle any change in the user input we're going to say that the response is going to be equal to just get response and we're going to pass in the user query from our user which is the text that the user is going to add right here okay and now instead of hardcoding the answer right here we can very well just uh return the response like this so now we are emulating our response from our chatbot which every time is going to uh respond I don't know but in a real I mean in an application that is already working instead of this part right here we're going to add the logic of our chat putut inside here so so let's save this and let's see how this works hello it seems to be working still how are you there you go so it seems to be working now what we're going to do is instead of logging one message at a time because as you can see right here we still don't have the the history instead of logging one message at a time we're going to log I mean we're going to show the entire message history and now that we have this function right here that's going to make it way easier so how this works is we're going to have to create a variable that will contain all of our message history okay I am going to initialize it right here on their app config I'm going to say chat history and I could initialize it as an MTR array but I'm going to initialize it with a test a sample message a welcome message from the AI okay something like hello I am a chatbot how can I help you okay so I'm going to initialize it as um an array and here I will add this message however when working with Lang chain what you want to do is you want to use the schemas that Lang chains comes with okay so the schemas are part of Lang chains core package so we're going to come from lank chain core remember this is a new syntax for the new version of Lan chain so from Lan chain core we're going to tap into the messages module and we're going to import the AI message schema and also the human message okay and here for the welcome message is going to be the AI that is going to be um adding this message uh sending this message so I'm going to say that this is a AI message and this one takes a content param and here you're just going to write whatever the content of the message is in this case it's going to be hello I am a bot how can I help you okay and this is it's important to use these schemas because these are the building blocks of any Lang chain application okay if you're using any other framework of course this is not what you're going to be using but since we're using Lang chain these are the schemas that you're going to be working with when you send when you work with with the messages for for the language model OKAY especially if it's a chat model um so now that we have this chat history variable initialized what we're going to do is we're going to append whatever the user sends as a query so whatever the user writes right here we're going to append it to the chat history so let's do that let's say the chat history append and we're going to append whatever the user wrote which is the chat query but we're going to append it as a human message like this and remember that it has to be inside of the content and there you go it's user qu it's the user query right there and now we're going to append as well the the response which we got right here and in order to do that we're also going to do his chat history append AI message content response there you go now I can delete this right here and just for debugging I'm going to show you what the chat history variable looks like in real time so I am going to log it in the sidebar so I'm just going to say that with my St sidebar I want to do St WR my chat history like that okay so there you go this is my application that is running and you can see that my chat history for now is only an AI message that contains hello I am a boat how can I help you now if I send a message saying hello you can see that I get a respon I mean that my message is appended right here as a second element as a third element we have the AI message with the response saying I don't know which is the one that we got from this me this function right here okay however there a problem with this and it is that if we for some reason want to ask another question let's say how are you our chat history is reinitialized okay which means that here my second element is no longer hello but is the new message that I sent and this is the new response um and this is a thing with Lang with uh with streamlit and let's just deal with that right now so the problem with this is that is in the way streamlit works okay so every time something happens in a streamlit application what it actually is doing is it's reloading your entire code okay so anytime anytime an event happens an event can be something like you type something here and hit enter or you type something here and hit enter anytime an event happens what streamlet is doing is it's reading your entire code again okay and that wouldn't be a problem if we were not initializing our variable like this right here because as you can see if whenever we type something right here it reads the entire code and while it's reading it it is reinitializing the chat history variable again with just that welcome message so what we want to do is we take we want to take this variable right here outside of the of the of this streamlet cycle and we want to make it persistent in the state of the application okay and in order to do that it's uh streamlet actually makes it very simple we're going to be working with an object called session State and the session state is an object that does not change every time you read the you reread the application okay so what we're going to do is we're going to say that if our chat history um property is not inside of the object session State then we are going to initialize it we're going to set our chat history to equal and we're going to initialize it just like we did before to this object right here like that okay and now when it's reading the application again it's it's going to arrive here and it's going to say so chat history has not been defined yet so we're going to initialize it with a single message and then the second time it comes here it's going to arrive here and it's going to say oh but this time chat history is already initialized of my session state so it's not going to re to redefine it and right now what we're going to have to do is instead of using chat history itself is we're going to have to tap into the session stage at history object instead now if we save this and we come right here you can say that if I say hello hello is appended here as a second message and then I have we my I don't know but now if I say how are you I hit enter you can see that it's actually appended to the rest of the conversation because now my chat history variable is not being reinitialized every time I something happens in my application okay so there you go and now we can actually show our conversation as messages and not just as a debug thing right here okay so for I mean we want this messages to be right here in order to do that instead of logging in logging them in the sidebar we're going to add here the conversation and in the conversation we going to say that for well here it is for our message inside of the session State chat history because we're tapping inside the chat history that is stored in the session state that we just defined we're going to say that if the message is an instance of an AI message we are going to add a chat message saying um remember that in order to add chat message you do with st chat message um and if I'm not mistaken we have to add here that it is a AI here we're going to write the message content okay and then else if it's a human message we're going to do exactly the same thing with st chat message and this one is a human and here we're going to say that St WR we're going to write the message content okay so let's see if this works there you go so just to make it clear and to be sure that we are all understanding what's going on here I am looping through all of the elements inside of my chat history which is stored in a session State variable and if it is an instance of my AI message object which are the schemas that we downloaded that we imported from Lang chain we're going to show it as a chat message and the chat message is going to come um it's going to be formatted as an AI with a little robot right here and if is it's an instance of a human message that means that we're going to Showcase it we're going to display it as a human message like this and we're just going to write s write message content like that and there you go okay so now let me just reload this hello if you see that if I reload this application the only message that I have is the first initialized message and then I can say hello how are you it's going to say I don't know um okay and then it's going to reply I don't know again so now our front end is pretty much finished now we can actually start coding the rag tools however something important to keep in mind is that at least for the purposes of our small application we remember that I showed you in the introduction that let's show it right here remember that I showed you in the introduction that if the user didn't write anything right here we were going to disable this part okay and that is very important at least for the purposes of this small application because otherwise we would have to handle what happens when the user sends a query and there is no website URL sent right here I mean that's also very possible to handle uh but for the purpose of this tutorial we're going to keep it as simple as possible so we're just going to disable all of this part if there is no website URL okay so let's do that right now um in order to do that I'm going to come right here to the side part part and underneath the website URL I'm going to say that if website URL is none or if it's an empty string I'm going to show an info box saying please enter a website URL okay and then else which means that if there is a website URL and it is different to an empty string I am going to actually show the application that we started to code so now if I save this and I come back here I reload this you can see that I need to enter about it enter a website URL I can I mean for now I can just enter whatever I want and now I have access to the chat but interface okay there you go what we're going to see now is what is actually happening behind the scenes in a rag applic okay um what is rag rag means retrieval augmented generation uh in other words it means that we're going to augment the knowledge of our language model with context that we're going to retrieve from a custom knowledge base okay um I have a diagram that I had made for a previous video if want to check that out this one comes from the video of chat with your PDFs but the idea is pretty much the same thing for chatting with your website okay what you're going to want to do well I mean what we're going to do in our application is we're going to take our HTML documents which are going to be fetched by adding the website URL right here and from them we're going to use Lang Ching to extract the text okay however the text might be huge I mean in our case it was a it was a short blog post but it can also be like a huge Wikipedia post or something like that and the problem is that you cannot feed a huge Wikipedia post to most language models um most of them have a context window that only allows you to send like uh limited number of tokens and if you send like the entire context the like all of your knowledge base you're probably going to go beyond that context window so what you want to do is you're going to take all of the text from your website and you're going to split it into different chunks of text so in our case for example um the blog post for Lang Lang graph um the first chunk is going to be probably the introduction the second chunk is going to be the first paragraph and Etc until the conclusion okay and this chunks of text then we're going to pass pass them through a an embeddings model OKAY in our case we're going to use an embedding models an embeddings model that also comes from open AI but there are other embeddings models that you can use um for example you can use them the ones that are available in hog in Phase okay now what does the embeddings model do what the embedding models uh do is they take your text in our case we're taking each chunk of text and they're going to vectorize it or in other words they're going to create a numerical representation of your chunk of text now why do you want your text to be in a numerical representation the answer for that is that with all of those numerical representations we're going to be creating a vector store and the use of this Vector store is that we're going to be able to find the chunks of text that are relevant to what the user asked in their query so for example if they're asking about Lang graph or what is a neural network or whatever we're going to embed their question using the same model that we used to to embed our chunks of text and we're going to perform a semantic search and the computer can only find uh can only perform a semantic search with vectorized data it cannot do that with simple words because computers do not understand words they understand numbers so in our case we're going to um have our vectorized chunks of text we're going to vectorize our user question and that is going to allow us to find the chunks of text that are relevant or similar to whatever the user asked so if the user asks a question about um for example what iside neural network the vector store is going to find which chunks of text are relevant to answer to that question it's going to return some chunks of text and from some and we're going to take those chunks of text to send them to our llm as context so the final message to our language model is going to look something like based on the following context and then we're going to paste whatever we found here answer the following question and we're going to send in the question from the user and in our case we're also going to pass in the history so our full prompt to our language model is going to look something like based on the following context and then we're going to add the retrieved chunk of text that we found from our HTML page answer complete the following conversation and then we're going to send the entire chat history of our conversation and then the user query so that it knows knows the history of the conversation and it also knows the context to answer our our question with okay so that's basically how rag uh chat BS work and uh I'm going to add this diagram as well in the GitHub repository that you can use it I'm just going to have to change this to HTML but yeah this is pretty much what is going to happen and the vector store that we are going to use for this tutorial I am going to use if I'm not mistaken but all there are many Alternatives there is pine cone there is quadrant uh there is f um and all of them have their strengths and weaknesses but yeah I hope that it's clear what is actually going on behind the scenes in this in this project so the first thing that we're going to do is we're going to create our Vector store okay and in order to do that we're going to take the contents of our HTML chunk them into split them into different chunks and then create the vectorized representation of them to store in to store them in our Vector store okay um now first before we do anything else we have to install a new package okay this package is called Beautiful soup because the tool that we're going to be using to fetch all of the text from our website uses a uses a library called Beautiful soup in case you haven't heard of beautiful soup is a library for scraping websites which basically just allows you to get information from any website um and in this case it's like very simple we're just going to be fetching all of the information in between P tags like paragraph tags right uh so in order to install it you can do pip install beautiful subp 4 or in my my case since I'm using cond I'm going to do cond install um because I'm using a cond environment but I mean honestly you can also do peep install uh beautiful sub 4 and that would be good um so now that it's installed what you can do right here is I'm going to say that from L chain Community because remember that uh in the new version of Lang chain all of the third party applic are stored inside of langin community and we're going to say that we're going to tap into the document loaders uh module we're going to import webbased loader okay and this is the one that requires um that requires beautiful soup I'm just going to add it right here beautiful soup 4 so you know there it is and now what we're going to do is we're going to add a new function down here that is going to be called um get Vector store from URL and then it's going to take our URL we're going to first initialize our loader using the webbased loader and this one takes in the URL and it's not like this and then from that webbased loader we're going to take the documents and the documents uh we're take them from loader. load and we're just going to return the documents for now I mean um the objective of this function is to return the entire Vector store but just for debugging purposes I'm going to start returning just the documents so get the text in document form okay so let's see how that works if I save this this and now down here if there is a website URL I'm going to say that the documents are going to equal get Vector store and then I'm just going to pass in the website URL that I got from the sidebar and I am just going to debug this adding a adding it to the sidebar with sidebar we're going to St write the documents okay so let's see how that works now I'm going to take my langra blog post and I'm going to come back here just rerun this going to paste this and just let's see how it goes now here it is now as you can see we have an array with a document inside of it and here we have the page content and all of this is the text from our blog post okay now as you can see we only have one one element right here because what is remember that what we're doing right now is we are right here we are just extracting all of the text from our HTML page okay now we have to chunk it into different text so let's let's just do that right now so in order to split all of our text into different chunks of text um we're going to be using a tool that comes from Lang chain uh that is called the recursive character text splitter okay um however langin actually allows you to do this in several ways if you want you can take a look at the documentation they have um a huge uh variety of text Splitters that you can use in our case we're going to use a very simple one which comes inside of Lang chain the Lang chain package P itself and from here we're going to tap into the text spitter modules and we're going to import uh recursive character text splitter like this okay and from here we're going to use this one to split the document actually let's put this in singular because uh remember that this one returned only one document so what we're going to do is first we're going to initialize our text splitter like this and we're going to initialize it using the recursive character text glitter that we just imported and we're going to say that the documents this time in plural or document chunks to make it easier we're going to say that we're going to use our text splitter to use split documents so that we know that the resulting elements are going to be documents themselves as well and we're going to pass in the document that we fetched using webbased loader let me just add a comment right here split the document into chunks like that okay now let's see how this looks like going to instead of now instead of returning the full document I'm going to see how it looks like if I return just the chunks and here we're going to say that we're returning the document chunks I mean this doesn't change anything just to make it clear for you um so now we can come back here I'm just going to reload this just going to paste this page again and if I hit enter you can see that we now have several documents right here and each of them contains different information from the website okay and they are shorter and what we were are right here here so far um also something important about this is that each document not only contains the content of the document itself but it also contains metadata all right and this includes the source of the document and the title and the language as well so this is important if you have like several several um data sources in this case we're only we're only talking to one to one um data source which is this blog post but if we had another if we had like if we were talking to several websites or something like that at the same time this would be useful to know from where our our chatbot is retrieving the information okay so there you go that's how we split the text Doc the text into different documents so we're going to create create our Vector store from these chunks that we have gotten from our HTML page okay um to do that we're going to need an embeddings model in our case we're going to be using open AIS and we are also going to need a vector store for the sake of this tutorial we're going to be using chroma which is a very simple very minimalist and very easy to use um Vector store that you can use in your local machine but feel free to use whichever you want I mean there is quadrant there is even pine cone if you want a hosted one um f so yeah just for the sake of this tutorial we're going to be using chroma and we're going to complete this right here so we're going to take those document chunks and we're going to import chroma remember that chroma is a third party integration so as of the new version of Lang chain this one is going to be included in the L chain Community uh package because all of the third party Integrations come in the um Lin Community package from now on and we're going to tap into the vector stores module and from here we're going to import chroma just like that and right here we're going to create a vector store from the chunks um so let's create it let's call it Vector store and we are going to initialize it from chroma and in line chain uh whenever you import a vector store from the third party Integrations you can also do you can also initialize your vector store from documents like this and this method takes two parameters the first one is the documents that you want in this case are the document chunks which themselves each each one of them is itself a document and the second parameter is the embeddings model that we're going to use remember that I told you that we were going to use open AI embeddings for this one and as of this new version of Lang chain we are going to be importing anything related to openai from its own from its own package so from Lang chain open AI we're going to import open Ai embeddings and we're going to initialize it right here like this open a embeddings don't forget to initialize it with the parenthesis otherwise it's not going to work and then we're just going to return this Vector store right here okay so now our get Vector store from URL is finished and we can just remove this debug right here now now next step is to actually use that Vector store so the next thing to do is we're going to have to remember that I told you that we were going to need an open AI embeddings model in order to vectorize our chunks of text okay uh in order to use the open AI model we're going to need the API key from openai so we're going to go to platform. openai come we're going to come to open AI keys and we're going to create a new key here I'm going to call it YouTube tutorial this is you can name it whatever you want and I am going to copy it and this is going to allow you to use the models remember that these models are paid for but they're pretty cheap so I mean you shouldn't you shouldn't really be paying more than a few sense for for an article like this for example um and now what we're going to do is we're going to come back to our project and we're going to create a file called EnV and this file is going to contain all of our secrets which means that it's going to contain our open AI API key now whatever you store here is going to be available to your application as a an environment variable and this thing right here we're going to add it as well to our sorry to our git ignore file and here we're just going to add EnV this is so that ourv file is not tracked on git and we do not accidentally push it to GitHub for example where other people can see it and they would be able to see our API key and they would be able to use it at your expense which probably you don't want that and which is also the reason why I'm going to be deleting this API key from my uh dashboard before uploading this video now that we have created all of these things in order to actually make this oh in order to actually make this environment V variable available to my application I'm going to need to install another package um something important remember that at least if you're using Lang chain you're going to have to name your open AI API key variable environment variable exactly like this because this is the name that Lang the environment variable name that Lang chain looks for by default otherwise you would have to specify it manually and here we're going to install python. EnV okay this is just for reference let me just install it I'm going to come right here I'm going to say pip install python. EnV make sure I am running inside of my virtual environment there it is I mean to you it might take a little a little bit longer because I already had it installed and now what you are going to do is you're going to say from EnV we're going to import load. EnV and now at the beginning of your application ideally you're going to run this function right here this function is going to make all of the variables right here a available for your application okay if you don't do this if you don't do this um this information is not going to be available for your application so now that we have our API keys we're now able to actually create our vect store with the open AI embeddings so so far it's fair to say that we have finished this part right here which means that we have extracted the text from our HTML files we have divided it have split it into different chunks of text um which are in the form of a document we have used open AI embeddings in order to vectorize them and create a vector store um not with pine con but with uh chroma okay now the next step to do is we are going to create a retriever chain the retriever chain is basically a chain that is going to take the user query and actually it's going to be a little bit different to what we see in this diagram because in this diagram we are only embedding um the latest user query and finding chunks that are similar to that user question but in this example that we're going to be coding in a moment we are going to be getting the the text the chunks of text that are relevant not only to the latest question from the user but also to the entire conversation so we're going to be embedding the entire conversation history and we're going to be using it to get the chunks of text that are relevant to the entire conversation so in order to do that we're going to come right here and I'm going to organize this in sort of a pipeline way so we're going to uh create a function that gets the retriever chain um I'm going to call it get context retriever chain because it's going to it's a contextual retrial chain and this one is going to take in the vector store I mean feel free to organize your code As You Wish um I think this is just makes it easier for educational purposes it doesn't mean that is the best way to do this in production of course um but here you can see that we're going to be using the vector store that we got here in order to to get our retrieved chunks of text or our retrieved documents Okay so so the first thing that we're going to do is we're going to initialize a language model okay um language models in Lang chain come either in the community in the third party Community package or since we're going to be using open AI models as of the new version they come inside their own package inside Lang chain open AI so we're going to import the chat model which is chat open Ai and we're just going to initialize it like this right here okay uh the second thing we're going to do is we're going to uh create a retriever now in Lang chain pretty much every Vector store that you create has a method that Returns the same Vector store as a retriever that is um that allows you to use it inside of U that allows you to use it to retrieve uh relevant text related to a to a query okay and then finally we're going to initialize a prompt now I don't think we have imported the chat prompt template so we're going to do that right now um the chat prompt template you're going to import it from L chain core um yeah I'm going to do this right here from lank chain core because remember as of the new version the core components of L chain come inside of the package L chain core and from here we're going to we're going to tap into the prompts module and we're going to import chat prompt template and also inside from here we're going to import messages placeholder so the prompt that we're going to initialize we're going to initialize it as a chat prompt template which basically is just a prompt but in the form of a list of messages and this one some this one takes a an array of messages sorry I forgot to mention that here we need to initialize it from messages in order to actually in order for it to actually take an array of messages and right here the first element that we're going to pass in is a messages placeholder with a variable name of chat history like that okay now what is this messages placeholder right this uh doing so as I told you before this right here is a prompt that is going to be um populated with the variables that we're going to pass in and the messages placeholder just replaces all of this with the value of the chat history variable if that variable exist otherwise it's going to leave it empty okay this is important because if at the beginning of the conversation we do not have a chat history this is going to remain empty and as the conversation continues this variable is going to change so uh that's how you use messages placeholder um the second element right here is going to be um also something interesting right here is that right here we're going to pass in a human message we could I think that technically we could use human message uh schema however Lang chain also allows you to send in messages as a topple the first element of the topple is going to be the kind of um the type of message that this is in this case it is the user and remember that in prompts at least in lunching they work pretty much the same as F strings in Python which means that you're going to add here your variables and then when you populate the prompt this variable right here is going to be populated with whatever uh value you set to this variable right here I'm going to show you exactly how how this works in a moment but so that you see it in action but just um keep in mind that this fireable right here and this varable right here are going to be populated with whatever I pass in in the chain and then we're going to add a last um uh message to this prompt and it's also going to come from the user and it's going to instruct the language model I have it right here let me copy it cuz it's a bit long it's going to it's going to prompt the language model to given the above conversation because remember that we have the chat history and the latest input from our user given the above conversation generate a search query to look up in order to get information relevant to the conversation which basically is going to create um um a search query that is is going to find the the chunks of text that are relevant to the entire conversation and not only to the latest prompt okay um and then finally we are going to use a method that also comes from Lang chain itself called create history aware Retriever and this one comes from Lang chain from Lang chain from the Lang chain package itself so from here uh you're going to tap into chains and we're going to get the create history aware retriever okay and uh this was this one's actually going to be the the complete retriever the retriever uh chain so I'm just going to initialize it like this retriever chain and I'm going to say create history aware Retriever and this one right here takes as first as first argument it takes a language model which is the one that we just initialized right here the second element is a retriever which is the retriever that we um got from the vector store that we had previously created so let me just add it right here and the last part is the prompt which is the one that we initialized right here and then this is the one that we're going to be returning uh from this function right here uh in order to show you how this works let me in order to test this function that we just created um I'm going to call it from inside of from inside of here so after our user sents a query I am going to call this chain the chain that has been returned from this function um that we have right here to see which documents it has retrieved right because remember that what we're doing here is we are retrieving the documents that are relevant to the entire conversation and that's what the chain is doing so let's just come down here to after the user query and let's call our retriever chain that we just created um in order to do that um actually something important that I forgot to mention before is that since we're using chroma we're going to have to install the package for Chroma so I want you to pip install chroma DB um now I have already installed it off camera but uh it's probably going to take a little bit longer for you and I'm just going to add it here chroma DP and um this is the now once you have installed it you're going to be able to run this code right here um so we're going to take the user query and we're going to pass it to the retriev chain so let's test the retrieved documents and we're going to use of course the retriever chain that we just created and as of the latest version of line chain in order to call a chain you need to use the method invoke now invoke takes uh an object with key value Pairs and in the key you're going to have to write the name of the variable that you're going to replace in the prompts that are inside of your chain right remember that here we have two variables chat history and input so these are the ones that we're going to be replacing uh so we're going to pass chat history and we're going to pass in the chat history that we saved in the session State and the second uh variable that we're going to pass in is the input which we're going to send as the user query uh which is the one that we send right here okay and these retrieve documents how about we just log them s WR retrieve documents okay let's see how that works um so let's come back here I'm going to take my web my blog post again I'm going to run it and here I'm going to say what is Lang graph and here if I'm not mistaken we're going to get the documents that are relevant to this conver to the entire conversation because remember that we're passing in the entire chat history okay and there you go now you have the documents that are relevant it seems to be working correctly I'm going to remove this test right here because um that's not how what the application is supposed to do but now we have tested that the retriever chain is working correctly so we have successfully tested that this part of the application works correctly now what we want to do is we're going to create a last function and what this function is going to do is it's going to return us the final chain that we're going to need to actually respond to our prompts okay um this final chain let me show you in the diagram so we finished this chain that would give us the ranked results I mean the documents that are relevant to not only the user question but to the conversation now what we want is a chain that will take this documents and we'll include them into another prompt saying something like based on the following uh context and then it will pass the documents answer the following question and then we will pass the question of the user alongside the chat history and then we will get an answer so let's create this function first um this function is going to be called it's a a stuff documents uh chain let me just let me just um import it first uh in order to use this you're going to have to import this directly from Lang chain and it's going to come as well in the chains sorry in in the chains module so from L chain the chains and in this case we're going to we're going to go into the subm module combined documents and we're going to import the function create stuff documents chain now this function right here what we're going to do um let's call it um get let's call [Music] it get conversational rack chain and this one since we are doing this like a pipeline so this one takes the respon The Returned element from this one this is going to take the returned element from this one which is say retriever chain right and here we're going to be using this function right here okay stuff documents chain like that and this function as you can see right here it takes a language model and a prompt it can take an output passer as well we'll just add a language model and a prompt so let's declare them up here this one is going to be our chat open AI that we had previously imported and in order to create a prompt we are going to to create it from the chat prom template and just as be we did before we're going to create it from the messages right now we're going to start the prompt with a system message telling the AI what it is supposed to do so I have this text right here it's a very very simple prompt it goes like this answer the user's question based on the following on the below context and then you just add the context and this is a function that we're going to have to to this is a variable sorry that we're going to have to replace during the chain okay when we call it uh I'll show you how that works in a moment now the second part is actually the messages placeholder just like we did before um this one is going to take the variable of chat history and it will be populated if we have a chat history hisory in this chain if it doesn't have a chat history it's going to leave this blank and then lastly we're going to append to our chat history our user input like that okay and then let's just close our prompt so as we were saying the stuff documents chain the first element that it takes is a language model and the second one is the prompt that we have just initialized right here there you go however this chain as you can see it all it's doing is it's just taking the the context that we're given it and it's passing it in it's passing it inside of here and right so when this in other words when we call this function what is actually going to be happening behind the scenes is there is going to be um stuff documents chain invoke and then as as a parameter we're going to pass in the context which are going to be the documents that are going to be retrieved from our retriever function and then of course the chat history and the input um which is the users query however right here we don't have the retrieve documents yet what we're going to do is link these two these two chains together so we have the retriever chain which gives us the documents that are relevant to our conversation and the the stuff documents chain which uses those documents to return an answer and given the chat history of course so we're going to basically just plug them in together using this other function called create retrieval chain okay create retrieval chain actually I haven't imported it let me just import it in a moment it also comes from chains I'm going to call and it it's called create retrieval chain like that so it goes from it comes from Lang chain. chains so you're going to create you're going to create re one second create retrieval chain like this and the first element that it takes is a retriever it can be either a vector store as retriever as we did for the retriever chain or it can be a runnable and a runnable is in other words in this case it can be a chain and we're going to pass in the runnable of the the runnable that was returned from our function up here which is the one that we're going to be passing as an argument right here so let's pass that one first um the retri a chain and then secondly it takes a combined documents chain which is basically the one that we had just created up here so let's copy it and paste it right here and actually this is the this is the last uh chain that we're going to be returning so this function right here all that it's supposed to do is it just I mean just to recap this function right here it is creating a documents chain that will take context and answer whatever question we have based on the documents that we pass as context and it's plugging that chain together with the retriever chain that we did before to create a final to create our final chain that will take the will'll take our user query our chat history and and it's going to return to us the entire uh it's going to return to us a an answer based on the entire conversation and on the context that the chain has found okay so let's test this chain right now and see how it does in order to test this function right here we're going to call it inside of our application okay and a good place to call it is right here once the URL of the website URL has been entered by the user right in order to do this actually what I want to do first is refactor this a little bit and actually I just want to initialize the state of the application I mean the the initial the chat history in the session state if there has been a website URL added otherwise it we don't really need it so let me just add here session State and then right here create conversation chain and actually something that I wanted to mention is that we probably need to make the vector store persistent as well because remember that in order to create the vector store we used the embeddings from open aai and that is even if it's not an expensive model it it is resource I mean it is resources that we would be spending every single time that the application runs we don't want to be re-embedding the same content from the website every single time that we make a query so let's just add the vector store to the session state right here if the vector store is not in session State what we're going to do is we're going to set the session State Vector store to get our Vector store from URL and now instead of instead of calling it from here we're going to call it from the session State like that okay there you go so now we have our Vector store in the session State we are creating our retriever chain from the vector store that is in the session State and now we can actually call our conversational rack chain from here so let's do that what we do let's just add here conversational let's call it conversation rag chain and this one is going to be equal to get conversational rack chain and then we're just going to pass in the retriever chain like that so there we go and this is the one that we're going to be able to use to actually answer the questions from our user so here let's do instead of calling it from the get response part let's let's call the conver ation rack chain like this and remember that since we're using a chain we can use the L cell language the Lang chain expression language to only pass right here the variables that we're going to need to replace in our in our prompt okay and that is actually very simple the first variable that we're going to have to to to to fill is the chat history and we're basically just going to pass in the chat history from the session State and secondly of course we're going to pass in the input from the user all right and let's just call this the response and let's see what the response is before before actually logging um like filling the messages Etc let's just let's just write the response like this and see what it contains okay so let's come right here let's just rerun this plug this in right here now it is embedding all of the contents here vectorizing them and here we have this now let's say what is Lang graph and there you have it here you have the response and apparently the response contains the context it contains the answer saying that langra is a module built on top of Lang chain Etc and it also return to us the chat history which is very convenient okay so now we see that we have have to use the answer right here um and this is the part that we're going to to to return um let's add this part all all of this part to the get response function because that's what we I mean that was the objective from the beginning right to to update this with the actual logic that is going to be happening behind the scenes so let's do that now you know that to refactor all of this into the get response function what we're going to do is we're going to take all of this and all of this out of here and Abstract it out to only leave the user interface with the function get response and that that should we we will deal with all of the logic behind the scenes so in order to do that I'm going to move this get response function and I'm going to move it right here underneath the other functions and it is here actually that I'm going to add these two functions right here there you go now I know this is not the most optimal way of doing this recreating the entire retrieval chain and the conversation chain every time the user makes a question but the thing here is that we're mixing the back end and the front end to make this easier to understand okay so in a real world scenario or in a more or a closer to production application what would happen is that all of this would be in the back end right and this would be initialized and we would just expose the the method from the last fun from the last um chain the method invoke that will be the only thing that we would expose but here since we are doing this all of it in the back end and the front end at the same time we are a bit forced to mix these things together so let's just return the response right here okay so every time the user asks a response we're going to build a retriever chain we're going to build the conversational retrieval chain um and we're also going to invoke it with this with the chat history and with the input okay and this function is of course never going to be called before our chat history is initialized because the only the only place where we call it is underneath here okay so now we can oops now we can uncomment this these two things and remember that the response actually included an answer element and this is the one that we're going to be returning because this one is the one that actually return that actually contains the the the answer from the chat but because there was the the response contains also the context and the chat history but that's not what we're going to be needing for now so this I suppose that should work let's just test it and see we're coming back here let's just reload this and again I'm going to try with langra again and let's see let's say um do you know what is langra let's see what it returns if it's going to tell us there you go and now let's just to test the conversational part of it can you explain that in simple in simpler terms let's see if it remembers what we were talking about before there you go of course langra is a tool that helps you there you go so now we have a conversational retrieval chain that works correctly with the data that we're passing in from a website okay let's test it now with Wikipedia for example so to test this again let's run it through the 2024 US presidential election and just to show you that it actually does not work without the augmented data I'm going to use just chpt 3.5 which is the language model that we're calling in our application and let's say who are the candidates for the 2024 US presidential election and it's probably going to return that it doesn't know because it's knowledge ends in January 20 2022 um so what we're going to do is we're going to take this URL we're going to paste it right here now this is indexing all of the data in that website I mean in in that web page and let's say let's ask the same question again who are the candidates for the 2024 US presidential election and it is going to say that as of now the candidates are have not been officially determined the incumbent President Joe Biden is expected to run Donald Trump Etc okay so it seems to be working all right who were in the primaries for example let's see if it also continues the conversation knowing that I'm talking about the 2024 presidential election and it does so everything seems to be working correctly um there you have it you have an application that is capable of responding questions responding to qu to your questions about any website um that has text in it and I hope this was an easy thing uh that it wasn't too hard but that it was challenging I hope that you learned a lot especially about the new features of the latest version of lank chain and how some of the packages have been restructured I hope that you like this and remember that if you like videos like this don't forget to subscribe and to uh leave a comment to tell me what kind of other videos you want to see all right thank you for watching and I'll see you next [Music] time [Music] [Music]
LBNpyjcbv0o,2024-01-24T10:07:00.000000,Create a RAG Chain using LangChain 0.1 (New version),good morning everyone how's it going today welcome back to this new video tutorial and welcome back to the channel uh today we're going to be covering langing version 0.1.0 uh which is the new and stable release and we're going to be going through the quick start which are all the lines of codes right here in this page of the documentation okay we're going to be explaining what each line of code does and how to install the new version of lch what has changed from the previous version to the new version and how to use the new version to do things that you probably already knew how to do but they're a little bit different now uh for example we're going to be creating a retrieval chain we're going to be creating a conversational retrieval chain and we're going to be introducing the new packages that come with langen now okay so remember that if you like content about uh software development and artificial intelligence and more specifically tutorials on how to implement these things don't forget to subscribe and to leave a like and tell tell me what what other kind of videos you want to see in the comments okay thank you very much for being here and let's get right into [Music] video okay so the first thing that we're going to want to do is we're going to want to open a jupyter notebooks if you don't have a Jupiter notebooks you can always use from Google it's also pretty useful and it hasn't changed a lot how to install lch Okay so first you're going to do bip install lanching now what does this do um remember that I told you in the previous video that as of this new version of Lang chain Lang chain is now divided into three different packages we have Lang chain we have Lang chain community and we have Lang chain core okay now Lang chain core contains basically the main abstractions from Lang chain for example The Prompt class the human message class the system class uh system message um and all of these schemas These are the main building blocks for your applications and they are located inside langin core the third party Integrations are contained in langin community these are for example language model providers Vector stores or tools for your agents to use and lastly we have Lang chain itself which contains some pre-build chains and other pre-build components that can help you bootstrap your application um more quickly okay and when you do pip install Lang chain you're actually installing all of them at the same time um if for some reason you only needed to install langin Community or you only needed to install langin core all you would have to do is PIP install Lin core or pip install langing community and that would only install that package okay in in our case we want to install all of them however there is also a little detail that you should note is that not all Integrations not all Integrations live inside langin Community um langin has around 700 third-party Integrations and some of them which are probably the most relevant ones have their own package okay so some of them for example open AI Google and mistol have their own package and in this case you would Al if you want to use those providers you would need to install their own package in Lang chain okay and this is the case in open AI uh which is the models that we're going to be using for this tutorial so pip install Lang chain um open Ai and this one is going to install not only all these three packages right here but also the packages related to open AI this is probably going to take a little bit bit longer for you because I already have this installed but there you go all right next thing to do is to get our API keys from open AI remember that in the order in order to do this you have to go to platform. open.com create an account go to API keys and then create your new API key I'm just going to name it test like that and of course I am going to disable it before uploading the video copy it right here and we're going to name we're going to add it here we're going to import OS and Os we're going to set OS Environ to set a new environment variable and remember that when you're using Lang chain the openai API key environment variable has to be exactly open AI API key in order for this to work if you name it differently it's not going to work or you're going to have to um pass it in as an argument um explicitly every single time so that's how you do it and now you can actually start using the open a language models with langing let's try something real quick we're going to do from L chain open AI remember that we're going to be importing our Integrations from open AI from the package Lang chain open AI we're going to import chat open AI there you go and now we're going to initialize our language model like this chat open AI now this is going to initialize our language model and now we can actually start using it we can do lm. invoke which is the method from language Lang expression language that you're going to be using to to invoke your language model okay and here we can ask whatever we want so we can say for example um what is Docker and how is it useful for deployment and let's see what it says again this is not going to work if you don't have the API key already set as an environment variable okay and here we have the answer as an AI message because we're using chat open AI if we had just initialized um open AI like that it would not have returned the message itself so there you go seems to be working correctly all right so what we're going to do now is we're going to create our first chain okay in order to do this we're going to have to first of all import um create a prompt template and then we're going to have to take our language model that we initialized together and we're going to chain them together to create our first ever chain okay um so the first thing to do is to create our prompt template in order to do that we're going to have to import it from L chain core because remember that prompts are a core component of Lang chain and we're going to go look inside prompts module and from here we're going to import a chat prompt template like that and now we can initialize it by doing prompt equals chat prompt template like that and we're going to call a method called from messages okay now this method takes in a list of messages um the messages can be at topples for example in this case I'm going to create the to a topple in which the first element is is the kind of message that we have so in this case it's a system message I'm just going to write um you're an English French translat translator that responds whatever the user says in French let's say returns whatever the user says in French and the second the second message is also going to be a topple and it's going to be the user message and here instead of actually saying the full thing we're going to just add an input um variable now this one right here is the one that is going to be parsed in the chain with whatever input the user whatever message the user sends to the chain okay so let's initialize this and once that it's initialized we're going to be able to create our Chain by doing llm n sorry we start with the prompt and then we chain together the llm that we initialized up here okay so there you go now that the chain is initialized we can do just like before the same method invoke and we're going to be able to to call it just like that so here let's say I enjoy going to rock concerts um now there was a problem here let's see what it was expected mapping type oh yeah sure sorry here actually you cannot just invoke it like this you're going to have to send in an object with the with the variable names that you included in your prompt okay so in this case this is going to be an object like that and the name is going to the first um it takes key value Pairs and the key is going to be the name of your variable and the pair is going to be the value of that variable so this one is going to be replaced with this and now let's see what it returns to us there we go pretty good so it seems to be working correctly now we have our working chain and now next we're going to add another component to our chain which is going to be an output parser all right so now we're going to add an output parser to the chain um now what is an output pars an output parser is basically um a core component of Lang Ching that allows you to make sure that at a given step of your chain or at the end of your chain you're going to get a data type or a file structure that you want okay so in this case we got as a response an instance of an AI message object and it contains the content right here which is the response that we were expecting but what happens if we wanted to every single time get a string Str as an answer instead of the entire object we can use the string output parser to do that now in order to do that we have to initialize it first and we have to import it from the Lang chain core package and we're going to have to go look at the output parsers um module right here and from here we're going to import the string output parser there you go and now we just initialize it as as an output output parser we're going to initialize it as a string output parser like that there you go once it is initialized we we can re re declare our Chain by saying that it's going to use the prompt first then it's going to use the language model and then in the end it's going to pass the result as an output uh through the output par that we just initialized up here okay there you go now let's try our chain again we're going to chain to chain invoke and remember that this one takes a a an object with key value pairs um this is very important because if you have here we only have one one input variable right but if we had more variables we would be able to add them right here like variable two Etc and this is going to allow you to get richer results in this case we're going to continue like that so we're going to say that the input is going to be let's say my friend Robert has a oops has a blue cat why not and let's return it and see what it returns there you go and here as you can see in return instead of getting an an instance of an AI message we can just this string and that's pretty convenient there you go so now let's actually use this chain to create a retrieval chain that is going to get our our documents from a website a PDF file Etc to be able to chat with it okay so let's do that now okay so what we're going to be doing now is we're going to be creating a a retrieval chain in the new version of Lang chain and see how that is different to what we're used to doing okay now what is a retrieval chain it's basically a chain just like what we created before but instead of answering the questions with the knowledge that the language model was already trained on I mean with the language with the knowledge that it already has we're going to enrich this knowledge with a private or with a new data source so that you're able to talk to your language model about um something that it may not be aware of so it can be your private data it can be um some news data that of something that just happened yesterday or something like that um and the language model is going to use it to respond to you okay um what we're going to do here is we're going to just ask about the latest Lang and release um which I suppose the language model is not aware of and we can test it right here like that we're going to we can do llm invoke um what is new in Lang chain uh in Lang chain 0.1.0 and let's see what the language model knows uh they say I'm sorry but I cannot find any specific information about a programming language or framework called Lang chain and its version 0.1.0 okay so um the language model has no idea what this is about so what we're going to do is we're going to pass in this information from the blog post and ask about it okay in previous tutorials and in previous videos of this in this channel we have been using PDF files and CSV files as kind of private data to talk to our language model um but in this example right here we're going to stick to what the quick start um they're doing in the quick start and we're going to load instead of a PDF file or something like that we're going to load a website okay so we're going to be able to just add in the URL of any website and talk to it and ask questions about it okay so in order to do that we're going to first let's just write here retrieval chain and something interesting right here that you have to know is that we're going to use a technique called scraping okay web scraping which is basically a technique that goes to a website makes the request and and then just Returns the valuable information that we that we need and in order to do this I mean this comes already with Lang chain but in order to do this you need another Library uh which that is very commonly used for scraping and it's called Beautiful soup so we will have to install it for our loaders to actually work we're going to do pip install beautiful soup 4 and then once it's installed um you should you should see a success message right here and we're also going to use a vector store in this case we're going to use f just because it's very it's very simple and easy to to get going in memory but you can use whichever you want um so in order to install it we're going to do pip install F CPU as well and there you go great now if you have any questions about how what is actually happening during the retrieval process you can check out this other video that I'll put somewhere around here uh where I go over this in a much more um easy and and approachable way okay uh but for now what we're going to do is we're going to initialize our webbased loader with the URL of this website right here okay so in order to do this we're going to go to L chain community so from L chain Community we're going to oh and we have to getting to the document loaders document loaders we're going to import web base loader like that okay and in order to initialize it we're going to need the URL of the web page that we want to load so the loader is going to be equal to web base loader and this one only takes the URL of the web page that we want to load and it's very simple just paste it like that and then we're going to say that the docs are going to be equal to loader. load and this is going to return the document uh object of this U of whatever is inside of this website okay so let's see how that goes now that's let's take a look at the documents and here you have all the data all the text from this website and of course you can use this for pretty much any other website that has uh I mean it should be a little bit organized the HTML structure because I think that what this loader does is it basically just takes a look at any P tags paragraph tags um but yeah I mean this is how you can load any website you want and as you can see a document object is still as it was before you still have your document object you have your page content like this and you also have just like before your metadata which should be somewhere around the metadata which should be here here's the metadata you have the source and you have the title and you have the language of the website okay so there you go now you have our documents and now what we're going to need is we're going to need an embeddings model to add them to our Vector store okay so in order to do that we're going to also use open AI embeddings so remember that open AI has its own package now so now it's from Lang chain open AI we're going to import open AI embeddings like that so the embeddings are going to equal open AI embeddings like that and remember just like before you should have your API key set as an environment variable just like I showed you before for this to work and then what we're going to do is we're going to import f as a vector store now this one comes in the Lang chain Community package and in a module Vector store Vector stores there you go we're going to import F and then from Lang chain. text splitter oops text splitter we're going to import recursive character text splitter okay this is going to create our Vector store with shorter documents so that we can fetch only the ones that are relevant to our question okay so first of all just like usual you would create your text splitter and we're going to go to we're just going to create an instant self recursive character text splitter like this then we're going to get our documents like that and we're going to split them using our newly created text splitter like that we're going to say split documents and we're going to split split the docs that we just got from here from the loader okay there you go and then this one with this one we're going to create our Vector store there you go we're going to create it using F from documents docments because we're creating it using this ones right here and then we're going to pass in first of all the document F the document file and the embeddings that we created before up here okay there we go you know what let me show you first the documents how they what they look like the documents are just like I told you before it's pretty much the same format as before but you have um this time we have two of them I think there you go and now we create our Vector store with these two documents and and there you go now you have your vector store your and you can start using it to create your your chain okay now let's create our prompt template for this retrieval chain all right what we're going to do now is we're going to create our prompt template and we're going to use that prompt template to create a stuff documents chain okay now here is something that's a little bit new about Lang chain um that has changed in the naming convention and the way to create um chains that are that come pre-built with Lang chain is that for example chains that you would usually create using something like this like this uh your chain conversation dral chain from llm Etc now it's pretty much just a function that returns a chain that's written in Lang chain expression language and it can be of course modified using Lang um Lang chain expression language so first we're going to have to import it so let's say create lank chain create chain for documents there you go and here we're going to first of all we're going to import from Lang chain. chains combine documents combine combine combine of combine documents we're going to import create stop documents chain there you go so I told you this is now a function this is not a class that has a method in it so we're going to do prompt it's going to equal chat prompt template remember that we imported this before and this one takes the template and we can we can actually decare the template before the template is going to be I have it right here it this one also of course comes from the documentation um here it is so it is going the template basically just tells you just tells the language model answer the following question based only on the provided context it it gives you uh where the context variable is going to be replaced and then it gives you the the input variable which is going to be the input from the user that we're asking like like whatever we're asking as a as a user to the language model and here we just pass in the template there we go and now we can use this function right here to create our document chain so let's say document chain is going to be equal to create stuff documents chain and here we're going to pass in first of all a language model which we have already initialized and second of all a prompt which is the one that we created right here so let's create a prompt like that and there was a problem takes one positional argument to given um oh yeah I forgot that here we have to say from template there you go seems to be working correctly now we can actually start man we can test it by manually passing a document okay let's just create one very quick document and remember that the documents we import them from L chain core because it's one of the main main one of the core components of Lang chain so we're going to do from Lang chain documents import document and we're going to create an instance of the document we're going to call the document chain that we just created and remember since we're using the new version of langin in order to run it or to invoke it you use the method invoke and remember that you pass in the variables that you previously declared right here context and input so first of all let's just pass in our input and we're going to ask it um what is new in l chain 0 point well let's say what is length chain 0.1.0 and just let's pass in the context this is just to show you what is actually happening behind the scenes when you do the retrieval okay behind the scenes um the chain is going to plug in right here in the context variable whatever the retrieval chain found that is that are documents related to your question okay so here we're asking this and let's say that the retrieval chain found a document that has the page content that says um Lang chain 0.1.0 is the new version of a llm app development framework so that's the documents this is kind of this is the context that um our that our chain is going to use and let's see how that goes uh page content tople topple topple oh yeah this has to be inside an array like that L chain and then it Returns the information I mean pretty much the same information that we s that we gave it as a as a context okay so yeah this is what's happening that's going to happen behind the scenes and this is how you create the document chain um all right so now it is time to actually create the retrieval chain so that this part right here is taken care of automatically without us having to to input manually the document which is going to be the context all right so let's do that right now all right so now let's actually create our retrieval chain I'm just going to add it right here create retrieval chain like that and so in order to do this we're going to have to import it from Lang chain itself so we're going to say from from L chain chains we're going to import create and you can see here that you have a lot of examples we're going to use create retrieval chain remember now as of flank as of the new version of lanching we use this kind of um this this functions to create our chains instead of using methods inside of the inside of the classes and we're going to first of all create initialize our retriever which is going to come from the vector store the that we created before so Vector store this one is calling the object that we initialized right here from f using the documents and the embeddings that we already got and we're just going to say as retriever this doesn't change at all from previous versions of Lang chain and now we're basically just going to create our retrieval chain retrieval chain like this and we're going to call create R oops create retrieval chain like that and this one takes in first of all a retriever which we just initialized retriever equals I's just call let's just passing it like that and the second one is the combined documents chain which is also the chain that we created just a moment ago up here so let's say documents chain uh sorry I called it document chain like that and there you go now we can execute it and see now what this chain is going to do is it's going to fetch the documents that are similar to my query to my question and then from use those as context to answer my question okay so let's test it let's see that my response is going to be equal to my retrieval chain my retrieval chain we're going to say invoke remember because we're using LCL LL invoke and here remember that we pass in an object first of all we pass in the input and the input is our question now let's ask what is new in Lang chain 0.1.0 let's see now once that's running we're going to be able to see the response let's see all right so here we have the answer um there we go so we have the answer we have if I mean the response the entire response object contains the input which is the question that we asked it contains the context that were returned that was returned um from the documents that were found that were relevant to the question that I asked and finally we have the answer okay so how about we just print the answer alone let's go like this and say answer uh in Lang 0.1.0 the new features include improved Focus Etc okay so now it knows what Lang chain is and it now knows with langing 0.1.0 um includes okay so that's going pretty good but so far it is only responding to our questions and it's not remembering anything it's not like conversation based so let's convert it to a conversational retrieval chain not only a retrieval chain okay and we're going to see how to do that also using the new version of lunching real real quick all right so what we're going to do now is pretty much the same thing that we have already done but we're going to include a conversational element to it okay so so far if you ask a question it returns to you an answer given a um a context that you already passed into the vector database however what we what it doesn't do now is it doesn't keep track of the conversation it doesn't know what you asked before so we're going to make it conversation aware okay let's just add another subtitle right here and we're going to say conversational conversational retrieval chain all right so just to be clear what this is going to do is exactly the same thing as the previous chain that we just created a few seconds ago but it's going to have two main differences first of all it's going to have um that the retrieval part of the chain is going to take into consideration the history of the conversation this means that the re the moment where it goes to fetch all of the documents that are relevant to the question is also going to take into account it's going to take the documents that are relevant not only to the question of the user but to the entire conversation and second of all it's going to take into account the history as well in the language model prompt which is the one that is going to be sent to the to the language model to get us the final answer okay so let's do that first of all let's create our history aware retriever to get the documents that are um relevant to the entire conversation uh we're going to get that um from Lang chain the Lang chain package itself Lang chain. chains this time we're calling Lang chain because we're using not not one of the third party applications or the core components of langin we're actually using something that lanching creates for us uh so that we that uh one of the functions that are ready to use and we're going to call the create history aware retriever function remember that we're using this kind of function naming uh this time instead of just importing the class and calling a method within the class uh and this is also a new thing from Lang chain uh from the new version of Lang chain so and then we're going to say that from Lang chain core this time we're going to download this from prompts we're going to import message placeholder and I'm going to show you in a moment how this one right here Works um so let's create our prompt for this for this history aware retriever we're going to first of all create a prompt from a chat prompt template and we're going to create it from messages remember that this method takes in a list or a an array of messages and the first element here is going to be the message placeholder and it's going to have a variable name variable name of chat history like that now what does this do very easy it basically populates this part of the prompt with the variable chat history if the variable is defined okay if it's passed into the chain if it is not passed into the chain then there is um then it leaves it blank which is very useful for this kind of usages like the chat history because the first message of the conversation is not going to have a history okay so after that we're going to pass in the first message which is going to be a user message and this one is actually going to be the input of our of our user so this is the actual question that our user is asking okay and second of all we're going to another user um message but this time I'm going to pass in this message that I have written right here it's see of course this is simply the commentation as well and um given the above conversation generate a search query to look up in order to get information relevant to the conversation it's basically a way to summarize the entire conversation into a single prompt uh to give a to retrieve the actual important uh documents to the conversation and after that what we're going to do is actually create the retriever chain okay so let's do that retriever chain and here is going to create we're going to use the function that we created that we imported before create history aware retriever now this one takes first of all a language model which is the one that we already imported it takes a retriever which is the one that we already defined as well and last it takes a prompt which is the one that we just created there we go oops now we can one second now now we can execute this and see how that goes we have an error right here Lang Shen core prompts not prompt there you go um okay so now we can actually emulate the emulate a history create a mock history conversation to see what what is going to happen when we have actually history okay uh to create a history a mock history with the chatbot I am going to I'm going to use the schemas or the messages uh the message objects that come with Lang chain core okay so from Lang chain in this case of course it's from Lang chain core messages we're going to import human message first of all human message there you go and second of all we're going to import AI message okay and then create our mock chat history remember that this is a list and the first message is going to be a human message and remember that the schemas of messages in Lang chain look like this you create a message inside you put the content and let's say um is there anything new about L chain 0.1.0 and then let's say that the AI is not feeling very communicative right now so we're going to a simulate I mean we're going to pretend that the AI only responded Yes and that's all okay um now what we're going to do is we're going to call our retriever chain and see if it finds something relevant to this conversation right here okay so let's call the retriever chain we're going to call retriever retriever chain remember that we're using L cell um um Lang chain expression language so we're going to use invoke to call the chain and remember that this one when you call invoke it takes um an object like um it takes an object with key value pairs okay now the first the first um variable the first key that we're going to pass in is going to be the chat history sorry and this one is going to equal the chat history the mock chat history that we just initialized up here okay the pretend the chat history and it also it's also going to include an input which is going to be the follow our follow-up conversation okay so we have this conversation started is there anything new about Lang chain 0.1.0 then the AI is going to be like yes and now we have our follow-up question that has tell me tell me more about it all right and now it is supposed to fetch the documents that are relevant not only about this single message because this single message doesn't say anything at all it only says tell me more about it what is it but since we're passing in the chat history variable to our retriever chain and that variable is declared right here with the message plus holder it is going to be injected into our prompt template and into our prompt and it's going to be passed is going to retrieve the relevant documents relevant to all of the conversation okay so let's see what it returns there we go uh so we have how many documents do we have we have one we have two documents and we have three documents that are relevant to this conversation right here okay and these are the documents that we are going to pass in to our other part of the chain which is going to be the actual chain that is going to to send the context aware conversation to the language model okay so let's do that right now all right so now that we have this chain right here that gives us the Rel relevant documents to our chat history and our question let's add something else and let's just pass that into another chain that returns an actual answer from that okay so let's do that right now in order to do that we're going to use um something that we have already imported before um let me just reimport it so that you so that you know what we're using I'm just going to import from Lang chain chains a retrieval chain okay all right and now we're going to all right so first of all we're going to create a prompt um prompt is going to equal chat prom template and we're going to create it also from messages just like before and just this usual this one takes in um a list of messages and the first one this time is going to be a system message and it's going to say answer the user's questions based on the following context okay and we just pass in the context like this this is like a shorter version of what we used um some up here like here okay so there you go and now after that we need to import the messages placeholder which we imported before and here we're going to say the variable name is going to be chat history just like we did before okay and then lastly we're going to add the user question which is the actual question that the user asked us and here it is now that is our prompt now we're going to create a document chain with it uh we're also going to use this create stuff create stuff document strs that we already created this one takes also just a language model and a prompt which is the prompt that we just created right here and after that we're going to use the retrival chain we're going to create the retrieval chain using this function that we had imported before and look here this one can take a retriever this one can take a um and the retriever can be just like the our Vector stol that we have already created or it can be a runnable and that is very convenient because we have a runnable that is a retriever which is our retrieval chain chain or retriever chain I don't know how we named it uh retriever chain there you go and then second of all it has a combined documents chain which is also a runnable and it can take the documents chain so what does this do this does that we now have let's just call it conversational conversational retrieval chain and now we can use this conversational retrieval chain to invoke because remember we're using um the new version of Lang chain and to run a chain you use invoke and this one takes the object with the names of the variables and here first of all let's pass in chat history and for now let's just leave it empty and it also takes in the input and this one right here I'm just going to say um what is lank chain um 0.1.0 about and let's see what it brings us you know what I'm going to store it in a response like this so it's easier to see and to visualize all right so this one is going to return the entire response like that and here you can see that we have the chat it Returns the chat history variable that we sent which is very useful if you're working on your own application you can just append the response to your chat history that was returned here it has the input it has the context that it found and it also has down here the answer so let's just show the answer like here um like that so Lin 0.1 first stable version of Lin framework it is fully backwards compatible and available in both Python and JavaScript this release focuses on improving functionality and documentation the stable version of Lang chain aims to earn developer trust and allow systematic and safe evolution of the library okay looks pretty good seems like it's working now let's test it a little bit further and use a mock history like we did before so let's create a chat history which is going to be a mock chat history like that and let's say the human message is going to be is there anything new about Lang chain 0.1.0 the a AI message is going to say yes again not feeling very conversational and then let's just try again but this time the followup question is going to be tell me more about it all right and now let's see what we have in the response it's fetching oh sorry I forgot to pass in the chat history here there you go now we're passing the chat history which is this mock chat history into the chat history uh variable and then I'm adding this as a follow-up question so let's see what the response is so we have the chat history that was returned to us is there anything new about L 0.1.0 and then the a message saying yes our input about telling more about it our documents fetched as context and then our answer uh it also has the metadata of course for each document and let's just show the answer response answer yeah first backwards compatible Etc okay so it seems to be working correctly and now I mean of course if I run the chain again it's not going to include the chat uh history by itself I will have to to re inject it um using this using the parameters right here but that is precisely what you want if you're building your own application in the next video I'm going to show you how to use exactly this to build a fully working application with a UI um so that you can actually put this into something um production ready that you can use with your team or something like that okay um next thing that I'm going to show you very quick if we still have time let me see is how to create an agent using Lang chain the new version of Lang chain okay so let's do that now all right so actually after looking at the recording time that we have we're all we're running at around an hour already um and I don't want this video to become super long so I'm going to leave the agents for another time um let me know if you want to see that maybe next week I can upload a video about it or the week after um in any ways all of those all of that is um the continuation for this is in the documentation I think I've covered pretty much the most important changes that have happened in Lang chain um compared to the previous to the previous videos that we have been covering in this channel but um yeah I mean let me know if you want a little bit more if you want to see a little bit more of of that anyways the next video that's coming next week is about doing exactly this thing but with a user interface so that you can deploy this thing in your team and use it or even sell it to clients if you have a web agency or something like that and you have your web development team um that can be really useful as well so yeah thank you very much for watching um don't forget to subscribe for more tutorials like this and I will see you next [Music] time [Music]
FbUhHUeI3ZU,2024-01-17T10:07:00.000000,LangChain Version 0.1 Explained | New Features & Changes,good morning everyone how is it going today welcome to this video and welcome back to the channel it has been a while now in this video we're going to be talking about Lang chain and specifically the new version of Lang chain which is its first stable release and we're going to be talking we're going to be going through the official article that they posted in January 8th so a few days ago about this new release we're going to be talking about the main changes that they have made to the library and what you will have to do if you're planning on building a new application using this new release of the framework okay now this one has been an amazing year here at the company we have been able to develop several applications using Lang chain and these applications are already working they're already in production and they are already solving real world problems and helping real people with their lives so I'm very happy to see that Lang chain is already getting to its first stable release um so yeah without any further Ado uh let's go right to the video and don't forget that if you like content about artificial intelligence and uh software development more specifically tutorials on how to implement them don't forget to subscribe okay so let's get right into [Music] it all right so let's start with the article right here um this is the article that was published when the official release was announced it was in January 8th so it's just a few days ago and we're going to go through all of what the article discusses and to explain the new features and changes right here okay now Lang chain as you may know is a library that is released both in Python and JavaScript um that makes it available for your backend applications here you have the links to the guides to the documentation and you also have here the link to the python GitHub discussion and the link to the YouTube walkthr made by Harrison himself who is the CEO and the creator of Lang chain okay I will leave of course the link to this article in in the description so that you can check it out um about the introduction we're we're presented with a structural change which is the main and the most important change that the that Lang is going through um the first one is that instead of considering it a library now we should start considering Lang chain as a framework a framework for developing uh language model applications okay um what does this mean this means that the Library part in its in itself is being split into different packages okay and that's exemplified right here before if you wanted to use Lang chain what you would do is you would install the lanching package if you were using for example python you would do pip install lanching and then you would have everything inside of that package from there you would you were able to install all of the Integrations with the third party providers like for example the vector stores you would do from Lang chain. Vector stores import chroma or quadrant for example okay now what happens is that they have split Lang chain itself into three different packages they have what is Lang chain right here they have what is Lang chain Community right here and then they have Lang chain core okay it's easier to see in this way here right here so what is Lang chain core Lang chain core is going to be basically where you will find all of the basic abstractions of Lang Ching okay here you will find for example The Prompt classes the AI message classes the llm classes all of these abstractions that allow you to um use sort of building blocks to create your applications okay that's Lang chain core okay now secondly we have Lang chain Community which is going to be the the in the third party Integrations of langing okay here in the article they say that they have almost 700 Integrations ranging from language models to Vector stores to tools for the agents of Lang Ching to use um in and all of these Integrations or almost all of them are going to be included in the langing community package so if you do pip install langing core you will not have the packages that pertain to the uh third party Integrations okay so for example now if you want to use chroma as a vector store you will not be able to import it from langin itself but you will have to do you will have to to do pip install langin community and then from langin community. Vector stores import chroma for example I mean I don't know exactly the path from the top of my head but that's that's kind of how it's going to look like all right um so that's the the longchain community right now you have also the model providers the retrievals and the tools like for example the ones that allow you to to serve the web uh Etc okay so that's the second part right here um however something to keep in mind is that not all of the third-party Integrations are going to be inside of the langing community package um so far as they say they have 10 packages that are outside from the langin community package and they have their own package among this we can find open AI Google and mistel for example okay that means that they have their own package that you will have to install if you are going to if you're going to to use them so for example if you want to use a language model by open AI you will have to pep install Lang chain open AI uh and then that's the one that is going to include uh the language models and the embeddings from open AI okay so that's for third party Integrations and thirdly we have the Lang chain The Irregular Lang chain package that one right there they have left it in the version 0.0 point x um because of course they don't want to break any already functioning applications so yeah um so yeah the main features of this release are going to be located in langin community and langin core and that's um from where you should start importing your your components in order to use the latest version okay all right and we arrived to the part of observability um as you may know language model applications are very non-deterministic and I mean there is a non-deterministic component to them in a sense that we are never absolutely sure of what a language model is going to respond to our input that is why observability is a main part of um building language model applications and that is actually exemplified right here here the observability is going to surround all of the framew work um in order to solve this problem of non non-deterministic components uh Lang chain they have built a tool called lsmith which is basically a tool that is going to allow you to log every single input and output for every element inside of your chain so that you have the best I mean a better debugging experience of your application uh I haven't tried it yet they currently they have it in a private beta version but if you want to check it out you just have to go and click right here in the lsmith Pod and you can just sign up to their weight list um so yeah that's basically what they're building and it's more of a platform than than the library or anything else it's going to be um a place where you're going to be able to debug your language model applications um as far as I know this is the first uh product that does this in the market but I mean there might be others now we also have right here an accent or a mention of composability um now what is composability it basically means that you're supposed to be able to chain different methods and components together which I suppose that is very useful to you if you're using Lang chain because as the name suggests it is a library or a framework that allows you to chain different different logic Parts logic components together to create an application or a chain okay um so we were already building chains and this time or I mean a few months ago already I think they they released what they call Lang chain expression language which is right here and they call it LC this language expression this langin expression language basically is just a way to write and to declare your your chains in a more pipeline like um syntax okay I think that we can see it right here an example um how to create um chain so yeah for example you would just create your different components of your chain and then you put them all together in a chain like this and this is supposed to to work for all of the chains available in Lang chain this is of course going this all of course makes it possible for you to modify already existing chains and then also some changes in the naming conventions but all right we we will see that when we when we're actually using the library all right something something else that they mentioned right here is their emphasis on the streaming end points okay that they are going to be exposing in the langu in the Lang chain um in the Lang chain expression language okay um now what is streaming in in language model applications as you may have noticed in chat gbt you are not getting the entire response and the entire generated response in one batch okay so let's say that in chpt you ask a question and the answer is this big you're not going to get all of this in one batch if you have noticed when you ask a question it starts um showing the answer as it is being generated it's it's like it's the as if the language models was right in front of you okay now this is important not not only um to make it look good but for the user experience in general otherwise the users would have to wait like several seconds before they get an answer so showing them in real time that the their answer is being generated is very important for the for the experience in our language model applications so that's why Lang chain they are putting out this their exposure using two different methods stream and a stream inside of any chain constructed with language uh with L chain expression language so now it's going to be even easier for us to stream our answers into into our applications and make it easier for our users okay uh we're getting to uh the section talking about output parsing which is basically the these are basically functions that allow you to be sure that a certain step in your chain is always going to return the same format as an answer okay so for example if for one step in your chain you need to get an answer in a string format there is an output parser that is I think it's called string output parser that is going to make sure that every time that you get a response from a given um from a given language model or whichever step you're in your chain uh you're going to get a string in return so this is basically uh something that they they have I mean they they already had in Lang chain but this time they are mentioning that for for this output parsers we're going to also be able to stream this output the the content that is being parsed through the output as it is being generated so that is that's also very very useful it's going to make it faster for our chains to work and easier for a developer experience in general okay all right now we arve to the section called retrieval um if you had seen some of the videos in the in this channel you know that one of the main aspects of Lang chain is being able to talk to your personal data okay um being able to ask a language model about data that it was not trained in data that you may have in your in your email account in your nodes in your personal private database or in your company's database and that is one of the main uses of Lang chain um they just reinstantiate that and they also included they they mentioned here that they are in including new Advanced retrieval strategies from Academia you may want to take a look at them if you're interested in the more um technical side of this but something very interesting right here is that they are exposing and indexing API that you can see right here so the indexing API uh we're going to make a video about it and show you how it works and everything but just so that you know what's new about it is that it's um it is here to make you to make it easier to index your data basically so this includes avoid writing duplicated content into your vector store I know that's usually um a delicate part of the application development process in which we have to make sure that every Vector has its its very precise metadata to be sure that we're not duplicating content so this right this one right here I mean this API is here to help us do that also it is supposed to avoid rewriting onchanged content and avoid recomputing embeddings over unchanged content so basically a more advanced indexing for our retrieved I mean for for our data that we're going to use for retrieval um and yeah they just mentioned some other other libraries that use Lang chain for a more opinionated approach and retrieval and here we have a section mentioning the agents now the agents are probably the main or the most popular part of Lang chain which and probably the reason why they become so popular why Lang chain became so popular in the first place um now what are agents in case you're not familiar with it it is a component in your language model application that is able to think by itself and Implement a solution based on what it reconed okay so it will take an input it is going to use the a language model to reason about what what it can do to implement a solution given your question and then it's going to be able to use tools to implement that solution um so for example a tool can be um an external API it can be a calculator it can be for example an API that serves the web and finds and finds website relevant websites relevant to the question that the user asked um so yeah I mean basically it's a a tool that's going to be able to reason and apply a tool based on what youve thought about it um here in the article they say that they have um reinvested a lot of time um covering Integrations with more thirdparty tools in the existing agents that come with lanching um they have also um worked on ways to structure language model responses to fit the input schema of those tools and a more flexible way to specify the the ways in which the agent um the agent tool tools work together and this is what we already mentioned which is the Lang chain expression language okay which is the one that allows you to create chains or agents in a more pipeline uh like synex um they also mentioned that they have implemented new methods agent methods from Academia one of them for example is react which you may see if you go right here they have the official I mean they have the paper if you want to take a look at it um the more technical side but yeah here basically they covered agents which are one of the main parts of flank chain and then finally we just see um I mentioned that they are already thinking of lunching 0.2 which of course is going to be um a a minor release um oh something that I forgot to mention probably is that with this new release they are also in changing the version in convention in a way that every minor bomb any any minor new version is going to be accompanied by a bump in the second digit and these ones are going to have breaking changes and any Buck fixes are going to come with a bump in the third digit um yeah so basically that's pretty much all for this article and um I mean they also have a mention of langra which is another product that they're working on but we will be able to talk about it in another video but so far this is how it looks like this is the what Lang chain is uh promising for us and yeah I mean to me it sounds pretty good let me know what you think about it and be sure to to come here for the next video because we're going to be making the quick start and Showcase of almost the main change es with the code itself um in a Jupiter notebook so that you can get your hands diry with some code So yeah thank you very much for for watching and I'll see you in the next one
VL6MAAgwSDM,2023-07-17T18:00:11.000000,Langchain + Qdrant Cloud | Pinecone FREE Alternative (20GB) | Tutorial,good morning everyone how's it going today welcome to this week's new video tutorial in which I'm going to be showing you how to use quadrant now quadrant is a vector database that is an alternative and open source alternative to Pinecone and they also have a managed cloud service in this video I am going to show you how to set up and configure a free forever one gigabyte cluster in their cloud service and how to use it to connect it to your application okay this is especially useful if you want to have a language model application that has its Vector database persisting over time and you want to store that database in the cloud and you don't want to deal with all the configuration of the servers and all that it's basically going to allow you to have your database available from a URL and you're going to be able to fetch all the information from there with just quadrants API okay in most of the videos from this channel we have created applications that don't necessarily have a persistent database so this is going to be a complement to all of those videos so by the end of this video you will have something like this and you will be able to query it with information that is already inside the database without actually having to re-run the embeddings every time that the application loads okay so there you go I hope that by the video you will have a very robust project that you will be able to Showcase to your clients employers or future employers and you will be able to add this to your portfolio I hope that you enjoy and remember that if you like Ai and software videos don't forget to subscribe alright so without further Ado let's get right into the video [Music] alright so the first thing that we're going to want to do is we're going to want to create an account in quadrants Cloud platform okay in order to do that you're going to want to go to quadrant.tech and then you're going to want to click right here on cloud and it's going to ask you to create an account I'm going to set up mine with GitHub I have already created my account which is going to connect but you will probably have to create your account first and once your account is created you will be created with this page right here which prompts you to create your first cluster okay now in order to create the first cluster you can either just give it a name if you if you wanted to if you don't want to personalize it or you can create a custom tier a cluster which can also be free okay I'm going to create a custom one I'm going to call it my cluster and something interesting about this one is that you can choose the region where your servers are going to be located so myself I'm going to set it up in Europe and as you can see we're still inside the free tier pricing as I mentioned before you have a free one gigabyte of memory if you want to increase it you're going to want to you're going to have to pay for it but you can leave it free here and there you go now we can create the cluster and it's going to take a little bit of time initializing it and mounting it so I'll be back when once this is done it should take a few minutes and there we go now our cluster is healthy and ready to be used as you can see right here we have in the configuration we have a one gigabyte of ram we have half a virtual CPU and 20 Gigabytes of disk space which should be more than enough for any testing that you want to do or maybe even for a very small scale production application okay now what we're going to do is we're going to go back to overview and as you can see the next step after setting up the cluster is creating an API key to connect to that cluster okay so that's what we're going to do if you had several clusters you're going to want to select the one that you want the API key from right here and then you can click on get API key here this is the API key that I'm going to be copying and I'm going to paste it right here in my notebook and then we can just continue and you can see that this is the curl command that you can use to access your your cluster okay so now let's start interacting with our cluster through this endpoint all right so let's do that now all right so now the next step to take is to start testing our our cluster okay once you create your cluster you get a URL which is the one that you're going to be using to send requests in order to interact with your cluster okay so for example if you want to create new vectors or if you want to store something or if you want to fetch the vectors that you have stored in a collection this is the URL that you're going to be fetching them from okay so the first thing that I recommend you to do is just like to get familiarized with how these things work is to start testing it using a HTTP client okay um you can use Postman for example if you if you want or you can use Thunder which is a HTTP client for vs code it's very minimalistic and I really like it um it's basically just like this you create a new request and right here you just write the URL that you want to send the HTTP request to so I'm going to send it to my URL that I just created and as you can see right here they ask us to send the API key as a header so I'm going to copy my API key I'm going to go to headers I'm going to say API key I'm just going to paste it right here in the value and there you go so now this is going to allow us to send HTTP requests to my cluster okay now before I show you some of the of the endpoints that you can use let me just explain to you a little bit of how the architecture of quadrant works so in quadrant we just created a cluster okay and the cluster can have several collections collection you can think of it as a database so you create your cluster then you can have several collections or several databases inside of your cluster and each collection can contain one or more points and each point is a vector okay and remember that a vector is just a numerical representation of your text so whenever you um embed your text and you send it to your database that is going to be stored as points inside the collection that you specify okay so the first thing that we're going to do is we're going to want to ask our host how many collections it has in in the cluster okay so in order to do that we're going to come right here to the quadrant documentation and here you have a an endpoint that lists all the connections the collections so you can see that it's a get request that you we send to collections so I'm going to add slash right here and say collections and I'm sending a get request my API key is here in the header so if I send it you can see that I get a response to 100 OK and you can see that I get that the result is collections it's an empty array which means that there are no collections in this cluster which makes sense because we just created it okay now if you wanted to create a collection using a HTTP client like this you can send a put request to this endpoint right here you just add the collection name and then you just specify what specs you want your collection to have but in our case we're going to be creating our collection from a python script so that we can implement it in our applications okay so let's get right into doing that all right so what we're going to be doing now is I'm going to be showing you right here on a notebook how to create a client to interact with your host in Python how to create a collection and how to add points or vectors to that collection in your cluster okay so um first of all what you're going to want to do is you're going to want to install the dependencies in our case we're going to be using Lang chain quadrant and open AI because those are the libraries that we have been using in the other videos of this playlist so that we can actually implement this in one of the applications that we have built before next let's actually start in importing our our dependencies so we're going to say that from Lang chain dot Vector store we're going to import quadrant and then from Lang chain dot embeddings dot open AI we're going to import open AI embeddings like that um sorry it's not Vector store here it's Vector stores like that there you go so then we're going to import quadrant client like that and we're also going to import OS to use environment variables there you go um there you go so now the first thing that you're going to want to do is you're going to create a quadrant client okay so in order to do that the first of the first thing that I'm going to do is I'm going to store my host and my API key in some environment variables okay so I'm going to say Environ and this one I'm going to call it quadrant oops I'm going to call it quadrant quadrant host and this one's going to be equal to my host URL right here like that then I'm going to do the same but quadrant API key like that and the value for this one is going to be my API key there you go um once that's done what you're going to want to do is you're going to create your client in my case I'm just going to call it client oops client like this and in order to initialize it this is going to be an object that is going to allow us to connect to our cluster okay so what I'm going to do is I'm going to do quadrant client like this and then I'm going to initialize a quadrant client like that now this one takes several parameters the first one as you can see is the URL of your of your database okay in our case it's our quadrant host so I'm going to just get the environment variable called quadrant host like this and then the API key is the second variable right here I'm going to call it I'm going to call I'm also going to do os.get EnV and this one we're just going to get our quadrant API key like that now if I run this it should create my client objective there you go now we can use this client object to actually start creating Collections and interacting with our cluster okay so let's do that right now all right so the second thing that we're going to want to do is to create a collection okay remember that I told you that in quadrant you we just created a cluster but we don't have any collections inside of it a collection remember it's just a database with vectors right so we're going to create a collection using the client object that we initialized up here so in order to do that it's going to create collection right here and the first thing I want to do is I want to set the name of the collection in an environment variable this just makes it a close look closer to production okay so I'm going to say OS Environ which I'm just going to copy this up here like this and it's going to be quadrant collection name like this The Collection name you can name it whatever you want remember we're just creating a new collection so you can really name it whatever you want in my case I'm just going to call it my collection like that and this name has to be unique okay you cannot create two collections in the same cluster with the same name um so there you go now we can use this client object to actually start initializing our new collection in order to do that I'm just going to come back here to the documentation of quadrant inside Concepts I have collections and here is the code for python in order that we can use to create a collection I'm just going to copy it right here I don't need the client initialization because I just initialized it before so I'm just going to copy this and paste it right here okay as you can see this one takes two different arguments two different parameters the first one is the collection name and the second one is the vectors configuration which I'm going to initialize up here I'm just going to call it effectors configuration like that all right so the collection name we have already initialized it up here so I'm just going to get the environment variable from there remember this is how we call environment variables and then the vector configuration is another object that we import from Quadrant okay in this case I think that they imported it from quadrantclient.http dot models so that's what I'm going to do since I already imported quadrant client I'm just going to call it directly from quarter client.hdp dot models there you go and there you go so now what we're doing right here is we're creating our vectors configuration object as you can as you can see the first one is the size I mean the first um parameters the size of the vectors this one right here takes the dimension of the vectors that are returned by your embeddings model okay for example open AIS embeddings return a model return vectors with a dimension of 1536 if you're using for example instructor Excel you're dealing with a dimension of 768 and these are things that you can just Google and you can just find out which dimension each embeddings model is going to be using in our case we're going to be using open ai's embeddings so I'm going to be setting it to 1536 let me just add this um comment right here just to indicate that for instructor Excel it's 760 768 and then the second parameter is the distance um if you're not familiar with how NLP Works don't worry about it you don't really need this to build an application this is more if you're more into the data machine learning side of this but the idea is that you want to tell quadrant which distance metric it's going to be using to find the most I mean the closest I mean to perform the similarity search okay so in our case we're going to be using cosine similarity and as you can see right here we're going to be that's an object also in my quadrant HTTP models and there you go so now this is the variable that I'm going to be adding to my vectors configuration parameter and now when I do run this you can see that I get a return message from the client which means that the collection has been created there you go so now what we can do is we can go back here to our HTTP client and in order to test that our collection has been correctly created we just send the same request that we sent a moment ago so remember we keep the same host here and remember that we want to hit the endpoint collections remember API key all is the same you can also do this in Postman I just like thunder because I think it's just more it's minimalist and then if I send it you can see that I get this time I get returned a list of Collections and this time it's not empty this time we have one element with the name of my collection which is precisely The Collection that I created a moment ago all right so next thing we need to do is we need to create our Vector store object which is the one that we're going to be plugging into our application in order to interact with um with our collection okay so in order to do that we're going to be using the integration that quadrant has right here we're going to go to the documentation page to Integrations and we had been using launching in the other video so I'm going to show you how to do this in launching in a pro in a future video I'm going to show you how to do the same with learner index which is also super powerful um and here you have the code that you need as you can see you require you need to create some embeddings you need to Define your client which we already did and then you need to initialize your document store or your vector store object and this one uses a quadrant class which you import from langching Vector stores here I noticed that I forgot I think that I named mine with a lowercase Q so it's supposed to be uppercase there you go and now we can actually just copy this part right here which is the one that we need in order to initialize our Vector store object okay so I'm just going to call it Vector store like this I'm going to be initializing it from Quadrant it takes as you can see three different arguments the first one is the client which we already defined the second one is the collection name which we defined right here um I'm actually just going to use OS get EnV and I'm just going to paste this one right here and then it requires the embeddings as well so let me just initialize the embeddings embeddings is going to be the open AI embeddings that we imported up here remember that if you want to use a different embeddings model you're going to have to change the size of the collection that you're using because you cannot add joint instructor embeddings to a collection that was uh that also has open AI embeddings in it okay so you're going to have to be consistent with the same embeddings model for each collection so in this case we're going to be using this collection and the embeddings is initialized and the open AI embeddings actually requires you to have an environment variable with the open AI key that you that you're going to be using okay so in our case um I'm just going to come right here to to my API keys in openai it's going to create a new API key copy there you go I'm gonna come back here and I'm going to initialize it like this I'm gonna do OS dot Environ and the name of the environment variable has to be open AI API key otherwise Lang chain will not recognize it and there you go now this if I'm not mistaken should create the vector store object that we require just add a comment right here create Vector store there you go now we have created our Vector store and now we can actually start adding vectors to this Vector store in our application so let's do that now all right so now that we have our Vector store we want to add some text to it okay I mean some vectors in my case I asked chatgpt to create a very quick story about a few friends who find a fluffy dog on the street and this is the story that I'm going to be feeding to my Vector store and that I'm going to be querying so I'm going to be asking questions about this story and my my application is going to be able to retrieve that from the database okay so let's I already uploaded the story.txt file right here to my workspace and that's where I'm going to be fetching it so first this cell is going to be titled add the documents to vector store like this so to do this first of all we're going to have to create a function that takes this huge string of text and it's going to split it into shorter chunks of text so that remember that where we what we're going to want to do is we're going to fetch the the chunks of text that are going to be relevant to our question so we don't want to send like uh 10 000 characters to our language model because we could very easily reach the token limit so what we're going to do is we're going to take all of this huge text and we're going to split it into shorter chunks so that we can feed them to our language model in order to do that we're going to use blank chains text splitter a class called character text splitter let's see there you go and I'm going to define a function called get chunks which is basically going to divide to split my huge string of text into several chunks of smaller size so this one was going to take a string of text I'm going to initialize my object called text splitter and I'm going to use my my class that I imported now this one takes several parameters the first one is my separator which is the character that is going to define the line break in my case it's just one line and then we're going to have to define the chunk size chunk size and in this case the chunk size is going to be a thousand characters this means that it's going to return different chunks of a thousand characters each then the other parameters is the chunk overlap which means oh sorry this thousand is not supposed to be a string it's supposed to be a number like that the chunk overlap is the overlap for each chunk size okay so for example if the first chunk goes from the character Zero to the character one thousand if I set an overlap of 200 the second chunk is not going to start at the character 1001 but on the character a thousand minus 200 so it's going to start at the add to character 800. so the first chunk is going to be 0 to 1000 and the second one is going to be eight hundred to a thousand eight hundred this basically allows us to get more context for in to each one of our chunks of text because if we split our text like arbitrarily add the character 1000 we might fall in the middle of a sentence and we will lose the sense of that sentence into different chunks so that's basically how this works and last but not least the length function that we want our uh text player to use to measure the text in this case we're just going to use regular python length function and then with this what we're going to do is we're going to create a new chunks array which is going to take my object that I just created and this one has a method called split text and this one's going to take my string of text that I'm going to feed my function then we're just going to return the chunks of text so in short this function is going to be returning an array of shorts uh short chunks of text that have been I mean is going to return this text split into different chunks okay there we go now what we're going to do is we're going to use this function to split my story so what I'm going to do is going to say that my texts are going to come from well first of all I have to open my story so I'm going to do with open story.txt that as file we're going to say that raw text is going to beam F dot read There You Go my file.read this means that inside this variable I have all these contents right here okay all the contents of my story are now in my raw text variable so now what I'm going to do is I'm going to take this text I'm going to take my raw text I'm going to divide it into different chunks of text with my function get chunks so in order to do that I'm just going to call get chunks I'm going to pass in my raw text function like this and now that I have my text function right here let me just show you what it looks like if I print it and I have error length function language length function nope not like that length functions written like that there you go so now you have an array with a bunch of chunks of text and each one a thousand character long and each one has a part of this story right here and now from this text these are the ones that we're going to embed using open Ai embeddings and starting in my Vector store so in order to do that I'm going to call my Vector store that I created up here and I'm going to say Vector store dot add texts and here I'm just going to pass in an array of texts that I want to import so this is just going to take my texts like that now before I run this I want to show you something real quick remember that I told you that inside a collection you can have several vectors in this case we have my I mean if we go back to the documentation we can see that there is this option to list all the collections that we have and also we can get information about a certain collection so we send us a get request to collections endpoint and then the name of our collection so if I come back here to my collections in my HTTP client and I say that I want information about this collection right here and I click on send you can see that I currently have zero vectors in my collection okay which makes sense because I just created my collection a few moments ago but now after I run this Vector store add text this is going to add those vectors to my collection okay so let's see how that works now if I run this if I don't have any errors there you go now my my vectors have been added to my Vector store and now if I go back to here and I send this again you can see that my Vector store account is now 5 because they have been added to my Vector database now if I it doesn't matter if I refresh this or if I or if I close the application or open it again I will still have these five vectors in my Vector database and all I will have to do is to connect to my database and to fetch these vectors in order to perform my my my querying from my language model okay so let me just do that right now great so now we have successfully added the vectors to our Vector store and this basically means that we now have a persistent database in the cloud that we can I mean as you can see we just got all the vector stores from a different program like this is not connected to to to this notebook which means that my vectors are actually stored in the cloud and I can fetch them from whichever applications from whichever application I want as long as I have the credentials this means that I don't have to recreate my embeddings every time I want to use them I can just connect to my to my database and then just fetch them and perform my computations and that's what we're going to be doing right now right now it is time to actually connect this Vector Store to our application and start querying it with user questions so that we can actually start chatting with our story that we uploaded to our database so let's do that right now so first of all I'm going to have to create a question and answer chain from language okay so let me just show you how that works if I go to line chain and I go to usage cases and I come right here to um q a over documents context aware there you go so here this is what this is basically what we're going to be doing we're going to be creating a question and answer chain that is going to retrieve the information from our from our Vector store and it's going to feed it to a language model so that we can actually chat with our information so let's do that right now so let me just title this cell plug Vector store into retrieval chain and this retrieval chain you will be able to use it inside your application so first of all I'm going to say that from Lang chain [Music] from Land chain dot chains about chains we're going to import the retrieval QA chain which is going to allow us to ask questions about a document and then also from Lang chain dot llms I'm going to import open AI because I'm just going to be using open AIS language models okay and I just need to create a QA object from my retrieval retrieval QA class and this one oops sorry now we're going to create it from chain type let's see from chain type there you go and this one actually takes a few parameters the first one is the language model that we're going to be using and in this case we're just going to be using open open AIS Le like that I think that by default I'm not mistaken we get um callbacks model name I think by default it's chat GPT turbo 3.5 I think so I'm not sure but yeah I mean like you can also like add some parameters here if you want to tweak it a little bit more but I'm just going to go like real fast on that then the chain type you're going to type it to stuff and then you're gonna have to set the retriever which is going to see which is going to be the place where you're going to get the information that you want to query from this means that it's your vector store okay so the retriever is going to be the vector store that we initialized before Vector store and this one has to be as retriever like this there you go and we run this and basically what we have done is um yeah basically what we have done is we have created our chain that we're going to be able to query about the information that is inside our database okay um so now what I'm going to do let's just Square it real quick I'm going to ask a question let's say how many friends are there and what are their names okay and then the response is just going to be my quer my q a object I'm going to say run I'm going to run my query and then let's just print my response if I'm not mistaken this should print a response related to my story there there are three friends namely Ben and Sarah and there you go apparently from my text here three friends indeed Emily Ben and Sarah so there you go we have successfully connected our application to quadrants hosted database in the cloud okay just to be sure that you understand what happened right here remember that we basically created our client created our collection that we didn't have before then we created our Vector store and it is inside this Vector store that we added new vectors and then we connected that Vector store to a retrieval chain which is the one that we use to actually query the text okay that we'll actually use and sort some sort of chat however this cell right here that added the vectors to our Vector store is not needed if we already had vectors in the database this means that since our database is persistent in the cloud if I reload the application I will already have my text from the story I will not need to re-add the documents to my Vector store okay and that is exactly what we wanted to achieve let me show you real quick how to do this in some sort of graphical use of a graphical user interface so that you can see a little bit in in a little bit more real scenario let's do that right now alright so really quick let me just tour you around how to use what we just saw into an actual application okay in a previous video we had developed an application that looked something like this but we had to import a PDF file in order to be able to actually ask questions to it because we had to ask questions about the PDF file that we were going to upload in this case I just like stripped it down into its very minimum it's just an input text and the idea is that we're going to have it connect to our remote database that we just created and we're going to be able to fetch information from there and ask questions to our remote database about the story that we just embedded without actually doing the embeddings again every time we reload the application okay so let's do that if you want to see how to set up python project you can check out the video I did especially about that but in this case I just already set this up with this user interface right here the idea is that we have our load load dot tnv so that we can load our environment variables then we have a simple header and then just our text input angle of this I built it using streamlit which is a graphical user interface library that allows us to create user interfaces very very quick and very very beautiful so there we go now what we're going to want to do is since we have our user question right here we're going to want to do something whenever our user um or submits a question okay so I'm just going to copy this right here from here let's say so if my user question is um if we find that we have a user question we're going to write the user question and then we're going to use a q a chain and run it to to compute the answer okay and this is going to use our remote database and so in order to do that we're going to have to first create our chain and we're going to use the code that we had right here retrieval chain there you go there you go there you go so we created the chain like this we're going to have to import all the things that we imported before which are these two going to import them up here and we imported all of this up here too there you go and then we're going to have to create our API our environment variables we have qhost quadrant host API key collection name and open AI API key I have them set up conveniently before so that we can do this pretty quick there you go this is exactly the same information that I had in the notebook okay so there you go we save this we have this right here we are creating the chain as we did right here but what were we doing before we had to create the client we had to we're not creating the collection because the collection already exists because we're dealing with a database that we already created but we create the client then we create our Vector store and then we connect that to our chain so let's do that first of all let's just create a function right here that is going to get the vector store um so Vector store equals get Vector store then we just create a function that gets the vector store and in this function basically all that we are going to do is we are going to copy the code that we had in here so first of all we're going to want to create our create our client there you go then this client we're going to want to use it to not create a collection but we're going to want to create a vector store using the embeddings from openai like this there you go like that then what do we do next we return the vector store return the vector store there you go so now basically what we're doing creating the client embeddings in the vector store returning the vector store we're fetching the vector store here create Vector store and then we are connecting it to a q a query a chain sorry so there you go this is basically all that we're doing and this is basically all that you're gonna have to do if you want to connect to a four to a remote database so now if I save this and I think that's sold if I'm not mistaken I'm just going to re-run my streamlit application then if I go right here and I refresh and I say what are the names of the friends and then it's supposed to run it the names of the friends are Emily Ben and Sarah which comes from the text right here that we embedded and we saved in the notebook so as you can see we didn't we didn't embed it or saved it inside this application we're just accessing the quadrant database right here and as you can see our cluster actually has this disk usage of zero zero one gigabytes which of course it's just five vectors but um yeah so I hope this was useful here you can see um I'll gonna be set putting this up in GitHub so you can check it and yeah now you know how to connect your application to persistent databases in the cloud using quadrant which is a very very neat um substitute for pine cone if you find that it's too expensive and they are free tier one gigabyte free forever cluster is very very good if you want to try some things out and just experiment with llm applications okay so I hope this was useful to you and And subscribe if you want more videos like this and I will see you next time [Music] [Music] [Music] [Music]
Zn5tmx0ynw8,2023-06-08T05:17:00.000000,Full Python Environment Setup for AI (or other) Apps + Virtual Environments,good morning everyone how is it going today welcome to this new video tutorial in which I'm going to show you how to set up a python development environment and also virtual environments for your projects this is some sort of a different video for from the other ones in this playlist but this is a very important one because I realized that it's not very obvious how to set up your development environment install the right version of python or switch between versions of python for different projects so this video is going to set you up to actually follow through all of the tutorials in this playlist and to actually pretty much develop any project in Python that you want okay to do that we're going to be going through this article that I wrote and I published on the on my website the link is going to be in the description if you want to copy the Snippets right here okay so without any further Ado I hope you enjoy it and let's go foreign [Music] so the first thing that we're going to be doing is we're going to install a package manager for our Mac okay if you are running Windows you all you can use winget which is very good as well and if you're running Linux you already have apt-get so you don't really need this this is for Mac um I mean if you have any experience with Linux you know how easy and convenient it is to have apt get it allows you to install your software with a single command and then upgrade it whenever you need it and then just uninstall it as well with a single command we don't have that in Mac by default and that's exactly what we're trying to achieve by installing Homebrew actually it will not only it will make your life easier it's just going to make you much more productive you can think of it as a app store for Mac but it's not regulated by Apple it's kind of a place where it's kind of a repository where many software developers upload their their software and then you can just fetch it with a single command and install it in your computer and get it working right away it is a thousand times better than downloading applications from the internet and installing them manually it makes maintenance and just management way faster and easier and actually sometimes especially for software development applications it will be the only way to install these applications okay so right here I mean just in this tutorial we're going to be using it to install several of this of our applications right so how do we install Homebrew to install Homebrew you can open your terminal so let's go right here we open your terminal and we have to copy this Command right here or if you don't trust third party blog posts like mine you can go to the official website from Homebrew brew.sh and then copy this Command right here and then paste it on your terminal and then click enter I am not going to do it because I already have Brew installed but once you have done this you can verify that Homebrew was correctly installed by running Brew version like this there you go if you see something like this that means that you have Homebrew installed and that everything is working smoothly okay good so now that you have Homebrew installed let's start using it to install other parts of our setup all right so now that you have Homebrew installed it is time to install python in our system okay this is going to be the system version of python or we might also call it the system python okay if you're in a Mac you already have python installed you can check that by going to your terminal and typing python dash dash version like this there you go and you will see your python version however you see right here that I have python version 3.10 if you have never installed python manually before in a Mac you might see that you have Python 2.7 that is because that is the Iceland version that is the version that comes by default with Mac but the problem is that not only is Python 2.7 an old version of python it is also a version that is not supported anymore by the official guys from python okay so what we're going to do is we're going to be installing and the newest version of python um in order to do that in a Mac we're going to be doing we're going to be using our very fancy package manager that we just installed before and in order to do that it's very simple you just run the command Brew install and then you say which package you want to install in my case it is python this works I mean if this sounds familiar to pip or npm it's because it's exactly that it's an it's a package manager but instead of it being for python or for node it is for your Mac it's very very convenient and then you're going to click enter there you go that was super fast because I already had it installed it might take a little bit longer for you but as you can see it is running the latest version of python now now if you do python dash dash version again you will see that you have the latest version of python if you're running Windows you may want to use winget to install it by running something like this or you can just download it from the official website it's very it's very straightforward um so there you go that's how you install python however something very very important that I wanted to make clear is that as I mentioned this is the system python okay now what does that mean this means that we are not going to be using it for development the system python is a version of python that is used by other software when they require python okay so if you download an application that requires python to X to be executed it is going to run your system version of python however and I really cannot stress this enough you should never use your system version of python for development um if you have heard or have had any headaches When developing in python or you you know that installing dependencies sometimes doesn't work or then you need another version of python or whatever most of the time all of those problems come from the fact that people are using the system version of python okay so in order to to just get away with not having all of these troubles we're going to be using something that is called a python version manager this is going to allow you to install different versions of python and to run them without having to mess up your system your system python this is very important okay so let's do that now great so now that we have um our system version of python installed it is time to install a python version manager okay it's pretty good that we have Python 3 and all but why do we need a python version manager well um in the tldr for this is this to bring your calm answer anything in your life okay in other words to remove most of our headaches um in my experience most of the headaches that come from developing in Python come from version management and dependency management for example how often has it happened to you that you're trying to run your code and it just doesn't work it's not recognizing your dependencies it might be because of your python version is not working with some of them and that's very very common actually in a previous video we were working with a dependency that required python 3.8 to work and it was very easy for me to downgrade to python 3.8 because I am running a pi conversion manager but I saw in the comments that many many of you guys were having trouble doing that and actually it sounds very intuitive to think that all right I am just going to delete or uninstall my current version of python right and I'm going to install a the version of python that I need for this development so you uninstall your previous version of python and you install python 3.8 all right good so now what happens with the event with the dependencies that you had installed in the pre in the other version of python are they going to work with this other python well probably not um and that's just going to break all of your development for a long time and you're going to spend hours trying to solve that that is one of the reasons why you should never use the system version of python for development so in short having a python version manager will allow you to install multiple versions of python in your system you will be able to switch between them very very easily you will be able to create virtual environments with a specific version of python for each project and you will also allow it'll also allow you to install the packages directly in the virtual environment with the version pattern with the version of python that they require okay so everything will be bundled together as we will do in just a few minutes um and then it also allows you not to use the sudo command because sometimes you may want to do I mean if you want to install something if and if you're running the system version of python you will have to do sudo install sudo pipe install and that's very very much not recommended um so yeah it'll just allow you not to worry about messing up your system your projects and your dependencies and to focus on what is important which is developing your application okay so there you go now how do we install a python version manager alright so now that you have now that you know why you need a path conversion manager let's see how to install it okay and it's actually very straightforward I like to think of a python version manager as some sort of Austin Stevens um it can be like source of some sort of your snake master or the one that's going to take care of all of your snakes or your pythons it will feed them clean them and make sure that they are healthy okay this is exactly what a python version manager does but with your python versions um in order to I mean for this tutorial we're going to be using payenf it's just the most convenient and simplest way to deal with python versions and here is the official repository and if you want to install it here are the official installation instructions for every for every operative system okay I am in Mac so I'm going to click here and as you can see you have to install it using Brew okay well that's good news because we already have Brew installed so we copy this right here we come to our terminal and we paste and we paste that Command right there we click on enter that is going to install um Brew in our sorry install Pi in our system I already have it installed so that was pretty fast but if you haven't installed it it's probably going to take a few minutes and then in order to verify that you have Pi NV installed you used to Pine dot dash dash version and if you see Pine followed by your current version it might be different for this one depending on when you installed it that means that you have time correctly and successfully installed in your computer and you can actually start installing as many different python versions as you want okay I must really really stress this it doesn't matter if you only want to use one python version in your development it doesn't matter if you don't intend to change your python version it is always a good idea to pass through science to install python because that way you're not relying on your system version of python because once you mess up your system version of python it can only bring you trouble okay this way you will have a you will have several versions of python or only one if you want and then you can just you can do whatever you want with it because it's a virtual python you can just delete it and reinstall it and then reinstall all the packages and everything will be running smoothly okay so just keep that in mind to always use pine version the pine python uh and now it's time to actually start installing our python versions great so now your snake Master is working in other words you have piant correctly installed in your system uh we can now actually start installing multiple versions of python or only one as you wish um using time okay you will see how easy it is all you have to do is to Pi install and then the version that you want to install now how do you know which version you want you you're going to want to go to python the python the official python website and you click on downloads right here here you will see the latest versions that they have and as you can see 3.10 is currently the latest security version okay 3.11 is already out but it is in bug fix maintenance status which means that it has bugs okay so if you want to develop your application on the work in a bugless environment you probably want to install 3.10 if you want to test 3.11 you're just gonna have to go with the Box and 3.12 well it's in free release so yeah um so yeah what you're going to do then is you're going to come right here and do pione install 3.10 like that now I already have it installed so it asks me if I want to reinstall it I'm going to say no because I already have it but you can um to you it's gonna take a few minutes probably well it downloads everything and it actually installs it okay so that is how you install a different version and if you want a lower version you can just specify it like this if also if you don't specify the prefix right like um because like if I do python version you will see that I have python 3.8.11 which is the latest revision of python okay so if you don't specify a prefix right here it is just going to install the latest one I mean to the latest revision okay so if you say python Pi MV install 3.10 it's just going to install the latest 3.10 in this case it is 3.11 okay now if you want to check which versions you have installed in your system all you have to do is to Pi in versions like that and this will list all the versions that you have installed in your system and this are as I mentioned before virtual versions okay environments that you can use and you can delete them as you wish all right uh the only one um that is not virtual is your system version right here and you have an asterisk right here depending on which version you have currently selected okay so if you just installed the latest version of python even if you just installed it and that one is not going to be selected just yet okay you're going to have to select it and I'm going to show you how to do that in a moment all right very good so now we have um all the python versions that we want installed what we're going to want to do now is we're going to install a global version of python okay now what does that mean basically all that means is that it is the version of python that is going to be run whenever you just do python like this okay so if I do python version that is executing the global version of python in this case it is 3.10 but to you if you haven't changed it yet it might still be 2.7 okay so let's change that um oh just you know just before we do that let me just show you how to see where your current version of python is being executed from okay to do that you just say which Python and it'll tell you which version of python it is I mean from where the command comes okay the binary that executes the command in my case it's coming in directly from Pine because I am running a pione version right here as you can see I am running a virtual version but to you it might be user bin python which is the default location for for the python installation if you if you haven't selected a pi inversion so let's select a pi inversion right now in order to set any of your versions that you have previously installed this is very important you have to add previously installed a version in order to to set it as a global version you're going to have to do pine Global and then the version that you want so let's do that um here I have 3.10.11 but let's say that for now I want to set it set a global to 3.8 so I'm going to do PI m global 3.8 now if I click enter and if I run Pi inversions again you will see that my asterisk right here is now um it's now marking my version 3.8 and that is because now I am running python 3.8 as you can see all right so there you go that is how you do and that is how you select a version I'm just going to go back to Globe to 3.10 but this means that any application anywhere in my computer that wants to run python it's going to run my Global version and this is how I select which version of python I want this to run okay so yeah that is how you do it and by the way just uh so you know now once that once that you have done that when you do next time you do which python you're going to see that it comes from the pient directory okay so there you go now let's take a look at how to create virtual environments which is the the real juice of this okay so let's do it all right great so now we have our Pines configured we have installed several versions of python and we know how to select each one of them okay now it is time to create our virtual environments okay um and this is actually the step where you're going to start next time that you want to create a new project okay um because you will already have all the previous things installed and yeah so Bravo for getting this far right um but first before I show you how to create a virtual environment I'm going to show you I'm going to tell you why it is important to have a virtual environment okay now if you have ever started a project in Python you of course you realize that you have to install some dependencies right so naturally you're gonna run to your terminal and you're going to type pip install and then you're going to install your package okay and I mean that may look very easy and very good okay the problem is that that package is going to remain installed in your system in your Global version of python okay now when you delete your project that package is going to remain installed in your Global version of python even if it's saying in a in a virtual environment in a in a virtual version of python that you installed with pyth it's still going to be installed in the global version of python and what happens when you want to start a new project and that other project requires a dependency that has the same name for example that may run into conflicts or what happens if you need if you're working at another project that requires a very specific version of one of your packages okay well that is not going to work either because you already have one version installed in your Global environments you're going to have to downgrade Etc it's just going to cause you headaches okay the right way to do this is to install a virtual environment that packages it all into the project okay so basically that means that every time once you create a virtual environment every time you run pip install inside of your project um all the dependencies will be installed only inside that project okay and not in your global environment that's very convenient right so that way I mean yeah you will have to reinstall the dependencies whenever you need to create to run a project but it also means that you're not polluting your Globe your Global version okay now um just to summarize a having a virtual environment allows you to install packages locally for a specific project it allows you to install different versions of packages for different projects it allows you to install packages that are not compatible with the version of python that you're using globally and it allows you to install packages without having to worry about conflicts and to bundle your application with the same version of python that you selected because remember remember that you can select any version of python that you want to use in your project and bundle it together with the dependencies so everything will be in the same container in the same box that's why the image right here are little boxes you can think of each little box as a project with all its dependencies inside of it and the python version that it's using inside of it so all you have to do is take the Box open it and you're ready to go that is the usage of a python virtual environment okay so let's see how to how to create one all right so now we can start but the first thing we have to do is to set the local version of python that we're going to use in our project okay you can of course skip this step if you don't require a very specific version of python that doesn't mean that you're going to be using the global version okay but if you don't specify a local version of python your virtual environment will be default will default to the current local version and we'll create a copy of your Lo of your Global version in a local virtual environment okay unless you manually select another python version so let's show you how it how that works I'm going to create a project as I would do if I'm if I was going to start a real world project so I'm going to create a new directory in my desktop I'm going to call it my project okay and then I'm going to use it I'm I'm going to open it using Chrome uh sorry code vs code so there you go now here's my here's my new project I'm just going to zoom in a little bit and I'm going to open the terminal right here there you go so now I can in order to set up the local version of python that I want to use here let's say I want to use Python version 3.8 okay so if I do python dash dash version you can see that I am currently using python 3.10 all right so if I want to use Python 3.8 in this version let's just check before that I have it correctly installed so I do high-end versions and you can see that I have python 3.8 installed right here so I am going to do pine local because I am not changing the global version of python I am only changing the version of python that I'm going to be using inside of this project which means inside of this directory okay and I'm going to set it to 3.8 like this I click enter and you can see a new file was generated with python version right here and it says 3.8 because it is the setting the version that I specified right here now if I do python dash dash version you will see that I am running python 3.8 now okay but if I go to another directory like my home directory right here I am not inside the project and if I do um python Dash Dash version you will see that here I am running python 3.10 but inside my project I am running python 3.8 that is very very convenient okay so that is how you set up your local version of python and if you want to see where that python is coming from you can always do which python and you will see that it is coming from PI INF but that is not what we want yet we want it to come in from inside our project now we we told our project that we were going to be using python 3.8 but we wanted to use the python from inside the virtual environment let me show you how to do that great so now that we have our local version of python all already configured we can actually start creating our virtual environment okay and it is very very simple so what we're going to be doing is we're going to be running this Command right here it's python-mvn and then the name of your virtual environment okay so let's do that python Dash m v n and then the name of your virtual environment myself I usually name my virtual environment just vnf because whatever but you can type whatever you want you want here that helps you identify this virtual environment I'm going to type this and then hit enter and as you can see a new folder called vnf because I named it vnf was created up here okay so there you go now um once I activate it you will see that every every time I I run pip or python it will be run from inside of here however not yet if I do which which sorry which python right now I am still running python from piant okay and I don't want that because that is my Global version okay I want my python to come from inside of here and I want pip to install my things inside of here as well okay how do we do that all right let me show you that in a moment great so now we have our virtual environment created as you can see right here however it's not activated yet what does that mean so far it is just a single folder inside of our project okay it's not doing anything yet what we want to do is that every time we want we type python it's going to come from here and every time we type I mean this is more importantly every time we type pip install we want it to install the things inside of here and not in our Global in our Global version of python okay so how do we change that in order to change that you can do source and then you you're going to execute this file right here activate Okay so we're going to do source V nth which is the name of my fault of my virtual environment but if you named it differently you will have to write the name of your virtual environment right here then you go to bin and then activate Okay you click enter and now you will see the name of your virtual environment right here that means that your virtual environment is activated and now as you can see if I do python dash dash version we're running python 3.8 as before but when I do which python you will see that it's actually coming from inside my virtual environment okay so the binary of python is actually inside of here and also the binary of Pip this means that it is going to be that whenever I run pip or python inside of this project when my virtual environment is activated it is going to install all the dependencies inside of here and that is not going to pollute my Global version of python okay so there you go um important thing if you are running Windows if I am not mistaken instead of running here instead of activating it like this you do exactly the same thing but without the command Source okay there you go and then at some point if you want to listen to deactivate this this local environment you say deactivate and there you go there you go and now we are back to our python from PI okay so there you go that was how to enable and to activate your virtual environment great so now the next thing we're going to do is we're going to be using git okay if you are developing software an actual application it is a very good idea that you work with Git git is basically a source control mechanism that allows you to roll back to previous versions of your code and it also allows you to store your code in a repository in a very very organized Manner and to work in groups Etc but git is a topic for an entire course in itself I'm just going to to show you the basics of how to set it up okay if you want more um more information about how to use git you can read this article right here learn the basics of Kit in 10 minutes and it's very very straightforward okay so if you don't have it installed just as usual remember you can always do everything with kit with Brew everything you can imagine absolutely so what we're going to do is I mean if you're not sure you can always do Homebrew install and then you check if git is available let's say apparently git is available for Homebrew so you just do Brew install git there you go so that's what I'm going to do right here I'm going to the Brew install kit and this one is actually probably going to take a while because I haven't upgraded it in a while and for you it's probably going to take a while as well if you haven't installed it yet so while that happens we're going to come right here and we're going to come to our project and we're going to initialize and get the repository to do that we do get init like that and that is going to start a new git repository okay and that is going to start tracking all of our files however some files we don't want them to be tracked okay so I mean we of course want to know which python version we're using but we don't want to track the virtual environment because we don't want to track all of the packages in our code we just want to know which packages are in our code so the way to do that is to create a new a new file called git ignore okay so we're going to do touch dot git ignore it's important that you that you name it like this and just in case you don't know touch is a command in Mac that just creates files so now I have created my git ignore and basically every single thing that you're writing here is going to be ignored like it okay so in order to to fill it I usually just go for a very generic git ignore so I do git ignore for python I mean it depends on the technology that I'm using but for python I just click here and this is a very generic git ignore it contains all of the usual things that you wouldn't want to be tracked on your git Repository and this is very important because um you're going to I mean one of the main uses of git is that it allows you to put your code up in the in in GitHub right and GitHub is usually public so if you have API keys or your virtual environment for example these are things that you probably don't want public so so this right here as you can see by default it just removes the virtual environment default name for the virtual environment right here so now I can I have I am tracking these two files but vnf is not being tracked and it's not going to be uploaded to GitHub okay so that is how how you initialize git and in order to add all of the other files you're just going to do get at and then you did say dot to say everything in the current folder and then you say git commit to commit your first um to make the first commit and then you do first commit for example okay um if you don't know what just happened don't worry it's not super important if you're not developing software but I do encourage you to read this uh very very simple basics of Kit in order in under 10 minutes okay to to get you started with it and there you go now before going to the notebooks I just wanted to show you something real quick about um dot EnV and API Keys okay so let's do that great so now what I want to show you is how to create this other file that you sometimes see in other videos that is called dot EnV okay so let's do it I'm going to do touch dot EnV and as you can see vs code already recognizes that this is a special file okay and actually whatever you put inside of this file is going to be whatever you put inside of this file is going to be kept secret okay because by default in the git ignore you can see that it's hiding the dot EnV files okay so this one is not going to be uploaded to your GitHub repository and this is the place where you put your API keys so my API key and then you save you you say whatever is your API key right here and then let's say the port in which you're going to be in which you're going to be exposing your application Etc right so that's going to be here now if you want to be able to read it from your from your script let's say that you have your script right here main.py and if you want to read it you are going to need a second you're going to need another dependency okay this dependency is called python dot EnV and it basically allows you to read whatever is inside this file okay so in order to actually use it we're going to first activate our our virtual environment and now everything I installed is going to be installed my VNV so I'm going to do pip install I'm going to say python dot EnV like that that is going to install python.dmv inside here and now I can import sorry from python no from dot dnv there you go we're going to import dot load.tnv now we can just execute this application this function right here that is going to allow us to read anything that is here so if I now do print and I say in order to read it I'm going to have to import OS as well so if I want to print OS dot get EnV y I'm going to get this variable right here called my API key um let's say like this I can say this comes from dot EnV now if I save this and I run it you will see this comes from Dot tnv and you will see my API key that comes from here and that is hidden from GitHub okay and from from whenever I upload this code this file is not going to come with this okay so that is very important but um I mean this sometimes this is very important for your code to work right because you will need your API key for your code to work you will need your port for your code to work and other important information so if this is not being added to your repository how do other developers know which variables to keep here and actually in order to know to help other developers use your application you have to re I mean to duplicate this file right here and you rename it and call it dot EnV example and basically this is exactly the same file but without the well it's raining hard but without the actual confidential information so we save it and as you can see this one is going to be added to git and this and then the new developers that come will only have to fill this fill this one in and change its name to dot dnv so that it can be read by your application like this okay so there you go that's how to hide important information from from the public and also something pretty important that you may know is that if you're running uploading your application to a server how does your server know um which where I mean what are the value the values of this variables and actually servers have something called environment variables that you will be able to set when you deploy your application and it basically is exactly the same file that you see right here but in your server but you can see that when you start deploying your applications so there you go that was how to use Dot dnv so there you go um now now you have you actually have your entire software development in Python environment setup okay so now this is something that you can already use to start developing your applications um however something that I like to have on the side for basically just sketching and running very quick tests is a notebook okay and this is where jupyter notebooks comes in jupyter notebooks is basically um I mean you probably already know that but it's just a piece of software and that allows you to execute um individual pieces of code of Pi of python and run them individually and it's very easy to run tests on them okay so it's way easier to to run tests over there than to start testing on your on your script and then you have to write a function then yeah you have to debug it Etc it's just easier to do it like this you can of course install jupyter notebooks like this you go to Jupiter notebooks and you download it or you can install anaconda and and it comes with jupyter notebooks but what I like to do instead of doing all of that I like to use collab and that basically is just Jupiter notebooks on the cloud for Google okay so you do you you can just Google Google collab and you will write that right here you just need a Google account okay and this basically works exactly like um you would expect it works like python you do python hello world and here it just executes it right away and here you can just upload your files that you want just be careful because whatever you upload here is going to be deleted once you refresh the session this is basically just for sketching if you're developing um a full stack application in Python okay um and yeah if at some point you need to install something um like you would in a terminal right so for example right here you have your code right here and you have your terminal where you do pip install things right if you want to do that right here all you have to do is to add an expression sorry an exclamation mark right here and whatever you put um after this is going to be executed in a terminal level okay so if you do pip install um I don't know tensorflow or whatever it's going to install it in the in this notebook in the cloud okay and that is just very convenient to to work with because you can also store it in your Google Drive Etc and just to show you and if I do LS it's going to display the current files in the current directory and as you can see in my current directory I have sample data and then you have sample data right here okay so yeah there you go um just use remember to use Google collab very convenient very easy and then this is how to set up your project there you go all right great so congratulations if you have successfully finished this video and you have successfully created your own development environment in Python that is going to work very good with your projects and just remember to always use a version of python that comes from pip install do not break your head trying to to run your development in the python in the system version of python that's just going to make your life easier if you enjoyed this video please just give a like And subscribe to the channel if you like if you would like to see more videos like this and yeah I will hope to I hope that it was useful and I will see you next time foreign [Music] [Music]
dXxQ0LR-3Hg,2023-05-29T21:52:22.000000,Chat with Multiple PDFs | LangChain App Tutorial in Python (Free LLMs and Embeddings),good morning everyone how's it going today welcome to this new video tutorial in which I'm going to show you exactly how to build this application that you see right here it is a chatbot that allows you to chat with multiple PDFs from your computer at once okay let me show you how it works and for this example I'm going to be uploading the Constitution and the Bill of Rights then when I click on process it's going to embed them and put them into my database right here now I can start asking questions about this so for example what are the three branches of the United States government that is a question related to the Constitution but then I can ask a question also about for example the First Amendment which is in the Bill of Rights and it's also going to be able to answer me it only answers questions that are related to the PDF documents that you upload so it really is only about the information that you provided I'm going to be showing you how to build this not only using openai but also using hugging face free models so that you don't break your wallet while trying to learn how to do this um yeah it's a little bit more complex than the previous projects that I had shared in this channel But be sure to follow to the end I'm sure that the result is worth the effort I hope you enjoy it and if you like videos like this don't forget to subscribe foreign [Music] real quick I'm just going to guide you through I have already created my virtual environment right here and which is where all of my dependencies are going to be installed as you can see I am using python 3.9 for this one we're going to be using that our DOT EnV file to store our secrets git ignore which is the file that tells git to ignore these two files so that our secrets and our local configuration are not tracked on git here is just my document of my python version and this is app.py which which is where all of the action is going to be taking place the first thing that we're going to want to do is to install the dependencies that we're going to need in order to do that you can do pip install and the dependencies that we're going to need are streamlit first of all to load to create the graphical user interface we're going to be using pi PDF two like that in order to read our PDFs we're going to need line chain to interact with our language models we're going to be using python dot EnV in order to load our secrets from tnv we're also going to be using files CPU as our Vector store we're going to be using open Ai and hugging face Hub because I'm going to be showing you how to do this both with open AI models and with hug and face models okay so once you do that you hit enter and it's probably going to take way longer for you because I already have this installed but yeah now we can actually start coding now that we our environment is completely set up all right so now let's start with the graphical user interface okay um first of all I'm going to first make this test real quick right here um this basically just tests that the application is actually being executed and not being imported so whatever is inside this condition right here is only going to be executed if the application is being executed directly not if it's imported that's kind of a manual test that you usually do and then you create your function right here and whatever is inside of this function is what is going to be run in the application so if I say here for example print hello world and I run it you will see that I see Hello World right here um because I am executing it um there you go so now let's start with the graphical user interface as I mentioned before we're going to be using streamlit for the graphical user interface and to do that we're going to start by importing streamlit that way previously installed so we do import streamlit as St as we do and then the first thing that I want to do is to set the page configuration okay so you do St set page configuration I'm just going to pass in two parameters but you can pass as many as you want from here and I'm going to set the page title to um chat with multiple multiple PDFs like that and I'm also going to pass in a page icon like that and I'm going to set it to the Emoji of books um also here I'm going to add a header why not SD header like that and I'm just going to say like this is going to be the main header of the application going to say that it's going to be also chat with multiple PDFs like that um like that and also it's going to add the Emoji right here of some books and also remember that below the header we wanted that to be a a text input where the user was going to be able to add their questions so let's add that St text input like that and whatever you put inside of here is the label from the input so you can say ask question ask a ask a question about your documents here like that that's going to be like the label that's going to appear on top of the user on top of the text input and then something else that we want to do is we wanted to add a sidebar where the user is going to be able to upload their PDF documents so in order to do that you do St sidebar and if you want to put things inside it you have to do with SD sidebar and then colon and then whatever you put inside of here is going to be inside of your sidebar okay watch out do not add parentheses here because otherwise that is not going to run you will have to pass in some parameters right here and you don't need that so just leave it like that and here just write the contents of your sidebar in our case we're going to be adding a sub header that reads your documents and right here we're going to add another streamlined component element that allows you to upload files right here and this one is called SD file loader there you go and just as with the text input inside of the parenthesis you just add the label okay label as you can see and my label is going to be upload your PDF upload your PDFs here and sorry about the ambulance upload your PDFs here and press on and click on process like that there you go um I suppose that's pretty much good let's just add a button SD button and the button is going to be process like that now if I click on Save and remember how you run your streamlit application you don't do python python app because that is not going to work you have to run it by with using extremely so you have to do extremely broad app.py so you do streamlit run and then the name of your file which is in my case at the py and now the app is running and as you can see I have my graphical user interface right here and up something happened here there we go I have my user interface right here and it seems to be working correctly now here I can ask questions and all here I can upload files in this case the files I want to upload are the Bill of Rights and the Constitution but so far it's just a graphical user interface there's nothing happening behind so yeah let's add some logic to it all right right so what we're going to want to do is to create our API keys and because we're going to be using some Services by openai and by hug and face so we're going to be able to connect to their apis and in order to do that we're going to be needing their API Keys the API keys we're going to be storing them inside of our DOT EnV file because that is the place where you put things that are supposed to be secret and they're not supposed to be tracked by git so whatever you put in here is not going to be tracked on GitHub when you upload your repository to GitHub okay that's the way to keep your secrets away from the public and the way to do this is we're going to create two variables right here one is open AI API key and the other one is hugging face Hub API token and let's go create them in order to create it at open AI you have to go to platform.openai.com create an account and then go to account API keys and then here you just create new API key I'm just going to call it PDFs you created and then you copy it and then you come right here and paste it here same for hugging face you're going to go to huggingface.co settings tokens and then you can create a new token I'm going to say that this one is also PDFs I think really smart and enough but I'm just going to give it right in case I want to use it again I copy it and then I paste it right here there you go um so now that I have my api's key set I need to be able to access them from here in order to be able to access them I have to first use this other package from python that we installed before and this package is called load load environment I think so you say from dot EnV file [Music] we're going to import load.tnv there you go and this is the function that you're going to run inside of Main in order to enable your application to use your variables inside of dnv so here let's just run load.tnv and now Lang chain is going to be able to access all of our API keys right here okay that's why I mean since we're going to be using launching remember that we have to name our variables exactly like this if you were dealing with your own framework you can name the variables as you want but since Lang chain things where you're going to be using language enhance it's a very specific way to name the API key variables so just remember that you have to name it like this and then just include.load.tnv right here and there you go now we click save and now our API keys are set and we can start dealing with the rest of the logic right here all right so what I'm going to do now is I'm going to show you how this and the logic of this application works um if you have already watched the previous video on PDFs and how to chat with a PDF this is going to sound very familiar to you if you haven't be sure to watch it because that's a much more thorough and detailed explanation of how this application works but in case you just want like a real quick refresher I'm going to cover it real quick right now but if you do want a detailed description with examples and everything of how this process works take a look at that video because it's going to make it easier for you to understand what is going on so um just like real quick what we're going to be doing is we're going to be taking the PDFs from our user we're going to be taking several as many as as he wants and this PDFs we're going to divide them into pieces of text okay so we're going to read all of the text from our PDFs we're going to have then just a huge string of text and that's that string of text we're going to divide it into smaller pieces and chunks of texts okay it is those chunks that we're going to later convert into embeddings now what are embeddings embeddings are you can think of that in a very simple way as a vector representation of your text or a number representation of your text and something very important about this string of numbers of the of this list of numbers that represents your text is that this list of numbers also contains information about the meaning of your text okay this means that we can potentially find similar text that has similar meaning to your text just by seeing their number representation and that's exactly what we're going to be doing later so once we have the vector representation of each of your chunks of text we're going to be able to store all of those embeddings um or your vector representations into a vector store or a knowledge base this is basically just your database of all your or folio or vector representations and this database it can be Pinecone it can be chroma it can be files in our case we're going to be using files but Pinecone is just like the most popular one so I just added this logo right here to show to help you see what's going on foreign but now that we have our database right here we're going to be able to take this um we're going to be able to take questions from our user the user is going to ask a question like for example what is a neural network or something like that and then the question we're going to embed it using the same algorithm as we did with the embeddings in our chunks of text that is going to allow us to find inside of this database the vectors or the vector representations that are similar from all of these chunks of text we're going to find the the ones that are similar or have similar meaning or semantic context to our question that the per that our user asked that way this is going to give us our ranked results of the chunks of text that are relevant to the question that our user asked and we're going to be able to send all of those um send that as context to our language model so actually the language model doesn't really know what the PDFs have what we're actually doing is the language model is already trained our language model can be can come from hugging phase or it can come from open AI or something like that but the language model doesn't really know what our model what our PDF documents have what we're doing is we're finding the chunks of text that are relevant to our users question finding them and ranking them in order of importance and then sending them as context to our language model so behind the scenes The Prompt is going to look something like based on the following pieces of text of chunks of text answer the following question and then we're going to pass in the chunks of text selected by our Vector store and we're going to ask the question and then the language model is going to be able to answer the question depending on on the context that we gave it and then it's going to be able to give us an answer and that answer is going to be sent to our user and that's actually what is happening behind the scenes and langching makes it extremely easy to do all of this with just a few commands so let me show you how that works all right let's do that all right so what we're going to do now is we're going to be dealing with the with the sidebar right here uh remember that we have our we have our document drag and drop here but so far it only takes one file as you can see only one file allowed so we're going to enable multiple files and we're also going to be dealing with what to do when the user clicks on the process okay so let's do that in order to take more than one file we're going to come right here to our sidebar and to our file uploader and there's actually a very convenient parameter called accept multiple files we're just going to set it to True like that there you go and we're going to store the contents of this file upload into a variable called PDF Docs like this and now what we're going to want to do is we're going to want to do something whenever the user clicks on the button so in order to do that we just have to add an if before the button that way the button will become true only when the user clicks on it and then we're going to have to actually start processing information right here and inside this button what we're going to do is three things remember the first of all is we're going to oops we're going to get the PDF text to get just the raw contents of the PDFs of all the PDFs then we're going to get the text chunks get the text chunks which is this part right here to divide it and then we're going to get the vector store I'm going to create our Vector store with the embeddings Okay so create Vector store there you go we're going to be building these three different functions in a moment but before that I'm just going to show you that actually something very useful to do when you're dealing with these kinds of processes especially when you're dealing with streamlit is to add a spinner right here so you do St spinner and then you just say processing or something like that and then just like with the sidebar you do with spinner there you go and then just wrap everything inside of it and what this does is that all the contents inside the spinner are going to be um processed while the user sees like a spinning wheel and it just tells the user that the program is actually running and except and processing things and it's not frozen so it's just for to make it more user friendly okay so there you go now we can actually start dealing with these applications with this functions now we're going to get the text from the PDFs right so let's do that all right so now what we're going to do is we're going to take all of the raw text from our PDFs okay in order to do that I'm going to create a new variable called Raw text right here and I'm going to create a new function called get PDF text like this and this function is going to take our PDF documents like that okay um so let's I mean the objective of this function is to take our PDFs documents which is a list of PDF files and it's going to return a single string of text with all of the content all of the text content of these PDFs okay so let's create that function up here um there we go so the function is going to be called like this and actually we're going to be needing a library that we installed before and this library has Pi Pi PDF so we're going to import it from PI pdf2 we're going to be importing um a class called PDF reader all right and you will see how we use it in a moment so inside of this function what I'm going to do is I'm going to first of all initialize the variable which is going to contain all of the raw text of my PDFs and then I'm going to Loop through all of my PDF objects right here and read them so and read them and take the contents of that and append it I mean concatenate it to this variable right here so let's do that now what I want to do is set for PDF in oops in PDF Docs I'm going to want to initialize a PDF reader object foreign here you have to initialize it with the PDF object that you want to that you want to initialize it from and what it does is that it creates a PDF object that has pages and it is actually the pages that you're able to read from so what we're going to do is we're going to loop as well through the pages to actually read each page and add it to the text so now for page in PDF reader um PDF reader dot pages then this page contains the method called extract text like this and this one just extracts all of the raw text from this page of the PDF and we're going to be appending it to our text variable and returning our final text variable in the end like this so let me just repeat real quick what happened right here so we initialized a variable called text which is in which we're going to be storing all of the text from our PDFs and then from each PDF we started looping we started looping through all of our PDFs we initialized one PDF reader object for each PDF and then we looped through all of the pages of each of these PDA of these PDFs and we extract the text from that page and appended it or concatenated it to our text variable right here so in the end what we should get is just a single string with all of the contents from our PDFs inside of this variable called raw text let me show you real quick how this looks so if I do St write and I just write the raw text right here I'm supposed to see I think I stopped the application yeah there you go now what you should see when I upload my documents right here and I click process you should see that it first of all shows a spinner saying processing and then it displays the raw text because that's what we're getting right here so let's do that I'm going to be uploading the Constitution and the Bill of Rights and then if I click on process you will see that now I have all of the text right here and now I am able to actually divide it into chunks of text so let's do that all right so um what we're going to want to do now is to split this huge piece of text into chunks that we're going to be able to feed our model like this okay and if you had seen the previous video you already know what I'm going to do it's actually very simple I'm just going to create a new function right here I'm going to say that I want to get the chunks text chunks like here and this function is going to be called get text chunks like that and right here we're just going to pass in a single string of text and this one is going to return a list of chunks of text that we're going to be able to feed our database Okay so um let's just create this function right here we come up here and we do Define this there you go now in order to divide our text into into chunks or pieces or paragraphs we're going to be using um a library we're going to be using blankching okay so we're going to be using a class from launching called character text splitter so we're going to do from Lang chain oops from langchain dot text splitter we're going to import character text splitter like that okay and this is the one that we're going to be using to divide our text right here so first of all we're going to create a new instance of it we're going to say that our text splitter is going to be a new instance of character text splitter and actually character text splitter takes several parameters the first one as you can see right here is the separator and we're just going to set it to say to say that this separator is going to be a single line break then we're going to say the chunk size like this now in this case we're going to set the chunk size to a thousand which means a thousand characters and then we're going to set a chunk overlap [Music] to 200 okay just to be clear the the chunk size is the the size of the chunk like this so if you start here a thousand characters probably going to go somewhere like here and then the chunk overlap is basically just to protect you whenever your your chunk ends in a place like this you're going to want to take the previews I mean you're not going to want to start the next one right here because you're going to lose all the meaning from this sentence so the overlap is just going to start the next chunk a few characters before so if it's 200 it's going to start the next chunk 200 characters before to be sure to to contain all the full sentences and to contain all the meaning that you need in or in a single chunk okay um so that's the chunk overlap and then the length function length function like this is going to be the length length function from python okay um and then basically we're just going to create our chunks from our text splitter we're going to say split text and we're just going to pass in the we're just going to pass in the text right here like that and then we're just going to return [Music] the chunks like that so if I'm not mistaken right now we should have this element right here that contains our split text method and that will just return to us a list of chunks of about a thousand character size and with an overlap of 300 so let's see how that looks so now that we have this right here we can just St write it and to display it in our sidebar right here so let's just refresh this page right here and let's load again our two documents we can click on process and there you go so now you have the first chunk is this one right here the second one is this one right here and as you can see this one starts like here okay so that's the overlap in action so there you go now you have all of your chunks divided and now it's time to actually use those chunks to create the vector store okay so now we are we created this and now we are going to do this part right here and it's very quick so bear with me right all right so now it is now that we have our chunks of text what we're going to want to do is we're going to create our embeddings okay now our embeddings if you remember correctly are here it is this part right here which is The Parting we create the vector representation of our chunks of text in order to store them in our database so that we can run this semantic search to find similar chunks of text that will be relevant to our question um I'm going to be showing you two ways of doing this the first way I'm going to be showing you right now is by using open AIS embedding models okay now this is paid for so you have to keep that in mind in your business model if you're going to be loading documents that are thousands of pages long but the prices are right here if you go to openai.com pricing embedding models like the latest one is like ridiculously cheap anyways I remember someone saying in Twitter that you could embed the entire transcription of Joe Rogan's podcasts for 40 euros 40 dollars or something like that so I mean it's not super expensive but it's definitely something to keep in mind in your business model okay um that's the first one and the second one that I'm going to show you is a free one called instructor and this one is actually very good however you do have to have the I mean it's going to be way slower if you're just running it in your computer and expecting it to to just make all of the embeddings in your CPU you you got to have a GPU or something like that in order for it to be performant however something that I wanted to mention that is that unlike with language models like GPT 3.5 or gpt4 were pretty much all the Benchmark for how a language model should be so far like open ai's language models are undoubtedly the best on the market so they're like other models are measured compared to them however when it comes to embedding models they are not at the top if you see right here the official I mean leaderboard from hogging face you can see that Adis I mean open AIS model which is Ada V2 here it's actually on six position and instructor which is the one that I'm going to show you how to use is in second position and it's probably the one that I would recommend if you have your own Hardware but yeah just keep that in mind that instructor you're gonna have your own hour your own Hardware or I'm not sure if they uh make it available here on interface API but it might be available on hogging face but yeah just keep that in mind and let's get to doing the hugging the open AI one for now all right so let's now create our Vector store from this text chunks right here using open AIS embeddings uh so I'm going to do vector Vector store equals get Vector store and we're going to do it from the text strings all right and then we're gonna have to Define this function right here I'm going to Define it down here there we go and this one actually is a very simple function um since we're going to be using for now open AIS embeddings we're going to do from Lang chain dot embeddings import open Ai embeddings and we're also going to be using files as a vector store okay files is pretty much just like Pinecone or like chroma or whatever it's just a database that allows you to store all of these numeric representations of your chunks of text okay the different thing about files is that it runs locally so in this case we're going to be storing all of our generated embeddings in our own machine instead of in the cloud or something like that so this is going to be erased when we close the application probably in another video I'll show you how to use a an external persistent database but for now let's do line chain dot Vector stores we're going to import files there you go so here we're going to say that the embeddings embeddings are going to equal open AIS oops open AIS embeddings and then we're going to say that the vector store is going to equal our files and we're going to generate it I mean right now we're creating the database okay we're going to be generating it from texts okay because we have the chunks of text right here and this one takes two parameters the first one is the chunks the actual text which are going to be our text chunks chunks of text and the second one is going to be the embeddings and here we take the embeddings that we just created all right so and this is the one that we're going to return return Vector store there you go um so yeah there you go now we have successfully created this Vector store right here by using open Eis embeddings and let me just show you how fast that is because we are sending just the chunks of text to open AI servers and then it is them who are doing all the heavy lifting um so let me do this streamlit run um one second stream late oops streamlit run app.vy let's see how that looks like there we go we have the application running right here I'm going to upload the same files as before I'm going to click on process and let's see how long it takes to process remember that we're using the open Eis API key that I set before and now it's ready all right so that wasn't very long um and it's open AI servers which did that if we want to do it in our own computer we can use the Transformers sorry the instructor API and and let me just show you how to do that right now all right so now I'm going to show you how to do exactly the same thing I mean remember that we have just successfully created our Vector store which is our database with all of our embeddings but do that for free okay before like just a moment ago I was charged for what I did for embedding the 20 Pages ish of my two documents all right so now we're going to do it in my machine and we're going to do it for free so let's see how that looks like we're going to be using just as I mentioned before the instructor embeddings and as you can see it is actually ranked higher as I mentioned before it's high ranked higher than open Eis embeddings um so let's click on that one and this is the one that we're going to be using however something that's important to keep in mind is that I forgot to mention that you have to install a couple more dependencies for you to use this so you're going to do pip install and the two dependencies that you're going to need are first of all the instructor embedding which is the main package that we're going to be using and then sentence Transformers which is just a set of dependencies that our instructor embedding is going to use however do keep in mind that this was super fast for me but these are pretty heavy packages so don't worry if it takes several minutes for you to actually finish downloading and then once that's installed you can actually come right here it's it it's inside the same module LinkedIn embeddings you come right here and you say hugging face instruct embeddings and here just instead of doing open AI embeddings we're going to initialize a new embeddings and this time we're going to call it from hugging face instruct embeddings okay and this one actually we're just going to pass in the model name model name and the model name for this one is exactly this one that you see right here remember that this is the one that we're going to be using so we just take this and we just paste this right here and now we should be able to pass in this embeddings that we just created from our hugging face embeddings into our Vector store right here and it should work however as you will see it's going to be way way slower let me just show you what I mean so if I do streamlit run app.py I'm going to put this on the side like this I'm going to get rid of this I'm going to show you on the terminal right here and if I bring my application up here um this as I mentioned before this is barely 20 Pages or something like that and remember that just before for open AI it took like four seconds for it to embed everything now if I click on process right here you'll see that it starts to process it loads the Transformer and as you can see it's loading in my computer okay so it loads the Transformer then you will see that it loads the it loads the CPU Etc and so here you have like the start time all right it started with my CPU I'm going to pause the video right now and let me just show you in a moment how much it actually took to embed only 20 Pages all right in my computer using CPU I don't have a GPU connected to this one right now so let's see all right so it finally finished uh it didn't actually take that much that long it took two minutes to do it in my computer however like do keep in mind that this can easily scale up if your computer is not um powerful enough or if you're just running on relying on a CPU okay so yeah so that's how to do the instructor embeddings in your application now what we're going to do is we're going to we have successfully finished all of this part we can actually do this and Langston actually allows you to do that super quick in just one single chain and we're going to include memory in it super quick as well so let me show you that in just one moment all right so now it's time to start creating this part right here and it's actually super quick and super simple because langching provides a chain that allows you to do this out of the box okay and it's actually very convenient because you can allow it allows you to add memory to it so this means that you can ask a question about your document and then ask a follow-up question about that about the same thing that you're talking about and the robot is going to I mean the chatbot is going to know the context of your question okay so let me show you how to do that real quick we're going to have to come right here and then we're going to have to create an instance of this conversation chain okay so I'm actually going to create a new function for that I'm going to say conversation create conversation chain so I'm going to call this conversation I'm going to store it in I'm going to create a new function just like we were doing get conversation conversation chain and this one is going to take my Vector store okay there you go so now let's just like before we're going to have to create this function up here um Define there you go and right here we're going to have to initialize a few things first of all since we're going to be dealing with memory I mean a chatbot that has memory we're going to have to initialize a an instance of memory in order to do that we're going to have to import this from launching and it's called conversational buffer memory okay so from launching dot memory we're going to import conversational buffer memory so there you go and now we can successfully initialize it right here we're going to say memory equals conversational buffer memory that we just imported like that um there you go and we're going to set this one in order to initialize it we have to set a memory key first of all I'm just going to call it chat history and let's say that it returns message let's set that to True okay if you want to know more about how memory Works in langchang and how you can use buffer memory or entity memory or other kinds of memories be sure to check my video I have a video especially about that so check it out and then once we have this memory right here we can actually initialize the session so conversation conversation chain let's call it and we're going to say that this equals the conversation the conversation of retrieval chain that I actually haven't imported so I'm going to say that from langching Dot if I'm not mistaken is from chains we're going to import conversational retrieval chain which allows us to chat with our switch our with our text with our context with our Vector store and have some memory to it so in order to do that first of all we're going to say that we're going to say that this one is going to be conversational retrieval chain from language model and this one right here takes a few things the first one is the language model that we're going to be using in my case let's use let's let me just initialize it right here the language model is going to be open AI open AI I'm going to import it from here blank chain from langchain.lms import open import open AI there you go so now I can use open AI this one's going to use DaVinci actually you know what let's use chat model a chat model instead chat models where you're going to use chat open AI and here we're going to initialize it with chat model there you go now we can use this llm right here um so the first argument that our conversational retrievable chain is going to take is the language model so I'm going to say llm equals my language model the second argument is going to be the vector store or the Retriever and I'm going to call my Vector store that I took right here I'm going to say as retriever there you go and then my memory is going to be the memory that I initialized just a moment ago okay and now this is my my conversation chain I'm just going to return it return my conversation there you go now something important to keep in mind right here is that we have just created our conversation object okay this one right here is going to allow us to to generate the new messages of the conversation this one in like in a very uh high level explanation all it does is it takes the history of the conversation and it returns you the next element in the conversation okay so this is the one that we're going to be using in the entire application later on right here so it is a good idea to have this persistent during the application something about streamlit is that whenever something happens like someone clicks on a button or someone submits a something on an input field or something like that um extremely tasks a tendency to reload its entire code so if I click on something or just submit a text input or something it's going to try to reload the entire thing and then that means that it's probably going to re-initialize some variables so if I don't want that to happen if I want some variables to be persistent over time I can do St session State and that way the variable is linked to the session state of the application and the application knows that this variable is not supposed to be re-initialized okay in this case we're not going to be doing this especially because of the originalization because this is only triggered when we click on the button however this is also useful when you want to use a variable or an object during the entire application so as you can see right here we initialize the conversation object right here but we may want to use it outside of the sidebar and that would be outside of the scope of the of this of this piece of code so a good I mean a good thing about the session state is that you can just use it outside of it if you go to session State DOT conversation oops conversation this is going to be available outside of the scope so that's a good way just to to use some pieces of some some objects outside of your of your scope if you're using streamlit uh something important about this is that it is a good practice that if you're using a session State object you initialize it before so we're going to come right here we do conversation and we're going to test that if it's not in my session State sorry session St dot session state if it's not in my session State we're going to initialize it and we're going to do sd.sessionstate that conversation equals none all right so this way when if the application re-runs itself it's going to check if conversation is already in the state the session state of the application and it's going to reinitialize it I mean it's going to set it to none if it's not been initialized and if it has already been initialized it's not going to do anything with it so now we can use it anywhere in during the application um so yeah so that's uh something important to keep in mind we're going to do the same thing with the history of the chat messages but yeah just so you know how to make your variables persistent during during the entire life cycle of your application okay just to make it clear this is not about refreshing the application it's it only lasts during the session of the application which is while the user is well the application is open all right for some reason extremely just reload some code um from time to time so there you go there we go all right so now that we have done this actually I'm gonna show you how to display messages all right in a previous video I showed you how to do this using a package from streamlit called streamly chat which is pretty convenient if you want to get it up and running real quick however I'm going to show you a different way to do this right now and it's basically just inserting a custom HTML into your application okay so if you're at ease with HTML this is probably a good idea for you if you're not probably not but um I mean it's pretty convenient um here I'm going to create a new file right here I'm going to call it let's say I'm going to call it HTML templates how about that um I'm going to call it HTML templates Dot py and this is some code that I had already prepared so what we have here is basically just the Styles The Styling from I mean the CSS styles that are going to uh style these two classes chat message and Bot and we have two templates so this is going to be the template for the user and this is going to be the template for the bot okay and as you can see I already added some images right here for the users but you can add your own just by replacing what's here in this Source part as well all right and yeah actually I don't need this part anymore now that we now that I think of it there you go so here you go and here's the message and this is the part that we're going to be replacing actually I don't like it this way I usually write my variables like this there you go there you go now actually we can we can save this and we can import these three elements into our application on this side so we're going to say that from HTML templates we're going to import CSS we're going to import bot template and we're going to import user template okay and remember that our CSS we're going to have to add it up here because the CSS is going to just like in a website you have to add your CSS on top so we're going to add it here we're going to do St write and we're going to add our CSS and we're going to say that HTML it's going to allow unsafe HTML okay and then just to show you how it works outside of the sidebar I'm going to add it right here underneath the input element I'm going to say SD right we're going to say that this is the message the user message user template and then we're going to say that we're going to allow unsafe HTML this is only to tell um to tell streamlit that it's supposed to show the HTML inside of it okay otherwise it's just not going to uh parse the HTML as HTML and this one's going to be the bot template okay and last but not least let me just show you real quick how to replace this thing inside I think that in Python the function is um replace yeah so in Python what we're going to do is here we're going to say dot replace and we're going to replace the message with my message here it's going to be hello human and here we're going to do the same thing we're going to replace MSG we're going to say hello Robert there you go let's see how that looks now if I refresh right here I should have there you go hello robot and hello human as you can see this is pretty much this looks pretty professional like a chatbot and here I am and here is the human here's the bot and all I had to do is replace the message variable inside of here with my user template with my personalized message out here I suppose that you can start to see how this is going to play when we replace this with our own sorry with our own message okay so let's do that right now um with our end conversation so let's create the conversation and just use these template to display the new messages all right let's do that all right so now it's it's time to actually generate the compensation all right so what we want to do is what when the user fills something in here we want to be able to handle that input okay so what we're going to do actually first of all I'm just going to get rid of the hogging face instruct embeddings because that's just too slow and this is just for demonstration purposes so I'm going to be continuing I'm going to continue using open AI embeddings for now but now you all at least you know how to do using hugging face instruct embeddings okay so right now what I'm going to do is I'm going to come right here to my text input and I'm going to handle the submission okay the thing is we do user question to store the value from the input in the user question and then we do if user question then this is only going to be triggered if the user submits the question we're going to handle user user input and we're going to pass in the user question like this and just as before we're going to create the function up here okay there you go and here actually it's this is pretty interesting we're going to be using the variable that we created just a moment ago in the sidebar this one right here we're going to be using it to generate the answer to the user's question and that's actually it's very simple to do that the way we're going to do this is we're going to right here we're going to say the response is going to be equal to SD session State and here's where we're going to be calling the conversation the conversation and right here we're going to be doing we're going to pass a key value pair of question and right here we're going to pass in the user question okay and now inside let me just show you what this looks like so St right no response okay so now when I click when I submit a question from the to the user I mean when the user submits a question I am going to handle that input and I am going to write the response from the language model and remember this conversation chain already contains all of the configuration from our Vector store and from our memory this means that this one right here if we use it again is already going to remember the previous question I didn't since I already set up the memory this is already going I mean if I keep asking questions it's it's already going to remember the previous context all right so let's see what this looks like I'm just going to refresh this and I'm going to bring I'm going to bring my two test files right here again I'm going to process them since I'm using open AI oh no I didn't rerun open AI I think it's oh no yeah okay um so I can now do um what is the first Amendment about then if I click enter it's supposed to tell me the answer to that however it's going to return an entire object with a lot of things right so here you have it it has the answer and it also has the entire chat history and that is what's important to us because remember that we want to we want to submit the entire history of the chat right so we're going to take this object right here and we're going to show everything up here everything in the chat history up here down here formatted with this template right here okay so let's do that what I'm going to do then is I'm going to just remove this part right here and I am going to create a new session State variable and this one is going to be session state DOT chat history like this okay and this one is going to be equal to my response and it's going to be equal to my response object chat history like this there you go and now this one is the one that I am going to be displaying now let's say for I message in enumerate s t um as teach at history like this this is basically allow me to Loop through the entire chat history with an index and the content of the index and if I if I mod 2. equals zero mod not and if I mod 2 equals 0 we're going to S to write we're going to SD write our user template our user template and remember just as before we're going to be replacing message with the message Etc so let me just paste this right here replace message but this time we're not going to be replacing it with something in particular we're going to be replacing it with the message and where is it located inside the message inside content so this is the entire message that we're looking through and I want only the content of the message so I'm going to do message dot content like this right here and this is going to since I did mod 2 this is only going to take the odd numbers all right of the history and then else for the pair numbers of the history we're going to SD write as well but this time it's going to be the bot template we're going to replace it as well and there you go now we can replace we can delete this part right here and now if I save this it should work now oh one one thing actually just remember that when you are using session State you have to initialize it up here okay at the beginning of your application so if um if chat history doesn't exist oops if chat history not in not in St session state we're going to initialize it to none so that we can never start using it without actually having it being initialized okay all right so let's go and test it um right here I'm just going to drop my two test documents right here I'm going to click on process and let's see how this works now it seems to be high to be processed I'm running the Bill of Rights so let's supposed to know what does the First Amendment say let's say if it knows and now it's supposed to be actually displaying the message templates that I created before okay so there you go what does the First Amendment say the First Amendment stage blah blah blah and then let's see if it rasps some sort of um context here so if I say how about the second one then if I click this let's see what it gives us going to put myself here and there you go so it knows that we're talking about the Second Amendment because we were talking about the First Amendment before okay so it has some sort of memory it has this um it has this chat like structure and yeah I mean I hope that you found it useful I hope that there's been educational uh let me just show you super quick how to do the same thing but using hogging face models instead of open AIS models because right here remember we used uh chat open AI but actually we can do pretty much the same thing with um with uh hogging face okay so in order to do that I'm just going to copy this that I have right here and I'm going to paste it right here so it's pretty much the same thing but we're going to have to import hugging face hub so from length chain Dot language models we're going to import hugging face hug and face Hub and now we can use it right here and I in this case I'm just using Google flight T5 uh but like you can use any language model that you have right here right so if you come right here and you find a model that you that you want to try with this uh with this structure you just have to remember that we installed before hugging face so hugging face Hub so this comes with that you don't have to install anything um I think you have to install anything else but in any case just read the errors it usually gives you exactly what kind of what dependency you're missing and that you have to install but yeah I mean just write the repository ID right here from uh Facebook Dyno um I don't know I mean just choose a language model that works and then you set the temperature for this one in particular temperature other than I mean temperature zero was causing problems but if you put it to anything other than zero it's supposed to be all right so I'm just going to test it like this and show you how it works um just going to come right here I'm going to refresh this let's just load the two files again and once it's processed I should be able to ask about the same uh First Amendment okay so what does the first Amendment saying and it's supposed to be calling yeah Congress shall make no law respecting establishment of religion prohibiting Free Speech there all right I mean it's less I mean here I passed in Google 25 but feel free to use in the language model here I am not running this locally I am using the hugging phase in inference API so that means that this is working pretty much just as open AI I'm sending the request to hog in face and I'm getting it back um but this is free and it's limited just for testing okay so yeah I hope this was useful for you I hope that you enjoyed it um I hope that you have a very nice uh project that you can now show your employers and your clients and I hope that you start creating really nice uh productive and beautiful applications like this to solve real world real world problems if you want to see more of this be sure to subscribe and if you have any questions just let me know in the comments and congratulations for following up the the end it was It was a uh some sort of uh long and complicated uh I'm a little bit more complex project than the ones I had done before let me know if you like this kind of project but I'm going to be continuing publishing uh content for beginners as well so thank you very much for watching and I will see you next time [Music] [Music] thank you
IaTiyQ2oYUQ,2023-05-22T09:07:00.000000,Create a ChatGPT clone using Streamlit and LangChain,[Music] thank you good morning everyone how is it going today welcome to this week's new video tutorial in which I'm going to show you exactly how to build this application that you see right here it is a chatbot with a graphical user interface and it is all coded completely using only python we're going to be using launching in order to communicate with our language models and it also has a memory and it displays the entire history of the messages okay this is actually a very simple project so stick to the end so that you can have it in your portfolio and it's pretty impressive okay let me just show you real quick how it works here you have that I already sent a message saying hello my name is Alejandro and it responded hello how can I assist you today then if I say do you remember my name you're going to see that there you have it it remembers my name because it has a memory okay this is especially useful if you're planning to create a a chat a specialized chat but for a PDF or for a CSV file and yeah if you're interested in more videos like this about software development and artificial intelligence don't forget to subscribe so without further Ado let's get right into the video all right so first of all we're going to start by creating our environment and our setup okay um all right so first of all I should mention that we're going to be using python 3.8 okay um since we're going to be working with this this component right here which is an open source component by the streamlit community I mean that has its pros and cons and one of its cons is that at least myself I haven't been able to make it work with python 3.9 and above so yeah just keep that in mind in order to do that you can use Pi INF so I'm going to do PI in local I'm going to set my local variable my local environment python to 3.8 there you go so now that we have our python version set to 3.8 we can actually start creating our virtual environment um just as usual remember that if you have any questions about the setup or the virtual environment creation Etc you can just leave me a comment and I will probably make a video about that but I'm assuming that probably you already know how to do this all right so python Dash M vnf to create my virtual environment and I'm just going to call it vnf and now I have my virtual environment right here with my python version of 3.8 and now all the packages that I install are going to be installed inside of here as well now in order to activate my virtual environment at least in Mac I'm going to do Source then I'm going to go to my VM directory and then I'm going to go to the binaries and then I'm going to go to activate in Windows if I am not mistaken you do the same thing but without saying Source just vnf bin activate okay now we can actually start creating our files and I'm going to start creating my git ignore first um oops it's not like that it's git ignore like that I'm also going to create my VM for sorry my DOT ends for my secrets and my main.py of course there you go now I have my files right here for git ignore I basically all I did was Iggy look for a git ignore template on Google and I copied the most um basic one there you go and now this is going to ignore all the files that I won't don't need to be tracked on GitHub so now I can actually start initialize my git Repository okay and I can just get at everything and git commit and say first comment and setup there you go now everything seems to be working correctly and as usual for my dot m I'm going to add my open AI API key variable save and then this one I'm just going to copy it I mean duplicate it and the second one I'm going to call it example dot of example and this is going to be empty and this is going to actually contain my files now I can save it at dot end of example and I can commit and say at an example there you go and now you can just uh start coding there we go all right so now we're going to actually start coding our application and the first thing that we're going to want to do is we're going to start with the graphical user interface okay as I told you before we're going to be using extremely for that and in order to use streamlit you're going to have to install streamlit first and to install it it's very easy all you have to do is PIP install streamlit like this there you go um it should probably take a little time because I don't have it installed yet just like keep that running in the background while you follow here and then we can actually start coding the first thing that I'm going to do is I'm going to test that name equals main like this stuff like that [Music] and then if that is true then I'm just going to execute the function Main and the function main is going to be up here this basically just tests that my file is being executed directly and not being imported as a dependency it's just a safety measure and now here I can just say print hello world then if I save this and I execute it you should just get Hello World there you go seems to be working correctly and now that streamlit has finished installing we can actually import it as streamlit as um wait yeah like well what happened there you I I don't know what that happened there you go so now I I can start importing extremely and instead of doing this I can just use St set page configuration in order to set some attributes for my page this is going to initialize my streamlined application with the title I'm going to say that page title is going to be your own chat GPT like this I'm just going to add a little Emoji right here for Robert [Music] um now you know what the Rob the Emoji I'm going to set it as a page icon because at extremely you can also set a page icon and right here I'm going to set the emoji of a robot like that there you go and then afterward I can just say St header in order to create an H1 element in the page and I can just say your own chat GPT like that and then just add my robot there you go now in order to run it actually what you're going to want to do is to run streamlit run and the name of your file okay this is not going to run if you just do python python main.py because it's not going to be able to I mean it's this is a streamlined application it's not just a script okay in order to run a streamlined application you have to do streamlit run and then the name of your in of your file and that is going to open my application like that okay now assign them as you saw before we had a sidebar right here with our message and then we had our messages right here in order to do that we can just start doing that right here like this in order to insert a sidebar in in streamlit you use St dot sidebar and actually in order to import to add things inside of it you can just do with SD sidebar like this and then whatever you do you add inside of this indented space it's going to be inside of your sidebar okay so I'm going to say that I'm going to add my user input right here and the user input is going to be another streamlit a component called text input [Music] text input like this and then I'm going to say your message like this this is the label of the input and then I'm just going to give it a key and the key is going to be user input like that there you go now if I refresh this part right here you can see that we have our sidebar with your message right here and now all that we have to do is add our messages right here now that is going to be a little bit more tricky but let me show you real quick how to initialize this component right here all right so now it's actually time to start creating the messages from that you saw in the introduction and in order to do that we're going to be using as I mentioned this component right here so the first thing that we're going to want to do is install is copy the installation command so I'm going to do pip install streamly chat that's what I'm going to paste right here pip install Streamlight chat I already have it installed so it's going to be so it was super fast but to you it might take a little bit longer now once you have it installed what you're going to want to do is you're going to do from streamlit chat like this we're going to import a message like that and once you have that actually that's all you need in order to actually display the messages now all that you have to do is to message then you just display the message of your content it can be I mean the content of your message it can be hello how are you and then we can add another message saying this one takes a a parameter called is user and if you set this one to false this is going to be the robot or no I think this is going to let's set this one to true there you go I'm good there you go now if we run it remember doing streamlit run this should create our messages there you go hello how are you I'm good there you go so just to recap we have the messages that we imported from streamlit chat uh for some reason I there's an importing error but it seems to be working so um yeah and then you have your messages and if you don't add anything or if um if you don't add anything this is user param is going to default to to true to false so if you don't have anything this is going to be the bot message and if you add is user true this is going to be your user message there you go so now we can actually start focusing on building the chat but functionality using Lang chain and using launch in memory as well so let's get right into it all right so now it's time to test that our application has the API key set and just to set that up uh real quick in order to do that we're going to use I don't remember if we already installed it but if you haven't you are going to use you're going to have to pip install python.env like that okay and this is basically the package that is going to allow you to fetch information from this dot dnv file which is not going to be tracked on GitHub but it's going to be in your machine or in your server and that way you can keep your API Keys hidden okay so once that is installed you're going to come right here and you're going to say that from Dot EnV we're going to import load.tnv like that and this you I mean this function basically just allows your application to use information inside of this file and all you have to do is just run it at the beginning of your application and now your file is available from your environment variables so if you do import OS and then you add this code right here I'm not going to type it because it's a little bit long it's going to paste it like this this code is actually reading from our environment variables if openai key is set or not okay so if openai key is not set or it's empty so if this one is if this one doesn't exist or if it is empty like this um this is going to return an error it's going to say open AIP is not set and it's going to exit then else it's going to just say that the the API key is set and that it's going to continue the application that's the first thing you want to do and the second thing you want to do actually is just to start coding the chart GPT I mean the land chain functionality okay um all right let's do that now all right so this is the part when we're going to actually install land chain and we're going to start dealing with the chat capabilities of it okay in order to do this the first thing that you're going to want to do if you haven't already is PIP install blank chain I myself I am going to be using openai as I mentioned before but you can always use hugging hubs hug and face Hub API and in which case you will have to do hugging face Hub like this okay I myself am going to be doing open AI like that and there you go now if you click enter it's going to probably take you a while if you haven't installed it already myself I already have it installed so it was quite fast and now we can already start e saying here from Lang chain dot chat models we're going to import the open AI chat okay and we're also going to import a couple of a few schemas so what are the schemas the schemas are basically just the template that is going to tell our API which kind of message we're going to be sending okay so from langching dot schema we're going to import three different schemes but the first one is system message which is the message that it's going to tell our assistant what it is supposed to be this is the first message that you send in any conversation and it basically just tells the message the language model um what role it is supposed to take for example it can be just a helpful assistant or it can be a translator or something like that so I'm going to say that the second one is a human message which is the message that we humans are going to send to the language model and the third one is AI message like that there you go which is going to be the response from the language model now um we have our setup right here actually you know what I'm going to take this away I'm going to put it in another function right here called init [Music] and then I'm just going to there you go so now we have our init function which has all of our load variables then test it and then initialize the the stream lead configuration and then afterwards we just have our actual graphical graphical user interface so now we can actually start creating our chat in order to do that we're going to say chat equals our chat it's going to be equal to an instance of the of the chat open AI that we imported before and here we don't really have to send to specify an API key inside of it because Lang chain automatically goes to look for it inside of our tnv file so no need to to add anything right here you're just going to have to add the temperature probably if you want to if you want to set it to something different like 0.5 or something like that I'm just going to leave it at zero but the temperature is basically how random you want the response to be or how deterministic okay if you set it to zero it's going to return the same thing every time you send the same prompt if you set it to 1 which is the maximum value it's going to return very different completions for every prompt that you send it so there you go and now we have another thing is that the chat actually takes um it doesn't take just a query I mean like a message it takes a history of messages right um if you if you have seen the if you haven't watched the other video that I made about memory I Rec I mean about memory in line chain I recommend that you watch it if you want to understand what is actually going on here but basically we are working with a type of memory called buffer memory in which we take all of the messages of the conversation and we're going to send them back to the API and that way since we are sending it all of the messages I mean all of the history of the conversation the language model is going to get have all the context it needs to continue the conversation as though it had a memory okay but we're actually resending all of the messages in every request right so that's also one of the reasons why this approach is not going to be able to take conversations that are like a thousand message long right so there you go so in order to actually do this we're going to have to start a new variable called messages [Music] messages and these messages are going to be an array or in Python we call them lists um an array of messages and the first one of course is going to be the system message and this is every message from this schemas have a Content attribute in which you have the actual content of the message so in the system message remember that it is the actual instructions for the language model of what it is supposed to be and in this case it is supposed to be era helpful assistant like that there you go and the idea is that every time the user is going to submit a new message we're going to append it here as a human message and we're going to get the content of it from the input and once we get that we're going to get I mean we're going to also store the value from the AI response which is AI message but I'm not mistaken yeah AI message but we're not going to do that immediately right now all right there we go so now what we are going to want to do is we're going to want to handle whenever the user submits a we're going to want to handle whenever the user submits something from the text input that we have right here okay um so let me show you how our application looks right now so this is our application so far and the idea is that we want to fill in here like hello how are you and then when we click on enter it is going to process that and then it's going to show the messages right here okay how do we do that where first of all here we're inside the cell of the sidebar so we're going to have to do that outside of the sidebar but we're going to say that if the user input if the user input is um is is I mean if the variable user input exists which means that the user input has been filled or someone clicked enter on it we're going to append that message into our messages history okay but first of all actually we're going to show it in the conversation how do we show it so we're going to say message and then we're going to say um user input just like that and then this one is we have to set is user to true just as we did before remember when I showed you how to use streamly chat that's exactly what we're doing right here we're just using the message from stream live chat and we're saying that the user input is going to be the content of the message and then that it is the user so let me show you what it looks like right now if I refresh this and I say hello and I say enter I'm going to have my message right here so far nothing else is happening so if I do how are you we have we still have my message right here but nothing else is happening so what we want to do is we want to take that message and append it to our message history and let's do that right now to do that we do messages dot append and we are going to append the user message but we don't we don't append it just like the content of the message we have to use a schema remember our message history our message history takes in the schemas so it takes the system message and then it's going to take a human message so since since this is the query from the human we're going to say that we're appending a human message and as a Content we are going to be appending the user input now that we have appended the message we can generate the response okay remember that our chat element right here it takes a history of messages in order to complete the next message now we have a messages object um sorry A message it's a list or array that contains all of our that contains our system message it contains our human message and now we're going to send that one to the chat like this and this is going to return the AI message so response equals to this chat and now we're going to show it as a message just like we did right up here for the human message but we're going to do it for the for the AI message I'm just going to come in the response and remember that it deals with the schemas so the actual content of the message is going to be inside the content um [Music] um attribute the content property sorry and there you go so now this should work I'm just going to set this as user to false so there you go so just to recap when the user clicks and sends an input submits an input we're going to show that in the show that in the graphical user interface using our streamlit chat then we're going to append that message to our message history then we're going to send the message history to our chat and we're going to show the response in another message okay so if I save this and I go back here and I refresh I'll be like hello my name is Alejandro you can see my message over there and then you will see the response there you go and now if I say do you remember my name what do we have here do you remember my name it is going to say I'm sorry but I don't have the ability to remember that is because we still haven't set the messages as saying persistent State variable okay so this is re-running every time so we're resetting um the messages variable in in a moment I'm going to show you how to not only make this um not only show all of the messages in the conversation but also make it remember the things by actually keeping the messages the message is viable constant even if the application has to reload okay so let's do that all right so in order to make our to keep our messages um I mean to make them persistent even if we're like submitting things and like making the application rerun because every time we click on submit it is going to rerun certain things and some values from some variables are going to get lost in order to get them persistent what we can do is to link a variable to the state of the application okay this is not exactly um like a reactive application like you would have in react but it gives some sort of reactivity to your application um so what we're going to do here is we're going to set the messages variable to the App State we're going in order to link it we're going to do St set State session State there you go there you go so now from session State we're creating the messages and we're creating them um we're binding our messages variable to the session State okay and this is only going to initialize if the messages variable is not already in the session state so we're going to say that if messages not in St session state [Music] that is if there you go if not in session State then we are going to initialize it with our system message okay but if it's already there we don't want to re-initialize it with a system message um so now we're initializing it with this right here and now instead of using messages just like that we're going to say that we're going to be fetching them from the searching State okay so now every time we click on enter it's not going to reassign justice system message to our application it's going to keep all of the history constant okay so let's see how that looks if I click on enter Then I refresh this part it's going to be like hello my name is Alejandro there you go it's going to be like hello how are you today and then I'm going to like do you remember my name and there you go yes your name is Alejandro because now our message our messages variable is not being reassigned to justice system message every time I click on enter because once I click on enter right here it's going to try to reload the thing but then it's going to arrive here and it's going to be like if it's not if messages has not been initialized in the session State then do this but since it is already initialized in the session State it's going to ignore this part and it's going to continue with the same value that it had before and that way it's going to allow us to keep the history of the conversation inside of this variable okay so there you go that was how to make the the messages persistent I am just going to do something else right here I'm going to wrap the response in a spinner so I'm going to do St dot spinner and say with the spinner and the response of the chat okay what this is going to do basically is it's going to say that um if I mean while we wait for the response it's just going to show a spinner just to show the user that the action the thing is actually thinking actually what I can do here is I'm going to say um thinking and now if I rerun this like hello how are you then you have a little thingy here spinning while you can get the response it just makes it a little bit more um user experience friendly okay so there you go that was how to do that now I'm going to show you how to display all of the messages right here and not only the latest one because so far it's only less than the latest one um um so like if I say something like what is kubernetes we're going to have our thinking but it's going to re I mean it's not going to show all of the history so let's do that in a moment [Music] all right so now it's time to actually uh show all of the history of the messages okay um and we're going to do that here outside of our if input Okay so what we want to do is we want to take all of the contents in our messages variable which is our state variable and we want to display them in a in in a conversation like uh manner like with the extremely chat component that we used before in order to do that we're going to fetch all of the messages from our state from St um session state DOT messages all right so you can do it this way but I'm actually going to do get like this and then get the messages because this allows me to set a default value in case the in case this variable doesn't exist so it's we're setting a default to an empty list and if not we're passing the and if not we're passing the contents of this state variable ones that we have all of our current messages inside of this variable right here we're going to Loop through it and we're going to display all of the messages Okay so basically if it is a if it is an odd number I mean if it's a it's in a nut position we're going to display it as the human message and if it's in a pair position we're going to display it in a as the bot message okay so let's do that right now in order to do that we're going to use for I and message in um instead of message let's use MSG because message is already supposed to be our function that creates our message in the graphical user interface so for I message in enumerate messages we're going to display them okay this basically just enumerates all of the messages and gives them an index for each one of them so now I have the index and the corresponding message inside of the messages array okay and now in order to test if it is the first one I mean if we should display it as a human message or as a bot message we're going to say if my index mod 2. equals zero then we're going to display it as a well first we're going to display it like this remember that we are dealing with schemas and the schemas actually contain the content inside of this content property so let's say that the content right here and since this one is supposed to be the human message we're going to say um we are going to say is user to True like that okay I am right now I'm figuring I'm realizing that we forgot to do something else like remember that up here we showed the message then appended it appended the human message to the history then generated it and then show the the AI message we actually forgot to append the AI message as well so let's do that now in order to append the AI message we're going to say SST session state messages and just as before we're going to append but this time we're going to append an AI message and we are going to say that the content is going to be equal to the response dot content like that now our AI message is going to be inside of our history as well and that way we're going to be able to fetch it right here so now that we have displayed this one right here [Music] we can say that else if we're going to display message dot content is user we're going to set it to false and there you go I'm actually going to add a key attribute right here just to be sure that every message has a different key just a good practice I'm going to say that it's going to be my index plus my user like this and for the other one it's going to be my index Plus AI like that there you go I suppose this should work or not why do we have a problem in here um oh yeah missing a coma there you go so now this is supposed to be working now actually we don't need to display the message right here and on user input and we don't need to display this one either because we are displaying the entire conversation okay so now just as a recap when the user fills in the input we're going to append that input to our messages history which is stored in our state then we're going to generate the response like this then we're going to generate the session State sorry we're going to append the response to our session State as the a message and that way every time the user um submits a question or uh yeah a question to the conversation we're going to have both his question and the and the AI response added to the history okay I'm actually going to be able to add this to the sidebar again because we're not um because we're not displaying anything right here so there you go and now if I click on Save and I will actually have to rerun it there you go all right so you can you see that there is a small problem right here but let me just show you that this is working almost perfectly um hello I am Alejandro now this is going to be displayed Asthma as the robot message right why does this happen Okay because remember that right here we were we were creating the um we're just displaying all of the messages in our history okay but remember that the first message is actually the history the system message right so we have to get rid of that one when we want to display them so in order to do that what we're going to do is we're going to subset our messages right here and we're going to say that we want everything starting from the first one not from the zero but from the I mean the second one so if I click on Save right now and I refresh there you go now I have hello my name is Roberto this time hello and then do you remember my name there you go so now we have our chatbot it works pretty good it has memory and it has what we call Buffer memory let me just show you real quick what we did in the code just repeat some of the things to make sure that everything is clear so basically we initialized our variable our sorry our application used load doten to actually load the environment variables we tested that the environment variables needed are actually there otherwise we close the application and we initialized this streamlit this streamlined application then we initialize the chat object from using the chat GPT model from openai then we create our messages variable inside the session State now what did we why did we do that in the session state that is because every time we click on enter or we submit a text input the application tries to rerun itself right and the variables that we don't want to be Rewritten every time we have to store them in this session state right here this way if messages is not already initialized we initialized it we initialize it with a system message and if it is already initialized that means that there is already a history of conversation we don't do anything right here there you go we have our header for application we added our sidebar with our user input and inside of that type or else as well we are treating the user input so I mean handling the submission of this user input so if the user submits a question we're going to take that question and append it to our messages System state variable as a human message all right then we're going to um generate the completion for that chat passing in the history of all the messages and then we're adding that response to the history itself so the next time that the user asks a question we have all this question and answer in the history as well okay and then last but not least which is what we're doing here right here is we are taking all the messages from the system State variable and We're looping through them so that if it's I mean almost all of them not the first one because remember that the first one is our system a system message because which we don't want to show in our user interface and we're displaying them if it's the first if it's um an odd message we're displaying it as a user and it's if it's a a bot message we're displaying it as the AI right here is user Falls it's user true and there you go I mean this is a very convenient and quick way to create chatbots in Python with a graphical user interface using streamlit I hope that you found this useful and I hope that you have many different applications and ideas of how to use this because I mean yes of course you can use it as a basic chatbot like this but you can also use it to make specialized chatbots for example for the PDF for the PDF chatbot that we created a few videos ago that video is also in this playlist so if you want to check it out don't hesitate to click on somewhere on the screen and yeah I hope that this was useful I hope that you found this educational subscribe for more videos like this and yeah I'll see you next time [Music] [Music] foreign [Music]
tjeti5vXWOU,2023-05-15T09:07:00.000000,Chat with a CSV | LangChain Agents Tutorial (Beginners),foreign [Music] good morning everyone how's it going today welcome to this new tutorial on Lang chain in this tutorial we're going to be building this application that you see in front of you it's very similar to the previous application that we had built in which we were able to ask questions to a PDF just that in this case we're going to be asking questions to a CSV right this is a very educational video because not only are you going to be able to build this application yourselves but this will also be useful for you as an introduction to the concept of agents in launching right so let me show you real quick how this works in order to demonstrate this application I'm going to use this data set the breast cancer Wisconsin data set which contains data from a lot of cells in different tissues samples and we're going to be able to ask questions about this data so I have downloaded it here I will upload it and then I'm going to be able to ask a question about the CSV for example I can ask a question what is the mean radius of the malignant tumors in the CSV and if I ask the question you will see that first it starts to to to think itself and then it's going to Output an answer the mean radius of the malignant tumors is 17.46 right I mean it's very useful it's very convenient and I'm going to be explaining to you how agents works with a beautiful diagram and all right so stick to the end for that all right I hope you enjoyed this video all right so as usual let me just tour you around the setup that we have here in for our project um I have my main.py application right here which is where I'm going to write all of the code um I have this pretty quick test that tests whether or not I'm importing my application so if I am importing the application this will not run if I am executing it directly then the main function will be executed with it which is where all of my code is going to live then I have my git ignore file just to get my sake to tell get which files I don't want to track then I have my DOT env.example in which I have the example variables that I'm going to be needing for this project to work in which case in this case we're going to be using on the openai API which is why I need this variable right here which is open AI API key remember that when working with line with blank chain we need the variable to be named exactly like this it cannot be open AI key or open AI Etc if we're working with blank chain it has to be this exact name and then I have my real.env file which is the one that actually contains my secrets okay if you want a more detailed explanation about the setup just let me know um the API Keys you can of course get them from platform.openai.com if you don't have an account you're going to have to create one account and then you're just gonna have to click on API keys right here and then create new secret key you can give it a name then create key then you copy this and you paste it right here right all right so that's it for the setup let's just start coding right now all right so the first things that we're going to be doing is we're going to start creating our graphical user interface okay in order to create this user interface we're going to be using streamlit which is a very lightweight and very very minimalist and intuitive way of creating graphical user interfaces in Python in order to do that of course you're going to have to have it installed so what you're going to do is to pip install streamlit like this I already have it installed so it's not going to take a huge time for me but to you it might take a little bit longer and once that is done you're gonna have to do import streamlit s s t because that's just the the usual the usual name we give it and then right here what we're going to do is we're going to SD set page config this is basically just going to allow us to get to tell uh streamlit that this is a streamlined application I am actually going to disable co-pilot because I always forget to do that before I start the videos but alright so St set main page config all right then right here this this function can actually take several parameters but in our case we're all we're just going to give it one parameter which is the page title and we're going to say ask your CSV and then why not let's add a little Emoji right here of Fame um of a chart yeah like this there you go now in order to create a title or a header you're just going to do header SD header like this and then just your title I'm going to say ask your CSV as well then just use the same emoji there you go and then of course afterwards we're gonna have to read our CSV streamlit comes with a very convenient input element which you can call just by saying St dot file uploader I mean input when I when I say input I mean file file uploader sorry about that and here it takes a label um we're going to call it upload your CSV file like this and then I'm going to specify the type that little file that I expect to get from here and let's say that I'm going to I'm going to store the the object that the user is going to upload in a variable called user CSV there you go now if I save it I'm going to be able to come back here and I'm gonna be able to do streamlit run and then I can just run my main Dot py there you go and I have my application right here um now as you can see just with a very few very few lines I was able to create this very quick graphical user interface with python which already is able to take my CSV file however so far we only were only able to upload the CSV file but we're we're not able to do much more than that so let's let's add a little bit more functionality to that and actually do something with the CSV file right all right so now that our application already has a CSV in itself and is able to use it to do things we're going to be using a launching agent in order to actually parse it and to read it okay why do we need a language agent because a CSV file is not readable by by a language model right it's not like a PDF file like you if you remember in our previous video and if you haven't watched it I invite you to watch it in our previous video we we only had text and our language model can take text and can read it and can understand it but a CSV file is basically just a table with data and the language model is not able to understand it what we're going to do in order to be able to read a CSV file is to take our language model to understand the question that we are asking and to have it generate the actions that it has to perform in order to understand the CSV file for example our agent is going to be able to perform actions in this way let's say like taken from the official documentation if we have our agent we're going to be using the create CSV agent pre-built agent from langching then we're going to create it like this and if we run it let's say for example if we want to say how many rows are there the agent is going to be able to think by itself and say oh it's asking me how many rows there are so I need to count the number of run of rows then it's going to be able to perform an action on this on this CSV file and then it's going to be able to observe the output of that action in our case the action that it performed was to calc to execute the function Len which Returns the length of your data frame and now it is going I mean once it reads the output of that action it's going to be able to think again and to give you a final answer and this is very convenient because that makes the agent pretty autonomous and it allows you to ask sort of I mean somewhat complex questions about your CSV file okay um here's some more a more um yeah here here's a more complete example for example what is the square root of the average age so it it'll first think that it has to calculate the average age then it has to calculate I mean then it knows how to calculate the mean but as you can see it's not actually knowing how to do it doesn't know the data right by reading it from the CSV it has to think in order to get the date okay let me show you a quick diagram of how this works all right so there we go I confected this really quick diagram just to show you what is actually happening um an agent in general I mean this is an introduction to any agent not just to say to our particular CSV agent which is built to be able to perform actions using pandas and other libraries on the data set an agent is basically a tool that is able to make decisions by itself and to use tools to interact with its environment okay in this diagram as you can see an agent works like this let's say we have the we are our user and our user makes an input the input is it can be a question or something like that in our example it can be what is the age of Leonardo DiCaprio's girlfriend uh to the 0.43 power all right I think the agent of course he doesn't know that but in order to think of a solution it's going to use a language model from our question it's going to think that oh I need to find who is Leonardo DiCaprio's girlfriend and then from that thought he's going to be able to choose a tool from from a set of tools that it has available let's say that it can have a calculator a coding interface or for example the web it might be able to search the web or to search the web or things like that okay in our case since it doesn't know who is Leonardo DiCaprio's girlfriend is going to go and search the web then there you go it search the web it searches the web and then it finds out that his girlfriend is Camilla for example um and then it's going to read that output from the tool that it used and it's going to interpret the output it's going to it's going to be able to ask itself do I already have the solution and then again through the language model is going to be able to think and it's going to be able to say oh no I still don't have the answer and if it doesn't have the answer it's going to go back to this step right here and it's going to be like all right so I need to use another tool and then it's going to select a new tool now it's going to be like all right so now I know who is this who is his girlfriend now I'm going to uh maybe it's going to have to use the search web tool again in order to be like all right so what's the age of Camila then once he has the H is going to come back and be like all right now I now have the H what do I need now I need to elevate it to the power of 0.43 and this time it may not use the search web tool it's going to be it's going to be able to use the calculator tool and then once it has that final final solution it's going to be able Again by using our language model that in our example is open AI um I mean the gpt3 from openai but in your computer you might be able to you might want to do it using Auto GPT or GPT for all and then it's going to be able to generate a solution and then read that solution to us and that's exactly what is happening in our CSV in our CSV agent is taking the CSV and being like all right so I need to do this and then it's going to be selecting the tools to use and then reading the output of whatever it did and this is like the most basic explanation that I can think of to how agents work and what is that we're going to be doing exactly right now so let me show you how this looks actually in the code um in our application okay let's do that all right so the first thing that we're going to do is that whenever the user already has uploaded their CSV we're going to test that that CSV is actually uploaded if user CSV is not none then we're going to be able to use it and in order to use it we need the user to ask a question so I'm going to be like user question and the user question is going to be a tech a very simple text input something like this text input that comes this is a component from streamlit and I'm going to say ask a question about your CSV all right there you go now if we look at how this looks like let me just open the terminal and just run it again remember that in order to run to run a streamlined application you have to do extremely run and then your file you cannot do just like Python and then your file that will not actually execute the streamlit application so there you go now if we upload our CSV file we're going to be able to ask a question but so far it doesn't do anything so let's do something with that question that the user gave us and in order to do something we're going to be actually needing a launching so as I mentioned before we're going to be using the pre-build launching agent called from we're going to be installing importing it from langchain.agents and we're going to import create CSV agent and then from line chain llms which is the language models we're going to be able to import open AI now I am using openai but it is in this step that you can actually use whichever Lan language model you want uh launching has support for a huge deal of language models if you come right here to modules agents nope two models and then in models if you go to llms and you go to Integrations you'll see the huge list that they have for language model providers okay so yeah don't don't hesitate to use your whichever you want um now what I'm going to do as well is I'm going to import from the 10th oh in order to do this actually I will I'm going to need to pip install python.env which is the package that is going to allow me to read the variables from my DOT end file okay and in order to do that I'm going to have to import from the 10th 1.10 I'm going to import load.nf and in order to enable my these variables to actually be read I'm going to have to execute this function at the beginning of my file okay now launching should be able to get this API key without myself doing anything else okay all right so now we have imported our language model and our agent so we're going to initialize our agent in order to do that I'm going to I'm going to first initialize my language model I'm going to say that my language model is going to be open AI and this I mean in the case of open AI this one takes several parameters which are optional in my case I'm going to set a temperature of zero um I believe it used to go from 0 to 10 but in in launching apparently it's from zero to one so zero is non-creative and one is completely creative um a good way to think about this is that if you set it to zero it's going to return exactly the same thing every time you send the same prompt if you set it to the maximum it's going to be more creative and give different answers every time all right I'm going just going to set it to zero and then once that I have my language model I'm going to be able to initialize it inside of my agent so oops come to initialize a variable called agent and I'm going to use my create CSV agent function that I imported from langching just a moment ago and this function takes llm I mean my language model that I previously created as the first parameter um and secondly it takes um sorry and secondly it takes the the file the CSV file that I'm going to be using and remember the CSV file I saved it right here from the file uploader I'm just going to pass it right here and what why do I have a problem positional cannot appear after keyword all right so just not going to use there you go I'm just going to be using only positional arguments and then last but not least I'm just going to set a verbose option to true what does this do variables actually just make do you remember that when we had our example right here we see the green text right here with all the thinking process of the model of the agent this is basically just going to print that at the same time if we set it to false it's not going to print anything it's just going to do it by itself all right um something that you might want to consider right here is that um in particular about the CSV agent our model is actually running code okay so it's using pandas or other libraries to get information about our about our data set so it's running code by itself this can potentially be quite dangerous if you make it right code that is malicious for your file or or something like that okay so um just keep that in mind that it's running code by itself it's not asking anyone for permission to execute the code so yeah just keep that in mind um once we have that once we have that we're going to we're going to be able to actually use this agent to answer our question so if we have our question let me just show you so far like right now what it what this looks like I'm going to do if my question is not none and my question is different to nothing I'm going to just estimate your question was and then the user question I'm going to just wrap it within F string then let's remember that we have to in order to run it we do extremely drawn Main and there you go now I can actually upload my CSV then ask a question hello and then your question was hello okay everything seems to to be working correctly now we can actually use our model to treat that question right here okay so in order to do that here right here we're going to have our response and the response is going to come from our agent all right so in order to do that we need to call our agent first so we're going to do agent dot run in order for it to run some instructions right here we're basically just going to tell it the question that our user that our user has and so in order to do that we're just going to pass in the user question right here and then if I save this and actually you know what I'm not going to run this right here I'm going to run it at a terminal run just beside it to show you the thinking process at the same time as it's reading the file okay so I am right here this is exactly the same directory as where I am in my code so in order to do that I'm just going to do as usual streamlit run in my file is mine.py and as you can see it runs just like usual there you go and now what I'm going to do let me just put this one right here this one to the right um there you go there you go now I'm going to upload my CSV file I'm just going to put myself right here and then now I'm actually able to ask questions so I can say the previous question that we asked before was what is the mean radius of a malignant tumor of the malignant tumors then if I click enter I'm going to see all the thinking that our agent is doing right here so let's see the thought is I need to find the mean radius of the malignant tumor so it can actually think and it has to decide what it's going to do now it decided to use the python interpreter as a tool and it passed this input so I mean this is going to return the the mean value of the radius for the malignant cells and there you go so I so now once that it executes this it can read the observation then it can think now we have the final answer and then you can just return the final answer in our program um we can actually test it a little bit further we can ask what is the mean area of malignant tumors or how about something a little bit different the main um what does it mean smoothness of benign tumors for example if I click enter you can see that it's going to think again well I already run something here um you can see I need to find the mean smoothness of benign tumors again it thinks that it has to use the python interpreter it runs this code it observes the answer and then it thinks I now know the answer and then it just gives you the answer um using the language model okay um so yeah I mean this is how how to build this very quick application and a very quick introduction to agents so there you have it I hope this was an a good introduction to the concept of Agents I hope that you liked this application I will leave in the description the link to the repository on GitHub so that you can download it and play with it play around with it um just I don't recommend that you copy and paste the code from there I recommend that you actually write it yourself so that you can um like it gets into your head and yeah I hope that it was educational and please subscribe for more videos about Ai and software development So yeah thank you very much for watching and I'll see you again next time [Music] [Music]
Cwq91cj2Pnc,2023-05-08T11:47:00.000000,LangChain Memory Tutorial | Building a ChatGPT Clone in Python,[Music] thank you good morning everyone how's it going today welcome to this Language tutorial in this tutorial we're going to be seeing how long chain memory Works we're going to be exploring two different types of memory that work with launching the first one of which is buffer memory and the second one is entity memory and in order to do that we're going to be building this project right here to demonstrate the use you will be able to open your terminal and to run chat GPT inside of it as you can see it introduces itself itself as chatgpt and I can say my name is Alejandro and as you will see it has a memory because if I ask my name afterwards what is my name it will say that it will tell me my name exactly alright so we will go we will be going through the theory and the coding part of developing this application and yeah I hope you will find this useful if you would like to see more videos about software development and artificial intelligence be sure to subscribe alright so let's get right into it all right so let's start with the coding part um here I have my project already set up if you want a more detailed explanation of how to set up your projects in Python just let me know in the comments but for now I'm just going to explain this to you super quick and over the surface so I have my main.py file reality right here I have imported to two dependencies that I'm going to use I have previously installed the 10th and I have my test right here that tests if the application is being executed directly or imported so that my function right here will only load if my file is being executed directly okay then I have my git ignore file right here in which I have all of the files that I don't want to be tracked on git I have my DOT EnV and Dot example right here which is the um the one the file that is going to be tracked on git about that will contain this structure of my secrets and here is the file where I will actually contain my secrets okay dot tnv and as you can see the secret for this application that we're going to be building is the openai API key because we're going to be building our chatbot using openai's API as a reminder remember that if you're working with launching you want your openai API key environment variable to have this exact name open AI low Dash low API low Dash key because that's the environment variable name that line chain actually looks for okay so yeah there we go and I also have my virtual environment already set up right here and yeah now to finish the setup I'm just going to install my dependencies and the dependencies that we're going to be working with are link chain and as I mentioned before dot EnV okay so let's do that I'm going to do pip install line chain and then I'm going so going to install dot 10 the package for DOT end is python dot EnV like that to me it doesn't take a long time because I already have them installed but to you it might take a little bit longer then I just imported the 10th and load.10 the load.n function which basically allows me to use my secrets that I have stored right here in other words once I run this function my API key will be available on OS dot get EnV and then the name of my variable so this is under the hood this is what langching is doing to find my API key all right so let me just show you how this works it's going to go back to my terminal there we go then if I get out of here and then if I go to my you know what I'm going to run it from here and then if I run this application like this you can see that I can run my API key is and it shows my API key because that's all that I'm printing all right so it seems to be working correctly now it's time to actually start coding the application let's get right into it all right so let's get right into using the first kind of memory from launching which is conversation buffer memory okay this is the most basic kind of memory because all that it does is it stores the history of your entire conversation and it sends that history of all the messages back to the language model that way the language model has all the context that it needs to answer the next question with memory right there is indeed a class pre-built in langching that allows you to implement this kind of memory but ourselves we're going to be building it ourselves first just so that you have an intuition of what is actually going behind the scenes okay so the first thing that you're going to want to do is import the chat model from launching okay so let's do that we're going to do from langchain dot [Music] um Dot chat models we're going to import chat open AI okay and just as a reminder yes we are importing it from langching but this is not coming from launching itself this is just a wrapper for the open AI API okay that is the reason why we need our openai key right here and then we're going to also import from Lang chain from the schemas we're going to import three different schemas the first one is going to be the system message which is the first message that we're going to give the language model in order to tell it the instructions of what it is supposed to be so for example it can be you are a helpful assistant or you are a translator from English to French or something like that the second one is going to be the human message which is going to be our message that we're going to be using that we're going to be asking questions to yeah it's the message that contains our questions and the third one is going to be AI message which is the message that is the response from the AI model okay there we go now once that we have all of that imported um first thing that we're going to do is we're going to test our API key I mean just verify that it is actually installed and it's actually included in our environment variables because if it's not included we want to close the application immediately because it's useless without an API key so I'm going to do if OS get nth I'm going to say that my I'm going to test if my open AI API key is none or not only do I want to close the application if this [Music] if this variable is none I also want to close it if it's equal to an empty string that I'm going to do print open AI sorry like this the open AI key is not set place at your key to dot EnV there you go and then we're going to exit the application like that this way if the open AI key variable is not set or if it equals an empty string which means that if it's set like this it's actually set to an it's actually set but it's an empty string so if it's like this we also want to close the application we're going to exit and else we're just going to print that our openai API let's just API key set like that there you go now that our API key set we can actually create our and start creating our models okay so first things first we want to create our chat model I'm going to call it chat like this I'm going to initialize it with chat open AI like this and this this class actually takes a few parameters or can take a few optional parameters one of which is the temperature which is a 10 the temperature is a number that goes from 0 to 10. the closer it is to zero the less creative it is and the closer it is to 10 the more creative it is so for example um a good thing to a good way to think about this is that if you set it to zero every time you send a prompt the same prompt is going to return to you the same answer all right if you set it to 10 which is the most creative level the same prompts will not necessarily give give the same answer in this case for example a temperature of 10 would be useful for something like copywriting generating brand names poems blog posts Etc but since we're doing something a little bit more technical we can go with zero I can go with three right here just to show you and then we can also adjust the model name as you can see here the default module model that we're going to be using is GPT 3.5 turbo which is the default language model for chat GPT however if you have access to gpt4 you just have to add here GPT 4 like that and if you want to see which models are available to you you just have to go to open AI open AI models like this and then just check them right here if you have access to gpt4 you will just be able to use one of this I myself I'm just going to be using GPT 3.5 turbo which is the standard one for chatgpt there we go and once that the chat is already initialized we're going to be initializing the variable that is going to track all of our messages okay so let's just add our variable called messages and this one is just going to be an array with all of our messages and the first message that we're going to be using that we're going to be adding is the system message so let's add it like this is the message and and this kind of messages take I mean this comes from the schema that we imported up here and this one takes a another context but a content and here you just add the content of your message in this case since it is a system message it is the first message of the conversation that instructs the language model the role that it has to take so I'm just going to tell it you are a helpful assistant like that and then all of the subsequent messages of the conversation will be appended by the at the end of this array so you can see it like this here you have your system message and then once I send a human message you will have a human message right here with content and then you will have an AAA message Etc okay so what we're going to be doing that as we send questions to our model so for now this seems to be working correctly we have added our chat we have added our messages and let's just let's just print a small greeting a short greeting for for the new user so to hello I am chat GPT CLI there you go now if we save it let's see if it runs there you go hello I am Chachi PT CLI and the API key is set so there we go so now it's time to actually start coding the the loop that is going to take our conversation okay there we go all right so now we're actually going to be building the chat interface for our chat application in order to do that remember that we're going to be requesting a question or a prompt from the user and we're going to be doing that in an infinite Loop so every time they send a question we're going to prompt them to ask to ask another question in order to create that infinite loop we're going to do while true and now in order to create an input in Python all you need is an input like this and this is the prompt that you want to give and the actual value of that input we're going to store it in a variable called user input like this now just to show you how it works I'm going to print out that input I'm going to say you send and then I'm going to just to print the user input just to show you how it works now let's execute it right here hello and if I say hello how are you you can see that our input is sent back to us because that input value is stored inside of this user input variable right all right so what we're going to be doing now now that we have that input stored in a variable we're going to be appending that into our messages history that we have right here in order to do that all we have to do is call the messages and we say that we're going to append a new message and here we're going to say what schema we want to append it with and just as you might remember we imported a human message schema which is going to be used when it's the human message and this one just as the system message takes a Content attribute and as the content we're just going to send the the content of the user input and now we're going to want to generate our response and you'll know that to generate it we're going to be using this chat object that we initialized before so we're going to do chat and we're just going to send the history of olive flower messages and we're going to store that in a response like this hey I responds like that and let's just print that response I'm just going to say that the assistant says I'm going to say that we're going to concatenate here the AI response like this now in the response actually from the object it's not the just not it's not just the text it contains the response and just as in the as in this schema it contains the the content inside of a property called content so I'm going to say that content right here to actually print just the text of the of the response there you go and last but not least actually before we print the assistant response we want to append it as well to our history because as you can see so far we have appended our system message we have appended our human message but we don't have the AI response message so let's do that right here I'm just going to say messages that append and in order to append the AI message I'm going to be using the AI message schema let's do that AI message and as the content I'm just going to say that it is the AI response and just as I mentioned before we need to access the content property inside of this response so let's do it like that there you go now we have the content and it should be working correctly if I'm not mistaken now let's open it again remember that when you're inside the chat if you want to get out of the chat you just have to do Ctrl C okay so now let's just open it again now hello I'm Chachi ptcli hello my name is Alejandro and there seems to be a problem with the temperature what's going on usually the temperature is supposed to be between zero and one um let's say does that work oops yeah apparently okay all right I think they probably changed it uh before it used to be between 0 and 10 but now apparently it's between zero and one so yeah the temperature is supposed to be them between your zero and your one so there you go now as you can see we have an assistant that is responding to us and let's just say my name is Alejandro will it remember name my name what is my name and it seems to remember my name correctly all right let's just to show you real quick actually just the his the entire history of messages I'm just going to print also the messages right here history oops history just to show you real quick what is going on remember to get out is Ctrl C let's just run it again hello there and as you can see here I have my response and also my history which contains the system message your helpful assistant and also contains my human message hello there and then the AI message which is the response which is hello hi can I assist you today which is what it responded right here and it's going to go on if I do um my name is Alejandro it's going to contain that message as well in the history so as you can see the history starts all from your helpful assistant and goes all the way to high Alejandro which is the latest response from the assistant there you go this is the um most basic approach to memory handling in and chat models for language yeah in chat models what we're going to be doing now is we're going to be doing exactly the same thing but without coding encoding it ourselves we're going to be using the wrapper by launching and you will see that it's going to make it way way easier okay I'm going to leave this file right here and I'm going to leave it in the in the repository in the GitHub repository so that you can check it right there we go all right so now it is time to do exactly the same thing but we're using this conversation buffer memory class from Lang chain it's a very useful class that you will be able to use in other projects hopefully and let me just show you how it works um previously we had imported this schemas by hand but this time we're actually going to be importing only um a conversation chain which is going to take care of this by itself right so we're going to say that from Lang chain we're going to import a conversation sorry from launching chains actually there you go we're going to be importing a conversation chain like that and then we're also going to import from Lang chain memory we're going to be importing the conversation buffer memory as we mentioned before okay so this time we're not going to be needing to initialize our chat and our messages what we're actually going to be needing to do is we're going to be initializing our language model so I'm going to call it language large language model I'm going to initialize it as chat open AI just as we did before and there you go there you have it just as before remember that you can set the temperature and you can also set the you can also set the model the model name Etc I'm just going to leave it as default for this example and also something I wanted to mention is that as you can see we're always we're just like initializing our language model in a variable this makes it this is like the main advantage of using launching because that means that you can just change this this class right here to any other language model that you want something like um I don't know hugging face or something like that and you will be able to just use it as as you would use the open AI model right let me show you how that works right here we're going to initialize to start a conversation object right here conversation and we're going to initialize it from the conversation chain that we imported a moment ago and here it takes a variable um an attribute of language model and we're just going to pass in the language model that we initialized before and that's exactly why it's important to to use launching because here as I mentioned you can just basically plug in any other language model that you want and then this just by changing this line right here this line will be completely the same and it's going to continue working perfectly the second one the second attribute that we want to set is the memory attribute this time and we're going to be setting it to the conversation buffer memory as I mentioned before don't remember the parenthesis because you have to initialize the instance and last but not least we're going to set it verbose let me just move it to a new line like this we're going to set it to variables to true so that it outputs what it's doing in real time all right not that we have initialized our conversation we have printed our welcome message as well and you will see how this part right here becomes way way simpler we will not need to append messages or anything it's all going to be dealt with and dealt with by our object conversation right here so let's do that here I'm just going to remove all of these things I am taking the input as well but here I'm going to be saying that the AI response this time is going to be conversation from the object that I initialized up here and here at this time it takes the we have to use the method of predict okay and then all that it takes is the string right so the string of the of the question that you're asking the model in our case it's the use for input and this one actually is a parameter called input like this there you go and actually this um this chain doesn't return the object with the content inside it just Returns the string so no need to open the dot content right there and yeah there you go now as you can see we're not storing the response from this conversation in any other object because the conversation object is taking care of all of it all by itself all right so let's see how that looks now if I run this there seems to be a problem here or it's not um what's going on here uh it's probably running somewhere else there you go uh now there was a problem with my terminal but there you go hello I'm Chachi PT hello my name is Alejandro and you will see that we will have more information right here because we set it to verbose true so now you have the answer from the assistant and you can see that it's tracking the entire conversation so I can do something like um what is my name and you see that every time it's thinking it's taking into consideration the entire current conversation right here okay and this chain also contains an initial prompt that looks like this so just so that you know that you have a an initial prompt inside of the inside of here as well so you don't have to set a system message saying you're you're a helpful assistant and there is a way to modify this as well as a as an attribute when you initialize the chain so there you go now that is how to use the buffer memory um now let's take a look into the more advanced type of memory from langching which is entity memory all right let's get right into it all right so the second and last kind of memory that we're going to be dealing with in this tutorial is the entity memory and this is a very interesting kind of memory because it doesn't involve remembering the entire conversation I mean the entire history of the conversation what it does is it inspects the conversation and summarizes it into entities and then it is those entities that work as a memory okay and it uses of course a language model to summarize it so for example here is a very very nice example that they give in the documentation so let's say that you start off by saying that Divan and Sam are working on a hackathon project and if we had been using a buffer memory all that we would do all that our chain would do would be store this in a in a history and then just send it back to the API but the idea behind the entity memory is that it saves some context from the conversation and it takes out the entities of the conversation the entities can be things like places people Etc and in our case the entities that the language model identified are given and then it contains some information about given so even is working on a hackathon project with Sam which they are entering a into a hackathon and then it identified Sam as another entity so you can say that you can see that it knows that Sam is working on a hackathon project with David and it also contains the entity launching for some reason here um so there you go I mean just look as an introduction to entity memory just remember that it doesn't involve remembering the entire history of the conversation but specific information about the entities of the conversation and it gets that information using a language model as well so let's see how that looks right here in action right um in order to use this we're going to be switching the conversation buffer memory for a conversation oops conversation entity memory like that and we're also going to be importing a new prompt that we're going to be using for the entity memory because that's we're going to um we're going to need to prompt the model so that it knows that it has to use entity memory so in order to to do that we're going to import from Lang chain from langching dot memory dot prompt we're going to import entity memo oops entity memory conversation template like that all right and what we're going to be changing here we're going to be keeping the llms chat open Ai and the conversation this time also involves the conversation chain just as before we set our language model just as before and instead of memory setting it to buffer memory we're going to be setting it to conversation entity memory and remember that I told you that this memory requires a language model to generate the entities inside of it right so it's remembering um important information about the entities in the conversation but it needs a language model to generate that information from the entities okay so in order to do that we're also going to have to pass a language model to the memory um to the memory method sorry to the memory class and we're going to do it just like this we can use the same one as we're using for the conversation and then last but not least we're going to set a prompt to The Prompt that we imported before which is entity memory conversation template like that now it seems to be working correctly and that's actually the only thing that we're changing because we're also using the conversation just as before but since I set the variables to true you're going to see how the the the bot is thinking differently than last name okay so I'm going to run this I'm going to save it and run it and you can see hello I am Chachi ptcli I'm going to say my name is Alejandro and I work in Paris [Music] there you go so now you can see that it's Thinking by itself and it has a it has identified two entities in my messages has identified Alejandro and Paris now if I I mean and of course it sends the its Center response now if I add more information to it let's say I am working here on a project with John who is a web designer then it identifies some other context it identifies that Paris is where I work and it identifies the context of John which is another entity okay in our case let's ask it a question about what John does what does John do and you will see that it identifies the context that John is a web designer who is currently working with me on a project in Paris and this as you might remember this is not some information that I wrote explicitly like this this is just information that appeared in the conversation and the language model is remembering it by associating it to the entity of jun and this just makes it a little bit easier to to deal with long conversations because if you have a super long conversation you're not going to have you're not going to be able to send the entire history of messages to your language model so this kind of memory is very useful when what you want to when you want to deal with long conversations you just have to summarize I mean by itself it just summarizes the important information from the entities and then answers based on that and last but not least just to show you so far we have been displaying this green text right here which is kind of the thinking mechanisms from the language model but in order to disactivate that to deactivate that disable that sorry we just have to set the variables parameter to false and then if I run this again you can see that hello hello how are you it doesn't print the green text anymore it just prints the response so there you go now that's how to make this chatbot now super quick let's just add it to to let's just create a command so that we can run it directly from the terminal whenever we want okay so let's get right into it all right so in order to add this to your to add this chat GPT to your command line and to be able to use it whenever you want from whichever location you you are um we're going to create an alias that is going to work as a command to open it directly from our terminal okay um first thing you have to do is you will have to figure out if you're running what kind of shell you're running I myself I am running status H you might be using bash instead I don't know it depends on your computer I mean of course this only works for Unix I mean Unix based systems like mac and Linux but in order to figure out which kind of um shell you're using you're going to do Eco shell like this and then if right here you see zsh it means that you're running set to Sage if you see batch that means you're running Bash now that what you're going to do is you're going to go to your home folder which is CD TLD like this then you're going to do LS and see everything and here um the files that start with the dot are the files that are hidden so you're going to be looking for the file if you're running set this age the file is going to be dot setshrc like this if you're running batch the file that you're going to want to modify is dot bash RC okay so in order to modify it I mean you can use V I like to use V but just to make things simpler right here I'm just going to use code and in order to open it you just do code set as HRC or bash RC if that's your case and then it's going to open this file right here for me it's a very big file for you it might be empty but just because I have installed several things right here and what you're going to do is just open a new line wherever you want I'm just going to add it somewhere right here and you're going to add this line right here as you can see it has an alley it is it starts as Alias and then the first Bud right here is the name of the command that you wanted to the command that you want to take to I mean how you want to name your command so this way every time I type chat GPT in my in my command line it's going to execute whatever is between these quotes right here so in my case when I write Char GPD it's going to run a pyth it's going to run Python and then it's going to run my file which is this one right here in order to know where this file is you can just access your terminal from your working repository and you print PWD print working repository and as you can see I am at users Alejandro desktop and launching memory tutorial I'm going to copy that and I'm going to go back to my settings Edge and then here I have that I want to execute python and I want to execute this directory and inside of this directory I want to execute the main.py file just as we were doing before then if I save it and I open a new terminal session bum if I open a new terminal session like this there you go now I can do chat GPT and it's going to run directly the charger PD that I installed that I created before in my script okay and here I can just go hello um what is if I have if at some point chat GPT is not working for me I can just come here open chatgpt like this and every question is what like less than a cent of a dollar so it should be okay so hello what is a part in kubernetes for example and it's going to come up with a response for me so there you go that's how to deal with memory in launching we need so two different types of memory which was buffer and entity memory just remember that there are more kinds of memory right here in the launching documentation so don't forget to take a look into that but I hope this was a good introductory video into how blank Ching deals with memory and how you can deal with that in your own projects all right and also I hope that you will be able to use this app in your terminal whenever chai GPT is down or just to show off with your sorry to show up with your friends and all so yeah I hope you enjoyed this video hope you learned a lot and I will see you next time [Music] [Music] [Music]
wUAUdEw5oxM,2023-05-01T14:21:53.000000,Langchain PDF App (GUI) | Create a ChatGPT For Your PDF in Python,[Music] thank you good morning everyone how is it going today welcome to this amazing tutorial in which I'm going to show you exactly how to build this application that you're seeing in front of you okay let me show you real quick how it works so it's uh it has a graphical user interface of course completely coded in Python and then if you write if you drop right here a PDF I'm dropping in the Constitution of the United States it shows this text input in which you can ask a question about your PDF okay so if I ask has who has the power to veto legislation passed by Congress and I and click enter it will answer me based on my PDF but if I ask a question that has nothing to do with my PDF so for example what is the distance between the Earth and the moon for example and I click enter you will see that it has no idea because it's not information that you can find inside my PDF okay I will show you how to parse this PDF how to divide it into different chunks and also as a bonus I'm going to show you in the end how to track exactly how much money you're spending per um per request okay we're going to be building this with Lang chain and I'm going to be explaining to you a little bit about how launching works and the amazing things that you can do with it okay subscribe if you want more videos like this um I'm gonna be publishing many more videos about launching and yeah let's get right into it all right so the first thing that we're going to be doing is we're going to set up our environment okay so as you can see right here I have created my DOT end file which is the place where we're going to be storing our secret keys in this case it is my open AI API key and my DOT end of example which is the one that is going to be tracked on git because this one right here will actually have our secrets which is the actual API Keys be careful you want you're going to want to name your API environment key exactly like this if you're going to be working with openai because since we're going to be working with Lang chain it it requires your environment variable for the open AI API to be exactly this name otherwise it will not recognize it okay so it's got to be open AI lower dash API low Dash key all right there you go then we're going to have a git ignore right here and for that I'm just going to come right here and I'm going to copy a very standard git ignore so that I not that I'm well covered and then I have my app.py which is the place where we're going to start building our application okay um all right so first things first we're going to want to install our dependencies um the dependencies that we're going to need in this case are line chain first of all pi pdf2 to read our our PDF files we're going to need python.nf to enable our environment variables and we're going to need streamlit to create our graphical user interface okay this was super fast for me because I already have them installed but for you it might take a little bit longer also don't hesitate to install additional dependencies that you might need that I may have forgotten because while you're when you will be running your application you might be running into problems like oh this dependency is not installed or these are the dependency is not installed usually you all you have to do is just read the error message and it will tell you which dependency you're missing all right so there you go um and then just to just to start off with this I'm just going to I'm just going to write this very basic test right here that this line I usually just added every single time I start a Python program which basically just tests that my application is being run directly and not being imported right and then only then will it actually execute the main content of the application so there we go let's see how this looks if I run it I see Hello World all right so there we go my project is set up my API key all I have to do is come right here to my platform.openai.com I have to create a new secret key I'm going to call it PDF chat tutorial I'm just going to copy it from here I'm going to paste it right here save and then if I come right here and I say from 1.10 import load the 10th and then I do I'm gonna have to do load.nf like this and then I'm going to print I'm going to print oh I also I'm also going to need OS import OS I'm gonna I'm gonna be able to access my API key okay this is just to show you how how you will be able to access your API key and this is what langching is going to be doing in the uh behind the scenes so if I do OS Dot get environment uh get an and I ask for open AI open AI API key uh sorry this is not supposed to go inside of here this is supposed to go instead of print there you go now if I save this and I run it again you can see that my API key is being recognized and this file is not being tracked on git so that's very important to keep your secrets secret all right so there you go now that our project is set up we can start building our application um to start uh parsing your PDF files all right so let's do that now all right so now it is time to actually start creating our graphical user interface I'm just going to disable GitHub co-pilot right here just so that you can code along and there you go in order to create our graphical use interface we're going to be using streamlit so I'm going to import streamlit that I already installed and I'm going to download it as imported as St there you go and now we can actually just start setting the page configuration I'm going to say that page title page title is going to be ask your PDF and there we go now let's set a header to ask your PDF I'm just going to add a little Emoji like this there you go and then below this I'm just going to create my input where I'm going to be able to upload my PDF okay so I'm going to do St file uploader and then I'm going to say upload your PDF right here I'm going to say that the type is PDF like that all right now in order to run this I'm going to have to do up um that's just one second I'm going to have to do streamlit I'm gonna do run I'm gonna have to Target this file right here where my application lives now if I click on enter it's going to open my new application and it already looks pretty much like this um so that's pretty good uh although so far it doesn't do anything if I upload my file right here it just shows that it's been uploaded but it doesn't do anything else all right so let's just add a little bit of functionality right here um just very quick before that in case you don't know what is going on streamlit is a very streamlined it's a very very fast and convenient way of building this kind of applications with python as you can see I just added three lines of codes right here three lines of code and it already outputs this with it with a very nice title nice with nice Styles and all so there you go I mean if you want to explore other kinds of components for example right here I just used a file upload component but you can see that they have many many components for you to use so don't hesitate to take a look into that um all right so now it is time to actually start adding some logic to our application and to add our um PDF reader and parser right so let's do that now all right so now what we're going to want to do is to actually take the PDF file and read it because so far we only have the file that we have right here but we don't know what the text inside it is and in order to read it we're going to have to use one library that we imported a moment ago which is PDF PI pdf2 right so I'm going to do from pi pdf2 and I'm going to import this class that is PDF um PDF reader like this and this is the one that is going to allow me to take the text out of my PDF all right so now what I'm going to want to do is I'm going to first test that my PDF file exists so if my PDF is not null if it's not none what I'm going to do is I am going to create a new well a new PDF reader that is going to do this I'm going to PDF reader like this and I'm just going to use the new class that I imported I'm going to initialize it with my PDF file that I that the user uploaded okay so just to be clear right here we are uploading the file right here we are going to extract the text of the file okay once that we have the PDF reader we can actually Loop through the pages of the PDF reader okay because the the reader does not by default allow you to take all of the text it allows you to take the pages and then the text out of each page so first we're going to take we're going to Loop through the pages and then extract the text from there in order to do that we're going to initialize an empty string variable and then we're going to say that for each page in our PDF reader.pages this is going to create a list with all the page elements inside of my PDF reader I'm going to say that the test the text is going to concatenate with page dot extract text which is the method that is going to take the the string text out of our out of our page and then with this text what we're going to do is we're just going to write it in our in our application just to show you what is going on so far okay if I'm not mistaken and if I rerun this thing and if I upload the Constitution again I should see the Constitution text right here there you go seems to be working alright okay so there you go now what we're going to want to do afterwards is to figure out a way on how to look for information inside of this text okay so let's let's get into that all right so we have a problem now remember that we said that we wanted our language model to answer questions depending on the information that we have in the PDF right um I mean normally in something like Chad GPT which works with the GPT uh 3.5 model um normally in charge GPT you would just give it the text and then just ask the question uh underneath right so you'll send you will send it something like this paragraph and then you say what is um the I don't know just write ask something about that paragraph right and the problem right here is that this is just too much text we cannot feed this enormous quantity of text to a language model and expect it to understand it in one go so what we're going to want to do is we're going to split the text into similar sized chunks and then look inside those chunks to see which chunks contain the information corresponding to our question and then feed those chunks to the language model okay um I found this article in in the internet from this guy or girl called Penny's mindhack and it's got this very nice diagram which I upscaled for you right here so shout out to to him and it's a very nice diagram and it makes it super easy to understand what is going on right here so basically we have I mean he calls it the book but in our case it's just a PDF and we're going to extract the content and then I mean this is the complete process of what is going on in in the back of our application okay so first we take our PDF we extract the content just like we did this is the content that we have right here and then we're going to split it into chunks all right so we're going to take this text and we're going to split it so this is going to be the first chunk then this is going to be the second chunk this is going to be the third chunk Etc and then each of those chunks we're going to convert them into embeddings which are basically just a vector representations of your text what does that mean basically you can see it as a list of numbers that contains the meaning of your text and I mean that's the most basic explanation for it but it's just a v a number representation of the meaning of your text and this way these vectors are going to be stored in your knowledge base and then when the user comes here and asks a question the question is going to be embedded using the same embedding technique that we used for the text chunks and that is going to allow us to perform a semantic search which is going to find the vectors right here that are similar to our Vector of our question and this will allow us to find the chunks that actually contain the information that we need and that is those chunks that we're going to feed to our language model and it is like that that we're actually going to get an answer in the end all right so this is basically how the entire application is going to is going to work in the back while we just ask a question right here so right now what we're going to do is going to divide this text into into chunks all right and we're going to do that using Lang chain all right there we go so now what we're going to want to do is we're going to divide our text into chunks and we're going to be using this library from um this I'm sorry this function from Lang chain right so first of all I'm going to do from Lang chain thought text splitter I'm going to import character text splitter all right and it is this one right here that remember all still inside of my if PDF actually I'm going to modularize it in a moment but right here I'm going to say extract I mean split split into chunks there you go and now let's actually split it into chunks um we're going to first have to create our text splitter like this and we're going to use our character text splitter class that we imported before sorry I mentioned that it was a function before but it's actually a class and this object takes different and this object has different properties the first one is going to be the separator which is the the separator that is going to define a new line basically so I mean in our PDF a single line break is just going to be using a new line and then we have the chunk size chunk size like this and this one is going to be a thousand characters okay this basically means that of all of this text we're going to take the first thousand characters and then the second thousand characters and then the third thousand characters Etc okay and then we have another thing called chunk overlap okay and this one I'm going to set it to 200. what does the chunk cover like me overlap mean well it basically means that if you come here and your chunk size is a thousand and your thousand ends somewhere like here in like in the middle of a sentence then the next chunk is going to start 200 I mean like every time the next chunk is going to start 200 characters before this one so this is the first chunk and the second chunk is going to be something like this and the third chunk is going to be something like this so it basically just allows you to get more context into each chunk alright and not split ideas in the middle and then the length function length the length function that we're going to use to measure the length of our chunks is going to be Python's basic function length there you go and then once we have our text splitter initialized we can just run it to create our chunks like this text splitter and we're going to say that we're going to split text and we're just going to pass in the whole Corpus of text that we extracted from our PDF which is currently stored in our text variable right here and now what I'm going to do is I'm going to St write the chunks so that you can see what this looks like right so I'm saving coming back here I'm going to going to refresh the page and once again I'm going to upload my Constitution and there you go here we have that the first channel I mean here as you can see we have an array and you can see that the first chunk goes all the way to qualify I don't know but then the second one starts at section two as you can see section two so I mean it basically just makes it easier to to have context I mean this is this is the overlap in work all right so these are the 200 characters that we said that we wanted the overlap full and these are the chunks that we're going to use to create our embeddings and to look for the actual information um later all right so there you go now that we have our chunks let's just convert them into embeddings all right there we go so now as you can see we have our chunks and we're going to convert them into embeddings so basically we are right here we already had our text we already extracted our content we divided it into different chunks and now what we want to do is we want to convert each of these chunks into embeddings and turn and take this all of these embeddings and make them all of our knowledge base which is going to be a document object on which we're going to be able to run a similarity I mean a semantic search to find the chunks that are actually relevant to our question okay so let me show you how to do that um the first thing that we're going to want to do is we're going to want to import from blank chain dot embeddings dot open AI we're going to import the openai embeddings like that okay I mean you are importing them from Lang chain but they come from open AI this is just a wrapper okay um so right here what we're going to do is we're going to say um that our embeddings is going to be equal to our open AI embeddings like that I'm just going to add a comment right here um create and bad things there you go and now with these embeddings we can actually create our object that is going to be able on which we're going to be able to search right and in order to search on this document we're going to use this f a i s s files which is the Facebook AI similarity search Library okay it's basically just a library developed by Facebook that allows you to perform this this similarity search this semantic search in the knowledge base okay so we're going to have to import that one too and in order to import it we're going to say that also from Lang chain and from Vector stores we're going to import FIS there you go and now we can actually create our document on which we will be able to perform the semantic search so I'm going to say that my document is going to be vise Dot from texts because we're going to create it from chunks of texts and then we're just going to say the first argument we're going to pass is the chunks that we have here and the second one is the embeddings that we're going to use which is the embeddings from open AI okay so yeah this is looking pretty good um let me just change this name right here to knowledge knowledge base because this is actually what we have finished creating okay um we successfully created the knowledge base out of our PDF file let me just show you here in the in the diagram that we showed before where we are exactly at this time um so we already imported our PDF file we extracted the text from that video file and then we split it into several chunks to make it easier for our language model to work with them then each one of those chunks we used openai embeddings to convert them into Vector representation of those same chunks and we used Facebook's semantic search AI to build our knowledge base on which we're going to be able to look for the chunks using the embeddings that are related to the user's question okay so whenever a user asks a question we're going to come to this knowledge base that we created before and we're going to run a semantic search to find the chunks that that are closer to that question so that we can send them to the language model and use that to answer our questions okay so this is where we are so far and this means that we have successfully finished all of this part which is the all of this part now what we're going to do is we're going to start coding this part the user interaction part okay so let's get right into it right all right so what we're going to do now is basically add an input element right here okay and this is where the user is going to be able to ask and their questions okay so the idea is that I'm going to upload a PDF here and then once that PDF is properly uploaded extracted the text split into chunks and created the knowledge base from the embeddings we're going to show a an input a text input labeled ask a question about your PDF there you go and we're going to store this value from this input in a variable called user question like this now if I save it and I refresh this and I upload my file again you can see that it's running I mean that means that it's splitting and embedding and all and now I have my question right here now what I'm going to do now I'm going to say that I'm going to show user input there you go and now if we have if we have a user question what we're going to do with that user question is we're going to look in our knowledge base to see if we find any chunks that could have important information about that question okay so in order to do that we're going to create a new a new element called docs which is going to be the documents in which we're going to I mean the documents that contain important information I mean the chunks that contain information about our our question and we're going to say that we're going to search in our knowledge base we're going to go for similarity search which is a method from the fias class from the Facebook similarity search Ai and then we're going to look for users question there you go and now let's just write the docs to see what we found okay so now if I save this and I refresh this right here and I drag a constitution again there you go now you can see that it's running embedding Etc now if I come here and I re-ask a question and I press enter it's going to perform a similarity search and it's going to find the chunks that are most relevant to this question so according to the Facebook's AI in our knowledge base these are the four chunks that are more likely to contain the information that we need to respond to this question okay and now it is this docs that we are going to use to actually answer the question with our with our language model okay so let's do that now perfect so as we mentioned before what we're going to do now is we're going to use this documents right here which are the chunks that we just retrieved with the similarity search and this question right here to actually answer a question based on those chunks of text all right and Lang chain actually comes with a very convenient chain that is already built for that okay and that one is actually this one right here that they have here question answering for dogs and this is the chain that we're looking at it's called load QA chain it takes a language model as parameter we're going to be using open AI but I mean you can use any other language model if you want you can use a and an open source language model it's I mean this one takes pretty much any language model from the wrappers that they have right here I'm going to publish a crash course on online Link Chain very soon so that you can see what this I mean how this actually works but what I mean is that you have many many language models that you can work with okay but since we're going to be working with openai we're going to just copy this right here and we're going to paste it in here there we go this one since it's just our importing we're just going to put it right here like that now we have as you can see it comes in the Lang chains and question answering module and here we're going to say that this is our language model which we're going to be using and our language model is actually going to be open a i like that okay and also we're gonna have to download it from Lang chain and also I mean of course this is a open AI language model but it comes as a wrapper inside of Langston okay this doesn't mean it's like it comes from launching it's just a wrapper so from launching llms I'm going to import open AI and there we go now right here we have our llm we're passing it right here the chain type stuff that's right and then we can actually run saying that the input documents are going to be the documents that we just retrieved from from our knowledge base and the question that we're going to ask is the user question there you go there you go and now this one actually is going to is going to it's going to return our response like this response there you go um and now I suppose that we can just basically St write our response and there you go do we have any other St writes right here I think that's all right so this should work so now just um just as a reminder what we're doing here is we're catching the question from the input then we are performing a semantic search in our knowledge base which is this thing right here and the docs are the ones that the are the results from that semantic search and then we're using the language model to generate our answer and to do that we're using this blank chain rebuilt chain okay I'm just saying that we're looking at it on the docs user question then showing the response let's just save and come back here to our application refresh and then let's take our hours to Constitution here serum and now running embedding and now we can ask questions about it and it should know the answers right so now let's say what is the minimum age for someone to be elected as senator 30 years all right seems to know but if I ask something that is completely unrelated to the Constitution let's say what is the the age of Paul um Paul McCartney not even sure if that's how it's written all right the question is not related to the context there you go all right so that's already an application that's working pretty good um the thing now is that we want to know how much we're spending per question okay I'm just going to modularize this pretty quick and then let's check how much money we're spending per question let's do that all right you know what I changed my mind I'm not going to show you how to how I modularize this I suppose you can do that on yourselves I'm just going to go directly into the pricing okay and how to monitor how much you're spending per question in order to do that actually land chain comes with a very convenient monitor however it currently only works with open AI but it allows you to see exactly how much money you spend per operation in this case per question answered by the language model okay so here what I'm going to do is I'm going to import from Lang chain thought um callbacks there you go I'm going to import get open AI callback okay and just to show you real quick also here if you go back to open Ai and you come to your platform.openai and you see the usage you will see how much money you have spent per day using their apis okay here in this example I'm as I'm recording this at the same day that I'm uploading it I've spent 90 cents which is quite an expensive budget just for a few tests and also I mean keep in mind that this is way more than what you have seen me do um I have been playing around with it all day so this is definitely this doesn't account only for the test that you've seen me doing the video so what we're going to do now is we're going to take this function from Lang chain and we're going to wrap whenever we're using the open AIS language models okay so I'm going to say with this one right here as callback it's going to say CB scroll back and then inside of it I'm going to run whichever whatever I want to be tracked with um whatever I want to track the price of okay so here I'm going to track how much I'm spending for this generation for executing this chain and then inside of it I'm just going to print the Callback and that's all actually now if I save this I'm going to going to restart streamlit like this there you go if I go back to my application there you go all right refresh actually I'm going to show you this in real time let's see here you have the terminal and here you have the the the application is going to put myself um where I'm gonna move myself here and then we're going to take the Constitution again and upload it there you go and now we can actually ask whichever question we want I'm going to ask how many senators does each state have okay if I click enter we should see exactly how much money we're spending right here okay so let me just zoom a little bit here we go so you have that the answer is two senators um and that operation apparently costed uh around a thousand tokens and it costed me around two cents just for one answer okay which looks pretty good um and then if I ask another question I will get the same thing again like for example let's say how has the power of the video legislation passed by Congress um let's say the person has the power to veto legislation and also around two cents right so this is a very convenient function in order to to track your spending and yeah I mean don't forget to use it um you can probably wrap the entire program in it or entire functions in it so there you go that's how to track spending thank you all right so now you have your application that's working correctly and you know how much exactly how much you're spending per question um and we built it with a graphical user interface all of it using python and I hope that you understand uh the die I mean what's actually going on behind the scenes in this application I hope it was clear don't forget to ask me if you have any questions don't forget to subscribe if you want more videos like this and yeah thank you very much for for watching and I'll see you again next time [Music] thank you [Music]
NfwfiyMi1lk,2023-04-24T05:07:01.000000,Streamlit Python Course: Build a Machine Learning App to Predict Cancer,[Music] thank you good morning everyone how's it going today welcome to this week's new video tutorial on software development and artificial intelligence in this video we're going to be building a complete application with a graphical user interface all of it coded in Python okay the application deals with some with the data set then trains a machine learning algorithm and displays some predictions based on the input data as well as some chart to visualize the data as well okay so by the end of this video you will have this application that you will be able to put in your portfolio and show it to potential employers and to your friends as well so let me show you just real quick how this works you have a you have a sidebar right here with a lot of inputs and the inputs are are represented in a chart right here so if I change something like here you will see that my chart changes okay and also in real time we are making a prediction using the logistic regression model that we're going to train in scikitlearn so if I move something like here you can see that the prediction changes from benign to malignant for example there you go um so I mean the objective of this I mean the real world use case of an application like this would be to plug it to a cytology lab a cancer in a Cancer Research Institute where you can take some tissue from a breast and then take some measurements from it login I mean input the measurements here like either automatically from the machine or by hand visualize this measurements to have an idea of what the cell cluster looks like and then make a prediction based on these measurements to see whether the cell cluster is malignant or not um and yeah I mean it's pretty cool uses data visualization machine learning and and a web application that you can deploy yeah by the end of the video we're also going to deploy it so there you go I am assuming that you know a little bit about how machine learning works and a little bit of familiarity with the logistic regression model I am also assuming that you have the basics of python and I am going to use very very little CSS and it is not essential um so don't worry if you don't have a CSS background um and yeah so make sure to stick to the end of the video to so that you have this awesome um project in your portfolio all right there we go all right so the first thing that we're going to do um in order to build this application is to to train the model okay but before we do that actually I just wanted to mention that if you want a written version of what we are doing right here all with the Snippets of code that I'm going to be using and the written explanation of everything it is in my you can find it in my blog everything that you that you will find in this video is also written in this blog post I mean including the the code Snippets and also be sure to check it out if you want um all right so back to this data set um of course we need a data set to train our model in order to be able to make a prediction okay as you can see we are trying to predict whether I'm cell cluster is benign or malicious given certain measurements that we're going to take from it and that is exactly what we have in this data set right here from the University of Wisconsin it's a free data set I will also put the link in the description and the data set contains a lot of variables of a lot of measurements made to many different cell clusters the measurements include for example the radius mean of the cells the texture mean perimeter mean Etc and then it also contains a column with the diagnosis of the cell cluster so if it is M that means that the cell cluster turned out to be a malicious cell cluster and if it is B that means that the cell cluster turned out to be a benign so cluster this means that we can train a machine learning model that is going to take all of these variables as predictors and it is going to predict whether or not the the cell cluster is benign or malignant so in order to build this machine learning model we're going to download this data set I have only it already downloaded it and I included it right here in my project but be sure to unzip the file and then I just rename the file data.csv and then put it right here and then once that is done we are able to start training our model in order first in order to if you want to better understand how machine learning works and how especially logistic regression works I invite you to watch the video that I made about that specifically because I use this this same data set in that video and and I mean here we're just going to be going through the cleaning and the model building super fast I'm not going to be explaining a lot of the logistic regression part so be sure to check that one if you if you have some questions about that um all right so now it's time to actually start training our model the data that we included right here actually comes by itself already pretty clean so we're not going to be doing a lot of exploratory data analysis either also that's in the other video so I'm just going to go through the cleaning super quick so let's get right into that all right so let's get right into it um the first thing that we're going to be doing is we're going to create our project folder the project folder is called streamlit app um that cancer in my case but uh extremely adapt cancer sorry and inside of it we have a model folder and another folder called date as I mentioned already I already imported the data CSV that I downloaded from kaggle right here and this one right here is the model this is the file where we're going to train the model and this is also the place where we're going to to clean the data and to test that the model is working correctly before exporting it once we export it we're going to be able to create a new folder right here which is going to be the app folder and this in it is in that folder where we're going to be creating our streamlit application but for now we'll have to first create a model that we're going to feed to our streamlit application so that's what we're going to do in this file right here um right here as you can see I have this basic condition what this does is it tests that this file is I mean it only executes what's inside of it if the file is being executed directly and not being imported this is basically just um standard convention convention thing to do in order to make your code a little bit more robust that way you can be sure that the main content of your application is not being run accidentally when you import the file somewhere else and it's only executed when you actually want to execute this file so there you go and now let's just start adding our data cleaning right here and our model building and all so there we go all right so let's get right into it the first thing that we're going to do is to import pandas SPD that's basic in case you don't have pandas installed you're going to want to pip install pandas in your terminal and once that's done you should be able to use it like this now let's just import actually what I'm going to do is I'm going to create a new function right here that is going to be called get clean data and then I'm just going to Define it right here Define get clean data there you go and this one first is going to read the data file that we have right here so we're going to do my data is going to be equal to PD dot read CSV and we're going to read inside of data and we're going to read data.csv there is something strange going here I mean like I'm not like super I don't have a lot like super long experience in Python so I I mean like my intuition would be to actually go up the model like the model folder and into Data but actually it seems to I mean in Python you just have to run it from the root folder where the where you're running the application so I mean all right let's do it like that and then we're going to be doing we're going to be printing the head of the data right so it's a data.head to visualize it and we're just going to return the data to see how it works so there we go now if we click on enter on read we should have our head right here and now it's actually time to clean it and to clean the data I mean you can do it by hand like actually do an exploratory analysis on the data and that is what you should do if this is a new data set but that I have already worked with this data set and I know how it looks like so I'm just going to clean it super fast so that we go so that we can go faster into building the application okay so for example I know that in my data I have this column right here called unnamed 32. and I know that I'm going to want to drop it because I know that it is all completely in the ends okay so let's first do that I'm going to the data dot drop and oops updated the drop and I'm going to drop this one right here which is called unnamed 32 like that and then I'm going to say that it has to be dropped from axis 1. and then I am also going to drop the ID column which I don't need either and but um I'm actually going to drop it from here ID like that there you go and now the diagnosis variable we have it that it uses amps and B's and we're going to encode it so that malicious I mean like ends become zero and benign becomes uh one now benign becomes zero and malicious becomes one because we want to test four malicious one Malaysian cells so let's do that so in order to do that we're going to be using the map function and we're going to be targeting the diagnosis um the diagnosis column right here and this one is going to be diagnosis diagnosis dot map and the map takes a dictionary and in this dictionary I mean of course it takes key value Pairs and in the key you have the actual value that you have currently and in the pair you want to have the value that you want it replaced with so malicious is going to be one and benign is going to be zero there you go now we can print now we can um I suppose that is the clean data let's just check that out right here print um data dot head there we go we save it we run it and now we have the data that is being run and I mean the head of the data we have the diagnosis a lot of diagnosis of one and we have the factor I mean like I mean we don't seem to have the unnamed column I'm just going to check it real quick using the info right here so as you can see we don't have an unnamed column and we don't have um we don't have the ID column anymore and the diagnosis column is now once and zeros so this is exactly what we wanted so now as you can see we already have the clean data and now we can actually train our model from this data so what I'm going to do is I'm going to do um create model there you go and I'm going to Define create model up here so let's do that right now all right there we go so in order to actually create our model we're going to first have to pass in the data right here that's something that I forgot the data that we just got from our clean data function right here we're going to pass it right here and inside of this function what we're going to do first is we're going to divide the data into into the predictors and the target variable okay so my predictors is going are going to be called X and I'm going to say data dot drop and I'm just going to drop my diagnosis right here I'm going to do axis 1 to be sure that it's dropping the right part um there you go like that and for y this one is basically just a diagnosis column there you go um and now what we're going to want to do is we're going to scale the data first because as you can see on this information from the data that we have some variables are much larger than the others like for example this one's in the thousands and this one is just decimals this one's in the hundreds so in order for our model to actually have uniform data it all has to be on the same scale so that's what we're going to do now and in order to do that we're going to have to import the the standard scalar from scikit-learn okay so I'm going to do from sklearn dot pre-processing I'm going to import standard scalar there you go and now I'm going to be able to use it right here so I'm going to say that my scalar is going to be equal to standard scalar like that and then we're going to basically just scale all of my training predictors okay because of course the diagnosis prediction the diagnosis doesn't need to be scaled because it's already either zeros or ones okay so my X is going to be my X is going to be equal to scalar and the Scala that I just created I'm going to say fit transform X to scale my X predictors there you go so now we should have our our scaled um and we should have our scaled scalar there you go and our scale data and now what we're going to want to do is we're going to split the data into testing and training set okay here scale the data I'm just going to comment it real quick and then we're going to split split the data super quick there we go and and there we go now in order to split it we're going to be using another Library it's going to come also from scikitlearn but this library is called train test split I suppose you already know it but I'm going to import it like this right here model selection import train oops import train test split there you go and now we can actually test and import split our data into training and testing set so my X train my X test and then we have my y train then we have my y test there you go like that and this is going to be equal to my train test split and this one is going to take first it's going to take my my predictors then my my target variable then I'm going to say that the test size is going to be 20 percent and I'm going to set a random state of 42 because that's the best number and now that our data is split we can actually train it now as you can now as you can see we already have this train which is 80 of our training predictors and this test which is 20 of our predictors and same with the diagnosis the target variable okay so now for the train model we're going to do auto equals logistic regression but we have to first import logistic regression from Psychic learn as well and from sklearn dot linear model we're going to import logistic regression like that then we're going to use it right here there you go and this is the model that we're going to export to use it in the streamlit application later okay so we're in order to be able to actually use it we're going to have to fit it to our data so we have xtrain and Y train there you go I'm going a little bit fast with this training model part because I mean I'm assuming that you already have a little bit of knowledge on that but if you don't all remember to check the other video where I explain the logistic regression model and how it what is the intuition behind it okay I go through this but in much more detail um so there we go and then finally once we have it tested what we have it trained we're just going to return it and we're going to return the model and we're also very important we're going to return the scalar right here this is going to be super important later because we're going to be using it to make our predictions later okay so here that basically means that I'm exporting the model and also the scalar there you go now that we have the model and the scalar we can actually test the the data so let's see we're going to test our model and that also means that I'm going to have to create a new function right here for testing okay test D model so Define test model we're going to test the model there you go um all right so first of all wait just let me be sure that this is actually that this is actually working does it run seems to be running correctly okay we're going to be testing it in a moment anyways so there we go ahead there we go so now it is time to actually test the model to make sure that it's working correctly and to do that as I mentioned before we have this test model function that we are creating right here and let's just create the test in order to actually run the tests we're going to be using also another library from scikit-learn I just wanted to mention that of course here we're using scikit-learn to build our machine learning model because we're making a very simple prediction based of a very simple list of variables but this actually works pretty much with any R2 which any AI model all right so whether it be machine learning or deep learning I mean you can be running tensorflow here and then build an application that makes prediction it's based on tensorflow so I mean the fact that I'm doing it with psychic learn doesn't mean that you cannot plug in a neural network right here and make your predictions with that okay just so as long as you're able to export your model later as you will see in a moment it should be okay so we're going to test the model right now to test the model we're going to be using first we're going to be using the predict function from the model that we just created and that we're importing right here so let's do that we're going to say that the Y predictions um actually you know what we're just going to test the model inside of here so that we can actually have access to all of this there we go um we're going to test the model right here train the model then we're going to test the model and in order to test the model we're going to create the predictions protect um yeah the Y predictions and they are going to be based on the model right here and we're going to run predict and we're basically going to predict under X test set okay as you remember we trained it on the training part of the predictors and now we're going to test it on the on the testing part of the predictors um and then finally we're going to print the accuracy accuracy of our model and we're going to say that the accuracy is the accuracy score but in order to use the accuracy score we're going to need to import that function from scikit-learn so from scikit-learn dot metrics we're going to import accuracy score basically tells you how how often you will write in your predictions and also we're going to import the classification report there you go so for the accuracy of our model we're going to say that we're going to check the accuracy score and this function takes two two parameters the first one is the actual values and the second one is your predicted values for y okay remember that the actual values are stored right here in the test variable and the predicted variables are the ones that we're predicting with our model and this should print out the accuracy of our model and second of all we're also going to print our classification report which is a more a more in-depth um analysis I mean in-depth report of our model so we're going to use the classification report and just as the previous one it takes the the actual values for the the actual values for diagnosis and then our predictions there you go there we go and then just as before we're going to be returning our model and our scalar there you go now we should be able to run this and let's see what it returns okay so we have an accuracy of our model of 97 which looks pretty good and here is the classification report we have a Precision of 97 for negative I mean for benign um for benign cell clusters and a Precision of 98 for malicious um for malicious cell clusters we also have the other measures other statistical measures right here like the F1 score which is very important if our data set is very [Music] if the yeah if the portion of actual of actual positive diagnosis is very very little so there we go I mean our model seems to be looking very good now it is now it is time to actually export that model and the scalar of course very important and to start using it in our application there we go all right there we go now that our model is script is pretty much ready it should look something like this just minimize the function so that it's easier to for you to see what is going on but as you can see we first created the clean data function that I just built super quick uh because I already know the data but remember to perform some some exploratory data analysis to make sure that your data is is clean before actually using it and then we created the model also I did that super quick because I already have already worked with this data set but also um this should be like a a little bit of a longer process uh if this is a new data set for you um and then we exported the scalar and the model in order to be able to make our predictions in our application okay and now what we're going to do is we're going to export the model and the scalar in order to be able to use them inside of our application this is very important because you I mean sometimes you might be tempted to just run this code inside of your application that would mean that it would be training a machine learning model inside your application every time someone opens the app which is terrible for all for usability I mean it's just going to make your application way slower because every time it's going to be opened it's going to be training an entire machine learning model I mean this one is a little bit is quite fast because it's just a logistic regression model on a few on very little data uh but like anyways you should uh it should be like uh something like you do systematically that you build your model uh apart and then you export it to a binary file and then you import that binary file into your application okay and that is exactly what we're going to be doing right now in order to do that you're going to want to install first um this package got called pickle pickle five so in order to do that basically you just do pip install pickle five it's the one that we're going to use for exporting our binary file then you're going to import it like this import pickle 5 as pickle and then we're going to write a binary file with this with this module okay so first we're going to open a new file we're going to call it model dot pickle and then the second argument of the model we're going to say that we're going to be writing in the in the file and then it's a binary file that's what the b stands for and we're going to say sf4 file and with this file we're going to pickle oops typical dot dump and we're going to dump our model inside the file there you go um and then second we're going to do the same thing with a scalar oops scaler dot pickle like this and just as before we're going to say that we're going to be writing on it and it's going to be in binary mode as file there you go and also we're going to pickle dump but this time we're going to pickle dump our scalar and all we're going to dump it into our file right here so there you go um quite I mean like just as I mentioned before even though we're running oh I mean this file is being executed inside of model we want to save it inside of model itself so we do model model like that that way the file is going to be I mean the binary for for our model is going to be stored inside the model folder and same for model for the pickle folder right so there you go um so there we go now if we run this and we save this we should be able to see that our model that pickle is being saved right here but our scalar doesn't seem to be saved so no such file or directory assess it right open pickle scalar f um [Music] maybe I have to change this here let's see if that works not switch file or directory modal scaler.pickle all right yeah sure I added just like an extra parenthesis right here uh so yeah the G was not a problem there you go now if we save it we should have our model.pickle and ourscaler Dot pickle like that there you go and these are the files that we're going to be importing into our application so now that our model is built and our scalar is built and both of these binaries are exported it is time to actually start building our streamlit application with this okay so there we go let's try get right into it all right so now it's time to actually create this app in order to do that as I mentioned before we're going to create a folder called app and inside of it I'm just going to create another file called main.py there you go and it is in this file that we're going to be running the application so just as before we're going to be testing that the fat that this is the file that is being executed and not that it's being imported somewhere else it's just like a safety mechanism then we're going to run main like this there you go and now we're gonna have to Define our main function Main and we're going to say print hello world we will build streamlit streamlit app there we go so now let's see how that looks Hello World we will build a streamlit application there we go um so let's do this first of all what we're going to want to do is we're going to want to import streamlit okay and in order to do that you're going to have to have streamlit installed streamlit is a python a python library that allows you to to that allows you to oops nope stream lit ah extremely to say python library that allows you to build web applications super quick um basically around your around uh around some data it's super useful to create like dashboards or data visualization applications or in this case machine learning prediction applications okay and it's super fast you will see how how we're going to we're going to start up this application with very little and very few lines of code so as I mentioned before you're going to have to install it so you're going to do pip install it first um I already have it installed so that's going to be super fast but then once you have done that you're gonna have to come right here and do import streamlit as St um what is going on here that's SD there you go then we're going to do import pickle pickle 5 as pickle like that in order to actually import our model and scaler and we're going to import pandas SPD as well in case we need it so there we go so in our main in our main function the first thing that we are going to do is we're going to set the page configuration for our flower or flower application so that goes St page config and here we're going to say that first we need the page title page title you know what I'm going to do it like this page title it's going to be breast cancer predictor there you go the second argument that it takes is the page icon I'm just going I'm not sure what I think it takes seconds like this so I'm going to say female female doctor supposed to work and the layout I'm going to say it's white because I mean if I just run it like this let me just show you in order to write anything where I'm just going to say right and let's be let's just do hello world there you go if we save this file like this and we do and we try to run it also watch out in order to run this file you cannot just do python python your your app Main .py because this is not going to actually execute the application in order to run the application you're going to have to do streamlit run and then actually Target the file that you want to run that has the streamlined application and then it's going to start up oh it's going to start up this um this app in your browser and as you can see we have our app and it says hello world which is the the text that we wrote right here okay so just with that we already have an application that is up and running so that's pretty convenient and now as you can see we have a a contained layout it has a container right here with a very big like margin but we want it to be like a wide layout so I'm just going to set right here that this is going to be layout and delay is going to be white there you go and and we are going to have a sidebar so I'm going to say that the initial sidebar state is going to be expanded this one takes expand it there you go now if I save it and I rerun the application [Music] rerun the application you can see that the layout is white and I still don't have a sidebar because I haven't created it yet but as soon as I add a sidebar it's going to appear open right here so let's get on to that [Music] um so there we go that is the pretty much the start for the streamlit application the next thing that we're going to do right now is we're going to create the layout of our app create the sidebar some columns and then start populating the columns okay so let's get right into it there we go so now what we're going to want to do is we're going to want to set a title for our app and set the set and just write some explanation of it and then just set the layout okay now I come from web development so it kind of is a reflex to me to put everything inside containers and streamlate comes with containers that actually just become divs in in the H in the HTML code okay so in order to create a container that is going to contain some of some other elements you do St container like that and you're going I mean in order to write inside of it you can do with um the default python thing and then in whatever you write inside of here is going to be contained inside this container right here um and it's just a very convenient way to structure your application so right here we're going to do we're going to write St title which basically creates a H1 header and we're going to call it rest cancer predictor there you go and then we're going to St right which basically creates a p element which is a paragraph in the HTML and I'm just going to copy this description right here from this file that I have on the side in order to not have to type it all it's just a description of the application for the users and to make it easier for them to understand what is going on and now that I have this container right here the container includes the the title and the P element so let's just start the application again and there you have it you have our title and then you have this quick explanation of the application uh the explanation rates please connect this app to the cytology lab to help diagnose breast cancer from your tissue sample this app predicts using machine learning model what whether a breast mass is benign or malignant based on the measurements it receives from the cytosis laboratory you can also update the measurements by hand as you will as you remember we have this we have this sliders that you can update by hand but like ideally for an application like this you would like you would want to plug it directly into the machine that is doing the measurement so that you have the the predictions immediately all right so there you go um now that this looks correctly we can continue with um with the layout that was one container now we're going to create two columns okay in the First Column is going to be is going to be this chart right here and in the second column is going to be this prediction um box right here so let's do that in order to create columns in streamlit you can do St dot columns um this is important because um just very a few months ago or years I don't know um this was a beta function so you had to do beta dot columns Etc but now that it's in the standard version you can just do St columns and it works and this one takes um okay I mean takes a list of how many columns you want and the ratio of them so I'm going to do four and one which means that the First Column is going to be [Music] um four times as big as the as the as the second one and since we're creating two columns this function returns two columns like this call one and call two equals SD columns four and one and then just as we did with the container we can write inside of these columns by using the width the width function from python so we do St sorry with column one we're going to do St that right this is column one and then with oops with call 2 we're going to do St right which remember creates a p element like a paragraph and this is column two remember that the first one is supposed to be four times as big as the second one so let's see how it looks um am I running it or not uh there you go so here this is column one and this is column two as you can see it's um shorter than the column one by a ratio of one to four so there you go that seems to be working correctly now what we're going to do is we're going to we're going to start um with the sidebar we're going to create our sidebar right here with all of our inputs and then from those inputs we're going to generate the chart and the prediction so there we go all right so what we're going to be doing right now is to create our sidebar for our application okay the sidebar should look something like this and it has as you can see right here it has a slider for every single variable in our data okay so here we have our data and as you can see we have around 30 predictors now if I remember we dropped two columns so we have 30 predictors and so we should have around I we should have 30 sliders one for its predictor and depending on the value here we will make our prediction and we will update our chart right here all right so in order to do this the first thing that you want to do is to subscribe to the channel and to like the video because if you have come this far that probably means that you're enjoying it and it would be very good for me thank you um all right so now what we're going to do is we're going to create this thing right here I'm just going to add it before the container um I'm going to make my own function and where I'm going to actually create the sidebar I'm going to show you a little bit later why I'm doing this um but let's see the first the first the function is going to be called add sidebar like this and then I'm just going to create my function up here add sidebar fine add sidebarm there you go and now inside of here in order to create a sidebar all you have to do is do St sidebar and then just create a heading for the sidebar I'm going to say header sorry I'm going to say that my header is going to be called cell nuclei measurements there you go now if I save it and I come back to the app that we are developing now refresh here you have your sidebar um there you go so I mean just a quick note I don't remember if I mentioned this already but I mean in this example ideally you would want this data to come directly from the cytosis lab and to not have to update all of them by hand um but it's just that example right so I mean ideally you would have this plugged into a laboratory and then the laboratory would fill the input values automatically based on the measurements from the machine and then like the the researcher would be able to just tweak some values to make sure that it's what they intend um so there you go so now we're going to create this slot and this slide is right here but here we're heading to a problem and it's the fact that as you can see inside of our app file we don't actually have access to the column names or to the maximum values of the column names because as you can see each site each slider needs a maximum value so that we know kind of like where to stop this and to like in order to not set a maximum value of 100 right here if all the if all the values will be between 1 and 10 right that would be extremely complicated to choose a value if all the all the real values are actually just like on this portion of the slider so what we're going to do there are two things that we could do here the more formal and correct way of doing this is to export an object just like we did with the model and the scalar from the when we're training our model export an object with the information that we need which would be the maximum value for each column and the column labels and the column names for example um since we are doing this like super quick and this is and also since the data is very very very small like our data set is just a few hundred a few hundred lines long so that means that we can probably get away with actually importing the data inside of the app this is not what you would do in a real production application but we're just going to do it right here to show you how how it would work like just keep in mind that in a real world scenario you would do this in the main file and then just export it just as with it with the pickle function and import it right here all right so let's do that um I'm just going to create a function where we get the data I'm actually just going to copy it from here get clean data because remember that remember that we want it clean and now that we have the function of get clean data we are going to call it right here inside the sidebar I'm going to say data equals get clean data there you go and now what we want is the column names of the sidebar inside of um finder inside of a list right because we're going to want to we're working on and also we're going to need the labels of each of these sliders right now I'm going to cheat a little bit right here because I had this ready I asked chai GPT to make it for me so I mean that just makes it a little bit easier because otherwise I would have to to type all of this by hand but the idea here is that you have a list with the label right here and the name of the column right here so this is the value that we're going to be using um as a label for our slider right here and oops um and here's the column name that we're going to be using to actually access the maximum value of that column okay so I mean this is the same for for every single column in our data set I mean you would probably won't find a better way of doing this but since charging PT just does it super fast I just um asked it to do it and then once we have that information what we're going to do is we're going to Loop through all of these labels and all of these column names and to create one slider with each of them right um so in order to do that we're going to say that for the label and the key which are the two values two values in my in my list in this in this list we are going to create St ABA dot slider I'm just calling sidebar because we want the slider to be inside the sidebar but we could very well just do SD that slider okay this is just to put the slider inside the sidebar and the slider we're going to say oops we're going to say that for each element in this list the slider is going to take the I mean the first argument that the slider takes is the label and we're just going to set it to the label which is this one um I mean the first value in our in our value pairs and actually I'm just going to erase it like that I'm just going to say label like that it's pretty much the same thing and then for the minimum value we're going to set it to zero and then for the maximum value um let's set it to 100 just just for now just to show you what is happening I'm going to save it and right here let's just refresh and there you go you have around I think it's 30 30 sliders that go from 0 to 100 and each one of them has the label that we require so that's looking pretty good so far um now actually tweak it let's just tweak it a little bit so that it actually is what we intend it to be now in here instead of it being a hundred we're going to make it take the the maximum value in the column that we're in so in order to do that we're going to take the data that we previously imported which is basically just the data set and we're going to say that we're going to pass in the key this is going to select the column in the data Associated to to the variable that we're using so here in this case for radius mean it's going to take the column named radius mean which is the column that contains the data about the radius mean there you go all right so and this one we're going to take this to take the maximum value right here there you go and in order to make sure that everything's working correctly we're going to convert it to a float and if we save it right here this is not going to work because this number right here is an integer and it should be a float as well in order for us to work if I refresh this we have the problem that it has the minimum value has an integer type and the maximum value has a flow type so in order to fix that we just do float there you go then we refresh this and there you have it now the maximum value is as it's like something that makes more sense for for this given for this given value so in this case as you can see the area can go to 200 2000 like 2500 and this one right here and the maximum goes to just 0.16 so I mean that makes it way easier to to actually visualize and to choose the the real value for it and now let's just set um an average I mean like um like a default value and we're going to set pretty much the same here as heat the same thing as we did here but we're going to say that instead of the maximum we're going to say that we're going to take the mean value of that of that column okay if we've got a comma here and then if I refresh I should have the average value for each one of them it's looking pretty good huh there you go um and now one thing that you may want to consider is that this this right here actually this function I mean the function slider can Returns the value of the slider so we're going to want to save that somewhere in order to take that information and build our chart and our prediction right just as a side note here we're using sliders but remember that you can use pretty much any HTML input element so if I go to streamlit inputs extremely inputs here we have the input widgets that you can use here like a checkbox a radio button select box here we're using the slider as you can see sd.slider but like you can choose among any of these and use them to build your application right so there we go now I was saying that this function right here Returns the value for each one of this so what we're going to want to do is we're going to create a dictionary input dictionary and we're going to say that for each one of this we're going to create a new key value pair in the dictionary that is going to have as a key it's going to have the column name and as a value it's going to have the current value of the of the slider so in this case for example it's 14 13. that means that in our dictionary the key value pair with the key of radius mean will have a value of 1413 and that is the dictionary that we're going to use to create the chart and the predictions later on all right so now we do that and here what we're going to do is input dictionary and we're going to say that the here is the key there you go so this basically is doing what I told you creating a key value pair well the key is the name of the column and the value is the value that the user input in the slider and then we're just going to return this dictionary input dictionary like that and then we can retrieve the data right here input data will be equal to whatever the sidebar returns and the sidebar is returning the data from those inputs so now if we refresh this seems to be working correctly and whenever I do this it should be updating the value of my input dictionary so there you go now we have created our let me just um let me see if I can show you this um Let's do an st dot write um can I write just input data I don't know if I can do this let's see yeah there you go so I mean like here I'm just like this is just for tests right every time I update this you can see that this one is being updated this one is being updated I mean like what I'm doing here is I'm just outputting the data that comes from the sidebar so now this is this is basically what we need what I told you the key value Pairs and we're going to be building our chart from this and our prediction um later on from this as well so there we go I'm just going to remove that there we go so let's get to building these two parts all right so now it is time to complete our application with a charge right here that is going to take the values from our input elements that we have on the sidebar okay um we want a we'll want a chart to look something like this the chart is a radar chart that's how it is called and it has different values right here and the on the on the circumference and it has different values here on the radiuses right radii yeah um and the idea is that you will have the perimeter the texture and the radius and you will have three values for each one of this you have the mean the standard error and the worst value uh for that one in the cell cluster um all right something to keep in mind is that this are not the same column all right so um how to put this in simple terms so the mean radius is one column the standard error for the radius is another column and the worst value for the radius is another column all right so it's not one single column from which we're taking the mean the worst value and the standard error they are different columns in our data set and that's basically just how our data set arrived so that's how we're working with it um so as you can see here you can see it clearly here you have the radius mean you have the radius standard error and then you have the radius um worst value which should be here there you go um so basically what we're going to do is we're going to create this chart and we're going to map we're going to map the values from the mean from the standard error and from the worst part of the data set into each part of these traces okay so let's do that in order to build this chart we're going to be using a JavaScript library that has a python module called plotly it's super powerful and it's it makes interactive charts unlike for example Seaborn or Matlab here you have like an interactive chart that you can play with I'm not sure if this is working um yeah here we have an interactive chart that you can play with um I don't know what this is what's going on here Zoom um yeah uh I don't know for some reason there is a bug here in my JavaScript I suppose yeah but I mean the thing is that you can you can usually play with it uh we should be able to do that in a moment but yeah I mean it's a very nice library and it is the documentation is right here okay um what we're going to be doing is we're going to be copying this example from the documentation and we're going to be upload upgrade and in updating it with our own data okay so let's do that I'm just going to copy this well first of all I'm just going to add my function right here instead instead of the text this is column one we're going to write um get Trader chart and this is going to be a function that takes as an argument my input data that we are retrieving from the sidebar do you remember that we're getting the dictionary of values from the sidebar and this is the dictionary of values that we are injecting into our I mean we're passing to our data chart as an argument so let's now create the function get um radar chart like this and inside of it we're going to actually just add the code that comes in the example of our documentation something to keep in mind is that you're going to have to install plotly first so in order to do that it's very simple you're just going to do um pip install plotly I already have it installed so I'm not going to do it but once you do that you're gonna be able to import plotly right here like that um using just as in the example from the documentation graph objects which is a part a module of the plotly library that allows you that gives you a higher level of customization in your charts but something that you can do is also use like I mean if you're using plotly for other things you can use the express module which makes allows you to make charts with predefined characteristics with way less code but since we want to be since we want it a little bit more customized we're going to go for this one and we're going to just copy this example right here now that we have this right here uh notice that here at the end they have fake.show that basically just renders the plotly chart in in the page but this is not where we're going to be using because um streamlit uses its own function to incorporate um plotly yellow I mean plotly elements into the application so what we're going to do is instead of doing fict.show we're just going to return return the figure like that and right here we're going to Raider we're going to get that figure which this function is going to return and we're going to use this streamlit function called St dot plotly chart there you go and then we're just going to call in we're just going to pass in the figure element that we got from from the function so now if we save this we should have this chart in our page let's see if we refresh does it work and there seems to be a problem here uh Raider chart takes zero positional arguments okay I forgot to add input data here there you go now if I refresh there you go now we have our our rated chart uh it's looking pretty good now what we want is to it to actually take the real values that we wanted to take and in order to do that it's actually very simple let me just show you what is going on in the in the chart so here as you can see we have five different values that the traces can take mechanical properties processing codes Etc right and this ones correspond to the categories list right here and they have they correspond to the to the parameter Theta Theta Theta Theta and this is basically just the yeah yeah the the values among the the yeah the angular the angular values all right and the r or the radial value so I mean the distance uh from the center to the actual maximum value that each value has right I hope it's clear there you go so here for example we have categories the first element in the categories list is processing cost and here the first element of this Trace which is product a is one and here we have it that it is the value for that one is one right here and the processing cost is the value Associated to it okay same thing mechanical properties is the second one and here it is number five the value for that one so it Maps two mechanical properties and here we have it it was one for processing cost and it is five for mechanical values okay so all that we're going to want to do is we're going to replace this with our own values that are here which come from radius texture perimeter Etc and we're going to replace the r values with the values that come from our input data that comes from our sidebar okay very simple it might get a little tricky and while we're doing this but stay with me it's not that hard just just feel free to replay this um this part of the video If at some point you get stuck or just ask me in the comments if you have any questions okay all right so what we're going to do is first of all we're going to replace the values on the on the perimeter with the actual values that we want so let's do that so we have processing cost here and I have my list of values right here where is it here it is and this is their list of values that I'm going to be using there you go we go from radius to texture area and cavity fractal Dimension Etc there you go and now these are the categories and we have one two three four five six seven eight nine ten values right here that we have to assign in each one of these traces okay I forgot to mention the what this thing these two things are this is basically just the name of the trace here it is product a and product B and in our application they are going to be mean standard error and worst okay and the fail it just tells plotly that it wants the the figure to be filled with color okay so if I set this one to none for example we won't have a ready color here like a red color here we'll just have like an empty space with the line around it okay um so there you go um so let's just complete it here we have the categories and now let's use the data in our input data to complete the values inside of the chart and the right and the values come right here and I'm going to say nope it's not there you go there you go and right here I'm just going to add the values I already have them copied on the side but I'm just going to start typing them here so that you get an idea of what they refer to and then I'm just going to copy them from my code that I have on the side um the idea right here is that you're going to take the input data and remember what is input data the input data is the value that we're getting inside the function and the value that are we're getting inside the function comes from the sidebar and you remember what the sidebar returns decide by returns a dictionary a key value pair a dictionary of key value pairs remember that in the key it has the name of the column and in the value it has the value of the sidebar so what we want right here is to take [Music] um is to take the key that that is associated to the mean value here let's just update this one mean value the key that's associated to the mean value of the radius okay so it is the key that's associated to this slider right here this is the one that is going to be mapped onto the radius the radius part of the mean Trace okay stay with me there we go so here it's going to be radius mean like that the second one is going to be input data and it's going to be texture mean and what is the name the key of this value well it's very easy it comes from this array right here the first one is radius mean the second one is text Charming so we're going to take that one we're going to put it right here like that there you go and like that we're going to do like that for every single one of our input data um that the for our input data that comes from our sidebar that's about the mean okay because remember that we have the mean we have the standard there and we have the worst value so we're going to do that for all of them up until here all right so I have that right here let me just copy it and paste it here there you go so it's exactly what we were doing before this is a list with all of our elements there you go the first one is the radius main texture mean Etc all the way to fractal Dimension mean and this comes from the object that we exported from the sidebar all right the Theta is the same categories and there you go looking pretty good now same thing for the second one the second one is not going to be the mean value it's going to be the standard error and this one is going to take the values of this one radius standard error up until this one right here okay and it's basically just exactly the same thing as the same thing as the previous one we take the R value and we paste the input data like this um here I'm just going to do like that there you go I'm going to some spaces there you go oops just make this a little bit more beautiful and easier to read input data symmetry standard there and I'm missing fractal mean yep I mean which is not a mean it's actually the standard error so there you go here we have standard error like that and like that there you go so just as before we have the input data for each one of this and here instead of targeting the first the first 10 one we're going to Target the second from from the second ten one from the 11 to 20. that's that's which are the variables Associated to the standard error and we're going to do the same thing for the third Trace which is going to be the worst value for each one of this and here it's going to say worst worst value this is the name of the trace and here instead of radius SE it's going to be radius worst and the same for all of them just going to copy them from the side mm-hmm [Music] like this there you go so now we have [Music] um radius worse texture worst all the way to fractal Dimension worst and this are going to map to our categories okay so there we go now if we save this we should have a radar chart that looks a little bit correct but it's not going to be correct yet um yeah the thing is that um [Music] let's see if what if I do something like this there seems to be an error here um everything seems to be falling on 0.4 for some reason um r r r categories to sell forced value the range return figure we're going to show the legend um what's going on here what do we have here we must have an error somewhere right here um maybe we're adding too many values here fractal them from radius to fractal Dimension one two three ten three though that's ten all right what's going on here um maybe this shouldn't have space here I don't think that's it let's see no all right give me a second all right sorry about that the air was this little thing right here okay so we were defining our categories but we had this coma right here so it didn't know what this was but now that we remove it and that we leave it like that it actually sees that every single one of this has a different um it's a different element from the list okay so there we go now our radar chart is looking pretty decent I mean not yet but it's getting closer to that so there we go we have different values for fractal Dimension concavity Etc um all right so now what we're going to want to do is we're going to have to scale all our values okay and how do we scale them um so the thing is that here you have for example the perimeter can go from zero to 188 which is a ridiculous like a ridiculously high value compared to for example smoothness which can only go to 0.16 what we are going to do is we're going to scale all of these values to get them to get them between 0 and 1 that way we can have a range for our we can create a range for our for our radar chart so that if it's zero it's closer to here and if it's one it's closer to here um because I mean if we set it to a thousand for example let's set it to 2000 and 2500 if we refresh this I mean it's going to be all right for them for the area value which is in the thousands but it's going to be too big for all of the others right so like if I put this one here I mean it will be able to detect it but let's just scale every single one of them between zero and one okay so let's do that right now in order to do that I'm just going to set the range to zero to in between 0 and 1 I'm going to scale all of the values so that they be between 0 and 1. to do that let's create a new function that is going to be um um get scaled values I suppose you can also I mean and this is going to take a dictionary okay input dictionary I suppose you can also use scikit-learn for this I'm just going to do this by hand because I don't know it was just a little bit faster but I suppose you can do it with scikit-learn as well so what we're going to do to get the scaled values is we're going to we're going to get the data first um get clean data remember that is the function that we created before and with this data we're going to take also just the predictors so it's going we're going for to do that we're going to drop the diagnosis part um oops data dot drop [Music] diagnosis and we're going to drop it on axis axis 1 like that if I'm not mistaken and now we're going to create the scale dictionary which is the one that we're going to return okay and what we're going to do is that for we are taking the input dictionary right so for the key and the value pairs inside the dictionary uh input dictionary and for the items so that we are looping through the key value pairs what we're going to do is we're going to say that the maximum value is going to be equal to X X and then the key for this element in the value which I mean remember that we're dealing with our with the original dictionary of value key value pairs that we were working with before we're going to do Max and then the same thing but for the minimum one the minimum value is going to be equal to the minimum one and then the scaled value which is the one that is going to have like all right so this is a little bit more of mathematics but basically we are taking the maximum value in the in the given column and the minimum value in the given column and then we're we're getting the scaled value based of that taking the value of the actual um of the actual input minus the minimum value over the maximum value um minus the minimum value oops uh not mean value mean vowel like that and this is basically just going to give us a scaled value um a value between between 0 and 1 for every single value in our in our input dictionary okay I suppose you can also use a scalar from scikit-learn but I don't know I just found it faster to do it this way so now in the scale dictionary we're just going to replace the key um in the value of the key which is this one with our new scaled value there you go and then let's just return the scale dictionary like that okay I hope I didn't lose you there basically all that we're doing is taking I mean this function basically just takes the input dictionary with all the values from this input right here and it looks in the data for the maximum and the minimum possible value for this one and then it just performs some operations I mean this separation right here which will always be between zero and one okay so the low the closer it is to the minimum value the closer it will be to zero and the closer it is to the maximum value of the same column the closer it will be to one so it will the this function will return and in production a dictionary that looks exactly as the one that it's taking but with values between zero and one okay and this is the one that we're going to be using right here in our in our radar chart our input data so the input data is going to be equal to get Scaled values of itself and now it should all of the data that came right here will be treated as values that are between zero and one so let's see how this works now if we refresh this oh and remember that we have updated our range to be between 0 and 1 because now all of our values are going to be between 0 and 1 right now if we refresh this there we have it now all of your values are going to be between 0 and 1. even if it's 2500 if I get it to the maximum it's just going to be 1 and if I get it to the minimum it's just going to be zero all right so there you go um now that we have scaled our values and our rated chart is ready we are ready to pass on to the prediction part of the application so there we go good job so good job to now there we go all right so now it is time to create this prediction part in our application okay I I just wanted to mention that congratulations for making it up to here to here this is a quite a long project so um and you have done a lot a lot of work so far so great job congratulations and let's just finish this application so that we can deploy it and show it in your portfolio all right so um what we're going to do now is we're going to build these predictions right here and we're going to do that replacing this function right here with a function called add predictions like that there you go and then we're just going to have to create the function up here add predictions and this function is going to take the input data right because we're going to make the predictions using the input data from the user and that input data comes from here there you go so now the first thing that you're going to want to do is to is to import the model and the scalar that we exported before from when we were creating the model okay do you remember that we are not training the model inside of the application but we're just importing it right so let's do that in order to do that we're going to first import the model from pickle remember that I had already imported piccolob here so we're going to do pickle dot load oops pickle.load and we're going to do open and the location of our model which is inside the model and model.pickle model oops model and model Dot pickle there you go and then we're just going to say that we're going to open it in read mode and it's a binary file yeah R is for read mode and R and B is for binary mode there you go and let's do the same thing for the scalar okay the scalar is also inside model but it's called scalar.pickle there we go um all right so now what we're going to want to do is we're going to convert this input data dictionary because remember that this is this is a dictionary with key value pairs in the key is the name of the of the parameter right so radius mean radius standard error texture mean texture standard error and the value is the actual value that the user input here right so what we're going to want to do is we're going to convert that into a single array with um a single array with the values right and in order to do that what we're going to do is we're going to use numpy all right so let's just import numpy import numpy SNP there you go and right here we're going to say that the in oops input array and we're going to convert all the values from our input data dictionary into a numpy array okay so we're going to say NP array we're going to select it as a list the input data and we're going to select only the values right now if we save this let's see let's do an st right and just pass in this input array all right so right now we should have we should be showing the input array of only the values of this one right here in our prediction side okay so let's see if that worked let's refresh and there you hope there you go you have this um 30 29 values no 30 values um and it's only it's just an array with um with all of this with the values that we input right so if we change this one for example to 138 this one is going to change there you go you can see that it's reactive right and that is that is exactly what we want because we want to make the predictions uh when chain when updating the inputs right so what we're going to do though is to reshape it because our model actually takes a two dimensional um array not a single Dimension array so we're going to do reshape one minus one like this then if we refresh it there you go that's how it that's how it that's how it's supposed to look right it's supposed to have like every single variable is supposed to be one single column um uh yeah so there you go now what we're going to want to do is scale it because as you can see right now the values are exactly what we set them here to so for example this one is 14 13. and this one is 14. uh I mean 14 27 12 7 right um and we want all of them to be scaled with the same scalar that we use to create our model because otherwise the model is not going to work so let's scale them with the model that we just imported that is why it was so important to you create and to export the scalar with the model when when we run on this spot so let's scale it in order to scale it I'm I'm going to say but array scaled and I'm going to use my scalar that I just imported like this scalar dot transform and I am going to say that I'm going to transform this input array right here and now if I write this one instead of the other one you can see that everything has a value of zero and why is that good question the thing is that remember that we set the default value of each one of our sliders to the mean value of the entire column we did that up here if I'm not mistaken um sidebar there you go so we set the value of each one I mean the default value of each one of our of our sliders to the mean value of the column so in the scalar since this what the scalar does is to take all of the values of the column and if it's very high make it closer to to to the mean and if it's very low bring it closer to the mean and then put everything in the same like in the same scale right if that makes any sense um so what's happening basically is that since everything is in the mean everything is at zero but when we move something a little bit let me just move the first one so that it's easier to see I move it below the mean then it's going to become negative and if I move it above the mean then it's going to become positive same with the second one Etc right so if you only see zeros at the beginning don't worry that's completely normal and that's how it's supposed to work all right so there we go now that we have this scaled values we can actually fit them to our to our prediction model to our model to make prediction sorry so let's see now we can say that the prediction is going to be we're going to use our model and we're going to say predict just as we did when we were testing the model we're just going to say predict and we're going to pass in the input hmm oops input array scaled there you go and now we can just export the prediction like that there you go now we can if we refresh it you can see that the prediction is zero which means that it is benign but if we move something a little bit too high then it's going to be 1 which is malicious all right so that's up to here we are already using machine learning to make a prediction in the model using our model and to show it in the front now let's just make it a little bit um like user friendly so instead of writing just a prediction we're going to say that if the prediction so the prediction is an array so if the prediction if the first and only element of the prediction is zero we're going to St right and I have it right here we're going to pop them right we're going to say benign benign and else we're going to say malicious there you go and now we don't need this part right here now if I refresh this there you go benign and then if I oh then it is malicious there you go it's looking pretty good and now let's just add another part right here which is going to be the probability of it being benign or not right so we're going to do as well St right and we're going to say the probability probability of being benign is and we're going to say that the model and we're going to say predict probe probability and we're going to say the input data input array scaled um zero and zero because this one returns all right so this one right one second so this right here predict probability returns an array with two with two elements the first one is the probability of it being zero and the second one is the probability of it being one if I'm not mistaken and then we're going to do exactly the same for the second one but instead of choosing the first element which is the probability of it being benign or it being zero we're going to take the probability of it being 1 which is malicious there you go then we will save it we should be able to see what's going on here there you go so we have benign probability of it being benign 0.50 I mean 50 58 and probability of it being malicious 41 it's looking pretty good um and now what we're going to do I'm just going to add another line right here at the bottom just to mention like um clarification that this app is only use only intended to assist Professionals in making a diagnosis but should not be a substitute for a professional diagnosis so there you go now if we save this we have we can refresh it and there you go now you have your application with this really nice um really nice um column right here which tells you if the if the if these cells are benign or malicious so there you go I'm just going to add a little sub header and header right here just to make it a little bit more um user friendly so I'm going to say SD subheader and I'm going to say cell cluster prediction and then I'm going to St right the cell cluster oops cluster s and then should there you go cell cluster prediction the cell cluster is B9 probability of being benign probability of it being malicious and then just our little text right here there you go um now there you have it now I mean your app could be finished right now I'm just going to add a little bit of styles right here but um for what we have been doing so far this should be um like already you have a very good app that is working I'm just going in the next part of the video I'm going to show you how to update a little bit these styles with some CSS and yeah and then I suppose we can deploy it so there we go awesome so now just for the record our application looks like this it looks pretty complete and the code looks something like this okay so we have our main function where we set up the page configuration using the streamlit configuration then we add the sidebar that Returns the input data in a dictionary then inside a container we added the title and some description of the application then we just added our two columns one of which is um four times as big as the second one and then for the First Column we added a radar chart with this function right here and we are displaying it using the streamlit function plotly chart and not just showing it right and then for the second column we're adding the predictions using the machine learning model and the scalar that we had previously created and that we exported using pickle right now what we are going to do is kind of an optional part of the video is to style it a little bit more with CSS right I know that streamlit is not thought of in order to I mean it's not made to use CSS on it but you can use okay it's unlike Dash it's kind of a little bit more complicated to do it but you can so I'm just going to show you how to do it but in general if you're using extremely to try to try to stay close to the default styles from from the framework all right so what we're going to do is we're going to create a new file in well first we're going to create a new folder called assets and inside assets we're going to create style that a file called style.css for my fellow well web developers this is probably where things are starting to get familiar so in order to actually just make some modifications and that's why why I meant that this is probably not the weight like streamlit is not thought oops it's not made to do this but you can see that we have I can just check right here inspect this element and try to find where my box is right here so it seems to be this one and I can just copy the class um chips there you go I copy the class then I then I use it to modify it right and basically what I'm going to do with this one is I'm just going to set a padding of one REM as I mentioned this is completely optional you don't necessarily need to know CSS but I mean it helps I'm just going to set a simple border radius oops for the radius of um half an RM and finally I am going to set a background color to to this color that I have right here which blends very well with the background so let's see how that looks like so far um well of course for now we're not going to see anything because we haven't imported it into our file okay and in order to import it into the application there's it's some sort of a hack because it's not I mean as I mentioned streamlit is not made for this but we are going to just hack around it a little bit to make it display our our [Music] to make it show our CSS okay and to do that we're going to add the CSS as though it was a markdown file okay so right here under the page configuration I'm going to say with open and I'm going to open my file which is which is inside assets style dot CSS as f for file and I'm going to say that I'm going to add some markdown okay as I mentioned this is a hack it basically just Imports the file into the website and and streamlit things that this is a markdown file but it actually contains CSS and it's going to modify the style of the of the web application but it's kind of not what it's intended to um with like this Magnum function right and inside of here we're going to add our style tags like this and inside the style text we're going to add our file and I'm going to say format we're going to say the F dot read to get the contents of our file and then we're just going to say that unsafe allow HTML to be able to parse it as HTML okay uh so there you go this should I think make us um format yeah I mean this should import our Styles file as a markdown file but not really into our into our file and it should update the style of this box right here which has this class so let's see if that worked there you go so it worked oh we just added a little bit of padding and just changed a little bit some of these things so to me that looks pretty alright um and the second thing that I'm going to do just to make it a little bit more um complete I am going to I'm going to add a few I'm going to make this one right here turn to red when it's benign and um sorry blue sorry green when it's benign and red when it's malicious all right so let's do that in order to do that we're going to have to modify the code that we added in the in the ad predictions right here so as you remember we added B9 and malicious depending on the prediction but here we're going to wrap it in a span element which is a HTML element and we're going to give it a class of um a class of diagnosis benign and then we have we're of course going to have to close the span there you go and if we save this like this actually and we refresh you can see that this span is actually not being parsed as part of the HTML in order to make the HTML elements that we put in into these strings to be passed we need to add this other [Music] um parameter right here which says on on safe allow HTML and set this one to true this one is going to allow us to parse the HTML inside of it and now if you see benign is actually um benign is actually inside a span with classes diagnosis and benign so now we can Target those classes in the CSS style sheet right and we're going to do pretty much the same thing for for our malicious one so let's copy this and let's paste it right here diagnosis malicious now let's just close this pen there you go and now we can Target that right here so diagnosis is going to have a second it's going to have a color oops color of white it's going to have a padding of 0.2 grams and 0.5 you know what we're going to use EMS here 0.5 Rems because we're dealing with uh with a yeah with this kind of button I don't remember how to call these things and then we're going to say that the Border radius is going to be 0.5 EMS there you go and now we're going to Target the background depending on whether it has a class of of malicious or benign okay so let's say the diagnosis dot benign is going to have a background color of this screen that I have right here I just looked up some nice looking green beforehand and then the same thing but for malicious okay and for malicious I'm going to use this red color right here um one second this red color right here I also checked it out before there we go so malicious like that benign like that and my classes they're supposed to be malicious and benign there you go so now if I refresh this benign there it is we should have um you know what let's yeah benign should have um green background and malicious um oh I forgot to add unsafe allow HTML here unsafe unsafe allowed HTML to true there you go now if I refresh benign has a green background and malicious hum what's going on here hmm apparently they're showing both um [Music] what's going on here why is why are both being shown it's only supposed to show one of them what's going on here let's see refresh benign and huh oh yeah sorry I guess I'm I'm blogging malicious here and benign by the side so malicious right here and then there you go like that now it's going to work now if we refresh there you help there you go now you have benign in green and if you turn into malicious oh foreign sorry about that um so now you have benign in green and malicious in red and you have the probabilities that are also being updated um reactively all right um so there you go now the application is pretty much complete I would say um and of course you can play around and add some other CSS code but I wouldn't recommend it I mean I just added some of it right here to make it look a little bit um more user friendly and just like I figure that the color is red and green looked very good there might be some options to do this extremely by default but since I just it was pretty easy to just do it with CSS so there you go I mean I hope this um now you have like your final application congratulations Bravo Now I hope this was cool for you now what we're going to do is we're going to deploy it so that you can share the link to our future employer or with your friends and to show them what you built and to get a job that pays you hundreds of thousands of dollars right so there you go let's do that all right awesome so the application is looking very good uh now we have this app that's looking like it works it works it looks perfectly and all now you're going to want to up and deploy it and in order to share a link and then your employer can visit it and your friends can visit it and you can just show off and feel very good about it okay um the idea is that we're going to be using a resource from like a service from streamlit called Community Cloud okay there are different ways to deploy to to this to deploy streamlined application as you can see it's just a regular application and you can deploy it in a like if you go to the documentation you can see that they offer um tutorials on how to deploy it on with Docker kubernetes and to to any to any hosting that you want but here we're going to be using streamlined Community Cloud it's the fastest and easiest way to do it and it's free so why not so what we're going to do is we're going to go to streamly.io slash cloud sorry like that and then we're going to sign sign up if you don't have an account of course and once you have signed up you're going to be able to sign in and to see a dashboard that looks like this one okay um this was just some tests that I had that I had started a moment ago just delete this up um oops not like that it's going to delete this there you go all right so your app your dashboard is going to look something like that okay what you're going to do right now is uh first of all you're going to have to connect your GitHub account okay and once you have connected your GitHub account you're going to want to create a new repository in this case I created a repository called streamlit cancer predict and once you have created that repository that is what you're going to be using to deploy to to streamlit Cloud okay so once you have done that we're going to come right here to our to our application and we're going to say get init if you haven't if you haven't been tracking your code which is a very bad practice by the way sorry about that sorry about that um and then just add everything right it's going to add everything and get commit oops git command and we're going to say first commit and first commit and finish app terrible way to make a commit but there you go um so now we have our app that is already tracked and get it has been it's now it's like the repository is complete now we have to upload it here what we're going to do is we're going to copy this one right here I'm going to add it to my git remote at origin if I'm not mistaken to add an origin for this one I'm just going to paste the URL and now you find that mistaken I should have it right here there you go now what I want to do is I'm going to push it to my remote repository in GitHub right what we're doing here is basically just push everything right here to GitHub so we're going to do git push U origin Main and now if we refresh this our GitHub should have the all our files good so there we go now what we're gonna have to do before actually deploying to streamlit is we're going to have to tell our application what are the modules and the packages that we're using right because remember that during our while developing our application we used several several several packages so we used pickle we used pandas which plus plotly we use numpy and what streamlit cloud does is it creates a virtualized server and once it's virtualized it doesn't necessarily have all these packages installed so we're going to have to tell it which packages you're going to need if you come from from JavaScript this is exactly the same as creating an npm package.json right so in order to create our package.json or our list of dependencies we're going to do we're going to need a new dependency from python called pip Rec okay so in order to do that we're going to have to install it first we're going to do pip install pip wreck if I'm not mistaken there you go and then in the origin of our file we're just going to do pip wreck and then usually you would you would write where you want your file to be but here I'm just going to say pip rack and it didn't work um pip wreck is probably [Music] wreck let's see does that work what's going on um one second [Music] um let's see what you're going to want to do oh sorry it's not peep wreck it's people Rex yeah sorry about that it's paper x with an S so there you go now I have to install this one and then I do pip Rex with an s there you go and now you have your requirements.txt right here there you go now as you can see this is a file that basically includes all of your dependencies I mean the packages that you installed so that streamlit cloud can install them um in in their own server and so that your application is able to run okay so now that we have this we're going to have to get at our requirements requirements.txt [Music] all right so I already added it so that's right and then we're going to have to commit it add requirements and that git push to our origin Main and now we should have our requirements right here there you go so that should be enough to tell our streamlit Cloud application service that we want to deploy using these requirements so now we go to our dashboard that's here we click on new app Remember to link your GitHub account and then you're going to say which is the repository that you're going to want to deploy it from which is the one that we just created streamlit cancer predict the branch is the main branch that we're using and the file the path to the file okay here it already detected that it's inside app and Main which is app and Main which is this file that we're going to want to to execute to load our application and now we can click on let's see do we have advanced settings I mean you can set up Secrets if you need to but I didn't add any so we can just deploy and it sometimes takes a little while because it needs to it needs to install all the dependencies and just to get your app up and running but it usually works very well and now as you can see we have deployed our application super quick um hopefully there will be no errors so if you got all the way to here thank you very much and congratulations you have um completed a a very very long course and you know now how to create streamlined applications that make um predictions with a machine learning model and you learned how to export that model that you created in Python and how to export it with pickle how to import it your application and how to use that to take some input from your user and to make predictions based on that input and we also learned how to make a really like a pretty sophisticated chart from the input that the user gives and to update the chart reactively so I would say that you have done an amazing job so congratulations and now here you go now your application is up and running and it's in the and it's in the web so you can just copy this URL and share it with your friends with your with your employers and to show how amazing your skills are at at machine learning and at creating web applications using machine learning Technologies okay as a reminder that you can use pretty much any machine learning um I mean any model it doesn't have to be like a logistic regression which is super simple you can be loading um like a neural network behind it and it will totally work so there you go I hope you found it useful I hope that you learned a lot and be sure to subscribe for more videos like this and be sure to leave a like and don't forget to write a comment as well if you liked it and to tell me if you had any questions also if you have if you find a comment that you know the answer to of someone I mean if someone if you see someone asking a question and you know the answer to that question don't hesitate to to answer it's a good way to to to learn when you explain uh what is going on uh so thank you very much again for watching and I will see you in the next one [Music] [Music] thank you [Music]
kjUSOa_KOts,2023-04-13T05:07:00.000000,"Full-Stack Project | ChatGPT API, React, Node.js, Express",good morning everyone how is it going today so good to see you in this week's new video tutorial in which we're going to be building an amazing um full stack AP application okay that uses the openai API we're going to be doing it step by step it's going to be very easy so stick to the answer that you can have this beautiful application in your portfolio and you can show it to Future employers okay I promise it's easier than how it looks um we're going to be building the full stack thing from scratch and the front end is built in react.js and the back end is built in node.js with Express okay and what the application does is it basically takes an input in English in natural language English and it converts it into a SQL or SQL query depending on what you described and basically this generation is done using artificial intelligence that comes from the openai API um we're going to be using I mean I'm going to be showing you how to use two of the open AI apis the previous one which we would normally use which is text completion and the new one which is the cha GPT API and I'm going to show you I'm pretty much explain why you should use the trgpt API instead whenever it's whenever it's possible for you um so yeah let me just show you real quick how this application works um so basically you're going to write something in English right here select all elements from the table uses let's make it a little bit more complicated so that you can see its power um let's see select the first 50. the first 50 elements from the table users whose um that have the column let's say where double users where the value of the column um last name is Smith and they're um there you go let's go like that if we click on generate query this is going to use artificial intelligence to generate our SQL query select everything from users where last name equals Smith limit 50. um so yeah I mean pretty useful pretty beautiful and it's actually very easy to do so stick to the end and and yeah I hope you enjoyed this video um there you go [Music] thank you all right so the thing to do now is we're going to want to set up our project okay as you can see right here I have created a new folder called open AI SQL and inside of it we're going to have to put two folders we're going to put the server and the client the client is going to be the react application and the server is going to be the node.js application um usually you would want them in separate in separate in separate folders I mean in separate repositories but since this is a very small project we're gonna put them both in the same place okay so right now what we're going to want to do is we're going to do um first let me check what version of node I'm using um there you go so it's version 18 I'm going to go with node I'm going to go with node version 18. um there you go and now I'm using node version 18. and inside of here what I'm going to do is do npm create vid at latest in case you don't know what this is this is basically the same thing as create react app but it's way faster and way more minimalist so um I mean I would recommend that you use this one instead of create react app every single time so for the project name we're going to call it client because remember that we want our folder right here to be called client I'm going to say that I'm going to be using react vanilla JavaScript and there you go now we have our client folder right here and as you can see we have all of the all of the project files inside now let's go inside of it and let's see the first thing that you're going to want to do is npm install the dependencies for this react folder I mean yes react application it's probably going to take a little bit of time depending on your on your internet and there you go so now that you have all of that you have npm installed we can do npm run Dev and there you have it now your Veet application is running and as you can see it's reactive there you go and good all right um now a good thing that you might want to do is basically start a git repository um you would want to do that from here up here from the parent like from the main repository and not inside the client or the server because I mean ideally your GitHub your git repository for this project we are going to try to Encompass both of both of the applications both front end and backend so I'm just going to do get init and there you go we just initialize the git Repository add everything and then just do our first comment there you go now we have it all and there you go now it's time to create our main component there we go so now it is time to start building the main component of our application okay as I mentioned before we're going to be doing this on react okay now let me just give you a very quick tour of what is going on here I'm going just going to move myself all the way there and all right so just to show you real quick this what we have right here is basically what we have in this template right here in app.jsx just as any other application Builder like create react app vit also has its own template and this is this is the one um what we're going to do is we're just going to remove the template so that we can build our application instead okay so instead of all of this in app.jsx we're going to erase it and just to show you let's add an H1 saying hello world if we save we have our text hello world on this side but also um we're having the CSS styles that are being applied to it so I'm just going to get rid of those there you go if I save again I still have some CSS Styles and they might be coming from main.jsx there you go so let's just remove them from here and we will also not need either this or this one so I'm just going to delete them and there you go there you go now our application looks extremely clean as it's supposed to be now something that we're going to want to do is we're going to open AI Quick Start and actually this application that we're building right now is some sort of a some sort of a um is some sort of a spin-off of this other tutorial that openai published themselves but they themselves they use next.js I'm just going to be using simple Express for a rest API um so I mean it's a little bit different but I am using the in their same CSS style sheet just to make it a little bit faster in the development so you can download that from here I'll paste the link in the description so that you can download this I'm just going to click on row and copy it all and right here in my source file I'm going to say index dot module.css right here I'm just going to paste the CSS from their tutorial this is only the CSS okay just so that we can start building our component faster there we go so um the first thing that we're going to want to do right now is let's just get rid of this right here and we're going to import our styles from from the file that we just imported which is in the same directory and it's called index dot module .css like that there you go and now we're going we can start actually building our things so we're going to wrap it all inside a main element and we're going to give it a class name of Styles dot Main in case you don't know what is going on right here the styles.main actually comes from our Styles which has been imported from index module CSS which is right here which basically gives gives it a class of main okay all right so now we're with our main component and the first thing we're going to want to do is to add a little image of if you remember the demo that I showed you before there was an image of um a SQL Server so I'm going to search for it in flat icon which is a very very convenient place to find Icons free icons and I already downloaded it it's right here so what I'm going to do is I'm just going to copy it from here to my assets folder and I'm just going to rename it to SQL logo dot PNG there you go now inside my app I can basically import it import SQL logo from and then where uh where are we inside assets and then the name of the file which is SQL logo dot PNG so now we can actually use it inside an image stack and in the source we're basically just going to say that it is the SQL SQL logo oh what's going on Logo like that there you go and we're going to add um a class name as well and the class name for this one is going to be styles again from our module CSS dot icon there you go so now there is our our very nice icon um second of all we're going to want a little title right here saying that this is our SQL generator app uh we're gonna wrap it in H3 and we're going to say generate SQL with AI there you go it's looking good and now we're going to have to add the main part of our application which is the actual input in which the user is going to input the description of their SQL query so that we can generate it with our open AI API and this is going to be inside a form element like that I'm not going to add any action right here and the form element is going to have an input element that's going to be a text element like that there you go and it's going to have a name it's going to be the name is going to be oops um query description like that it's going to have a place placeholder as well and the placeholder is going to be pretty much just describe your query there you go starting to look pretty good um there you go and let's let's just add another button right here which is going to be another input element of type submit there you go and the value which is going to be the name I mean the text that is going to be on the button like if we leave it like that we're going to have an empty um I mean it won't it won't read anything right here so in the value we're just going to say describe your oh sorry no the value is going to be generate your generate query like that there you go so now we have a button and it's a submit Button as you can see it's submitting this to our um to our current file but that's not what we want to do we're going to handle that a little bit later but for now I mean the component seems to be looking alright and we have our input element right here which actually takes some our input but if you remember correctly actually for react applications you're going to want to make your input elements I mean your input elements um you want to track their state and their value in the state okay so basically the way to do this is to import we're going to import use state use state from react and then we're just going to create the state for this the value of this input now the value of this input is going to be the user prompt I mean what the user is going to prompt our Ai and we're going to call it like that we can call it um actually we can call it query description query description because this is the query description that the user is going to set and then we're just going to say set querying description right here and we're going to set the state to nothing at the beginning like that there you go and then just to track the state right here we're going to say that on change we're going to want to sorry we're going to want to update the state okay so on change we're going to execute this Anonymous function that basically sets the state oops set state so set not set State set query description [Music] there you go and we're going to set it to the current here it takes the event so it's going to take the current event without Target if I'm not mistaken dot value and there you go um I suppose this should be alright right now let's refresh and yep seems to be good all right so that's been how to handle this thing right here how to handle our input all right next in just a moment we will see how we'll just create our submit function okay there we go so now we have our very beautiful um component right here super simple I mean of course I'm zooming in because this is supposed to be a little bit smaller but just to make it easier for you to see in the screen um what we're going to want to do right now is to actually do something on submit okay we still haven't built our backend as you can see we're still working we're still working in our client folder our server folder is still empty but what we want to do right now is we're just going to create a submit function and we're going to just get it ready so that when we have our backend API ready we can just plug it in and get it working okay so for that we're going to add an attribute right here that is going to say on submit and it basically tells react what to do when the form is submitted okay because for now when we click on submit it actually submits and reloads the page and that's not what we want to do in a single page application so in here we're going to say that we're going to unsubmit we're going to trigger another function which is going to be answer we're going to call it on submit as well now let's just create it up here click on submit is going to be equal to now let's just say we're passing an event as well and first of all we're going to do first of all we're going to do e dot prevent default there you go and second of all we're just going to console log and we're going to say form submitted form submitted Double T no just want to there you go and right here we're just going to say what was submitted and once we have our back and ready we're going to submit the query description okay so since we have our query description that we set on change right here we're going to say that this is the one that we're going to be submitting so let's just concatenated right here now let's see how it works now if we basically let me just go to the origin of this there you go let's say that we want to select all elements from a table called users and we click on generate query so far as you can see in our console the I mean we are preventing the actual submit event and we are console logging form submitted query description so there you go now our react our react component seems to be ready and now we can actually go on to start structuring our backend which is where we are going to be dealing with the openai API all right so one last thing before we before we go to the back end we're probably going to want to add everything to our git to our git repository I just in case you don't know what this is It's called um set this age um I don't remember the name but it's a it's a beautiful extension for for setsh terminal I can leave a link in the description and it's super useful it adds a lot of aliases like this this basically just means get at all it's just an alias for that so now that I added everything I'm just going to commit I'm going to say um fit your client react component create react component there you go now we have our git that's being dragged and now we can start focusing on our API that is going to deal with the open air API there we go great there we go so now it's time to actually first before creating our server we're going to want to we're going to want to get our node.js our openai API sorry to do that we're going to want to go to the dashboard from openai you can go to platform.openai.com and then if you don't still if you don't have an account yet you're going to want to create an account once you create a developer account you're gonna get a certain amount of free credits for your API I mean to test the apis and that's more I think you get 18 or something like that so that's definitely more than enough to run all the tests you want and once you you I mean but that expires I think in within a month or something like that so once that happens you're gonna have to to enter your credit card to actually use the API okay um so once you have signed up you're gonna come right here to your user account you're going to see your apis and you're gonna create and create new secret key and you're going to copy it um I can leave you pause the video and copy this one and take advantage of my credit card um I'm just kidding that's going to be I'm going to delete that API key in a few seconds but the idea right here is that you're going to have your API and you're going to paste it somewhere right here um you're going to create a DOT EnV file and right here you're just going to say open AI API equals and then your key all right and then you save it now what did we do here basically this dot EnV file is what we're going to be adding to is the file that includes all of our secret information about our application in case you don't if you in case you haven't worked with these kind of files before and then we're going to basically just duplicate it and call it dot env.example the difference is that this one right here is not going to be tracked by GitHub so this information is going not going to be in your GitHub account but this one right here is so from here you can delete all the sensitive information and then the user that downloads your GitHub repository will be able to just um to just fill in the the variables that you need and these are the variables that we're going to be importing from from our server to make the actual API calls okay there you go all right so now that we are inside of here of the server we're going to we're going to start an nnpm project so to do that we're going to go inside the server and we're going to do npm init and of course the name of the package server just leave it as is there you go yes so there you go now you have your package.json and now to continue the setup what we're going to do is we're going to npm install openai and Dot N dot end is basically the library that is going to allow us to use this secret information inside of our development environment um so there you go now install that oops I think the 10 was actually supposed to be um that's right um all right so now that we have our API key inside of here you have our Dante dot end our DOT Dev example um you're going to want to create a git ignore file for this one because whenever you add your information your your files to your Git You don't want your Dot N file to be tracked so what we're going to do um let's just look for a git ignore for node there you go and basically what I usually do is just copy a standard git ignore from here and this is basically tail get to ignore node modules and also.env so there you go now.tnv is not tracked and tnv.example is so now we can add everything and we can git commit and say um setup setup API setup set the back so let's set the back end there you go now that's been the setup of our server now let's actually start building the server um Network I mean let's actually start building our node.js server okay there you go all right so now let's first of all actually now that we have things right here what we're going to want to do is we're going to want to create a new file called api.js in the root of our server project okay this is where we're going to make the API call to the open API open AI API sorry and we will also need to import the open AI SDK which is basically what we just installed using npm um let me show you how to do that so let's just create a new API dot Js right here and we're going to import configuration and we're also going to import openai API like that these are the packages that we need to actually make the API calls all right and we're also going to import the 10th hmm from the 10th which is basically the library that is going to allow us to use this information right here in dot end and basically let's just say dot NF dot config there you go now now this should be available to us and in order to do that we can just do const open open um open AI API key and we call I mean to access the information that is inside of this folder.env we can just do process dot EnV and then the name of our variable remember that our variable's name is openai API like this and now that value is actually stored in our in our constant right here and we didn't actually write it in our code so that way we are protecting the privacy of our API key and no one else knows it but they can see our code and now basically just test our API key so that it exists um in order to do that this is basically so that if for some reason the API key is not set in the server variables I mean this information would you would usually set it in the server configuration so if there is no API key what we're going to do is we're going to say that we're going to lock an error and we're going to say open AI key it's oops it's not set actually open AI API let's give it a better name let's say it's going to be key like that and here it's going to be key like that that's why it gives better information of what actually is the name of the what actually value the variable is holding so open AI API key is not set and then we're going to process oops oops process dot exit there you go that basically just closes the the back end if the opening EI key is not set and now we're going to have to set up the configuration for our openai client okay so let's do that now we're going to create a new variable con called configuration configuration like this and we're going to initialize a new a new a new instance of configuration that we imported right here from open Ai and inside of here we're basically going to pass in some arguments and then the main argument that we want to pass in is the API key and here we're going to pass in the API key that we just um that we just imported there you go now this seems to be going all right actually no because this is supposed to be a JavaScript object like that now it works okay because this is like a key value pair um object not just a single parameter there you go and now we can create our open AI object and let's say new open AI API now we can just pass in the configuration right here now this is going to be our openai object that we're going to use to actually make the calls later on okay now that you have created this we can basically just export it oops open AI there you go let me just explain you real quick what is going on right here basically we just did the configuration of our of our I mean the new the configuration that we're going to pass into our open AI client we created an instance of our openai client and we're exporting it this object right here we're going to import it in in our service in our API in order to actually make the call from there and you will see how this this makes everything a lot easier that way this is where we configure the API and then the requests we will do them in another file let me show you that in a moment but so far we can say that we have successfully configured the openai client in our server okay I'll show you how it works in a moment there we go so we have now our openai API configured already and we are now able to use it in whichever function we want and that is actually what we're going to do just in a moment but for now what we're going to want to do first is we're going to want to create our own API which is the one that will communicate with our front end okay let me show you here we have our front end that we previously built and using reactive course and the idea is that when you when you like submit anything right here it's not going to submit it to the openai API it's going to submit it to your own API and then you will call the open AI API inside of your server Okay so in order to do that we're going to have to create an index file that will receive your requests from your front end okay so let's do that now um we're gonna have to create right here and index.js file and I am pretty sure that I got it in the wrong part right here because it should be inside in inside of server okay remember that both server and client are each their own application even though we are tracking them in the same git for this small project but usually you would have them separate um so right here inside of index.js what you're going to want to do is create your application using Express I mean your backend application and in order to do that we're going to have to first install Express all right let me just move myself over here and just so don't forget remember that we are we are inside of the server directory and this is where we're going to be running um our npm install commands Okay let me just clear this so that we can do it together um because if I run this in client for example I would be installing my server dependencies in the client and then my server would not work so remember to CD into your server I mean I am already in so I'm not going to do it but um yeah there you go um so here what we're going to do is npm install or just npme for shorter it's the same thing and then we go to in uh we're going to install Express and course all right there you go I already have them installed because I Was preparing this tutorial but to you it might take a little bit longer and then we can actually start coding it right here we're going to do first of all we're going to do import Express not like that input Express from Express and then we're going to import course from course there you go um then we're going to have to actually create our application and to do that we're going to do const app equals Express like this there you go and and we are also going to we're going to also have to use our course package right here so in order to do that it's just like middleware you go app app.use course there you go and then here you could like if you were if you were like building the actual application for a production environment you would have to for example right here right yo your white list for the IP where you have your your front end but I don't think we need this for for our local environment so I'm just going to leave it like that and next we're going to have to create our variable where we're going to store our Port okay const [Music] port and this one is going to take either process.env.port [Music] this basically will call the environment variable in the server I mean just like this one but it's inside the server by default so if we were running this in a in a production server the port in which the server will be running the application will be stored in this variable right here by default so we will be calling that and if we're not in production then this value will return false and then we will run it in Port 3005. there you go and now that we have this configured we can actually start creating our endpoints and the endpoints are very simple to create in in Express basically you call your you say that your app is going to get this is going to create a get endpoint if I wanted to create a post and put I would just do post but I want to first of all just very simple get endpoint just to get this started and this right here is the route in which this endpoint will be triggered and then this one takes two parameters right here [Music] oops there you go request and response and then basically we're just going to say that as the response we're going to send hello world from our from our API there you go and then last but not least we're going to set it to listen in the port that we wanted to listen to okay so listen [Music] and we're going to say that we're going to listen in our report that we declared up here and this one right here will just take callback function in which we're going to basically just say that we're listening listening on Port we're just going to add right here the port in which we're listening there we go I suppose this should work right now let's see um if I am not mistaken I had already added this one right here but I'm not sure that you will have it um so basically in order to run your your application I mean your your backend you're gonna have to come right here to your server and you're going to have to do node index.js okay and this is going to tell you that you're listening on Port 305 because this is the Callback function that you wrote that you added right here and basically it means that if you go to localhost local localhost and if we go to three oh [Music] three double O five we're gonna have Hello World from our API because the browser makes by default a get request and since we default we set this one to a get request at the default route um where this is just what we're getting and there you go I mean the index file seems to be working correctly everything seems to be going red now what we're going to have to do is to call this and oh you know what first of all I'm just going to add something real quick right here just to make it a little bit more standardized it's basically what I just deleted just a moment ago if you do if you add the script start and you write right here node index.js basically every time you run npm start you're going to this is going to run node index.js automatically and this is just another way to make it more standardized and so that pretty much everyone understands that when you do node start sorry when you do npm start that basically means that your application is starting so there you go um this did exactly the same thing as before so now let's actually create our function that will generate our SQL and then we will we will plug it in to our index.js okay so let's do that there you go so now let's create our generate.js file in which we will create this and we will create this function that will generate the SQL depending on the query description that we send it okay so in order to do that what we're going to want to do um you know what first of all I'm just going to commit this [Music] there we go and now basically what we're going to want to do is we're going to create a file right here called generate .js and again I put it accidentally outside of server just moving it inside of here there you go and then inside of here we're going to generate our SQL and in order to do that we're going to be using the API server that we configured right here okay so remember that we are exporting exporting this element right here called open AI and we're going to import it right here so that's the first thing we're going to do I'm going to call it open AI client like that from [Music] api.js like that and then right here I'm going to do I'm going to create my function that is going to be called generate generate and it's going to take my query description and it's going to it's going to make a request to my to the open AI API in order to generate this open this SQL code from my query description okay so let's do that right now um I'm going to create my response and I'm going to call my open AI client there you go now something important right here is that since we're going to be using this openai client that we have right here and remember this right here is going to be calling the remote API from open AI so we're going to have to make this an asynchronous code an asynchronous function and this one we're going to have to await for this function to do its work so here we're going to be calling this this method called create completion there you go and this method takes several parameters the first one we're going to do is we're going to mention the model that we want to be running on and that is very up um open AI the models right so this is pretty pretty interesting because you're going to have to choose the model that you're going to be using for generating your your SQL code and here are very different models that you can use um the regular one I mean the first one that I'm going to be showing you is the text completion one which is this one right here um you can try it on the playground on the open AI playground that is um an AI playground that is right here text completion how did this still have it open yeah there you go playground there you go so I mean basically here you have the model that you can choose Etc right now DaVinci zero zero three is the most expensive one and it's even more expensive than the chat GPT API but I figure that it's useful that you know how to use it because maybe you will you will find it sometime in the wild or something okay so basically this is the one that we're going to be using first it is this one right here text DaVinci zero zero three and basically here we just write DaVinci zero zero three and this one takes a prompt okay and the prompt is going to be in our case convert [Music] the following natural language description into a SQL query and right here we're going to add our query description okay it's going to add a couple of empty lines right here oops not like that there you go a couple of empty lines Lines line jumps line break sorry and then my query description right here and something important very important that you're gonna have to do this we are going to have to add a DOT right here okay that is super important because otherwise your your text completion model will not really understand it I'm not going to add it just now just to show you what are the errors that you may encounter if you don't add a DOT right there I'm in year period and then you're gonna set a maximum number of tokens that you want for this request and I'm just going to set it to 100 that should be absolutely more than enough for a complex SQL query and the temperature this is another setting that you're gonna get um this is another setting that you're gonna get um for your models and you can get it from Z it goes from zero to ten basically 0 means zero creativity and 10 means complete like very high creativity and this translates to when you set zero it should return exactly the same thing for every every time you send the exact same prompt okay so if I set it to zero technically this same prompt should return the same exactly the same um the same completion every single time if I set it to 10 that is more useful for more creative tasks something like generate brand names or generate um pet names or generate I don't know maybe some code refactoring would be somewhere in around five or something like that you're gonna have to run your tests probably in the playground to actually know which level you want which temperature you want for a sequel and for SQL query you're probably going to leave it at zero and then in the end you're basically just going to return whatever the response gave you and and how this model works is that it returns it inside of um an object called data and then it Returns the choices that you have and we're basically every single time going to choose the first the first choice of the array because choices is an array and then you're just going to select the text of that choice right and there you go and here we're basically just going to be exporting this this function as default there you go there you have it now our function generate is ready and now we are ready to import it in our index.js remember that we forgot that we are intentionally leaving out the period in the end of year I'll show you how how that makes our code makes our response um wrong in a moment but let's just save this for now and let's go for let's go for let's go to integrate this into an endpoint in our index.js all right what we're going to do right now is basically we're going to click on the Subscribe button and on the Bell icon so that you get notifications because if you're if you have made it this far in the video that means that you are enjoying it and that you are learning a lot so in order to be able to enjoy and learn from future videos that would be amazing and also leave a like in this video if you're liking it it really helps a lot to me it's free for you and I would really appreciate it um all right so back to this um we're going to create this new route and we're going to add it on a post um to handle post requests okay and we're going to add it in the generate path generate route okay this one as usual takes a request and a response parameter and then it takes a callback function just as our get endpoint right here and this one right here let me just um Explain real quick what is happening be here um what is going to happen with this one basically as you remember we have our front end and we're going to write a SQL description right here something like select all elements from the table users Etc and when we click on submit we're going to be receiving it we're going to be sending it to our API which is this one and we're going to be sending it to this endpoint right here which is going to return the generated SQL query okay but first of all we're just going to test it to make sure that our endpoint is working correctly and let's do that right now so for now what we're going to do is we're going to say that we want our we're going to extract the query description from the body of the request okay so we have the request we're going to access the body of the request and inside the body we're going to have send from our front end an object um called query description okay this is something that the user is going to set up I mean that we're going to set up in the front and a little bit later and just for now just to make sure that we are actually accessing the information correctly what we're going to do is we're going to console log it on the back end of course because here we're on the back end and we're going to say received description [Music] and we're going to add the query description right here okay and then we're also going to send some oops it's res dot Json not let's just send because we're going to return some Json and we're going to send a Json object right here and it's going to say a response is [Music] going to be you sent this and then just add his own I mean the own query description that we sent before there you go now this is not going to work just yet okay why the reason is that we're accessing the body of the request but we haven't actually enabled our server to handle body body objects okay so let me just show you how this looks right now the first thing I'm going to do to show you this is I'm going to open this thunder client which is an extension for vs code if you haven't used it before if you're familiar with Postman for example which is a great tool for testing apis it just lets you send HTTP requests to to whichever destination you want and to get the response it's very minimalist very easy to use and it's inside of vs code um so it's an alternative to postman basically and right here you basically just send the request that you're going to to send I'm going to send it to my local host and I have to specify the port and I'm listening on Port 3005. now I did make some changes which means that I have to restart my server I'm just going to move myself to the right right here and then right here I am sending a get request to the origin of my of my of my server so if I click on send um all right so localhost htti edit three T's there you go so if I send a regular get request to the origin of my Local Host I get Hello World from our API and that is exactly because I am sending a get request to the origin of my server and then I set it up to return hello world from our API now what we're going to do is we're going to send a post request to generate okay and so to do that we're going to add a route generate and we're going to change this to post and inside the body of the request we're going to send a Json a Json object okay and right here remember that we said that we were going to be accessing a property inside the body that is called query description so I'm just going to add it right here I'm going to say show all elements of the table users for example now if I if I click on send I'm going to have an error why the problem is that right here in my index.js I have I mean everything seems to be set up correctly but the problem is that I haven't specified Express that I'm going to be using a body object inside my request usually you would do this with body parser which is a package for node.js but now in the latest version it comes right off the box so you don't have to install body parser to use this so basically in order to enable it all you're going to have to do is go to app Dot use then you're going to say Express dot Json and there you go now you should be able to parse body parse Json inside the body of our request okay so I'm going to restart my server and let's go right here and let's send again this request remember here we have the console of our server so now if I click on send I get a response because remember this is the object I am sending back response you send this and I'm just sending back the query you send this show all elements of the table users and right here receive description and this is exactly what we are console logging right here so it all seems to be working correctly now it is time to actually generate a SQL SQL query based on this description okay so let's do that now um what we're going to do I'm just going to check take this out and we don't need this part anymore what we're going to do is we're going to try or also because we're since we're going to be using the generate function that we created up here and this one is an async function we're going to have to turn this func this endpoint I mean the callback function from this endpoint into an asynchronous function as well so we're going to be trying something here and then we're going to be catching um oops catching it catching any errors right here console um we're going to console error we're going to cancel error the error and then we're going to respond with a status of 500 this is just some error handling um you would probably want to do this I mean to set this more carefully in your own projects but since this is just for the demonstration purposes I'm just going to do this real quick basically everything is going to return a 500 code um so internal server error let's say let's say there you go and now let's add a now let's actually generate MySQL Query in order to do that I'm going to have to import this generate function that I created up here which is actually making the entire request to the open AI API and to do that let's just import generate from generate there you go I'm just going to put it up here there you go and inside of here I'm going to say that my SQL query is going to be I'm going to await for my function generate to generate the query from my query description there you go and basically after that I'm just going to respond with a Json and saying that my response is going to be my SQL query and that should be all now actually my if everything is working correctly my generate endpoint is supposed to be a returning I generated SQL query that actually comes from this function generate which calls the open AI API so let's test it again right here of course since I modified my files I may want to um what's going on having a problem here um [Music] there seems to be small error going on right here what is it you cannot find module generate um I suppose I have to add the drive oops not like that like this there you go now it should be working there you go now I'm listening on Port 3005. now let's test it again right I'm once again I'm sending this to generate and I'm adding this Square description show all elements of the table users if I click on send I'm getting back select all from table users now your API is working correctly one thing though that I want you to to keep in mind is that um it's important to add the point I mean the period at the end right here because let's suppose that you're sending several requests and this model kind of tries to complete your text with its own I mean text completion artificial intelligence and sometimes it will if you don't add a period it might try to come to finish your own sentence right so for example let's say that I'm I want to do show all elements of the table users where the status column equals um I don't know from yeah where the H column is column value is greater than 18 for example and if I click on send then I'm going to get select all users from where H is more than 18. I mean I'm not sure if it's going to happen this time but sometimes when you have sent something like that and then you try to resend the Regular Show all them something something shorter it's kind of trying to complete it right so if you go sandal right here all right it didn't happen this time but sometimes he may I mean this is an AI model and it may want to complete your own prompt um because it's a text completion after all so if you send something like this without a period in it may reply with something like show all elements from the table users and then the response would be something like where the H is more than 18 and then um return the the actual SQL query which is not what you want so basically it's always a good idea to add a period right here and there you go now our endpoint is working correctly it Returns what we wanted to return and we can test it right here and it's working perfectly and now it is time to connect it to our front end and to display the new generated SQL query in the front end so let's do it now all right so now what we're going to want to do is we're going to want to make a request from our front end and we're going to be sending it to our endpoint right here and to do that we're going to go back to our object.jsx in the client folder of course and inside of here you know what I'm going to do I'm just going to close all the other all the other tabs and right here remember that we already have this function called unsubmit right and so far all everything that we were doing was logging console logging the query description that the user had sent but what we want to do right now is to actually send it to our endpoint in our API and in order to do that what we're going to do first is we're going to create a new function that is going to generate the query based on the current query description in our state okay so let's do that we're going to say that the function name is generate query like that and of course this one right here um sorry there you go and of course this one right here is going to be an asynchronous function because it's going to be calling our API and let's just add some add the request right here um let's say that the response is going to be equal to weight because we're going to fetch this from our API and I I don't really uh use axis a lot when I whenever I can I just use fetch but if you want you can use axios and right here we're going to say that we want to make a request to our Local Host and the port which was the port of our server um Port is 3005. 305 right here and we're going to be sending it to generate right and remember that this one right here is going to return um is going to return an object containing the the generated query so we're going to fetch to this the design point right here and then the second parameter that it takes is the actual options uh it takes the first one which is a math the method and the method of our request remember that we are dealing with a post request so there you go then we're going to add some headers and the headers are basically we're going we're here to just to tell it that we're going to be sending a Json object so in order to do that you use file complete this content type okay and it is application Json I hope there are no typers right here application Json content type seems to be alright and then we're going to actually send the body of the request which is exactly what we were doing in our Thunder client and the body is going to be a Json object and we could just send the query description like that but this would this would not send a Json object and we want to send a Json object because remember that the way that we structured our backend is so that it can um deal with Json objects so in order to convert our query into a Json object we're going to say Json stringify [Music] there you go so it converts my JavaScript object into a Json object and I'm going to stringify this object right here and remember that we need an object called query description inside my a property called query description inside my Json my Json object and just as we saw in my thunder request before this one right here remember we're sending query description and the value of it is going to be the current query description which is in the state of my component I'm just going to send query description like that there you go um and now what I'm going to do is I'm going to say that my date equals to a weight again it's my response dot Json to convert it into my to be able to modify it and then I'm going to return I'm going to return data Dot um I'm just going to return data for now let's do to actually see what is going on and then right here up here what I'm going to do is I'm going to say that the new um SQL query is going to be equal to generate query there you go and of course on submit has to be async as well because this one right here is a synchronous and then we're going to have to await for its um for its return value so now if we save it this thing right here is saved um you know what we're going to console log our SQL I mean returned from server and we returned SQL query right here now if we save we come back here we open the terminal and let's see what is going on right here just gonna zoom in there you go we're going to say select all users from the table users let's just make sure that my server is running it is not so I'm just going to do npm start there we go and now this if everything's working correctly it should send the request to my endpoint so let's see send and indeed it returned from the server response select all from users so basically what we're going to want to do right now is we're going to console log as you saw we want to tap into the object called response because that is the one that we're sending from our API and then instead of doing like this we're going to say um that instead of returning all the data we're going to return response [Music] and then this one right here notice that it includes two line breaks and we probably don't want it we just want a single line break I mean a single a single string so that we can actually put it whenever whatever we want so we're going to add a response Dot trim right here which basically gets rid of all of the of all of the the Extra Spaces and things in the in in the in the end or in the middle okay so this should basically just return our query and now if we return this like this and we console log this like this and we save this we should see something let's change a little bit let's see select the first 10 elements from the table users where the column H is greater than 18 let's see generate query and return from the server is now just a string that says select everything from users where age greater than 18 limit 10 which is the query that we needed and now it's actually just very very simple we just have to instead of console logging this adding it to the state in our component and basically just showing it on the bottom so let's do that right now we're going to do const we're going to say that the SQL query I suppose did we already use this one somewhere else didn't we SQL query yeah um oh yeah so [Music] um yeah I'm going to change this one to generate it query right here and right here I'm going to say that SQL query and set of course SQL query like that it's going to be equal to use State and I'm going to set it to an empty string as well for now okay and so now what we can do right here is instead of just console logging it like this we can actually set the not the query description but the set the SQL query to I mean of course remember that we're dealing with the state right here so we don't want to we don't want to just show it in the front end we want to actually make it part of our state um so that we can actually fetch it from that and so now we're going to set the SQL query to this generated query that we just got so there you go now our SQL query value should be um should be reactive so now we can actually just add it right here on the bottom and what we're going to do is basically I mean you could create a code block with with a custom react component or something like that I'm just going to add a pre element right here with the SQL query string right here so there you go now if everything works correctly if I make the make request this time and I click on generate query it should generate my query update the state with this new generated query and then since the state is being is reactive it's going to display it inside this free element on the bottom so let's see how it goes there you go so now you have a working um application that basically takes your code in plain English and displays it displays a SQL query based on the description that you gave it and it does so using the openai API works very good there you go so now for the fun part which is the actual update for this API we're going to be using I'm going to show you how to change a little bit one of the functions that we did in order to use the chat GPT API instead of the text completion API so let's do that right now so that you can save a lot of money when they'll make in your application there we go right so what we're going to be doing now is basically we're going to convert I mean update this generate function right here that currently uses the text DaVinci model which is the text the text completion API so that he uses the new chargpt API and why would you do that okay um if the text completion API seems to be relatively straightforward and easy to use the thing is that even open AI recommends that for every single I mean like most of the average uses of this API that you update to the chat GPT API why is that well the first thing is that it's way more way less expensive um the text completion API according to open AI is 10 times as expensive as the new charge GPT API and also the charge GPT API is a little bit more sophisticated in that it allows you to train it as though you were actually having a conversation just like with rgbt I'm going to show you right now how it works but first of all I'm gonna wrap what's going on here in and another function so that we don't lose this code that we already made okay so basically I'm going to say that I'm going to create a new function called DaVinci which is the name of the model that I'm that I was using here and it's of course an asynchronous function and it takes a query description and we're basically just going to put the same thing that we have right here inside of there we're going to say that we're going to return DaVinci and our query description like that and there you go now this should do exactly the same thing we just created a wrapper function so that we we will not be using this code right now but I'm going to leave it right here so that you can check it in the repository that I'm linking in the description um but now we're going to create a new function that actually calls the chatgpt API instead of this one just to make sure that this is still working I'm going to go back to my to my front end I'm going to restart my server of course my front end is working so let's restart this now let's just send something select all elements from a table called tasks [Music] select first [Music] 100 elements from a table called tasks and it seems to be working correctly all right so nothing has nothing is broken uh so what we're going to do right now is we're going to create this new function called now we're going to call it chat um chat GPT API and just as the previous one is going to be an asynchronous function it's also going to take the query description and we're going to do something similar to what we did up here but with the open AI sorry with the Chad GPT API and first of all what you want to do is you're going to want You're Gonna Want to create a conversation that is going to train the model before your new your new prompt okay and it's very simple it works like messages I'm just going to call it um messages and this is an array okay an array of objects like this that have a role and one of the rules is system [Music] and then it has the content of the message from the system right so let's say um so the system I mean this is the first prompt that you gave it you're going to describe to the model what it is supposed to be so let's say the model is supposed to be a translator from plain English to SQL so that's what I'm going to write right here um you are a translator from plain English to SQL there you go and now I'm going to add another message from a user so that it kind of understands what it should do whenever a user sends something okay so the user is going to send um something like we had just up here there you go and this allows us to give it examples a little bit uh easier I mean to actually tell it what it is supposed to to what it is supposed to do right so now I can say that the role the new role is of course the assistant and it is going to be and the content the the I mean the answer that I expect is the answer to this one right here so in order to train it I'm just going to give it an example instead of sending this I'm going to send I'm going to send um show all elements from the table users there you go and now I'm just training it right now remember so I'm just giving it the example so it's going to be select everything from users is that correct convert the following natural language description to an SQL query show all elements from the table users show all from users good and now what we want is the actual prompt that we're going to give it so now this is this was basically just to show the model what it is supposed to do and now we want to actually do it for us so now I'm going to actually send it [Music] um the prompt again we have the user we have the content and we have our prompt right here convert the following natural language description into a SQL query there you go and now I'm using a comma right here there you go so those are the messages that we're going to feed into our model so that it knows what it is supposed to do and the last one as you saw is the actual prompt that we want that we wanted to respond to and now all that we need to do is we need to do just as before we're going to create an object called an object called response and we're going to await from the same openai client that we created before and that we're importing from api.js and this one instead of calling this endpoint called create completion we're going to call the endpoint called create chat completion all right and inside of here just as before we're going to specify the model just at this time instead of it being the text to DaVinci text DaVinci model we're going to be using the GPT 3.5 turbo which is the model that runs on chargept currently um I mean once gpt4 is not unlimited beta beta better I can I will show you how to use this one but so far I'm still in the waiting list so I'm just going to be showing how to use this one but it should be pretty much the same thing um basically instead of adding this you're going to add GPT 3.5 Turbo or you can use any of this but I mean this is the the most recent one so let's use it and right here we're going to say that our model is that one and then [Music] we're going to say that our one second we're going to say that our messages are going to be these messages right here there you go and now we should be getting our response correctly so now what we're going to want to do is return from here the response which is this one right here that we're getting from the chatgpt API and just as before we're going to be getting data dot choices and then from the choices we're going to pick the first one and this time we're going to be choosing the message from that choice and we're going to be taking the content of it um there you go so I mean it's a little bit different from what you're getting up here so I mean the data is structured a little bit differently but in the end it's very similar so you have the data you have to access the choices and instead of just accessing the text you're going to have the message and the content of that message so let's save it and instead of using the DaVinci model we're going to be using the chargpt API model and that should be all I mean we should be actually returning the actual content um before we actually test it on the front-end application how about we test it in our API client right here I'm just going to restart my server there you go and we're going to do exactly the same thing as we did before we're going to say that the query description and instead of showing all elements of the table users I'm going to say show the first [Music] um 10 elements of the table users were the column H is great word the value of the column H is greater than 18. let's see how that looks now we're going to send it and there you go we're getting our response and our responses um being fed to us through the kgpt API in order to track your expenses because this is quite um I mean this is definitely less expensive than the text completion API but of course you don't want to live your credit card there just like to to just like to to explode your prices here you can see in in your chat with your open AI dashboard you can come here you see manage account and there you can see how much you have spent every single day since you logged in I mean since you loaded up your account currently I spent five cents which looks alright um what I have done very very few very few requests um and basically yeah the thing is that when you sign up you get 18 for free for you to experiment and to test which is very convenient and there you go now basically we have our application you know what I'm I don't think I have tested it from here so let's do that select the first 100 elements select the first 70 elements from a table tasks where this the column status equals completed generate query um there you go select all from tasks where status equals completed limit 70. I mean of course this is a very very basic application but I hope it has um taught you how to how to use the openai API how to use the chat GPT API in particular and how to create your own full stack application using both I mean using both of these apis using react of course and node.js for the backend so I hope you enjoyed this video I hope you learned a lot I hope you subscribe and I hope you liked the video If you enjoyed it and yeah I will see you in the next one thank you very much for watching [Music]
nviEA5chYA8,2023-03-26T08:07:00.000000,Create a Chrome Extension (Manifest V3) for ChatGPT,good morning everyone how is it going today today I'm going to show you how to build a Chrome extension for charger PT all right this is going to be a Project based tutorial so by the end of this video you will have this extension right here that I'm going to show you the extension has an icon right here if you click on it there is a pop-up that shows up and then you have two buttons inside the pop-up one of them prompt sends a prompt to charge upt there you go I just click the button and as you can see there is a prompt that was automatically sent and we're also add another button that will render mathematical equations automatically like this okay the main the main goal of the project is not to show you how to render the equations but basically how to create this kind of extension that interacts with rgbt so also this knowledge will not only be useful for chargept but you can apply this for pretty much any other website and any other Chrome extension idea that you have we are going to be using the latest technology of Chrome extensions which is Manifest V3 and yeah without further Ado let's get right into it [Music] thank you all right so the first thing that we're going to want to do is we're going to want to load a boilerplate okay of course you don't necessarily need a boilerplate already made in order to build your extension you can build your extension from scratch but this is just going to make it a little bit easier if you want to you can download the extension I mean the boilerplate the spoilerplate right here I will leave a link in the description so that you can clone it from GitHub okay so let me just throw you around the folder structure of the spoilerplate and how it works because it's a little bit different to other kinds of JavaScript applications so of course uh Chrome extensions run on JavaScript and here we have it so the folder structure pretty much looks like this we have our webpack configuration right here um I added a teraser plugin um right here it basically just allows us to load a production build to the extension because there was some problem with the encoding um so you I mean you should load that um we have like of course a redmi we have a package.json with as you can see we have only webpack and our encoder and of course we have Babel um to to make our JavaScript as compatible as possible um I get ignore our Babel configuration and here we have our source okay this is basically where we're going to be writing some of the code that will be I mean this is where we're going to be writing the code that will be loaded in the page that we want to to load it in but actually the extension itself the file that you're going to load into the Chrome browser is not all of this it's only this one right here extension and as you can see in our webcam webpack configuration the output of our source JavaScript is going to be content.js inside extension so here it is content.js and content.map if you don't see this of course that is going to happen when you just download it if you just downloaded boilerplate what you're going to want to do is going to do npm install to install all the packages that are in my package.json and once that is done you're going to want to run npm run if I'm not mistaken it's build diff there you go and now you should have content.js and content.js.map okay and so as you can see this is the actual file that you're going to be loading to Chrome inside of it you have a manifested Json we will take a look at it in a moment we have our content.js which is the file that is going to be loaded inside our page we have some I mean a folder for a pop-up but we haven't added anything there yet and we have our icons as you can see this is the icon that I had loaded here into my extension and there you go so this is pretty much the boilerplate let's take a look at these files and what they do all right [Music] all right so now what we're going to want to do actually first is to load our extension locally okay why so because I mean as you are developing your application you you're going to want to be able to test it of course um the problem is that the way that you usually install applications is you download them from the web Chrome web store the thing is that if you're developing it it's not there yet so you're gonna have to load it locally in order to continue improving it and testing it okay the boilerplate that I that I shared with you should be already should be all ready to to be loaded into Chrome and let me show you how to do that okay remember of course that I told you that the actual extension file that we're going to be loading is this one right here the extension directory not the entire project folder okay so there we go in order to do this I mean I had the icon here just a moment ago but I just deleted it to show you how to load it um from from zero so you're going to want to go to Chrome extensions like your extension manager and right here as you say you we have a developer mode toggle you're going to want to enable that one and then you will see you have more you have more more features and then what you're going to want to do is you're going to click here and load unpacked okay and then from here you're actually going to choose the extension folder all right remember that if we go One Directory up you have your entire project folder but you don't want to select all of it you only want the extension folder all right then you click on select and there you go the boilerplate was correctly red as you can see we have our we have our icon right here that we selected from here as you can see we have inside our extension we have our icon.png it's this one and it is the icon that has been showing here okay here you have the name of your extension the description of your extension and that is exactly what you see in the manifest.json okay so now that your extension is loaded um I'm actually just going to pin it up here just to show you how where is it um there you go now we have it pinned right here just to show you how it looks and now let's take a look at what each file in this extension does and how to use them okay there you go all right so now let's take a look at our file manifest.json this is the most important file in your extension as it basically tells the Chrome browser what your extension does what its name is and what permissions it has and also what other files it's going to be using okay so basically if you don't have this file your Chrome browser is not going to be able to read it your extension to show you very quick some of the some of the things that you have right here we have the manifested the Manifest version is the first the first element and here you're gonna write number three because that one is the latest version of um of the Chrome manifest okay this basically means that if you have like the number two um your extension is probably going to take longer to get accepted and validated in the Chrome web store and also the Manifest number three has like more secure features and it's going to I feel like it's a little bit easier to understand um so definitely go for number three if you're if you're watching this video um then you have the name the name of your extension as you can see right here um the name is the name of your extension and here you have the name of your extension but if I update it let's say oh once second um let's see let's update it to your awesome extension and let's update the description as well this is my awesome description there you go if and if we save it and remember that we had loaded it before so you're going to be seeing it here but as you can see it's not it hasn't changed yet and that's normal because we need to click right here in order to reload the extension okay so basically whenever you modify your extension be it just the manifest.json file or any other file inside your extension like a Javascript file or whatever you're going to have to come right here and click on reload right here in order to actually take your changes into account so this is basically just going to update our name and our description um what else do we have right here we have the version um you you're free to set it to whatever you want but of course this is useful to keep track of the development of your application here if I set it to 1 0.01 this is going to be updated to 10.01 um they don't have the icons right here and you have I mean you're able to choose different images for different sizes I just pretty much loaded the same image to the different sizes but just wrote them that um just included them so that you know that that it is possible to include them and also so that you know that you can like load different images like different sized images for different sizes um so there you go of course the whatever what you pass right here is the location of your image so as you can see um I'm going to a directory called icons and then inside of it I'm going I'm looking for icon.png which is basically since my manifested Json right here it's going uh Manifesto Json is right here it's going to look into icons and then to icon.png and this is my icon and as you can see right here this is the icon that is being loaded so there you go for that what else do we have right here um we have the background and the service worker I'm going to explain this a little bit more in detail when I go through the background.js but this basically is the file that is going to be running on the back end of your extension okay this the JavaScript that you that you write right here is not going to have access to either any of the pages of your I mean of the current tabs that are open in the browser or the pop-up this is basically just to handle API calls or whatever I mean it's I mean you can think of it as a back end of your extension um then you have um the action element right here and of course if you if you add the option default icon it basically means that there is going to be an action Associated to the icon this basically means that when if you come right here I mean this is not a feature in the current application I mean in the current extension that I showed you but I imagine you might have seen some extensions that just by clicking them they do something that's exactly what this what this action action feature does that means that I mean you're just going to pass the the icons is this exactly the same object as this one right here and basically means that you're going to be able to tell your extension what it wants to do when you click on those icons coming on that icon and this is something that we can set up in the background.js I can show you how to edit that in a moment and also the permissions this is very very important because this is a crucial part in your validation procedure of your extension and it basically tells Chrome what permissions your extension has um about your user data and your users like whatever they have open um so in this boilerplate for example we are requesting access to the tabs API which basically gives you access to all of the open tabs in your all of the open tabs in your in the Chrome browser and that of course is a little bit a lot of permission so just by adding this API right here you're probably going to be asked to to write a personalized message to the Chrome developer team to tell them why you required that API and why it's essential for the use of your application okay I mean most extensions use it but yeah I mean as you're gonna have to take care of the permissions and the active tab basically it's pretty much the same but it just gives you access to the current tab so there you go actually since I'm running tabs I can just ditch current active Tab and that's basically the same thing and then finally we have the content scripts this right here is not um all right so remember that the background dot JS which is the service worker right here did not have access to the page that we are loading that is normal because it's the the one that is going to have the handling the API calls and all that but if you want to run some JavaScript inside the page that the user has opened you're going to have to write it in I mean you're gonna have to create that file inside of content scripts right here and as you can see each element in this content scripts array is going to have like the Javascript file as you can see this one coming in our case it's content.js which is right here and as I showed you before is built I mean it's bundled from index.js right here and you're going to tell it as well when I mean in which Pages you want this file to be loaded so I mean if your extension only use is only meant for chat GPT you're only going to write right here um you're only going to write right here chat.openai.com of course because otherwise your your JavaScript file is going to be injected into every single file every single page that the user opens and you probably don't want that so yeah basically just have to say in which in which in which Pages you want it to be open and the Asterix right here just means that what um anything can come before fit and anything can come after this so This basically means that it can be HTTP or https and this right here basically means that it can be like whichever sub directory of chat.openai.com and last but not least we have run at which is the location where you want your script to be injected so as you can see right here we have our chat GPT um application and if you write down that you want your script to be loaded at the document end it's going to be loaded right here right off the body okay that's just a standard procedure if you're running a JavaScript that modifies the the elements of the page you want to run them you want to run them at the end of the document so that when you I mean so that they will have access to all of the elements that have already been loaded okay I mean that's just like standard web development so yeah document 10 where you want your your file to be loaded the name I mean the location of your file and all the rest I think it's pretty pretty clear so let's go to the next file all right so now what you're going to want to do is to create a pop-up all right remember that what we said is that our extension when we click on the icon right here it's supposed to display a pop-up okay and that's actually super easy to do um what we're going to do is we're going to come right here to our Manifesto Json and we're going to add another line it's going to be inside the action object okay so right here we're going to add default default pop-up like that because remember you have to bind the pop-up to an action in order for it to work okay and here you're just going to say the location of your pop-up okay I'm going to say that it's inside of a folder called pop-up and inside of it it's going to be popup.html there you go now let's create this file right here and we're going to do it like this so we're in manifest there you go we're going to create pop-up um wait I think I already have yeah I had already created the file the folder now I'm just going to create the file popup.html there you and something that you have to know is that the pop-up is actually in a way some sort of its own application okay so in right here it actually you just write your HTML as if it was a regular website and right here you can just add the title let's say chat GPT extension like that there you go and now inside of the body let's just say H1 and let's just write hello world and then just write a paragraph We are inside the pop-up there you go now we're going to have to come back here to our extensions and we're probably gonna have to reload it and then let's just click on this part right here and here we have it our beautiful pop-up which is not extremely beautiful at this at this point we still have to style it and Injustice any other application you can take some CSS or JavaScript for it and that's exactly what we are going to be doing right now okay so um you can follow me let's first of all let's add a couple of buttons how about that instead of hello world let's just write buttons these are the buttons that are going to be used to create to trigger actions inside of our our page okay so these buttons we're just going to give it an ID of button prompt because this is the one that is going to send the prompt to chargept and let's say prompt chat GPT or let's say send prompt there you go and then let's create another one and let's call it render because I mean the idea behind this app is to render mathematical equations but I mean you can do whatever you want with with these buttons render math let's say there you go um all right so there you have it now you have a beautiful a beautiful pop-up working with two very beautiful buttons um actually let me show you we can just add some styling to it so let's do that I'm gonna do that right here beneath um beneath the head and I'm just going to follow the regular styles the regular like the regular CSS that you would use in a regular front-end application okay so first of all what I'm going to do is I'm just going to add I'm just going to um standardize the dough in with a box sizing of border books there you go what else we can add a margin of zero just to standardize it all and then the padding of zero as well there you go now for the budding let's say that we want a background color um um I think default is wide but let's just add it right here and all right so now um we have let's just say that we want to add all of this inside of an native called app like this there you go and then the buttons are going to be inside the app like like there you go so the app oops the app element is supposed to have let's say we're just going to say it's going to have a display uh display Flex um in order to show the ball to show all right we're just going to add a little title right here let's say uh H1 [Music] um beautiful extension like this there you go and all right so what we're going to be doing right now is all right so we have a beautiful extension right here and let's add some more Styles let's add let's let's make it a flex Direction uh column so that we have like our H1 and our bottoms afterwards um so let's do that um Flex that nope not fun display Flex Direction [Music] um let's say column then we're going to say that we're going to align the items to the center and we're going to justify the content to the center um just as a reminder if you don't know what are these like um like shortcuts it's just emit abbreviations okay um usually I don't remember but I think it comes by default with um vs code so you should have it um then we're gonna set a minimum width to 300 pixels and let's add a little bit of padding of one REM remember to use REM uh prefer the use of REM to pixels whenever it's possible unless you set a default color to Black and let's see how that looks like so far all right it's looking a little bit better but it's still not um great okay so what we're going to be doing right now is let's add some more elements here right here um all right we're gonna add it we're gonna update a little bit our skeleton right here let's say this one's going to be a section and this one's going to be the um let's say the class is going to be header like like and our our our header is going to be there and then we're going to add another section with the class buttons and our buttons are going to be inside of here oops there you go there you go now there are buttons and there is a section and now it should now this in the buttons are displayed one beside the other because they're inside one single section I mean html element um all right what else can we do this is going to be a very very very quick uh CSS thing so let's say section the header um it's going to be let's say [Music] um what do we have all right let's say font size oops let's say font size let's set it to 1.5 RM let's see how that looks all right well that's probably a little bit too big let's say 1.3 all right there you go then let's style the buttons a little bit okay um the section 40 buttons we're going to say that it's going to have a width of 100 first of all and then for each button let's just add some margin right here let's say 0.2 um top and bottom and say zero for the rest I mean for for the sides and one just add some padding as well let's say one or am on top and two two REM on the sides the width is going to be a hundred percent of the available space border none let's add a border radius nope that background repeat for the radius there you go of half an REM then the courser of course we want it to be a pointer the background color let's set it to I have the color right here so that you can copy it and then the color of the text is going to be white there you go let's see how that looks like there you go it's looking a little bit better uh maybe the header wanted to send it um text align Center nope Center like that let's see how that looks like my beautiful extension let's just add a little bit of margin to the bottom here margin oops margin but um let's say 0.5 Rems there you go oh it's looking a little bit better and now we have our two buttons let's add just a little bit of a hover effect on this button and that should be all button dot nope hover like this and let's say let's add box Shadow an unbox sizing but box shadow box shadow um it's going to be 0.5 Rems and let's add this call right here up like that like that there you go let's see how that looks like and now there you go now you have your beautiful styles right here and it looks pretty good and just to show you how I mean to what extent this is it itself it's actual application we can right click on it and we can click on inspect right here and it opened on the other screen but what you have right here is actually pretty much its own inspector and it's all developer tools for the pop-up as if it was its own application you have a console right here because you can add some script some JavaScript to it um yeah I mean basically you can do what it's your own mini application inside a pop-up okay so that's the way to see it um we will live we will leave the Styles and they pop up like this right for for now but um yeah next step will be to add some actions to this to these buttons okay and for that we're going to be using JavaScript so let's do that now all right so now that we have our beautiful extension pop-up right here it's got the right HTML structure very beautiful CSS styling it's time to add some JavaScript to it okay and before showing you what actually is going to be doing with the JavaScript I want to show you a little schema right here a little graphic that I made for you so that you can see what x what is actually going on with each of our JavaScript files okay so right now we're going to be editing a JavaScript for the pop-up and that file is actually only going to have access to the pop-up itself as you can see if we come back here and we click on our pop-up and we right click inspect we have our own console here I mean it's just as if it was its own application this console is not the console for the website for for the page this is only for the pop-up okay and that is why we considered this to be like its own application and then content.js is going to be the one that is going to be running in the in the page itself and then background.js is the one that is we're going to use to to organize our tabs and our API with chrome okay so there you go let me just show you real quick how it works um so to make it a little bit easier by doing okay so let's go back to our code right here and this is the HTML of our pop-up and right here before the closing body tag we're going to oh actually let's add it right here we're going to add a script tag and we're going to say that the source not the area the source is going to be popup.js this is basically just a path to the file where you have the JavaScript for your pop-up and here of course we are referencing a file that doesn't exist yet and since we're inside of popup.html and we're just adding the name we have to add the popup.js inside the same directory like this there you go so now that we have imported it right here and right here we have the actual JavaScript we can just do a console.log and do hello from pop-up.js all right I'm going to get rid of um co-pilot just so that you can code along um so there you go let's just close this and reopen this I mean as you can see in the console for this coming for charger PT for the website we don't have anything and that is normal we are supposed to have it in the console for our pop-up as I showed you before if we come right here to console we see hello from Papa PS okay um now what we can do is we can start getting our button so let's say our button prompt is going to be equal to document dot query select or and let's do what was the ID I think it was button from prompt like that honestly the same but what the other one which is going to be render and we will do just button render like that I suppose that's the actual ideas that I gave it yeah there you go and now we can actually start adding um event listeners to this and it's very simple all that we're going to do is I mean basically just to as you would in any other in any other in any other application you can just do different listener and then we're just going to listen for a click and basically we're going to console log um prompting because this is the button that is going to prompt to to charge your PT prompting to chat to charge GPT like that and let's do the same thing for the other one which is button prompt but render we're going to say rendering math in chat GPT there you go now if we save this um if I'm not mistaken if we reload the pop-up and we click on inspect we come right here to console of course we don't see anything else anything yet because we deleted the first console log but if we let me just bring this to the side like this there you go if we click on send prompt we see prompting to charge upd and render math also control logs so we see that our JavaScript is working correctly now remember I cannot State this enough um this is not the console for the website this is just the console for the pop-up if we see the console for the website you can see it right here I'm just going to put it down here this is the console forgept okay there is nothing of what we're doing going on in the console yet that is because as you can see in this diagram right here all of what we're doing is on I mean so far it's only involving um pop-up.js and then it's only interacting with the pop-up what we're going to want to do now is we're going to want to send [Music] um a request to the Chrome API so that the Chrome API can send it to content.js so that's exactly what we're going to be doing now we're going to be seeing how to catch a request from content.js um like how to catch a request on content.js from the pop-up.js all right so let's let's do that all right so the objective for this section is basically just to do exactly what we did before but instead instead of console logging while we were console logging in popup.js I mean in the console from popup from our pop-up we're going to console log it in the console from our website and in order to do that we're going to send we're going to have to interact with the Chrome API and send a request from the popup.js and then we're going to catch it with content.js and that is actually very simple to do in our Chrome in the Chrome API basically it works you can basically see it as an HTTP request the only difference is that it I mean you're more free to do whatever you want because you send a message and you can catch it wherever you want okay so basically if you send a message or a request from here you can catch it anywhere else and then see you send if you send it here you can catch it anywhere else Etc um so there you go in order to send a message we're going to be using this function right here Chrome runtime send message and in order to catch it we're going to I'm going to we're going to I think it's this one yeah Chrome runtime on message as listener and this is the one that we're going to be using on on the content.js site um but in the meantime before doing that we'll I mean this kind of sends a message to all of to like to everywhere I'm going to have to Target it to our open tab just to make it a little bit more concise and more robust so let's do that um so right here we're going to first of all get the current Tab and to do that we're going to use this function right here I'm just going to code it myself just so that you can code along and this is what we're going to be sending and let's say um first of all we're going to do const and the current tab and this is going to be this is going to be Chrome dot tabs dot query and then you're going to say active equals true and then we're going to say current window to true as well there you go so now this one right here is going to contain our current tab information um let me um all right so um and now let's just send the message to our to this tab itself and to do that we do as well Chrome dot tabs dot send message like this and the first parameter that we're going to say is the tab where we want to send it to and our object current tab contains an ID which is the argument that we have to pass right here and then we're gonna basically just send our date and we can say we can say hello world [Music] hello world hello world like this and then also let's send our message or yeah our message which is going to be from [Music] a prompting from I mean to chat GPT there you go um one uh kind of important thing is that this is not going to work if you had just done it like this because we're interacting with an API and that basically means that we need to use an asynchronous function because we need to wait until Chrome actually responds with the current tab um and in order to actually use it so we're going to have to add a weight right here and also we're going to have to add and a weight right here and of course if we're using a weight we are going to have to make our function asynchronous so let's do async like this and just delete it the event because we were not using it and there you go let me just show you real quick the current tab object now this is going to show in our in the pop-up in the pop-up console like here inspect there you go let's see the console and let's oops let's click on send prompt and there you have it this is our tab and there you go it has active Audible and as you can see it has our index which is the one that we are sending in the message something important as well as I I just noticed right here and this is not only an object but it is an array with one object inside because what this function does is it returns an array with all the tabs that that satisfy this this uh this options and since there is only one tab that is active and one tab in the current window this is going to return an array with only one tab so I mean in order to select it you can either do like this just select the first element or in order to make it a little bit more readable and More Beautiful You can just add it like this which is exactly the same thing and now when we click on this button it is actually going to be sending our message right here so there you go but now we have to catch it on content.js and in order to catch it in content.js we're going to have to come right here to source um of course this is only because we're using a boilerplate with a builder which is webpack and of course this is going to be bundled up into this content.js right here whenever we do npm run build okay so let's first of all let's do um in order to catch it which was the function to catch it the [Music] just one second term there we go it's all in order to catch it we had to do Chrome runtime and then on message like this um and then add listener if I'm not mistaken there you go add listener and then you just add your listener it basically takes um we're going to take in a synchronous function as well um actually I'm not sure if we need a synchronous function let's just leave it like that for now and we're going to take the first is the request that we're going to be that we're going to be receiving then the sender and then the response I mean this is just a standard this is not um we that our that are creating it this just comes from the documentation as you can see it right here request sender and response and then you can do whichever whatever you want with your request okay so right here if I just do console log my request [Music] there you go and of course I am just writing this in index.js so in order to build it I will have to I will have to actually run build so in the boilerplate that you have I mean if you downloaded the one that that I published in on GitHub what you're going to want to do is npm run actually yes you can run watch if I'm not mistaken yeah there you go it works and this basically I mean the watch is a watcher so basically every time you save it's going to regenerate the content.js file and now as you can see our function is in there so let's come right here I think that this time we will have to up up um update our our our extension and now let's just show this to the right like this there you go and let's see if this is working so we're going to click on send prompt and it is not working for some reason maybe we're supposed to actually use a hmm maybe we're supposed to actually use an asynchronous function if I'm not mistaken let's see okay let's say we refresh this right here we reload this there we go send prompt yep all right so apparently we had to do a synchronous so every time we click on it there you go now we have our message that we were sending and we have hello world and our message which is prompting from chat GPT to chargept and this comes from this pop-up which is itself its own application okay so yeah I mean basically what we have managed to do is to communicate between our pop-up and our content.js and now I mean if you see the power that you have right now you can basically modify I mean run JavaScript in your in your page as much JavaScript as you want uh just from your from your pop-up okay so all right let's just finish this this extension real quick and let's get on with it all right so now what we're going to want to do in this section is basically to just send the right messages from our pop-up to our content.js okay but first of all I just wanted to clarify something real quick is that I had uh mentioned before that you had to add async here in order for it to work and the problem is not actually the async thing um I mean of course you're gonna need an ace to make it an asynchronous function in your content dot JS if you're making an um a call to the Chrome API or to any other API but in this case the problem why it was not loading is that actually you need to reload the extension and also refresh charger PT I mean your your website in order for this to work um so let me show you real quick what what is actually happening so if I do console log hello my friend right here and I save it as you can see it's already here in my content.js it's all right but if I come right here to my Chrome um I mean to my to my website and if I refresh it I'm not going to see anything and the problem is that I haven't refreshed the application the extension now if I come back I'm still not going to see anything because I need it to I need to refresh the page as well in order for it to work because I need to refresh the extension and then the page so that my JavaScript is inserted at the bottom of the page okay remember that what we're doing here is basically just inserting this JavaScript at the bottom of our website so you're gonna need to reload the website for the for your new JavaScript to be included um so all right um what we're going to do now is we're going to send the right messages um and to do that um first of all I'm just going to take this current tab declaration and bring it up out here and send this a message as well on the button render click as well and of course I'm going to have to make this function as synchronous as well there you go so which messages do I want to send I'm going to say that this is going to be an action and I'm going to call it prompt okay remember that when we are catching this information in the content.js this is basically just whatever information you send it so this is totally arbitrary that means that I can call this message or or something whatever and just catch it on the other side with that keyword but since I am performing an action I'm just going to call it action and same with the value I'm just calling it prompt because it makes sense to me because I am sending a prompt to charge up team but I can just call it action one action 2 Etc okay this is completely arbitrary and it is you who chooses this um and I'm going to do the same thing with the second one right here I'm going to do action and the action for this one is going to be um render like that okay all right so this is an interesting thing to show you because this is not going to work um if I just run this um it's actually going to not be able to detect my current tab right here because I'm using a weight and a weight is of course an asynchronous an asynchronous function an asynchronous functionality and I am just importing my pop-up my pop-up script like a thing like a simple default script and in order for my script to have a asynchronous capabilities outside of a regular fan asynchronous function because I mean as you see I am using a weight here but it's not inside a phantasynchronous function so if I want this to actually work I'm going to have to come to my script declaration and say that the type um I'm just going to say that it's a module because modules have an intrinsic um support for asynchronous code and now if I save this right here and I just save this right here um I'm going to be able to let's just come back to my content.js um to my content and let's just log the request so there you go now remember that we have to reload the extension and also reload the page so that our JavaScript is inserted at the bottom of our document and then if I come right here and I click here and I click on send prompt I can see that I have receiving a request um in the content.js with the action prompt and then for render I have the action render and this I can basically use it to trigger different different functions in my content.js okay all right so now it is time to actually subscribe to the channel if you're enjoying this video and you are finding it useful um just give it a thumbs up and subscribe because it helps me a lot and um so that you can also see more videos like this alright so what we are going to do now is we're actually going to build the functions for prompt and for render and we're going to do something some object oriented programming right here for that all right there we go for the for the object-oriented programming right here what we're going to do we're going to be creating a class um but first of all um all right now let's create the class first so our class is going to be called um uh chat GP team charging PT extension just like that and we're going to make a Constructor right here and then after the Constructor we're going to have we're going to have a Handler okay so first of all we're going to have a handle request and it is right here where we're going to include our listener all right so our handle request right here and let's just include our listener inside this handle request thing and of course we're going to have to call it inside of our Constructor for it to actually work so let's do that this dot handle request there you go there you go so basically I mean if you're not familiar with uh object oriented programming in JavaScript this basically is just creating a class um with our Constructor we have our method which is handle request and every time the class is initiated it's going to it's going to run this handle request and it's going to keep it so I mean just help us to keep our code more more organized um so right here we have created our very simple class now we're gonna have to just run it let's do new let's just say const extension chat GPT extension and we're going to say that we have a new if I'm not mistake and I have to say new yep GPT extension like that oops there we go now it has compiled let's see if it's still working again I have to reload refresh and it's still working all right so now inside our handle request we can actually start checking what we want to do so first of all if I like to use if statements instead of case statements I just I mean if I'm going to I mean if you're using several like too many request types you can use a case statement but for Just Two I guess just if if statement is right I'm going to say that the request if the request action oops action equals to prompt I am going to I'm going to execute this other function called this um prompt to chat GPT there you go the problem is that I still don't have this function that is called prompt to charge epd so let's create that one and right here let's say prompt to charge GPT and it is right here that we're going to be saying console.log we are prompting to chat GPT let's just see if that this is working so far um there you go we're prompting to judge PT all right it seems to be working so now basically all that we need to do is to finish this prompt to chargeptee function let's see how to do that right so in order to do this um basically I mean this is the the most fun part I think of of developing something for AI or for like yeah especially a language model um is that part of your code I mean it's basically programming but it you're actually programming in simple English English as you as if you were telling instructions to a person okay so here we're just going to create our prompt and here I'm just going to say my prompt let me just copy it here my prompt is this right here just so there you go so my prompt is basically the text that I want to tell that I'm going to send charging PT every time I click on this button and it is right here so from now on if you need to write a mathematical expression use K-Tech notation and follow the following rules if a block if it's a block equation etc etc okay so this is basically the text that we're going to send to charge upd whenever we click on the button okay all right so now what we're going to want to do is we're going to we're going to want to fill that text into this input field right here and then once that is done we're going to want to click on this button right here or just trigger the submit option okay let's see how it can do that first of all we're going to have to to find this element right here and the problem with chart GPT I have um what I've found is that the classes are not super intuitive in order to actually modify it with with JavaScript or where yeah so what I'm going to do is basically I'm just going to say that I want this text area right here and if I'm not mistaken there is only one text area in the entire page so if I say text area I should be getting this one or I can also say um copy copy selector let's see how that works okay so let's say const input and we're going to say document that query selector and we're going to paste it here all right that is um that's probably too specific I'm not sure it's going to work with every with everyone but I don't know I'm just going to say text area let's say let's hope that works um um yeah I'm just going to leave text area let's see how that works I'm just going to console log our input let's see how that works refresh refresh now if I click on send prompt I should get it right here nope I am not getting it what is the problem so far hope it's not an ID it's just an element okay [Music] there we go Cent prompt we have our text area all right so basically we have it now what we're going to want to do is we're going to say that inside that input we're gonna want to say that it's value is going to be our prompt and then we're going to want to click on the button that is right here let's see can we click on submit let's say input Dot sub MIT does that work not sure that works nope uh submit is not a method for it I'm basically just going to click on the on the button beside it I'm going to do query selector and let's say that it is our text area text area oops text area and I want the button that is beside it in CSS this this um this symbol right here basically just means that you want the element that is at the same level but um not inside of it if I'm not mistaken let's see where it is so here's the text area and the button is just beside it it's not inside so this is basically just CSS and then we're going to check the button and then we're just going to click on click there you go um of course we're gonna have to refresh refresh right here let's let's see what happens so if we click on send prompt um all right there's brawling cannot read properties of null reading click um all right sure because I'm reading this from the query selector I needed to read it from the document alright so that was dump um just gonna reload this right here reload this right here and there we go the ascent prompt should work now but let's hope for charge reputation not break down right now and let's say send prompt and there you have it we have our custom prompt that is exactly the text that we were storing right here um yeah so I mean basically now you know how to store a prompt in your JavaScript and to automatically send it in from from a pop-up that is that's quite useful I mean you can from from with this knowledge what you can do is basically you can um make I don't know a library of prompts or or get prompts from an API or whatever and then just automatically send them to Chachi PT just by clicking a button right so now you know how to do that um and yeah so let's see what else we have here let's see it is time now to just enable the function for render math I'm going to go a little bit faster on that one because that is not the main objective of this tutorial but um let's just finish the extension real quick all right let's go all right so in this section we're basically just going to add more functionality to the other buttons in our pop-up okay um in the meantime while I was making this video actually I found out that actually charging now has a default um support for mathematical equations so now the extension that I was applying you to build is kind of like not super useful like I like the extension is also already in in the web apps in the Chrome App Store but um now apparently it's already inserted into latex so I mean that's good but I'm going to show you how to do something just a little bit different then because now it's not super useful to make it able to to display equations because apparently if you just if you just send this prompt like this you will have your your mathematical Expressions as they are supposed to to be so what we can do now is instead of adding instead of having another button called render let's just say that this one is prompt hmm prompt one and this one is going to be prompt prompt two there you go um there you go and then so this this one is going to be prompt one this one's going to be my button of prompt oops prompt two there you go and this one of course is going to call bit button prompt two and this one is going to call Button prompt one all right um and now basically [Music] um yeah I'm just going to leave the IDS like that I mean it's just just to show you real quick how this works um and now what we can do here is that we can call this prompt one if I'm not mistaken and then let's just create another I mean another case for prompt two um and in this case let's just say we're not going to use from we're going to take out prompt from here we're going to we're going to put it right here like this so this one's going to be our prompt one basically right now I'm just creating a property of this object which is which has one prompt which is right here and let's just create the second prompt like this okay prompt two and we're just going to say hi but in French why not now let's say say something smart but in French there you go um and basically I just modified our prompt hrgpt function to take any prompt that we want and we're just going to pass in the prompt okay so in this case if it is the prompt number one we're just going to say this prompt one and this is going to pass this um this prompt to all right so just to show you real quick what we did here I mean just to explain a little bit more in detail what we did here um here we had Crea we had previously created a case in which if a request action was equal to prompt one um we're going to call this function which is a method in our object which is prompt to chargept and we're going to pass in um a parameter this parameter is supposed to be the prompt and it is the prompt that is inserted into the input value and then send to chargept and of course this makes it that you can use any prompt that you want a higher just created prompt 1 and prompt 2 but you have you can create as many as you want here basically you have um this is basically just gonna send different prompts depending on which action you send so here of course the first button is going to send the action prompt one and the button 2 is going to send the action prompt to so let's see how that works um of course remember reload the extension reload refresh the page and now these buttons are supposed to send this to different prompts okay now let's test the first one uh it seems to be working it sends the prompt that we previously told it to prompt it is sending um this right here the first one and for the second one let's see how that looks I'm just going to say I'm just going to ask it to stop because it seems to be a little bit too too slow Let's test the second one all right the second one all right the button is titled render map but let's just change the titles of the button so that it's easier send prompt one and here we're going to say send prompt two there you go now send prompt one and send prompt two let's send prompt two then say something smart but in French let's see what it brings and yeah I mean this has been pretty much how to build a charger PT extension right now basically you know the very Basics on how to create your own extension and how to communicate between your pop-up and your website and how to actually trigger actions in your in your active tab um so now basically you're ready to to build your own projects don't forget to subscribe if you enjoyed it and like please and yeah just uh was hoping that we could wait to see what it generated no network error all right so let's try next time but I hope you enjoyed the video and I hope to see you next time um see you and cheers [Music] [Music] thank you [Music] [Music]
wiCEVVNxCYU,2023-03-13T22:17:39.000000,Display Equations in ChatGPT,good morning everyone how is it going today today I'm gonna be showing you real quick how to go from this kind of mathematical expressions in chat GPT to this kind of mathematical Expressions okay all right so without further Ado let's get right into it [Music] all right so if you've been anywhere near the internet in the past few months you have probably heard about charger PT and how incredibly useful it is to actually learn and to explain yourself very complicated topics among which is mathematics and some mathematical Concepts um so I mean personally I've been using it a lot for studying mathematics and some topics in machine learning and it's been extremely useful but something that really came short that it came short with was with rendering mathematics inside cha GPT so whenever I would want to display some sort of equation or something or I would kind of ask it to explain a concept to me and it would explain it with an equation I would have to ask it to use latex to to to print the equation and then go to a latex converter to actually display the equation with beautiful symbols so basically I started looking for it so this is a moment to give a shout out to this awesome dude who did this pretty much for free and uh who gave gave it away for everyone he basically developed exactly what what I'm showing you um which is this piece of code right here um which you can copy and paste somewhere where you're using um and then just ask chargpt to use latex to to display mathematical equations and then you you just gotta paste whatever the code he developed and then just hit enter and it's basically going to render the code in chargepd however I found that there is a problem with this one because if you're using it for a long time it tends to break the thing I suppose is that either Chrome or charger PT doesn't really like having external Javascript and injected in a script tag so yeah after a few minutes it would just crash and just I would have to reload and it was very um not extremely a good experience so what I did was basically I just bundled that and repackaged it into this equation right here which basically does the same thing but I've been using it for a few weeks now and it works pretty good so I'll be showing you how to install it yourself so basically the idea behind the question is that you go to chat GPT and you're gonna want to ask chargpt to display all of the equations using latex right so basically I mean what I would do usually is just write a prompt myself but here I just added a button to ask for to to create the prompt automatically and then you would you have to click on render latex right and this basically just takes all of the instances where there is this kind of um latex language in the in the screen and then it just renders it especially for chargept right and then you can just stop the rendering but the thing is that if you continue working with this like for example give me another equation it's going to continue rendering it even if you don't like press the button again it's like continuously rendering a related expression in um in the screen so I mean that part is pretty useful for the moment it only works in charge of PT because that's where I was using it and so now I'm going to show you how to install it to install it I actually tried to put it on on Chrome Webster uh this weekend but um it's taken a bit of time to actually have it like go through all the permissions and like to have it validated so I'm going to show you how to install it from GitHub so I'm gonna put this Link in the description which is the link to the repository of the extension and of course if you're a developer you can totally contribute to it and just send a pull request and we can go through it but the idea here is that if you want to install it in your computer you're going to want to come here I mean to go to the link in the description and then you're going to come here to code and then click on download zip right so download this file right here you will have to unzip it like like in Mac you can just unzip it by clicking on it like this and here you have it all right so inside the file let me show you what it looks like inside the file inside the unzipped file you will have this folder right here it's called extension the rest of it is basically just to to build it to to I mean if you're a developer you know what this kind of things are but um if you just want to install it in your browser the only folder that you're interested in is extension right here so in order to install it in your browser you're going to have to go to in your browser you're going to have to go to Chrome extensions which is like the list of your extensions that you have installed I'm just going to remove the one that I already have here installed and you're going to have to click right here and develop developer mode so that you can see this button right here which is load unpacked then you're going to click on load unpacked and you're going to look for the extension that you just downloaded right and inside the file you're going to select the extension button right I mean ideally I would place this not indeed downloads folder but in some folder that I know that I'm going to keep for a long time because if you delete this folder you're going to delete the extension as well so I would just put it in my document so wherever you want um and then just select the extension folder click on select then it's going to load it and if for some reason the extension crashes you're just going to have to click right here and refresh the extension and now you can definitely just go to chatgpt like this and you will have this new extension right here which is Chad GPT equation renderer I chose just to pin it here and then you click on it you have a pop-up the first button does what I showed you already it automatically creates The Prompt for chatgpt any tasks it asks it to use latex to render equations and then you just render all the equations in its request and as you can see the renderer is is turning all um while you have this enabled so you can continue asking for I mean you can just continue your study session and your all of your questions will be converted into this beautiful Centex like symbols so yeah I mean I'm sure that if someone has um done I'm has a little bit more experience with rgbt maybe there is a prompt um to actually do this without an extension I have been trying to do something like this um these are some tests that I that I used I mean at some point it worked to do this without um the extension but sometimes it just goes crazy and sometimes it just doesn't work like asking it like if you ask it to use double like special characters or something like that um sometimes it works and sometimes it doesn't display the equation um for my I mean myself I've just found that the easiest thing to do is just to use this pretty simple extension uh if you're interested I'm going to show you how to build this equate in this extension in a future video so you can subscribe if you like that um so yeah I mean that's all for this video I hope you you found this useful and I'll see you next time cheers [Music] [Music] foreign [Music]
My4JgIeFdWk,2023-02-27T06:07:00.000000,Logistic Regression Project: Cancer Prediction with Python,good morning everyone how is it going today today we're going to be working on a machine learning tutorial and we're going to be learning how to build a machine learning model in order to make predictions on a cancer project okay we're going to be working with a logistic regression model and this project is aimed at data science beginners and also add software developers who would like to implement the machine learning side to their applications especially in the back end okay so if that's you this is definitely the video for you um all right so we're going to be using python um for this tutorial um that's also I mean for software developers it's going to make it easy if you want to take this code into your server and also I'm going to be delving a little bit into a very very mild side of the mathematics behind this so that you kind of understand what is going on behind the scenes but just for intuition this is not going to go very very deep into the mathematics don't be scared about that um all right so without further Ado let's get right into it so in this project where we pretty much have a data set of a lot of cells measurements that some doctors have made and we're going to basically predict if based on these measurements the cell is malignant or benign so that's basically how it works so to do this we're going to be using a logistic regression and the kind of the process that follows is very very simple you basically are going to build a model and you're going to be able to feed it some numerical values in this case it's going to be the measurements of the cell like I don't I don't know like in medical terms I'm not very I'm not very good but the idea is that you have a lot of measurements the nucleus they I don't know the membrane Etc and then based on all those measurements you're going to fit them to your model and the response that you are going to get from those measurements and from the model is going to be a categorical value basically a yes or no answer in this case this kind of model logistic regression is super useful because that's basically the situation we have all the numerical values and then we what all that we need to have is a yes or no answer that's basically how logistic regression works um to make to give you an example broken real quick um it's kind of a good idea to have some sort of background on what linear regression is as well um so if you don't know how linear regression works I'm going don't worry you can watch I have another video on linear regression but if you don't don't worry this is I'm just going to explain it real real quick to you um so let's suppose that you have a data set um a lot of people that work in a marketing agency and they want their running TV ads and they're selling their product and they want to see how much um the number of ads that they publish on TV impacts the sales okay so you have this very basic chart in which you have a lot of dots and every single point in this in this scatter plot is a sale okay so here for example we had one sale we had three sales here Etc and you can see a trend the more TV ads that the company has run the more sales they have they have got and that basically makes a lot of sense so you kind of intuitively know that there is some coin that there is a correlation between the tv ads and the sales now how how this linear regression Works linear regression basically is uh also a predictive model just like logistic regression but instead of giving you a yes or no answer it gives you a numerical answer okay so in this case for example you have all of your scatter plot and then what the model does is it draws a line across it and then it measures the distance from that line to every single point in of your of your data and then it squares the data I mean that that distance in order so that the more distant points are more punished than the shorter than the closest ones and then it adds all of those together and then it tilts the line a little bit and all I mean it does this like several times until it finds the inclination and the slope that has the minimum sum of the squares of the distances so basically it's finding the line that is the closest possible to every single point and that's basically what a linear regression does now if you remember from high school or call I don't know where you had this mathematics um the idea behind um a straight line in a plot is that you can plot you can you can represent it as an equation like this in which Y is your value for this side x is your value for this side um beta0 would be your intersection with the y-axis and then this one right here would be the coefficient of how important the value of x is for the value of y so the higher this one is the higher the slope okay that's basically how it works and what the model is doing it's finding this equation right here and basically it's super useful because that means that once you have X you will be able to predict the value of y just by performing a very simple um very simple sum and basically one I mean another way of saying it is that if you have this line right here and you have this value of let's say 200 and you want to oops one second and you want to know how how many sales you will get if you make if you if you publish 200 tv ads you can basically just come up here and then you come here and then you say all right so with 16 ads we're going to have 16 sales and that's basically what is going on so that's that's basically the intuition and the mathematics behind linear regression and this is very important in order to understand what is going on with logistic regression because as you can see here the answer from this model was basically a 16. and I mean that's a numerical value the problem is that with logistic regression we want a yes or no answer so what do we do and this is where logistic regression comes into play and why it's important so let's say that you have let me just make myself a little bit up um I'll just put myself make myself a little bit smaller here there you go all right so let's say that you have um all of your data points and then just as in the linear regression example you would have your you would have your you're a scatter plot the problem here is that all the values that you have are zeros and ones so basically all of your yes are going to be scouted here and all of your no answers are going to be scatter key now um ideally I mean of course you you could technically build a machine learning a linear regression for this and it would probably look something like this that might make some sense and you would be like all right so it kind of makes sense I mean it doesn't necessarily fit um as well the line as this one but what you can say is that all right so starting from 0.2 or 0.5 or something like that we're going to predict that that's uh yes A1 and if the model comes below 0.5 we're going to predict that it's zero and I mean that could work in some cases but here it's just very very hard to do that so what we do in logistic regression is that instead of fitting into a straight line we fit it to a line that looks a little bit like this this and this squiggle is basically everything behind the logistic regression we're going to build the function that that draws this squiggle right here and then if the value of our prediction Falls over 0.5 we're going to predict that it has a value of 1 if it goes if it falls below 0.5 we're going to predict that it has a value of zero that's basically how logistic regression Works in a nutshell now on the algebraic side how it's represented with an equation here remember that you had the formula for your straight line and the formula for your mathematical I mean for your logistic regression is basically just the same thing but we're using this logic formula in which this I mean this coefficients right here come all come here as the power of E and then here as well what this makes is that this value will always be between 0 and 1 which is exactly what you want because you want to be able to make this divide between 0.5 and Below 0.5 so there you go that is basically the intuition behind logistic regression uh once you have this we can now get right into the code and start building our model okay so let's get right into it all right so welcome back and we're going to be working with this data set all right in order to build your model in order to train it you're going to need some data so that it knows now what kind of input should return a certain output okay so basically what we're going to be working here is a project in which we have several several measurements of cells this is a data set that is public publicly available I will put the link in the description if you want to download it but the idea is that you have this this um huge amount of huge number of measurements from different cells and you also have for each one of these observations you have whether or not it was malignant um yeah or whether or not if not or not it was malignant so basically you have this yes or no set of questions that you're going to use to build your machine learning model which is the logistic regression model okay um we're going to be I mean in order to use this you just have to download it I'm going to put it inside here my my Jupiter lab but you can use jupyter notebooks or whichever um thing that you use in order to you to build um to do data science project okay you can use Jupiter notebooks or whatever and this is how the data set looks like basically you have several IDs which is just every single measurement and then you have the diagnosis which is whether or not if it was malignant so here m means malignant and b means benign for each cell and then you have all of the measurements about the cell you have area means smoothness mean perimeter mean I mean this one just very complex um sets of measurements I don't intend to understand um each one of them but the important part is that they're not extremely important the what is important is that their numbers and that they play a role into the diagnosis into the end diagnosis and this is basically what we're going to be using to train our model okay so let me show you now how this works in order to start we're going to be using pandas in order to read our our data set this is a python library that allows us to you to read data sets and to manipulate them and we're going to also import Seaborn which is a plotting Library okay there you go now of course you will need to install them first if you don't have them installed you can do just pip install or condo install um all right so let's now load the data so in order to load the data I'm just going to call it data and I use PD read CSV like this and then I'm just going to write the location of my data set which as you saw it's right here pressed cancel breast cancer dot CSV and then in order to see the top part of the data set I just do data dot head like that um let me just zoom a little bit more that way it's easier for you to see all right there you go um so there you go um here I mean head the head command just shows us the top part of our data set which is very convenient it's basically the same as we saw right here but just the upper part okay so that kind of allows us to start to get an idea of what this data set looks like what we can do now is also get the information about the data what I like to do is do data.info and then it pretty much gives us a list of all the variables in data science will usually call variables every single column so it gives us data for the variables that we're going to have um so as you as we saw before we have the texture mean area mean Etc all these measurements that are already in float 64 format um also this comes with um with a notebook that's on kaggle with all of this explained if you want to go through the notebook the link is in the description and all right so now that we have this information we might I mean it it's usually a good idea to understand what your data is but here it's a little bit um technical so I don't really know exactly what each concavity was to compactness worse with each one of these things mean but I mean usually you can use describe to kind of get a feel of what your your data of the ranges of your data you get like the mean the count the minimum value the maximum value and then your your quantiles etc for each of your variables which is very convenient if you if you kind of understand your variables now the next step after kind of familiarizing ourselves with the data a little bit is to clean the date the first part of cleaning the data is dealing with nans in every data set that you're going to encounter in the wild you're going to have some some fields that are actually just empty or that no one bothered to to put information in or that are like damage or something so you're gonna have to deal with that a good technique to deal with nas is to plot a heat map of it like this and you use SNS which is Seaborn as you so up here and basically it's going to tell us if you pass the data that you have and give pass is no like this basically it's going to give you a a hit map of with zeros wherever there is data and A1 wherever there is a and a so here you can see that you have one entire column which is unnamed 32 that is completely empty it's full of any ends you can also see it here in the in the no not here well yeah here too you can see that everything is in a n but also here in the head you can see that all of it is n a um you can see it here as well basically yeah everything is nice so what we're going to probably do with this one is we're going to drop it and to drop a column what we do is do data dot drop and then inside here you pass a list a python list or an array if you're coming from a different language of all the columns that you want to drop and indeed we're going to want to drop this one right here on name32 I'm just going to copy it and paste it like this in order to not make any typos but also I want to drop this other column that we don't really need because it doesn't give us any information about the data which is the ID we only care about the measurements and the ID it's just an integer like to record to identify the observation we don't need it for for this for this so in the list I'm going to include ID as well like this and then in order for this to be in place I mean to modify the actual variable that I'm passing in I'm going to have to specify in place equals true like this and then if I see my data dot head again you can see um that there was a problem and the problem was that I didn't specify which axis I was dealing I was going to drop so the drop command basically just deletes data from your from your data set from your data frame but here I didn't tell it what on name32 and ID is so it doesn't know if it's a row or a column so I basically have to specify that it's a column one is for columns and zero is four rows so I'm going to go with one for columns and now you see that my data set looks a lot more cleaner we don't have this empty variable anymore and we also don't have the ID and that's basically all that we need in order to build our model so now let's just convert this one into ones and zeros because remember that's pretty much what we need for our for our model to work so basically what I'm going to do is I'm going to convert data diagnosis which is this variable right here and I'm going to convert it into I'm going to convert it into A1 if it's value equals M which is malignant and else it's going to be zero like that and then we just as passing a 4 a for Loop which is 4 value in data dot diagnosis there you go this is basically just a one-liner for for a for Loop basically this is just the same as doing four value in data return one if value equals Etc okay so this basically is just a one liner for that and now that we run it you can see that if we do a head again you can see that the diagnosis is now one and one one for every M and you know what I'm going to show you real quick how this looks in a very simple plot so another way to I mean so far we have been using data Dot and the name of our variable but we can also use the bracket notation you just add brackets after the data frame that you have and then you just call the the name of your variable and here it is diagnosis like this and what we're going to do is we're going to turn it into a category type because so far it's still an integer type because we just say that it's going to be 1 or 0 and that's an integer so we're just going to say tell python that this is not only an integer it's supposed to be a category okay so let's do that data diagnosis that then we're going to say that it's equals to as type and we're going to say it equals to category and then copy false like this there you go and now let's just look at it so we do data diagnosis in order to build a plot and then we're just going to do a value count like this and then we're just going to plot it value counts basically just returns a table with the cat and the value counts for ones and zeros so it's going to tell us so once are this and zeros are these let me show you real quick what happens if I don't use if I didn't convert it into a category type let's see how this works so I'm going to do kind equals bar in order to make a bar chart right here and let's run it um well it actually kind of works without converting it into a category type um let's see what's going on data dot info um yeah I mean it's an integer but yeah I guess we can leave it like this I'm used to I'm used to converting it to to a category type before and it works as well so yeah I mean basically you have zeros and ones in your in your variable and this is exactly what you want now that you have your data set that is clean and you have all of your diagnosis distributed in I mean like divided into ones for malignant and 0 for benign and also you have all of your variables that are going to be useful for you and you don't have any useless variables you have your data set that is clean and you have it ready for training okay now you're going to start to train your logistic regression model in order to perform some predictions based on the data that we're going to input on it um so basically um we're going to start dividing the data set into the training part I mean yeah before doing that actually we're going to start dividing it into the predictors and the Target in data science the predictors are all of this all of the input values that you're going to include so here's radius mean Etc all the way till the end and your target value is going to be the variable that you want to predict the value of which in this case is diagnosis and in this case the diagnosis um sorry data diagnosis let me show you that it now looks like zeros and ones so yeah this is the one that's going to be your tag available in order to do that we're going to let me just divide into Target Fireball and predict it and predictors predictors like that okay there you go so the target variable is going to be y just to keep it consistent with a mathematical notation and in our data frame we're going to call diagnosis basically this is our Target variable and then we're going to add the X variable which is going to be everything except for diagnosis okay so basically actually we have to drop we have everything in data except for diagnosis so we're going to do data and then we're going to do pretty much the same as we did before but we're going to drop diagnosis like this and as you can see right here we are not using oh we are not using in place anymore that is because we don't want the variable data to be modified we only want X to take the value of whatever it is that is data without the diagnosis variable so there you go now if we run this we're going to have our both variables so Y is our ones and zeros and X is all the other variables so good so now that we have our X and Y variables what we probably want to do is to normalize the data why do we want to normalize the data that's a good question the answer to that is that because all of your data I mean the predictors that you're going to put into your into your model they they're basically going to have different units because I mean their measurements of different things in this case for example you have the sum of this are around 20 20 11 Etc and some are like 122 100 and 135 and some are very very close to zero like 0.3 0.08 so basically how would your model know which I mean if you just fit it like this it's not going to know that this one's are not super important or not much more important in compared compared to this other ones Etc so basically you just want to have like a uniform unit for all of your all of your variables and that's basically what normalization does it makes all of the units um normalized and in order to do this I mean just to give you another example how this works is that for example let's say that you're building a model for a bank you're building an application form for a bank and it's supposed to be able to predict whether or not a client should get a credit card or a loan so one of your variables is going to be the age of the client probably another of your variables is going to be the balance in their bank account and the balance in their bank account is probably going to be in thousands or in tens of thousands or in hundreds of thousands or millions and their their their age is going to be in years so it's going to be like less than 100 so how are you going to put this into your model basically you're going to have to normalize it so that both variables are like relatively as close to zero as the other one so that you can fit them to your model to build the the mathematical expression that you want to find and in order to do this actually scikit-learn which is the library that we're going to be using for machine learning comes with a very very convenient method you just have to import it so we're going to use scikit-learn import from scikit-learn Dot preprocessing and you're going to import standard scaler like this there you go and now the first thing that we're going to want to do is we're going to create a scalar object and we're going to do scalar equals standard scalar and then once that we have created our object important thing don't forget the parenthesis this means that you're initializing the object of course if you're a software developer you know that that means that you're initializing an instance of this class and then we're going to fit the scalar the scalar to the data and then just transform the data so in order to do this we're going to declare a new variable that is going to be called I'm in a new python variable it's not a variable from our data set and it's going to be X scaled and we're going to do scalar dot fit transform and then we're going to pass it the actual values from our predictors which is X and there you go now X is scaled and now we can actually take a look at how it looks like nope it's not ready yet because I made a typo here it's supposed to be standard scalar and there you go um sorry I returned X not X scaled so now we do you know what I'm just going to run this right here I'm going to show you X of course looks like this and X scaled looks like this as you can see all the variables are relatively close to zero which is exactly what we wanted from our data set from our predictors in order to train our data so there you go that was how to normalize the data let me just add a very nice neat title right here um like this and we're gonna do there you go and now right here what we're going to do is we're going to split the data slipped nope split the data and as I mentioned before we want to split the data into a training part of the set and and another one to um yeah a training part of the set and the testing part of the set so that we can train the model on the training part and then we can test it on data that it has never seen before so that we know that it actually is able to predict based on new data and this is very convenient as well because scikit-learn as well comes with a very convenient method that allows you to to to do this so you do from SK learn dot model selection you're going to import train test split and this right here is very important because what you want to do now is like the video and subscribe because that helps me a lot and that would be very thankful and then after that what you want to do is just split your data you're going to be using this function right here and this function basically returns four different values the first one we're going to call it X strain the second one is going to be X test the third one is going to be y train and the fourth one is going to be wine test and basically I mean you're just going to declare them like this because since it's going to return for values in Python you can just return all of them like this and just assign them with with commas separated by Comas and it's going to go right into where it needs to go so now you do train test split oops split like this and then inside of here you're going to say your predictors first and remember that we're going to use our scaled version of the predictors then we're going to use the target value which is the column width ones and zeros and then we're going to tell it which what is the number I mean what is the proportion that we want for the testing the testing data set this one right here is going to be called test size um so the test size let's say that we want 0.30 that is 30 of all of our observations we want to be um put them into a testing I mean so of all of our data we're going to take 30 percent of it right randomly and we're going to put it away into a x-test and X strain um side and then we're going to test our model on those okay and it's going they're going to be selected randomly so that like our model is sure to be working and then the last argument that you want to pass in here is the random State basically this is just an arbitrary number that you can pass and it basically means that if you ever need to repeat this exact split because remember that this is a random split so if you ever want to repeat this split split you're going to have to pass in the same the exact same number in order to get the exact same um like division of training and testing and this is just what whichever number you want and of course you usually choose 42 because that's the answer to everything um so now now what we're going to do is we're going to actually train the model and also to train the model of course we're going to be using scikit-learn so we're going to use SK learn dot linear model hmm linear model and we're going to import logistic regression like that and then we're going to create the logistic regression model like this we're going to call it LR for logistic regression and we're going to do logistic regression that we just imported right here remember don't forget the parenthesis that is very important I mean if you're a software developer you know that this is um this is just used to initialize a class an instance of of this class but just remember that this is I mean it's important to add the parenthesis and then what we're going to do now is we're going to train the model on the training data and to do that we're going to also call our model that we just created which is LR and we're going to call this method that is fit and then we're basically just going to pass in the data that we have from X train and also we're going to pass the data from y training this is of course the predictors and this is the the target values and then we're basically going to predict the target variable oops variable based on the test data I mean on the on your test data on test data and this is very simple you're going to basically create a new variable that is going to be called y predictions let's say all white bread to be short and this one is going to be linear regression dot predict as you can see we're using exactly the same model that we already trained so LR starting from here LR is already trained with our data and right here what we want to do is we're going to predict based on our X testing data and this one if it is equal to y test that means that our test was perfect now our predictions were just perfect because every single wipe red is going to be equal to Y test let me show you how this works I'm just going to run this I'm going to run I'm going to show you what white bread looks like so it looks just like zeros and ones that's exactly what we wanted because every 0 means that um means that the prediction was that it's not malignant and everyone means that the prediction for that observation was malignant and then if you want to check how y test looks like it's basically also a list of of zero I mean this one is a series this one is a list but I mean they're basically the same when we're going to compile them so I mean you can start to see that I mean the prediction seemed to be pretty close so the first one is zero the second one is one the third one is one then zero so our predictions seem to be doing quite all right so let's see what we can do now now that we have our predictions from our testing model we can actually start testing I mean evaluating our model to see how well we did okay so I'm going to write this down right here and I'm going to do um like this let's do evaluation of the model there we go and now right here we're going to also from scikit-learn import an evaluation method that we can use so let's do SK learn dot this time we import it from metrics and import accuracy score and that means that the accuracy is going to be equal to accuracy like accuracy score of then we have the first one is going to be the actual values and then the second one is going to be the predicted values and it's basically going to return us the accuracy of our I mean our percentage of the accuracy of our of our predictions so let's do this we're going to do the accuracy it was we're going to say like here is C and let's round it to two decimals how about that and I suppose this should work so let's see there we go so now we have the accuracy for our model was 98 which is basically amazing um we did a pretty good job here the evaluation looks pretty good and now let's get into I mean let's do a little bit more of an evaluation let's check the Precision um the Precision the recall the F1 score which are some I mean if you want to go more deeply into the statistic statistical side of it this might be useful for you so also from scikit learn sklearn dot metrics oops metrics we're going to import a classification classification report then we're going to print it we're going to say classification report and we're going to call as well the Y test and then our predictions to see how well we did and here you have it as well you have the prediction you have the recall you have the F1 score you have the support um so I mean this basically the predict the Precision for for negative um diagnosis which is like when it's not when it's benign so when it's not malignant was 99 and for the malignant ones was 97 which is pretty good we had the recall F1 score and support um so I mean that's pretty much all the evaluation that we're going to do on this tutorial but just so you know I mean I mean it you you can you probably need to to go through some of the steps to actually evaluate it more thoroughly but this should be good enough for starters um in conclusion you already have a model uh right here and this one right here this LR is the model that you can use to predict um what your what whether or not your cell that you're going to be measuring is actually a malignant cell or a benign cell and this is extremely useful because now that you have a model inside of a python variable um I mean you built it in Python so you can basically just put it inside a server in flask for example or whichever other backend technology that you can use in Python and just build a server around it you can build a rest API around it and I'll pull another rest API but you can build an API around this model and then basically just make your users um feed some data to your front-end application then you send the data to your backend application you perform the prediction then you return the value of your prediction so this can be useful for doctors in the sense or you can basically probably plug it to some automated Automated machine that is going to be able to measure the cells and give a diagnosis immediately to some patients and of course this logistic regression method you can also use it in finance to predict to make predictions about whether or not a client is going to default about a loan or if they should get or not a credit card Etc so since it's clearly callable remember that you can use it pretty much anywhere um what else can we say um hmm yeah I guess that's pretty much it don't let don't forget to let me know if you have any questions uh please like And subscribe if you liked it and yeah um this is a series in which I kind of show you how they design send some machine learning models work in order so that you are able to use them in your backend applications if you're a software developer if you're a data scientist um beginner this is I mean of course also useful to you to learn how to use these models and what is the intuition behind them and yeah I hope this was useful for you and I hope you enjoyed it and just you can subscribe in order to get all of the other tutorials on data science for software development so cheers [Music] [Music] [Music]
O2Cw82YR5Bo,2023-02-13T06:07:00.000000,Linear Regression in Python - Full Project for Beginners,all right good morning everyone how is it going today um today I'm going to be showing you how to do a linear regression model in Python this is going to be pretty much the same tutorial as I showed you before using R but this time we will be using python okay um basically what we're going to be having is an e-commerce data set with several um with several variables and in the end we're gonna try to predict based on those variable variables um how much a customer is going to spend per year in dollars okay and then we're going to try to evaluate our model to see how well we can predict the state from the state okay so let me just explain to you real real quick how this dataset works so we have um the business situation is that we have a we have a clothing store that offers free um appointments to their clients with a stylist then the clients come in person to the shop they have disappointment with the stylist they try and try out new clothes Etc and then after a 30 minute ish session they can go back home and they can order what they want they want what they enjoyed so they can order either from a desktop application or a mobile application okay and we have some other variables as well and we're going to try to predict from these variables how much that person is going to spend per year okay you can find this data set on kaggle it's very common for studying linear regression I'll write up a link I'll link in the description okay I already downloaded it so I'm not going to re-download it it's already here as you can see in inside my notebook file there you go so it's this one ecommerce.csv and let's just work with this all right so there you go um so I'm just gonna show you a little bit how the data set looks like what the date this it looks like so first of all of course we're going to import the libraries that we're going to use for the analysis so pandas we're going to import matplotlib matlit lip a thumb pipelate s PLT and then we're going to import Seaborn as well for some visualization as SNS there you go um there you go so now that we have our libraries we're going to have to read our data I'm just going to do it like this I'm just going to do PD read CSV and then we're going to just write the name of our file okay this time I can just write it like this because the file exists in the same location as my notebook okay but if that's not the case you would have to find it like here users and then your user all the path to your file but here since it's in the same folder I can just write the name okay so there you go now now that we have the file we can start to look at it and see what it looks like I print head um to see the first elements of the data set and here we go so we have an email we have an address we have the Avatar which is probably the name that you use in the online platform we have the average session length this is the session that I told you that they spend with their with a stylist in place okay we also have an average session length and I'm sorry the average session length we also have the time on the application which is the mobile application that they spent before they actually make an order so when they go back home they open their phone they spend like this person spent 12 minutes in the application this person spend 11 minutes in the application before actually ordering and then we also have time spent on the website we can see that people tend to spend a longer time on the website before actually ordering and we also have the length of their membership in months so this person has been a member for the store um for four months this one for two months three months Etc and this one right here is the variable that we're gonna try to predict it's the yearly amount spent in dollars okay so this person spends 50 [Music] 587 392 Etc okay um and the way linear regression works is that we're going to take several of this um numerical variables and we're going to create a model that is going to predict how much they spend based only on the numerical variables okay linear regression works with numerical variables too a numerical variable as well so let's get right into it to analyze a little bit more how this works I'm just going to move myself all the way here to analyze a little bit more how this data set is structured we're going to run info right here and this is going to give us a little bit more information basically just displays the name of the column so we have email address the avatars I told you the average session length kind of time on the application time and website just what we saw before and we can also see the data type okay so we know that from the average session length to the yearly amount spent we have float64 which is a data type for numbers with decimals and yeah so I mean that basically means that what we're going to be using is this only from column three to column seven so that looks pretty good um something else that we can do to try to understand a little bit better our data set is we can run this scribe like this and this is basically just going to give us some statistical information about each of our numerical variables so as you can see we have I mean you can see that here as well 500 observations we have 500 observations for each of the variables of course um and then we can see the mean for each one of these for example the average session length as I told you that it's 30 minutes ish for everyone so the mean for that is 33 and you have the and it's the a standard deviation of 0.99 which means that mostly it's um very very close to 33. same the time on the application is 12 your time and website average 37 we have a minimum of 33 minimum of 8 Etc okay so I mean this is basically just to give you an idea of how much um of each of the numerical variables and this is very important as well to check this after you have done your your model construction to actually know that what you are I mean that what you are getting actually makes sense so for example here you have that the yearly amount spend you have a maximum of 765 a minimum of uh 256 and an average of 499 if your prediction returns that someone's going to spend like 2 000 um for similar session length and time and application Etc I mean you probably want to check again your model because there might be something fishy about it but yeah I mean this is basically how it works um so let's just start doing some Eda okay some some Eda exploratory data analysis okay um I'm just going to guide you through some plots so that you can um compare different variables together and we're going to be using Seaborn which I imported up up here before and for Seaborn we're going to use a joint plot right here up joint plug like that okay um basically it takes several it takes some arguments it takes it it takes an X argument that's going to be the variable that's going to be plot plot on the x-axis and for this one we're going to use time on a website I'm just going to copy it from here so that I don't make any mistakes any spelling mistakes and for the Y we're going to of course use our predict our Target variable which is the one that we're going to try to predict and then as data we're just going to say that our data is our DF variable there you go then let's run it and here we have it so as you can see a joint blood is basically a scattered plot which makes one point for each observation and it also creates a histogram of the variable on on the other side of the axis so that's pretty convenient that gives you an overall view of the relationship between two variables here you probably cannot see it extremely clearly because having its many points are cluttered together and clustered here so you don't really see how many there are actually so a good thing that you can do is that you can pass in an alpha argument like this so now you're passing a parameter of Alpha and that basically means that each point is going to have an alpha and opposite an opacity of 0.5 which basically means that the more points are on the same place the darker it's going to look so here you can see it's very faint and here you can see that it's starting to be a little bit more um dark so basically means that there are more points right here it's just easier to visualize the concentration of points so there you go this also like allows you to see if there is any relationship between the two I don't see any correlation here I mean it's not very easy to see but let's let's test another two two variables okay I'm just going to copy this code right here and instead of using time on the website I'm going to say that the time on application remember that right here I am passing the name of the variable and the name of the variable is time on app okay that is why I can write it like this I'm just going to run it and as you can see here you have a little bit more of a correlation we have time and application from 0 to 15 minutes as we had seen before and you have the yearly amount spent and you can see a faintly correlation a faint correlation in which the more time people spent on the application the more money they tend to spend um in the on the year okay um so that's how you do like bear plots it's very convenient to compare two variables um I'm going to show you um sorry yeah join put I'm going to show you how to do a pair plot this time okay burplete purplets are a little bit more com like a little bit more a little bit heavier because they compare all of the numerical variables at the same time so if you if you are just starting out your analysis you might want to to do this one but try not to overload it with 100 numerical variables it's just going to give you um too many too many too many plots to actually visualize so this one right here works pretty good right now because we don't have so many so many numerical variables so I'm just going to pass in our data um and then I'm going to say that it kind of fit the kind of blood that I want is a scatter plot and there we go um hmm let's just passing this argument right here set an alpha again let's set an alpha of zero point four all right let's see how that looks pair plot not parallots um all right what's what's the problem here is supposed to be an S there you go all right there you go um so basically here we have just what we had before but it's comparing all of the variables at the same time and if at some point you have the same variable against itself it just creates a very a very simple histogram okay this is basically just to add the alpha as I told you before to so that you can visualize the the concentration of points a little bit easier um so there you hope there you go um you have the time you have the correlation between time and application for example against average session length Etc of course what we are interested in is basically the last line right here or this last column right here which are the ones that talk about the yearly announcement which is our Target variable so you can see that there is a faint correlation as well between the yearly amount spent and the average session length um timing website doesn't seem correlated at all as we had seen before and there seems to be a lot of correlation with the length of membership so I mean this is basically just to give you some general idea of what is going on um all right so once that you have like understood a little bit better what is going on with your data set and how it how it behaves and your variables that how some correlations are expressed and some correlations are not very don't seem to be very important we can actually start building our model okay um all right so let me show you real quick what is actually going to happen during the model okay to do that I'm just going to write a single plot right here which is going to make it a little bit easier to visualize this one called this one's called LPM plot which is linear model plot and it's very convenient to actually visualize what is going on so I'm going to plot the length of membership this time [Music] this is not supposed to be a comment length of membership like this and that's an X now for y I'm going to plot yearly announcement and then the data is of course going to be rdf like that and then just as before I'm going to add an alpha right here um nope the alpha scatter and then we add an alpha right here this is basically when you have like a little bit more of a complex um plot you sometimes have to use this kind of um parameters to actually set up the alpha but there you go I think that's all so let's see how that looks like there you go okay so here what is going on is very simple we have the scatter plot that we built right here okay and so what we're going to do basically imagine that we only have two two variables okay this is a very very basic explanation of linear of linear regression imagine that we only have two variables we have the length of membership and we have the yearly amount spent and you see that there is a faint correlation uh I'm like a like a strong correlation between these two um all right so what we're going to do is we're going to ask the computer to write to create a line right here that line is it's um in the first time that it's going to create the line it's just going to write a very random line it might be somewhere like here one to one Etc okay and then once the line is is created it's going to start measuring the distance from each point to the line okay so here here we have one distance here you have another distance here you have another distance and it's going to square them like this one say it's 12. this one say it's 15. this one say is 40 and it's going to square that distance that means that the higher the bigger the distance the bigger the square so um bigger I mean bigger distances are going to be more penalized than smaller distances okay so basically it's going to it's going to measure the distance between the line and every single of this part of this um of these dots it's going to add them all together and then it's going to tilt the line a little bit and it's going to continue doing that until the sum of all of these distances of this Square distances is the minimum possible distance that you can get that's I mean other way of seeing it is that it's going to write create a line that is as close as possible to every single point in the scatter plot okay and that's basically what a linear regression is for two variables it's just trying to create a line that gets the least sum of squares of all of this but of all of this um of all of these dots now imagine that we that that's what we're doing with two with two variables now imagine that we want to predict how much uh someone's going to spend if they have six months of of if they have been a member for six months and what the purpose of this line is that you're going to go here and you're going to check and you're going to see oh okay so this person has been a member for six months so it's going to be somewhere like here and then you're going to calculate them the value of your function right here and it's going to basic probably 640 or something like that so you're going to predict that it's going to be 614. that's all that is going on with the linear regression and as you can see I mean it might not be perfect but it's pretty close to actual values so it's it's a good enough model to do predictions now this is with only two variables now imagine you are doing exactly the same thing but with more axis then more than two axes so you can add a third variable right here and you have like Scatter Plots in a three-dimensional space and you have a line that is passing through them okay so all that we're trying to do is find the equation I mean yeah the equation that describe this line into into dimensions in three dimensions and in N Dimensions right so that's basically very very basically what's going to be doing um this model that we have right here which we're going to import from scikit-learn okay um so to actually apply that we're going to add a scikit-learn um and then we're going to add it from model selection there you go and then from here we're going to import train test split okay what we're going to do right now basically with this with this function that we have just imported is we're going to tell take all of our data and we're going to divide it into a training set and into a testing set okay um the reason to that why we're doing this is that we want to take let's say 70 of our data and we want to show it I mean we want to create this function that is going to predict the the value of the yearly amount spent and but we don't and then we we're going to have to test it of course to see if our predictions of this function are correct but we cannot test it with the same data that we use to create the model so that's why we're just creating a different data set a different um portion of the data set to test our model in um so basically what we do here is we're going to quickly say that we're going to have to we're going to have um two sets the first set is just going to be all of our predictive variables okay which basically is all of this right here let me just copy this for you there you go so we're going to have our data set and remember that to to choose a certain set of columns which you can just say all right so I want the Timon app [Music] this is basically just going to up show you is basically just going to select all of the time on the application all of the values in the time off location column if you want more than that you can pass a list with the names of the columns like this so you can say the timeline application and you want the time on website too like this there you go so oop uh what is going on here yep I'm gonna close it like that so now you have Diamond app timing website and you have a different data data frame with time on application and time on the website what we're going to do right now is we're going to basically we're going to create a data set with all of our predicted variables without the target variable the target variable is of course um the one that we're trying to to predict and our predictive variable is basically just going to be yearling amount spent like that so there we have it we have our predictors and we have our Target and now what we're going to do is we're going to use this one right here to make this split into our training set and our test data set um so to do this we're going to create a variable called X train one called X test another called y train or and another one called y test okay remember that in Python you can just um initialize several variables at the same time just by separating them with a comma as long as your function is returning several variables as well so that's I mean that's what basically what this function right here does it returns four values one for train one for test one for one for the predictors for training test a one for the target for test for training test um so there you go so you have the train test split um the first argument that you're going to pass is the predictors and the second argument that you're going to pass is the target variable then you're going to just set your test size um basically this means how big your testing um how big your your the port how big it how big is going to be the training section the testing section of your data set okay so we're going to train on 70 of the data set and we're going to test our model on 30 of it so let's say 30 which is 0.3 and then after that we're going to set here a random state right here this um this argument is basically just any number I mean whichever number you want to to add right here it really doesn't change anything the idea behind this is that if you ever want to reproduce I mean you're creating a random uh split okay so if you ever want to reproduce the same split you're going to have to pass in the same number so that's basically that's basically all that we're doing so that means that if you pass in here one um and if you sometimes want to reproduce this same split you're going to have to pass the same data and the same number one um a good rid of that rule of thumb is to always go 442 because that's the answer for everything um there you go so now basically we have just created our four variables let me show them to you X string um you might be wondering why X is an uppercase and Y is lowercase and that basically is just to mimic mathematical language in which Opera I mean uppercase variables are often expressed several um a matrix of several other variables and lowercase variables expressed just a single single value so here is since X represents several predictive variables using it's in uppercase and Y since it represents just one variable it's in lower case so you can see that here we have X strain we have 350 rows and we have our numerical variables then we have let's say X test we have exactly the same amount of the same number of columns but we have only 150 rows because this is the number of rows that we're going to this is the number of observations on which we're going to test our predictions same with Y we have y test which is 150 values and Y train which is 315 right basically that's our split so there you go now we're going to actually train our model okay um let me just write right here training the model there you go um okay so to train the model we're going to also use psychic learn and we're going to do from um it's a scale learn psychic learning case I didn't mention it before it's just a library um with many machine learning models that you can just import and use um it's as simple as what what I'm doing right now you don't have to actually build the model it's built for you so linear model and we're going to import linear regression like this so now we have imported so I could learn now what we're going to do is we're going to basically just initialize an instance of this model like this linear regression oops here we're just calling the function that we just imported let's run this so there we have it linear model this is our model and now from this linear model we're going to want to fit the data to it that basically means that we're going to train it okay so let's see LM fit we are going to pass in X strain which is the training portion of our data set and then we're going to say y train basically we're just selling it all right so given this variables that we have right here every time it it should return this thing okay so given this x you should return this Y and it's going to try to find this the the equation that is going to pre that is going to predict this function right here there you go um so now oops what is going on yeah there you go so basically we have now created our data uh our model and we have trained it all right so now something important right here now we're going to have to take a look at our coefficients okay so basically let me just show you what I mean lm.fit no sorry LM that co-f like this this basically just returns all of your your coefficients but what are coefficients in a linear regression model all right so um let me show you linear regression formula all right so basically um let me face if I can find a little bit easier formula to visualize um actually I had one in on my medium thingy all right so basically a linear regression is just um basically a linear regression is just a this formula right here this formula right here okay so I mean for any for any line in a two-dimensional plane you can describe it using this formula it basically is that you're predicted value is going to be um some intersection with the x-axis which in this case is somewhere around 200 and something ish plus a coefficient plus your coefficient that modifies your your X that like weights your x value okay uh your X variable and the more variables you have the more coefficients like this you have so basically this coefficient is going to tell you how important your variable is and here right here you have the coefficients for each of the variables that we have that we have created so let me show you this real quick um to show you what how the coefficients look I'm just going to do this like this PD we're going to say we're going to create a data frame data frame from our coefficients that we have that I have just showed you co-f like this then you're going to take Exit columns and the columns are going to be equal to co-f um then let's just print it let's see how that looks like all right so basically I just run the columns as observations and then one created one column for the coefficient and this coefficient is basically this right here this type this just gives us how important each of the variables is to our model okay so basically instead of having just a simple linear model with one variable we have a multiple linear model with multiple variables so we have our that our predictor that our Target value variable is predicted by a coefficient of an intersection with zero and then we have one coefficient for the variable one one coefficient for the variable two one coefficient for variable three and all the way until n variables here we have four variables so these are the coefficients for which one for each one of them and of course each each coefficient I mean the higher the coefficient the more important the variable so here we can see that the variable that is actually having the greatest impact on our Target variable is length of membership which is 61 then the next one that is important here is the time they spent on the application and then we have the average session length all right so what we're going to be doing right now is basically we're going to use this model that we have just created using this equation that basically is just a relationship between X and Y all the x's and Y with different coefficients and we're just going to use it to to create some predictions for our data okay so let's just write it down right here predictions um I'm of course I'm going to write to leave this Notebook on on the description so you can check it and I'm going to add some other some other titles so that you can so it's easier for you to actually follow through the notebook to see what's going on um all right don't forget to like the video of course please that helps a lot and all right so so the predictions we're going to for the predictions we're going to Quick store them in a variable called predictions and basically we just run this method on our model that's called predict yep predict like that and basically we just say we just give it some values of X that we want to test in now if you remember we had just we had create previously created a test X section so I mean subset of our data set that we were going to use to test so we just give it to it like this X test like that and basically this is just going to let me show you this is just going to return an array with all the predictions that it of what it thinks it's going to be the Y column I mean the target column which is the um the amount yearly amount spent based on the X that we gave it okay so that's basically all that it's doing it just returned um the column um on the left side um all right so um what I'm going to do right now is we're going to create a scatter plot to see the actual values because remember that we had a y test as well which is the actual values of those variables so what we're going to do right now is we're going to try to plot the this predicted variables towards against the actual values and see if they form some sort of straight line because if they form a straight line that means that our predictions are rather accurate because everyone I mean if the prediction was 200 and they actually spent 200 that's going to be a one-to-one relationship and if it's a one-to-one relationship in every single in in every single case then it's just going to create a a straight line of one to one okay so let's see how that works basically I'm just going to use Seabourn again to do this I'm going to do a scatter plot and on the x-axis I'm just going to say that let's add the predictions on the x-axis predictions and on the y-axis we're going to add the actual y value which is y test um um yeah I think that's how it goes yearly amount spent I'm just going to add another another name right here PLT let's add an X label of predictions this basically is just going to add this label right here that is going to say that it's a prediction there you go so here you have predictions and the yearly announcement you can also I mean of course you can add a title if you want um evaluation of our linear regression model so there you have it we have title and as you can see our predictions if at some point the prediction was 400 and our actual value was 400 ish I mean that basically means that our model seems to be rather good as you can see this sort of creates a straight line so our model seems to be rather behaving rather good um let's just make some other measurements to see that it actually works okay um scikit-learn actually comes with a with a set of evaluating methods that you can that you can apply to see how your method did and that's basically what I'm going to do right now let's import from scikit-learn scikitlearn.metrix metrics and from there you're going to import the mean squared error and the mean absolute error okay and let's import math as well because when we're going to do some operations as well basically I'm just going to ask you to print the mean absolute error if you don't know what these things are you probably want to look them up I'm just going to explain them real quick um but let's just show you this real quick okay so we we can use the mean absolute error of Y test white test and predictions against the predictions like that and then instead of the mean absolute error we're going to use the mean square error like this and then here we're going to use means squared error and then the last one is actually going to be the root mean squared error um it's working it's quite error just like that and actually I don't think there's a for uh get a function out of the box for this one so I'm just going to do this like real quick like I'm going to use math let's see actually I have the formula right here I'm just going to copy it real quick for you there you go there you go okay so basically it's the square root of the mean squared error uh yeah so there you go um all right so let's see how that looks like so the mean absolute error is basically the average distance of upon of every point to the actual line okay so remember that we had this line right here that it describes our model and then we have several points around it um basically what we're doing here is we're saying so what is the average distance between this line and every F and the closest point I mean and the point that it's supposed to predict um so the average distance is eight um units and that's very telling because the mean absolute error actually is in the same unit as your variable so which means that this is eight dollars and I mean um I mean distance I mean error of eight dollars is actually pretty good considering that our yearly amount spent usually lingers around five hundred dollars so I mean eight I mean an error of eight of eight dollars in an 800 prediction in a prediction of a value that usually is between around 500 it's actually pretty good we have a mean squared error as well which is one 103 this one um basically it's the same thing as the mean absolute error but every time that there is a distance between the predicted viral value and the value that and the real value um you square it so you take the square of it which basically means that the longer um yeah the bigger the distance between the predicted value and the actual value the more it's going to be penalized okay so if you have a distance of one the square root sorry this Square uh error of that one is going to be one but if you have an error I mean and that's going to be considered into the error but if you have a an error of of 10 then the then it's going to add 100 to your to your to your to to your metric and that's like that's just going to I mean you can see that the bigger the error the bigger the the most the more important it is and this one is basically just this one is also in the units of of um in the original units so I would say that this this model seems to be looking pretty good um something also that is pretty important that we need to do is we need to analyze the residuals okay so I mean linear models uh like linear regression usually assume that the residuals of your predictions is going to be normally distributed okay which basically means that your residuals which is to this I mean what I told you the distance between your model prediction and the actual um and the actual value are going to are supposed to be random if they're random then they're supposed to come they're supposed to fall on a normal um distribution so let's see how that works so we have the residuals which as I told you is basically just the the actual values minus your predictions that's all there is so the first thing that we're going to want to do is we're going to plot this residuals and see how they are distributed okay the easiest way to do this is to create just a histogram with with your with all of your residuals and see how they fall into the distribution okay this we can do the we can do it using Seaborn so basically I'm just going to use SNS dist blood like this and I'm going to pass in the residuals which is basically let me just show you real quick what the residuals look like okay so as you can see it's basically just the distance between the predicted vial value and the actual value for each observation so for observation 361 the predicted value was something and the actual value was something else and the distance or the difference between these two is minus I I mean it's 2.63 okay um so yeah there you go um now what we're going to do is we're going to test for normality because linear models actually assume that if you are using um yeah linear models actually assume that if you if you make a prediction using linear regression the residuals which is this distance of the things of the actual prediction and the value the residues are supposed to be random if they are not random that basically means that there is something sketchy about your about your model and it's biased towards something so if your residuals are completely random that basically just means that the errors come from nowhere but from just the statistical um uh not I mean non estimate statistical errors that are normal to find in in any prediction okay so in order to file to test for these errors what we're going to do is we're going to write this the we're going to create this histogram so to do that we're going to use the display that I mentioned before and I'm going to plot the residuals like that and let's see how that looks like all right this is starting to look pretty normal I mean there is some sort of a tilt on there's some sort of a skew on the left side but I think it could qualify as I as a normal distribution uh let's just augment the number of bins that we have here so we have 13 bins I mean beams basically means how many of these bars we're going to be creating so the more bars the I mean the the less clear the the actual distribution is so it but I mean you can play around with it just to try to find some um bin number that actually it is easier to visualize for you and then if you want to actually plot a the distribution right here we can use KDE and just set it to through to true and it basically is just going to add this line that's going to allow you to see the curve that is going to allow you to basically see a little bit better if it's a distribution a normal distribution or not another graphical method to test for normality is to create a QQ plot okay I'm not going to explain to go into the details of what is a QQ plot because I mean the video is already getting quite long and I it's not the objective of the video but basically it's a plot that you have normality on one side and you have your residuals on the other side and if it's and if it creates a straight line if it's one to one It basically means that your that your that your residuals are normally distributed so let's see how that works we have side pi and stats that we're going to import and we're going to import it as stats like that and then from stats what we're going to do is we're going to call probability plot like that and we're going to call we're going to pass in the residuals the distribution that we're that we try to test for is normality and let's say that we wanted to we want to plot it using pilot like that now we just do pile up that shell um there is not supposed to be two T's here and residuals is actually spelled with an E not an a of course and normal no it's not supposed to be normal it's normal all right sorry about that there you go so there you have it you have your probability blood basically what I told you is that if it's normally distributed it's going to resemble it's going to approximate the straight line as much as possible so this looks good enough there are also some analytical methods to test for normality but we can discuss that in another at another time all right so I hope you found this useful I hope that you enjoyed something that you learned something from it and yeah I mean so I mean the application for this are are huge I mean you can of course be doing just a linear regression for your company um based on some data set that they give you and you just give them some predictions but also I mean the big Power of this kind of models of them being automatized um automated like this is basically that you can run this in a server and connect it to a web application for example so I mean there are several I mean you we're using python here and there are several backend Technologies for servers and if you I mean you see that there is very little very little code um involved in this prediction so if you train your model and once your model is trained you put it up on your server you can basically use it to make predictions um if you connect it to a web application and then it you can basically just return your prediction using this test so that's basically all the power that comes with it being so simple and so automated in Python um all right so I hope that you found this video useful I hope that you learned from it please leave a like if you enjoyed it and yeah follow And subscribe for more and gonna be putting up some more um machine learning models and explanations for you probably some web Technologies as well um all right so I'll hope to see you next time ciao [Music] [Music] [Music] [Music]
jD6813wGdBA,2023-02-06T06:07:00.000000,React Leaflet Tutorial for Beginners (2023),good morning everyone how's it going today my name is Alejandro and I'm a software developer working from France um in today's video I'm going to show you how to develop a react leaflet application or reactively flick component actually and actually I'm just showing you pretty quick the end result of what we're going to be building today so basically you have a an interactive map you have um you have some markers right here and each one with its own pop-up and also something pretty interesting about it is that when you zoom out these markers that were pretty close uh together they get clustered together into one single marker one single icon displaying the number of markers behind it so that's what we do with the with the leaflet marker cluster and I'm going to show you how to do this in react um pretty quick pretty simple so let's get right into it okay mm-hmm now for this video I'm going to be using Code sandbox um it's basically just so that we are um so we have this project already set up with react but you can also follow from a local environment if you create your app using feed or create react app Etc okay I'm just going to show you pretty quick the environment right here we have our app.js which is where we're going to be building our map we have index.js as well which is the root of our application and also of course we have our index.html which is the HTML page where our react tab is going to be included um let me show you something pretty quick as well we have some styles.css that are imported into our application and I'm actually going to change some things here pretty quick um just some standard things let's set the Box sizing to border books like that then let's set the margin to zero and then let's add the padding to zero so that we have actually full control of our sizing and our Styles in this application um second of all we have that our application is going to be running on the div with the ID of root and I'm just going to set it a height of 100 VH all right so that's something that's all that we're going to be doing here on style.css and let's get right into building our application all right so what are we going to start by doing first of all actually we're going to install leaflet and react leaflet and to do that we're going to have to install them right here adding the dependencies so I'm just going to look for leaflet like this and I'm going to look for react leaflet um leaflet like lift lit like this okay just so you know what I'm doing right here when I'm adding dependencies is pretty much the same thing as as if I was just doing npm install leaflet npm install react leaflet okay as you can see um after what I just did right here they just appear in my package the Json um right here leaflet and react leaflet just as if I had installed them using npm install Okay so that's how it works now let's go back to our application right here now that we have installed and there's dependencies that we need and let's start importing our components okay the first component that we're going to need to import it comes from react uh react react leaflet and it is map container like this that container from react leaflet okay now this is actually not a default export so we're going to have to import it like this and let's just replace whatever is inside here with this new component that we have imported so it's going to be map container like that and it's actually going to have an opening tag and a closing tag as well because we're going to put a lot of things inside it all right there we go now in order to initialize it we're going to have to actually set it um Center like this and for this video I'm actually going to center it in the city of Paris and the coordinates for the City of Paris I actually have them right here so let me just copy them and paste them like this okay so these are the coordinates where your map is going to be centered on and then you also need to pass in a second um param which is going to be the zoom level okay I don't remember exactly which are the zoom levels available on leaflet but I mean if you want to see the entire city from a distance a zoom of 13 usually works pretty well okay now there you go now we have our map container the problem is that the map doesn't have anything inside of it and in order for our map to have something inside of it we need to actually show the map tile layer okay and that's very easy to do if you saw my previous video on I mean pretty much the same tutorial about leaflet but without using react just using vanilla JavaScript you know that we have to use tile layer but right here we actually flip creates a very very convenient component that we can just add like this now this is going to be a self-closing tag and inside the tile layer which is going to be the actual component that is going to show the the tiles of our map um the first thing that we're going to want to add is the property of attribution we're going to be using openstreetmap which is a free map provider and I mean it would be pretty nice if at least we just attribute it to them um it's already free so it doesn't cost us a lot this right here what we're adding right here is basically what you can see down here at the bottom open street map contributors just so I mean just to to attribute it we're already getting it for free so so next we're going to add the actual URL of the tile um and to do that actually we can go to oops leaflet JS and here we have a map tile layer that they use for their tutorial and it looks pretty good so we're just going to use it ourselves too like that there you go now if we if we hit save we should have our map working but the problem right here actually you know what I'm going to just add it like this hmm all right so the the problem right here is that we already have our map and it's supposed to be loading and everything's supposed to be working correctly let me just reload this so that you see that we don't have any errors in the console but the problem is that our map really doesn't look very good um the tiles are all over the place and it doesn't seem to be loading correctly for some reason but I mean at least we're getting something um all right so the problem with this happens is that you leaflet actually consists of um a JavaScript site and of a CSS site and now when we do npm install we're getting both of them but we're actually for the moment we're just importing the JavaScript type because we're only importing the the JavaScript components the react component so what I'm going to do right here is actually import the CSS just like that and I'm going to say that it comes from leaflet and if I'm not mistaken the path to the actual CSS is this Dot and then leaflet dot CSS there you go all right so now we have leaflet being loaded into our application but another problem again um the map is gone um and why is this happening um the problems actually that the map is actually loading let me show you pretty quick if we inspect this map right here we have the ID root and we have our leaflet container right here but the problem if you see is that it has a let me show you problem is that it has a height of zero for some reason and actually the reason is that we actually have to set a size for this container to do this we're just going to go back to our Styles and this is pretty important every time you work with leaflet we're just going to set the sizing off map container and the map container is called leaflet container by default and let's just set a height of a hundred keyboard height there you go so now we're going to get a full screen map I'm just going to refresh it so that you see what's going on and there you go we have our working mat centered in Paris as we wanted it to be at the beginning so there we go um what else can we do right now um all right so we have added our map container our tile layer let's just add some markers to it okay all right so how do we add some markers I'm going to I'm going to make it as though we were actually importing the markers from an API so I have here just an array of markers that way you're going to be able to use um it's every marker and I mean in this like mock API that I'm supposed to be testing returns a geocode with the location of the marker and it also has some HTML test for the pop-up okay so each marker is going to have its own pop-up and its own location so let's do that now in order to show you how to do it I'm going to map through all of these elements okay um so first of all we're going to call the markers and then we're going to use the map method around it and we're going to say that for each marker right here we're going to be returning we're going to be returning our a marker element like this um now as you can see I imported marker from leaflet by default but we actually don't want it from leaflet we want it to come from react leaflet so let's add it like this there you go and now here let's create our marker there you go now this is supposed to work if I'm not mistaken there you go and in order for your marker to actually work you you're gonna want to set it at position set a position to it and the position of our marker in this case actually comes from our element right here and it's going to be dot marker.geocode okay so let's just write it down here marker Dot geocode there you go so all right so now we have our three markers and it's working pretty good um the problem is that we don't have an icon for these markers um of course leaflet comes with a default marker icon that you can use and you can activate it if you call back um the core of leaflet but actually this is a pretty good opportunity to show you how to create your own custom icon okay so to do this what we're going to do is we're going to actually create our custom icon like this now that we have imported the markers right here a little bit down here I'm going to create my custom icon like this there you go and actually to do this I'm going to have to create a new icon and this one right here actually is not um a react component but this one actually comes from leaflet so I'm just going to say import new icon and this one actually comes from leaflet so I'm just going to save it like this and this instance actually to initialize it we require two things okay the first from if we require is icon URL like this and the second one is this size okay so for the icon size we're just going to set it to very standard 38.38 pixels this is going to be the size of the icon there you go and now this right here is going to be the icon URL that we're going to load in order to actually show something right here um there are several things that you can do for example let's say that we want an icon from Flat icon all right let's say that we want let's say which one do you want we can actually use we can use this one how about that yeah we can use this one so one possibility is that you can download it and import into your application that works pretty good and another possibility is that you can just copy the the URL of this image and it sometimes works let me see if this works this time so let's come back to our application right here and let's just paste it right here and let's see if that works um well for some reason that's not working um oh wait sorry actually this is obviously not going to work because we're not using our custom icon yet um actually another element that we have to add right here is the icon so in order to add an icon you just said you set an icon param here and you're going to pass your custom icon and my custom icon is custom icon like this and actually it works so there you go you have our three icons that come from our um flat icon CDN directly or another possibility of course is that you can basically just download it and or use your own icon that you designed in an SVG or a PNG format okay so let's say I want I want this one instead so what I'm going to do I'm just going to download it and once it's downloaded I'm going to add it here to my project and I'm going to add it to image there you go oops gonna put it inside an image folder and I'm going to rename it I'm just going to say that the name is going to be marker icon like that so this is the one that we're going to be using now and in order to actually make it work we're going to want to import it right here so instead of calling the actual URL like this I'm just going to comment this out and I'm going to add a new icon URL paramet here and I'm going to require the icon that I have just added to my image folder okay so it's right here and it's inside image and the name of the file is marker icon dot PNG Lambda is taken and here we're missing a comma there you go so now our marker is working correctly um be sure that actually you have set the icon size because if we remove this thing the actual size of the icon is going to be the actual size of the image which you probably don't want right so yeah be sure to set the icon size to like a pretty standard size is 38 by 38 or you can also add something different like uh 40 or something I mean but there you go I mean this is pretty pretty important thing to do um so there you go so that was how to create custom icons we created our element from the leaflet library and then we just imported it here as a param to our marker component so there you go um then how about we actually add the pop-up to our to our draw markers so to do that basically we're just going to want to add a pop-up element and since this one right here is a react component we're just also going to have to import it from react leaflet so now that we have imported it right here we can use it down here and let's do pop pop like that and inside right here we can add any pop-up and it's going to be bind bound to the marker in question okay so and inside right here actually you can add any HTML that you want that's why leaflet pop-ups are so so good I mean it's just a space where you can add your own HTML so let me see let's just add an H2 and let's say hello I'm uh there you go and then we can check here right here and there you go we have three pop-ups but the problem is that the three pop-ups right here are identical and we want each of them to have their own pop-up so remember that we imported our markers right here and we are pretending that they come from an API and the actual pop-up comes with I mean the actual marker comes with an attribute property called pop-up and this is supposed to be some HTML and so it's obviously going to be different for every marker so we can just call this property right here instead of coding it this hard-coded we can just add marker pop up like that and there you have it now each pop-up each marker has its own pop-up pop-up one iron pop-up two and right here I am pop-up three so there you go um all right so that's how to add markers and how to make your map work in react looking pretty good something pretty important as well let's just have them cluster together because I mean so far if you move if you zoom out they just like become like too crowded and in the in that very little space very small space so what we're going to do is we're going to wrap it all the markers in a different layer that is going to be the marker cluster layer and that's very simple to do but we're going to need another dependency right here so let me add this dependency it's going to be called react leaflet react leaflet cluster like that there you go remember this is exactly the same as if you had done npm install okay so right now what I'm going to do is I'm going to import this new component called marker cluster group from react leaflet cluster like that there you go and this is the one that we're going to be using to actually create our cluster okay so let's see how we can do that um basically this is a react component that we're going to add right here then we're going to wrap all of our markers around it like this there you go um so I mean basically now it's supposed to be there you go there you have it if we zoom out we have this new cluster group it's displays the number of elements that are behind it as you can see I mean you probably cannot see it because it's very faint I'm gonna try to zoom in a little bit more but yeah I mean you can see that here it's a three and then if you click you yeah I mean it zooms in and it displays the three um the three markers that are behind it um but right now what I'm going to show you how to do is to modify that that icon right here to make it your own okay um but first of all something pretty important that you're gonna want to do is right here inside Mark your cluster grip you're going to want to pass a couple of of um attributes and the first one is going to be chunked loading which basically is going to make it allow react to load each layer each marker um one by one instead of loading them all together I mean this is basically just to help with performance and the second one is actually going to be our custom icon for the cluster so this one's going to be icon create function like this and we're going to set it to our custom function so let's call it create custom cluster icon there you go and now that we have actually um assigned it we're gonna have to actually um declare that function so let's say we're going to declare it like this and it's going to be a function that is going to take hmm one second it's going to be it's going to take a cluster a cluster argument and here we go and it's about the only thing that you have to remember about this function is that it's supposed to return a div icon element and what is a div icon element well it's an element that comes from leaflet so we're going to have to include it right here let's include Def icon like this um I think it's actually with like that there you go um so actually we're going to want to return this thing right here um or let's yeah return our new div icon like that there you go and then this one right here we're actually initializing an instance of active icon and it takes several problems the first one is the HTML which is actually just what it's going to be displayed and this um in this icon and I'm just going to say that it's going to be a div for me um it's going to be a diff for me and there you go and I'm just going to give it a class of um cluster icon like this there you go and inside of it we're going to want to actually display the number of markers that are inside that cluster and to do that actually what I'm going to do is just call this cluster element that I imported right here I'm going to call the method get child count like that so now you have the now you're going to be able to display the count I mean if I zoom out um right there's problem going on right here um let's see what's going on I'm going to add just an icon size maybe that's the problem that's going on an icon size I'm going to say that it's going to be a point 33 33 and true right here in the end there you go let's see if that works um there is something going on right here um let's just add this class name probably let's see if that works all right there's something going on right here comes custom cluster icon I can create functions supposed to be this one hmm we're written create icon and it's causing a problem for some reason let's see uh each child in the list you have a unique key prop yeah I mean of course you're you're going to want to deal with that at some point I don't know what's going on just a moment ago but there you go I mean it's working right now um so right now we have our right now we have our cluster div right here if you can see this is a cluster this is our cluster icon right here and it's displaying the number three which is the number of markers that are behind it and there you go so I mean we have the class cluster icon which is actually the class that we're gonna want to edit in order to to actually style it neatly right and I'm going to do it right here in styles.css there you go um what are we going to do with it so let's say we're going to want to make it a circle all right so let's give it a height of um 3 REM and a width not widows but width of 3 REM 2. now in order to make it a circle we're going to have to set a border radius of 50 like that and let's add a background color background color um let's set it to let's set it to White let's see what happens there you go so now we have our Circle right here and it's supposed to display our number of markers inside of it the problem is that the number of markers is very small and it's actually all the way up here and if you see what's going on actually the marker Center is up here and our div is over here so what we're going to want to do is we're going to have to Center this thing up here and that's very simple to do we just trans slate no transform if I'm not mistaken and then translate it there you go minus fifty percent and minus 50 percent let's see how that works now if we move it up there you go um um yeah there you go I think maybe it's still maybe it's not supposed to be 50 here I don't know I mean it's weird minus 25 probably yeah this seems to actually be the center I don't know why it's 25 I thought it was minus 50 but well there you go I mean the idea is to center it over the actual cluster and then let's just Center our number right here so let's say display uh Flex and let's just Center everything inside of it align item Center and justify content Center and then let's just add some color to it I mean the color is black let's just leave it like that and let's just add a font weight of 900 and a font size of two Rems let's see how that works um let's make it 1.5 there you go so now you have your actual icon um and then if you click on it you have the different markers so there you go um so that was how to create your custom cluster icon and how to make it show your markers with their pop-ups behind it um now finally let's I'm just as a bonus I'm going to show you how to actually change the look and feel of your map and to do that we're going to actually change this I mean because right here as you can see it's a very very um standard kind of map so in order to actually change how your map looks you're gonna have to add a skin to it or change I mean change the provider right here we're using openstreetmap but we can use other providers so let's say to actually find different providers you can use you can just Google for leaflet skins and I think it's this one right here yeah so right here you so right here you will find several um skins that you can use for your map and be sure to choose one that you that you know that you can use in order to know if you can use them you can go to their GitHub page and right here they have the instruction for each of the providers right here so I mean for example let's say you're interested in this one right here here you have the instructions you have the plain JavaScript that you can use and you have the actual provider and here the provider is openstreetmap dot bzh let's see what do we need for visit h b said h um visit H um nope it's not here actually probably that one's free um let's use let's see another one like oh my here for example this darker one this one looks pretty good and the provider for that one is stadia so let's see first Dahlia what are the requirements so for stadium yeah stadia there you go for stadia maps for stadia maps in order to use Stadium Maps you must register and once register you can whitelist your domain within your account settings yeah I mean so not all of these maps not all of these games are going to be completely free or completely available right out of the box but I mean you have the instructions on how to use them in their calendar GitHub page I just for the sake of the demonstration I'm just going to take up like the simplest and most um um in most um and I see a free one let's say I suppose it's um watercolor I remember that's the one that I used for in the other video I know that this one's free so I'm just going to copy the actual tile layer right here um you know I'm just going to copy all of this and let's go back to our our app right here and in order to actually import it I'm going to need this part right here there you go there you go and this right here is basically just if we were using plain JavaScript for our app so what I'm going to do here is I'm going to add another tile layer remember that this one is self-closing and just as before a very regular attribution stamina watercolor and then our URL right here is going to be DRL we just download it there you go I think that is how it's supposed to work um let's remove this one right here let's reload it and there's some problem going on right here um yes what's going on here oh yeah it's because I mean for some reason I needed to add an extension right here but it's jpeg uh yeah I mean if it's not working for you just do that I mean the default um the default website usually just adds extension as a variable but I'm just going to use jpeg like that and now there you have it you have your custom skin that is working pretty good and you have your marker that's working and remember to add our skin we just added a different tile layer which is the the component that is charged of actually importing and loading the tiles for our map and yeah I mean if you want to use the basic one from from openstreetmap you can just comment this one out and then go back to the basic one there you go so that was how to create your react leaflet map I hope you found it useful I hope you liked it and if you enjoyed it please subscribe and and yeah leave a like and yeah I stay up um I'm just like uh yeah follow and active enable notifications so that you're um notified wherever I publish new videos so there you go hope you enjoyed it and I will have a good one I'll see you next time [Music] [Music] thank you
uzOzpWu5pUY,2023-01-30T09:08:57.000000,How to do AJAX in WordPress correctly (2023),good morning everyone how's it going today um today we're going to be talking about Ajax and how to do this in WordPress I'm going to show you a few examples with a website that we were working with just a moment ago and the idea is that by the end of this video you will be able to create your own Ajax requests to fetch any data that you want and you will understand how Ajax works on the back end all right so let's get right into it and I hope you enjoyed this video [Music] thank you all right so let's get started um first of all we're going to open this website that we had started creating before it's um it's just a template that we started working with working on in a previous video and it's basically just um uh very simple WordPress theme all right but first of all before actually starting to to develop an Ajax request right here let's talk about what an Ajax request is all right for this I'm just going to I'm just going to use this very neat Ajax for how to do HX and WordPress correctly article that I published in medium so we're going to go through it just as a companion for this for this article okay um so first of all what you should understand is that WordPress has its own way of implementing Ajax calls okay it already comes out of the box so it might be a little bit different if you're already used to using Ajax in other Frameworks okay in case you're like in a hurry or something like that here in this article that I'm going to put in the description you already have the Snippets that you can use for J for PHP of course also the Snippets for using jQuery and the Snippets for using axios which is just another HTTP request library that you can use okay but first of all let's start by defining Ajax and what it is and what it is not okay um so let's start by saying what what Ajax is not because I think that sometimes there is some sort of misconception about this Ajax is not any programming language it's not a new or different JavaScript library or PHP Library okay it's not even a different technology what it is is just a different way of using languages and Frameworks that already exist okay so you can use Ajax in framework in different Frameworks and this doesn't change at all but Ajax is in in its sense it's basically just a technique that appeared in the 1990s and in the early 2000s and the idea is that it allows you to update the content of your page without actually reloading the page okay that's actually what's really revolutionary about this technique until then I mean before Ajax in the world of just regular websites if you wanted to add new content to your page you would have to actually reload the entire page and in that case you would have to ask your server to fetch all of the data including the data and the new data right so imagine that I wanted just to click a new a button to update I don't know mailbox and inbox um up until then before Ajax if you clicked on reload or load more messages in my inbox it would actually load everything in your page again just for the new just for the two one or two new messages that you wanted so that was just a waste of resources okay um so reloading an entire page for for only a single element was not really resource effective um what Ajax allows you to do is to update a particular part of your website with some information from your server with without refreshing the entire website um in other words this is basically worth single page applications to all the time they do not refresh the website they just ask the server for some particular information and then they display it inside your application without actually reloading your application that's basically what single page applications like the ones that you build in react or angular or view do that's what they this this kind of Frameworks do and in WordPress we can do pretty much the same thing while using PHP all right let me just move away from the light there you go um so here's just a very simple diagram to show to show you how it works so just to be clear before what would happen when you would do a simple https HTTP request is you have your client which is your web browser and you would ask your server for a certain information and then your server would fetch that information from the database and then send it back to your website but it would send back the entire page okay the difference with the Ajax model is that you have your client which then calls your Ajax engine which is built in JavaScript and then you send that request to your server your server analyzes that and treats that fetch request that Ajax request and then sends back all only the information that you needed okay um and then it's with JavaScript that you actually update the content of your website so that's how this goes the techniques really came from the realization that you could use JavaScript to update your website even without refreshing um so let's go through the steps of a regular Ajax request okay so first of all you would need to record to define a trigger that's the thing that will actually trigger your your agent request uh so for example let's say that you click on refresh inverts or you can click on um load more posts or you can click on um yeah just send your email to a newsletter or some yeah sign up for a newsletter these are kind of the the triggers that that trigger your Ajax request okay once the trigger is sent then you send your requests with J with JavaScript to your server and then your server let's say that you send the request with the question are there any new messages in my inbox then third step is your server receives that request and it executes the appropriate function to treat that request and then sends back the new information for example the new messages for your inbox then your JavaScript code now catches that response to the server and without refreshing the website it just adds those new three messages to your to your mailbox so no all right so no refreshing of the entire page just the inbox part of it all right so that's pretty much just a very basic explanation of how Ajax works I mean I'm not going to get into how XML um works or how this requests work without these libraries I'm just going to show you how to do this in WordPress okay so that's the theory okay now let's get to do this in WordPress now WordPress has a very unique way of handling Ajax requests it requires you to use a specif specific file called admin Ajax that you can find in WP admin um and I mean not in your WP admin but in WP admin the the folder the directory in your WordPress installation and only then from this from this file you will be able to actually get the information inside your functions.php okay uh so let's show you on the codes how this works so that you can actually understand what's going on here okay so for this as we mentioned before we're going to create a trigger that's the first step and here we have just a little button right here but let's use a different one let's just create a different one that's going to be called call Ajax request or something like that so for that I'm going to get inside the content of this website then let's see the themes and this theme if I'm not mistaken what's called my awesome theme so there you go there we have it um here I have the code there you go I hope you can see everything I'm just going to put this here and here there you go so I hope you can see everything uh let's see my front page there you go and this right here is this button right here so what I'm going to do is just add a new button beside it I'm going to call it Ajax okay there you go um wait like that there you go I'm going to remove the URL for this one if you don't know how to how we created this template I invite you I suggest that you watch that video about um converting HTML to template to Wordpress theme it's very very useful and there is no target out either and inside the text for the button we're just going to call it make Ajax request okay we save this we refresh here and here we have it we have make Ajax request that's our new button and this right here is going to be our trigger okay um so let's write our trigger there you go um let me just show you one more thing right here I'm just gonna put this on the side um just going to put this on the side there you go so what we're going to do right now is we're going to Define this trigger in our in our JavaScript okay so to do this I mean you would usually do this in a different in a different file of course you wouldn't want to to put your scripts inside your inside your template but this is just to show you how it works okay so first of all we would have to define the this trigger and we would do this pretty much like this let's just Define my Ajax button and let's call it from the document we call it with a get element by ID and this one's going to have an ID of ajigs button okay and let me just add this idea right here there you go ID there you go at Ajax button so there you have it and let's say that when we click on it we're going to we're going to do the Ajax request there you go when we click on it we're going to do the Ajax request okay so we're going to require a an event listener so let's add down my Ajax button add event listener and let's say that we're going to listen to clicks and to this we're going to add another function a callback function that's going to for a moment we're just going to console log our button okay um my Ajax button and then clicked my Ajax button okay so there we go let's see if this works let's refresh right here and open the terminal um we have an error here but it doesn't come from from our from what we're working on so we can ignore it for a moment we click in here and we say we see that we see clicked and Ajax button so it's working and inside here what we're going to do is we're going to add our Ajax and JavaScript okay um now uh when I'm working with WordPress I usually code my Ajax requests with double with jQuery just because it's extremely simple and extremely straightforward but you can use any https request Library um that you that you want I mean some people like to to use axios or if you're inside JavaScript you can also use fetch but since we're inside jQuery I just like using that one it just makes it very very simple because jQuery already comes out of the box with WordPress and if it doesn't I'm going to show you how to what to do um what to do to actually activate it okay so we're going to call jquery.ajix method and inside here we're going to add the type of the request which is going to be post um then we're going to say to which URL we want to actually send this request and as I told you before we need to send this request to admin ajax.php okay now some people just use the default Ajax object for JS in WordPress I think they actually make it let me see where it is Ajax and plugins I think they actually make it available inside um Ajax object I think no what's the name they send it to they send it to Ajax URL yeah supposedly I mean you have Ajax URL that's already defined in every WordPress site but I don't like doing it that way because I mean what if Ajax URL is not defined for some reason so I just like manually type it in and to actually manually type it in you would have to type something like this and we're going to add window.location.origin this basically is going to return the origin of your of any request which is going to be my awesome website.local that's I mean but it's just going to return the home URL of your of your website okay and then to this I just add WP admin and then admin.ajix.php this is going to send a request to the to this file that I was telling you about that's the PHP that's the WordPress default um like place where you actually can manage your HTTP your Ajax requests so another argument that we're going to tell is we're going to take the data that we're going to send and inside here you can send any data that you want it's going to be processed by WordPress but there is just one very important thing that you need to add here you need to add an object with a key of action okay and you you're going to name this one um with the name that whichever your name you want but you need to keep it on the side and choose to remember this very well because we're going to use this one in a moment okay so action we're going to call it for a moment my custom action let's say and then I just like I mean you can just add your data right here data one data two uh in an up in a JavaScript object but I just like to add a new object called data or Ajax data let's say and then inside it I can actually send all my data and this one right here you can add any JavaScript object but I'm just going to add a custom JavaScript object let's say my data um and we're going to set it equal to a JavaScript object and we're going to say let's say that we're going to send user information to the to the to the to the server okay so let's say the user number one data is this is the user one data there you go then you have user number two this is another user's data and basically what we're doing here is where this is the data that we're going to send our server and this is the data that our server is going to actually process right now we're we're right here in this part of the of the steps right so we're actually creating our HTTP request that we're going to send to the server um and this is the data that we're going to send so I'm just going to add it right here my data there you go um there you go so now just to make everything clear we're adding an event listener to this button right here and once we click on it we're actually sending this jQuery ajax request okay and last but not least we need to add a complete um argument right here and this one right here is going to take another function and this is basically um let me just move you here there you go this is basically just what you want your server to do uh I mean your your page to do with the response from the server okay so right here we're going to add a function and an anonymous function with the response from the server and let's say that for the moment we just want to console log it okay so this right here is going to send us the response from the server that we're going to get um let's go ahead and test it um we're right here and I'm just going to refresh here and I'm going to click on make Ajax request okay so this by clicking is going to send the Aegis request to our server if we click on it of course we're going to have an error we have a 404 because it didn't actually find admin Dash Ajax for some reason admin a jigs WP admin local yeah I think it's pretty much I mean I'm I'm not sure why you'd return to 400 uh error um I would have guessed that it would be a 500 error but um I mean the what we're having here is that we're sending something to our server and we're not selling we're we're not saying this telling the server that we actually want to treat that request so the server has no idea that I mean it just receives that request and it's like yeah so um I don't have anything right here for you so let's just go with the Ajax request on the PHP side okay to do this on the PHP side all you have to do is basically just add an action let's say add action and this action right here is going to catch your Ajax request okay um so this action takes double p Ajax as a hook and then right here you need your the name of the action that you sent here and this is why I told you that this was very important because WordPress is going to create hooks for your action in in Ajax I mean it's this is why I told you that WordPress makes it extremely easy because everything is already set up and the second one is going to take your function that you want to do do this do this when Ajax when button clicked I mean this making this extremely variables you wouldn't never call a function like this in real life but just show you see what's going on okay and then I have to Define that function and then I just have to say what's going to what WordPress is going to do inside of this function okay so for the moment as you will see we have all our data inside our post so that post variable this right here I mean WordPress is going to make all the data available inside this variable okay so in other words everything that's right here is going to be right here okay so what we're actually interested in is the element that's called Ajax data so let's call it right here let's say that my data with my data is going to be equal to post and inside here nope it's AJ State okay so AJ state so right here we're setting my data equal to our all of our post requests only Ajax data so it's my data so it's going to be this one right here that's going to be inside stored inside my post variable okay and then just to show you how this works what we're going to do is we're going to send it back to our to our client all right so to do this we just do WP send Json to send uh adjacent to our to our to our client and then we say what we want to send it I'm just going to send my data back okay this is basically I mean extremely simple just going to send this data to the server and then send it back okay this is all I'm doing so right now there's another thing that we need to do we have to add actually two of these hooks to PHP okay so the first one is WP Ajax my custom action and the second one is wpx Ajax no priff my custom action okay this is basically just how WordPress works it takes I create it actually creates two hooks for your Ajax requests this one is going to be triggered whenever your user makes the Aegis request and this one right here is going to be triggered whenever a member that's not a I mean someone that's not a user in your WordPress installation when that someone who's not a user sends a request okay so this one right here is when the website user is now signed in and this one is when the website user is signed in so I mean basically you would always want to add both because I mean you would usually create your Ajax request for everyone that's using your web your website okay this one right here is pretty much just for um creating Ajax requests from the WAP admin I mean from the back end that you actually only want your your signed in users to have access to it okay so in general you would always add the two actions and then you would add the same function as a callback to both actions so that the same function is always triggered for for both okay so see how this works I'm just going to save this and let's go back here let's refresh and let's click on make Ajax request so I click here and you can see that we we don't have an error anymore we have ready State full everything Etc then you have right here response Json and then you have right here our data that we're sending back okay so um the function WP send Json sends a a very complex array a very complex Json Json element but inside it you have the response Json element which is the actual response that you're interested in so let's fix this right here instead of actually console logging everything we're just going to console log um response Json element okay so let's add that one right here insert up we're just going to be interested in response Json we save we refresh we make Ajax request again and now we have that all we got is the Ajax user1 and user2 which is the data that we sent initially we cut it in our server and we sent it back just as we found it okay so let's suppose I mean just this um final part of this video Let's suppose that you want to um I don't know add different data to these users okay so let's say right here we're sending user1 this is user1 data and user2 this is useless to data and let's modify it okay so let's say that in my data in my data we want the user1 that's the name right user1 we want the user one to be um this is the server response for user1 and then let's do the same for user two we're just going I mean I'm just simulating I mean making it as though we were actually doing something with this data that we sent to our server I mean right here you can actually do whatever you want you can fetch new posts and return the new posts to your JavaScript you can fetch the users from the from your WordPress you can add new I mean functionalities you can add pretty much anything you can send your user data to a newsletter CRM you can do anything you want in here and then you just send a response okay and then let's say my data user one user2 this is server response for user 2 for user one okay so let's save this one and as you can see we're sending the data this is user1 data this is users to data and we should get back this as a response okay so I'm going to save this I'm going to refresh this just to clean this up um actually realize we're not we don't have uh this is very small so I'm zooming in right now and if I click on make Ajax request there you have it now you have the response business es server response for user 1 and server response for user 2. so basically what's going on is that we treated our data that we sent from the front end and we modified it in the back end and then we sent back the modified data from the server and we did that I mean right now what we could actually do is just use it inside of our our page okay so I mean like right here we could just add um I mean you wouldn't usually actually use in your HTML but let's say that you want this to be um let's update the inner HTML of my Ajax button okay I mean this is not something you would actually do but in your HTML equals um response oh sorry response Json let's see response.json dot what is it user1 use A1 okay so right now we're actually let me show you this make Ajax request click here and then this is the server response for you so one you can see that we changed it and that basically changed updated the state the inner HTML of our page without actually reloading the page that's the magic of Ajax and that's how it works now as a bonus we can do the same thing that we did right here with axios but I mean when I'm working with I mean if you know how to use axios just basically it's just the same thing but you would have to import access from npm Etc I'm not going to show you how to do that here but basically it's pretty much the same you just import access require and something important about um about this if you're using a different library is that when you post or you send the data you need to stringify it right here I'm just using this Library called Qs to stringify the data but you don't send the actual JavaScript object you just stringify it before you send it and then you and then you get it back and Etc okay just this is very important it would cost you some headaches if you're if you're having trouble with it and another common error that I see is that when you call your Ajax request like like this you might get something like jQuery not defined or something like that okay um let me show you how that look what it looks like um I mean this oh yeah let me show you how it looks like I think I have it in my footer and there it is yeah I'm just going to comment this out it's going to refresh and let's close this and I'm going to click here and then uncut error jQuery is not defined all right that happens when when jQuery I mean WordPress has jQuery if ID by default but you do have to enqueue it or to include it in your website in here I included it in my in my footer so it's actually working but um if you don't include it in your footer a very simple thing that you can do is you come to your functions.php and wherever you included your your assets I mean I'm just going to come right here but if you don't know how to include assets check the video on how to include JavaScript and how to include CSS or JS into your WordPress theme but the idea is that you come right here and you do WP and Q um in Q script and since it's already registered in WordPress you just type jQuery like that and that should make it work I mean I'm not sure it's going to work I'm going to keep this commented out I just added this thing right here I'm just going to refresh this right here I'm going to click here and it works right now because now we have jQuery okay so just remember if you're getting the error jQuery not defined just enqueue it to your WP and Q Scripts or you can add it by hand to your footer but like this I mean right here I just imported it like this this is not the best thing to do but this was how it was configured in the template so I didn't move that um so there you go there you have it um that's how to that's how to do Ajax requests and I hope that I hope that you found it useful and and yeah I hope that you wait something's not it's not it's not working but now yeah I think that yeah there was a problem with this footer there you go uh functions yeah there you go so um yeah I hope you found this useful I hope that you like this and I hope that you now know how to use Ajax requests and that you actually now understand how it works on the back end and what it is actually an Ajax request what it means so Ajax requests are by no means particular to Wordpress and they're actually the main thing that's going on in a single page application they in this way to implement them in WordPress just allows you to add some sort of single page application feel to your WordPress website even though WordPress is not particularly made to handle single page applications this is basically you can use this for loading more posts in a page or for adding different adding a user to your newsletter Etc I hope you found this good useful and I will see you next time please make sure to like And subscribe so that you don't miss out on the next videos and if you want you can also follow me on medium um you can check out the Snippets that I added for you right here I'll add the link in the description so see you around and I guess have a good day I'll see you next time [Music] thank you [Music] foreign
AA0Rd9MDEik,2023-01-23T12:07:00.000000,"Vanilla JS Project: Multi Step form in HTML, CSS & OOP Javascript",good morning everyone how is it going today welcome to this episode well my in my channel Alejandro and where we talk about programming computer science and data science and today's episode we're going to be building this multi-step form as you can see it works and it has multiple Pages multiple steps and you can toggle um between them and it also has a progress bar okay for this project we will be working with vanilla JavaScript and we're going to be using the object oriented programming Paradigm um and we're also going to be working with vanilla JavaScript which means that we will not be working with any any Frameworks such as angular or react.js Etc right so we're not going to go very deep into the software design because we're basically just going to build one class for this one but hopefully it'll be very clear and it will show you how to use classes in JavaScript and how to organize your clothes your clothes your code a little bit more neatly all right um all right so we will be first we will be starting with the structure of the HTML Etc then we're going to actually style it so that it looks like this and then in the end we're going to get into the JavaScript okay so without further Ado let's get right into it [Music] thank you there we go so we're going to be working with Coach handbooks because it's very useful for front-end projects as you can see I'm going to be starting with a template that has SAS already configured which means that I'm going to be able to use SAS inside my styles.scss file right here this file as you can see is imported in my app.js and it is loaded inside my HTML right here right before the closing of the body tag there you go and we can start actually coding right here we can say for example we can start adding just an H1 and say hello world like that and if we say you can see that it is um shown right here we can also test that this part right here the the CSS is working so we can add a background color background color red just to test and it seems to be working correctly there you go I'm not going to be using this anyways um and yeah.js as well since it's imported I mean included in the end of the of my file it should work correctly if I console log something right here let's say hello world 2. all right and right here you can see that it does show Hello World okay so there you go that's how it works um that's how the template's organized so now we can actually get right into it okay so first of all as you can see it's already configured to have a very basic CSS um standardization but right here what we're gonna do is we're going to start with the structure okay since this is only going to be the the form we're not going to add anything more than a form wrapper inside the body and we're going to do it with a class and the class is going to be called form wrapper like that there you go and inside it we're going to add the actual div of the form which is going to V which is going to be multiced um we're going to add it an ID I mean if you don't know how I'm building this um um code with classes and I IDs just with this kind of code multi step form and then just add a DOT this is emit okay and this this pretty much is a faster way to building to creating to generate divs with classes and IDs Etc so the class for this one's going to be form and then there you have it all right so right here let's figure out the structure for this one um we're gonna start with a form header form header like this um and then underneath we're going to add a form body like that okay let's start with the header okay as you see right here we have our header with the title and we have a progress bar which we're going to build a little bit later in the tutorial but first of all let's just add a very quick H1 saying multi so step form there you go now for the body the body is going to be divided into several pages with which we're going to toggle an active class to show them or not to show them depending on its if it's the active class that we want to show or not so first of all inside the body I'm just going to create a form page okay so form page like that there you go and inside that form page what I'm going to do I am going to add just three three pretty basic input inputs okay so input it's going to be type text of course and I'm just going to add a very quick placeholder I'm going to call it name like that there you go and then I create three more of this there you go then for this one I'm going to add a last name last name placeholder and for this one I'm just going to add email like that there you go then underneath we're going to add our buttons and I'm going to add a div to wrap them all together I'm going to say form buttons like this up not like that buttons like this there you go and inside that one I'm just going to create first I'm going to create let's say a couple of buttons I mean I know this is the first page but I'm just going to show you how it would look with two buttons okay so I'm gonna add one button right here I'm just gonna add a class of vtn form as you can see we're not actually dealing with um uh pre-made CSS Frameworks we're going to be just styling it ourselves which I mean hopefully it will be educational um we're gonna call this button button form and button previous we're going to say previous for previous page and then we're going to do the same but this one previous this one's going to be next and this one's going to read next right there so we have our we have the basic structure for our form as we can see um I mean later in the tutorial we're going to add more form pages so like for example this one right here we will have another one right here there's going to be another form page and they're going to have some data attributes to actually um be able to tell between them and to show the active one but we're going to deal with that in a moment okay so for the moment this is looking correctly now we're gonna go to styles.ca Dot dot SAS and first of all let's just style a little bit the background because we want it to be something Bluey um so let's do that first um body of everything um we're the same which font family are we using we're gonna we're gonna leave that one family that looks pretty good and we're gonna say that the the height of the body is going to be a hundred pH which means the entire screen we're going to say we're going to say that the background color the background color is going to be a color that I have right here there you go this color I like it is kind of pretty pretty nice blue um what else we're gonna we're gonna Center everything so it's gonna say display Flex justify content Center and the lying item Center as well there you go so everything is centered and we also want everything to be white I mean the color right the color of the text there you go so that's body um now we're gonna have to actually start dealing with the form class right here with this element right here and what we're gonna do with that one let's say we're gonna say that it's going to be at least 300 pixels wide okay so let's say the minimum width will be 300 pixels like this um we're gonna give it we don't want to get to give it an actual border because that would I mean we want it to be a little bit more stylish so instead of a border we're going to give it a box Shadow how about that box Shadow and this box Shadow is going to be in the center it's going to have 10 pixels here and 0 pixels there and it's going to be white like that one there you go um let's add some padding to it let's say two Rems there you go it's starting to look a little bit better and now how about we add some rays on board the radius to it so border radius there you go and we say to REM as well and that's starting to look a little bit better there you go all right now inside the form well maybe let's try to style a little bit the header all right so we're gonna say since we're in SAS we can say Ampersand would be which basically takes anything that's up here so this form underscore underscore header basically basically means the same thing as this right here okay so header like this and then right here we say that we want to add some margin between these two so let's say margin bottom and we're going to add a margin of 2 Rems like this there you go and then for the actual text of it not that way for the actual text of it we're going to say that the font size up not like that the font size is going to be 1.3 REM and we're going to center it okay so text the line Center like that there you go starting to look pretty good so that's the header for now now after the header um let's try and edit a little bit of the body okay remember the Ampersand means takes the value of the previous class so this right here will be form underscore underscore and here we're going to Target the body like this and then Ampersand again on the score form or page is it um what is it we have the f um we have the form right here and we have the form body yeah I was doing the I was doing yeah form body and inside the body we have form page okay so we're going to add instead of form right here we're going to add page like that there you go now we have the page um let's say that we want to add some some [Music] um all right let's add some Flex Direction Flex Direction let's say it's going to be column like this the problem is that I don't think it's display Flex yet so let's just add display Flex like this there you go now it's starting to look a little bit better there you go um all right so right now we already have sort of one of uh sort of our our page right here um but let's how about we continue styling the input elements right um for the input elements what we're going to do is for the input like this input not like that like this for the input we're going to do margin bottom and we're going to say it's going to be 0.5 IMS like that looks pretty Spacey and it looks a lot it looks too too close to the text so I'm going to give it a padding okay it's usually a good idea to give it I mean when you're dealing with buttons or input elements to use instead of REM as units to use EMS because Em's uses the actual size of the element not of the root of your HTML so here I'm going to say 0.5 em and 1 em for for the sides okay so this one's uh of course this one is vertical and this one is horizontal and just to make it clear EMS means that this size is relative to the root to the value of of the element and since I mean the padding is to make the contents look good it makes sense to use CMS but in general you should use Rems in most in most cases so that's for the padding let's just have some radius as well order radius we're going to say um 0.5 EMS like that there you go and now let's get rid of that border let's say border none like that and just as with the just as with this border right here instead of adding a border we're just going to add a box Shadow so box not sizing but Shadow like that and the book Shadow is going to be 0 0 again 10 pixels zero and let's see how it looks it with white you know let's use a little bit darker one yeah there you go um so that's starting to look pretty good um I suggest we start with the buttons right now hmm the buttons are also inside the page so I'm going to add it um not here but here if I'm mistaken like this buttons like this is this how I named it buttons let's say form buttons and it's inside page um but we wanted to take form from form okay so yeah I'm gonna put it here so this way the Ampersand means form okay so there you have it so the buttons are going to have display Flex display Flex like this we're just going to add some justify content instead of Center we're going to say stretch up stretch like that and so that they take the entire space and we're going to set a gap for 0.5 REM all right this doesn't work yet because we haven't actually styled the buttons to take the entire space so we're going to do that right now okay the button.btn dot form like this which is the class that we gave it right here BTN Dash form like that we're going to style it like this we're going to say it's going to have a display block there you go the padding is going to be 0.5 just as with the input we're going to be using EMS and like this there you go starting to look a little bit more Spacey the border of course we want no border at all the color we want the color of the text to be white like this um The Border radius we also want it to be a little bit um around it as we had before let's set it to 0.5 VMS as well remember dealing with buttons so we use EMS for the background color I'm going to use a darker shade of blue so let's say background color like this and you know what I'm going to add them up here as variables like holders okay so this one's going to be my primary color where I'm gonna be in this right here is SAS variables I know JavaScript has a JavaScript I mean CSS has native variables but I'm just going to be using this um just to be consistent with SAS but yeah usually it's I mean if you the closer you are to to CSS the better and I'm going to add the darker color right here so my Docker color is going to be right here this one's going to be secondary color like that there you go and now this one right here is primary color and this one right here is going to be the secondary color like that let's see how that looks looking pretty good all right so let's continue with the button right now we we already have the buttons but for some reason they're not taking the entire space so what I'm going to do I'm going to add a width of not like that a width of 100 and there you go now they're actually taking the entire available space and since they're inside a flexbox and the justify content is set to stretch they just take all the space available in that line and they defy and they have a zero five REM gap between them if I remove this the Gap is removed okay so there you have it um let's just add a little bit of space over here between these two so let's say uh margin top it's going to be 0.5 Rems like that and then and then let's I mean the cursor is not changing either so let's add a cursor pointer two okay cursor cursor uh pointer like this there you go so now we have a pointer but when I click on it it doesn't do anything yet so we have to deal with that right now um the ampersand's also useful for this one because I mean as I told you before this in SAS this one takes the value for all of the parent element so this right here is going to be a hover for the button form class and the full in Hover what we're going to do is we're just going to add an opacity of 0.8 so right now when I hover over it you can see that it changes a little bit in color still when I click it nothing happens I do want to add some some sort of effect when I click on it so I'm going to say active right here active like this and I'm going to add some filter to it instead of adding a third color which is going to be another shade of blue I'm just going to add some contrast to it that way I keep my color palette to the minimum and I'm just add some contrast of 150 150 percent oops like this um found that mistaken this should work and now if I click on it it also has a third shade of blue which is pretty consistent with our palette with our color palette and it's looking pretty good already okay so there you go um what else can we do right now um let's add some of the other pages right here so just to be sure I'm doing things correctly let me check out this pay in this side um all right I forgot one thing in here and it's the the fact that actually our form page is going to be inside a form element like this okay um like that so form action we're not going to add an action because we're going to be using JavaScript with it but let's just add a form to it okay and the form is going to have the value of um you know what it's not actually a new formula right here it's just this one right here that's not supposed to be a diff this one right here is supposed to be a form like this there you go so now it's all inside a form and now if I click a button of course it reloads because buttons inside forms when you click them automatically submit um so yeah let's just we will get rid of that in a moment when we add some JavaScript to it okay but for the moment what I want to do is to add more form pages to it okay so let's do that now here right here you can see that we have one form page right here I'm just going to copy it and we're gonna copy it three times like this there you go now we have three pages all right and what we want to do with these three pages is actually make them a little bit different so the first one instead of having two buttons we're just going to have one which is going to be the next button the second page obviously makes sense that it has that it has the two buttons previous and next but the last one doesn't make sense to have a next button so it's going to have a submit button I'm going to remove the button next class because I'm going to be using that in JavaScript later to Target all the next buttons and right here I'm actually going to add a type of submit like this that way when I click on this one you will I mean it's you will know that when you click it you actually want to submit the form okay um so there you go um so we have next previous next previous science submit there you go um but so far all of the pages are showing at the same time and we probably don't want that right so what do we do what we're going to do is we're going to go back here to our Styles and we're going to go to our form page right here and as you see we had added a page display Flex right here but instead of this what we're going to do is we're going to add the display none so that by default no pages are shown okay and we're going to add an active class to the first page right here which is form page the first page right here is going to have an active class and also right here we're going to add we're going to say that whenever the page has an active class to it we're going to say that it's display is going to be Flex just as before and just to make it clear that the active is supposed to override everything else we're actually going to use the important attribute important um this is the actual right way to use important um not by just trying to correct what you miscoded before when you have one class that has one particular act one particular characteristic one particular attribute that you have to do that it has to do it's good to have the important tag over here okay so there you go now we have the first the first page that's showing because that's the only page that has the active class and everything seems to be working correctly right now so that looks pretty pretty good okay I guess we can now actually go into JavaScript oh oh no you know what I actually I'll almost forgot the progress bar that we had right here all right so let's do the progress bar um to do that we're going to add it to our header right here and underneath the title what we're gonna do is pretty much we're just going to add a new div that's going to have the class of progress bar okay so it's going to be like this progress bar like that and inside the progress bar we're going to add three diffs or spans or whatever you like we're going to be editing them in a moment anyways I'm just going to add divs and the divs are going to have the class of page step like that there you go and inside it and you're going to have the number of the page which is one for this one and then for this one's going to be two and then for this one's going to be three like that okay now let's just style them so that they look like this one's right here look okay and to do that we're going to go back to our Styles up here and we're going to go we're going to create an entire new and entire new element an entire new class right here I mean I really like using SAS because it allows you to actually create your elements that are self-contained right so right here you can see that all of the contents inside the form class right here they're targeting the class I mean it's just one single CSS component and then you have the buttons that work to get in that work independently as well and what we're going to do is we're going to add the progress bar right here as well okay so let's say progress bar like that and inside the progress bar we're gonna say that we're gonna have a display Flex first of all we're going to have a Justified content of space between space between like this let's see how that looks there you go so you can see that they're starting to be spaced um between of course and now let's just add let's say let's just style the actual steps okay um there you go let's let's add the actual steps so right here I'm just going to add page step like this and let's just say that they're going to have a display um block oops I mean divs already by default have a display block but in case you were working with I don't know spans or any other HTML element it's I mean I just putting in there so you know that it's important that this element has a display block we're going to say that the width it's going to have like this the width it's going to be two Rems and the height it's going to be two Rems as well there you go you know what we're going to name it EMS so that it's relative to the actual number that it's contained um and the Border radius border not top or the radius um it's going to be 50 because we want them to be circles okay then we have the margin top up Margin top to actually separate them from the title that is going to be 1.5 REM so let's just see how that looks there you have it we already have a little bit more space between the title and the actual elements and let's just start adding um I mean since we're not working with borders like because we we don't like them for this project we're working with box Shadows instead so let's add a box Shadow right here and a box Shadow for this one is going to be again zero zero it's going to be a small one five pixels and we're going to say that it's going to be white like that there you go now the problem is that the the actual contents of this div are not centered and we want to Center this in the middle of this part right here so we're pretty simply just going to say um display Flex oops display Flex display Flex well display Flex uh justify content Center and align item Center like that so now we have our number centered at the center and it's working pretty good looking all right all right um and just one more thing well remember that here right here the actual um Step that is being shown is colored in white what we're going to do right here is we're going to do that so if the class has another class of active like this we're going to say that the background color is going to be white like that okay I mean you can also add an important element right here just to be sure that it always overrides everything else and right here let's start with by default the page one being active Okay so let's say now this one's active and it already is illuminated in white the problem is that now we don't see the actual text so we're going to just going to change the color and we're going to use the variable that we have just created which is going to be primary color like that there you go so now it's working correctly um last but not least for this design what we're going to do is we're going to add the line that we have separating right here the two elements I mean between all of these elements and we're going to say that every one of these elements is going to have an after pseudoelement that's going to have a content of nothing just to be able to actually show it it's going to have a display block to actually be able to manipulate it its height and its width it's going to have a width of a hundred percent it's going to have a height of a hundred percent as well but the question right here is it's having it's going to have a hundred percent of what exactly okay so it's going to have a hundred percent of its relic of its container element and its container element is going to be um it's going to be the page step right here because we're actually going to be saying that it's going to have a position absolute like this absolute like that okay um and this one we're going to give it a position of relative so that it's absolute relative to this one okay oh so there you go so now we're actually we can actually start working with the background color um just to actually see it a little bit better where it is right now color now let's say it's going to be red so there is there you have it um I actually got it wrong it's not supposed to be red it's not supposed to be a hundred percent the height now let's say it's going to be one pixel because we want it to be one line like that okay and of course the background color we don't want it to be red we want it to be probably white like that let's see how that looks um all right so we have this line right here and we have this line right here and that's looking pretty pretty good so far um the problem right now is that we want it to not be over the actual um page step right here we want it to be shifted to the right so what we're going to do is we're going to translate and transform it and translate it on the x-axis 150 percent to the right like that so there you have it now we have it here and here now let's just touch some pretty quick opacity of 0.3 until then make it a little bit more slick there you go but we have this one right here that is hanging out and we don't really want an extra one we just we're just interested in having this two right here so how did we target these two without targeting the third one uh to do one is pretty easy actually we just add a notch right here and we're going to say that we want to take everything instead apart from I mean what that's what this knot does it takes everything except whatever you say inside the knot right here and we're going to say that we don't want the last child there you go so now you are targeting everything instead apart from the last child and you're adding a after pseudoelement to it and this is how you what you see right here so now it's looking it's working correctly we can save this and you can see that if we click it it reloads because we haven't added any JavaScript that is going to prevent the default behavior of this button okay so let's create the default behavior of this button right now um and to do that what I'm going to do is I'm just going to go to my JavaScript right here and I'm actually as I told you before I'm going to be working with classes object oriented programming in JavaScript and we will we're not going to be working with like very sophisticated um software design but the idea is that you kind of have to have a grasp of how object-oriented programming Works in JavaScript and how to organize this of course there are easier ways to organize I mean not to organize but to build a multi-step form which is a few lines of JavaScript but the idea is that you are going to learn how to use oop and also you're going to learn how to make this sustainable and maintainable in the long term because if you just add a few a few lines that just hide and hide and show the next the next page I mean it's probably going to be all right for just one single form but if later you want to add more steps to it or you want to actually add an entire user interface around some multi-step form simulator or something like that you're going to be much more comfortable working with them with a self-contained class that has everything in it and you can just add some functions to it okay so let's get right into the design the class is going to be we're just going to create a class called multi-step form like this and we're just going to call it right after like this new multi-step form like this okay there you go so you might remember if you have taken software design or um of oo object object oriented programming courses the idea behind this is that everything is I mean self-contained so we're going to or since we're I mean and it also has to have one single function okay um was yeah I want single objective so we're just going to be dealing with the front and the UI part if you actually wanted to add some other part you would be able to add you would have to add another class to it okay but so far this is all um so the idea right here is we're going to add a Constructor first of all Constructor like this and right here we're just going to activate I mean get all the elements and enable the pages there you go that's pretty much what the Constructor is going to do and also I mean the rest of the software design is going to be pretty simple the we're going to have some properties um some of the properties are going to be of course the form this form and we're going to I mean we're supposed to I mean it's going to have yeah the property of the actual form that it is it's going to have a property that contains the pages so here we have three pages that are two of them are hidden so they're going to be stored in this part in this property right here uh we're going to also have next buttons like this and we're going to have all the previous buttons like this okay so this is going to be an array or a node list and this one as well and this one's going to be an array or node list as well and this is going to be an HTML element okay and then in the end we're just going to call the method that enables the pagination there you go and we're going to be building several methods for this one to work um remember that when you use this it basically means that you're accessing a property or a method of your class okay so right here what we're going to do is we're going to create a new methods called initialize buttons that is going to be there's going to be the one that actually initializes the pagination okay um initialize we're just going to add some comments to it any Shelley's pagination like this we're also going to have a method that's called get current page like this there you go and this instance is going to return active page these are going to be the methods that we're going to be using inside this one right here okay now we're going to have another one that's called get Max page which is going to return the maximum return maximum number of pages in this multi-step form and last but not least we're going to add a method that's going to update the progress bar okay update progress bar like this progress bar like that and this method right here what it's going to do is basically going to um just going to check in which page we are currently and it's going to illuminate or just colorize the background of it okay so update progress bar like this and colorize um active step in progress bar there you go um I almost forgot we're going to be using a couple more helpers which are just going to be hide page which is going to it's pretty much just going to oh hide the page and I mean basically it's just going to remove the active class okay I'm just going to have show page which is going to show the active class nope like this show active class there you go so now that we have our architecture I mean very simple architecture we can actually start working with it for the Constructor we're actually going to be passing in um a on a parameter an argument which is going to be the form ID okay form ID so that it knows where to initialize the form and we're going to set this one equal to document dot get element by ID and right here we're just going to pass oops form ID okay like that and right here this one right here now takes one argument and we're going to pass the the ID of the form and the ID of the form is if I'm not mistaken I haven't actually created it have I um or have yeah here it is all right multi-step form there you go so this is the one that we're going to be using there you go multi-step form this is the ID get the element by ID and now our form property is defined and now from it we can actually start taking the pages in it okay so instead of calling this um get no query selector all from the document now I can actually take it from the form and it pretty much just kind of um con it serves as a container so that I don't accidentally Target any other element so this way I know that I'm only targeting the pages that are inside this form element that that I um created I mean that I targeted by its ID okay so right here I'm going to say that I want all of the pages that have a class of form page like this there you go so now I have my array or node list of pages and then we are going to have do the same thing about the next button and about the previous buttons okay so this form dot query selector all and the class for the buttons is actually but um oh no it's button wait what am I defining next buttons so it's bottom next like this there you go and it's actually supposed to be pretty much exactly the same thing but button previews for previous buttons button brief like that there you go now we have all of our properties defined already and last but not least we're supposed to initialize the buttons that we have right here okay so there you go uh initialize the buttons let's start with that one okay and this is basically the main element main part of our of our I mean this is where the actual pagination is what is happening so um yeah let's let's get to do that one and this one's going to take two arguments actually we're gonna take um the next buttons and we're going to take the previous buttons okay like that and right here we're going to have to pass them in because when here's where we're calling it and here's where we're defining it and to call it we're going to call we're going to call it from the next buttons right here and second argument is the previous buttons you know what I'm actually going to change the order for this one I'm going to pass the previous buttons first and that's next I'm going to pass the next buttons so first we pass the previous buttons like this and then we pass the next buttons like that there you go so right here what we're going to do is for each of the next buttons right here for each like that for each of the next buttons right here what we're going to do is we're going to add event listener that will go that will will basically just change the page to the next page okay to change to next page there you go and we're going to do pretty much the same thing with the previous buttons like this previous buttons like this and for each one of this we're going to add an event listener to change to previous page like that okay and basically pretty important as well we're going to have to remember that up till now if we click on the button it actually reloads the page because it's a button inside a form element and we don't want it to actually submit the the page the form what we wanted to do is to do what we want what we tell it to do in our JavaScript so first of all the first thing that you have to do if you're dealing with something like this is you're going to have to pass in [Music] um um we're going to have well first of all of course the event listeners the button dot add event listener if I'm not mistaken um button for each button that add event listener like this and the event listener it's going to we're going to listen to clicks and the event is going to take actually the event parameter and right here we're just going to first of all let's just test that it's working okay so we're going to do prevent um prevent default if I'm not mistaken prevent default so that it doesn't trigger the submit action and then let's just for testing we're going to console.log clicked on next there you go so let's see how that looks already so I'm going to open up my console I'm going to click on next and I say that it's actually not working so why is it not working um so we have a next buttons right here and um let's cancel log to see if my next buttons are actually being targeted console log this buttons let's see are they being targeted up like this are they being targeted um they're actually not being targeted for some reason so multi-step form multi-step form all right so this line is never running for some reason um cons oh because I named this wrong it's not supposed to be Constructor which is going to be Constructor like that so now if I reload this let's see how that works mm-hmm gonna go console and let's click on next and click the next so this right here is working my event listener for my next button is working and pretty much what we're going to be doing right now is we're going to get um I mean we're going to actually do all the the logic for when we click on it okay so we already prevented the default so as you can see when I click on it it doesn't reload so that's pretty convenient and right now I'm just going to write comment here the steps that I'm going to be doing for each of these buttons um so the first step is basically just one second so the first step is prevent defaults of course default and then when you click also you want to get the current page and then you want to go to pick to current Page Plus One of course and you pretty much want to do the same thing for the previous button right here so let's just add let's just add all the event listeners right here there you go so I'll just pretty much copied um what's up here so button activate listener click and it's going to listen to a click it's going to prevent the default for the next for the previous buttons too um and instead of going to current Page Plus one it's going to go to current page -1 like that there you go so let's now just add get um let's just get the current page so we can just come to add a new variable that's going to store that one current page will be equal to whatever is returned by our function get current page like that there you go so now what we have to do is we actually have to Define this function and let's see how we can get the current page all right so to get the current page let's see what we can do um get the current page right so um to get the current page we're actually going to be adding some extra elements to our to our HTML template okay so first of all for each page that we have right here let me see index.html there you go for each page that you have right here here you have the pages where the pages um each page there you have it you're going to have a data um now you know what it's going to be on the at the level of the multi-step form right here we're going to have a data attribute that's going to be current page like that and the default value is going to be one like this there you go so now this one is one and there you go so now we can actually pretty much just return that value there so get current page is going to be um first of all we're just going to get that value so const current page is going to be equal to this form because we're going to be targeting the form element that we just defined in the Constructor of course and that form element is as I showed you before the one with the ID multi-step form so we can just access this attribute right here so we want data current page so let's see how that looks this form dot data set to actually access the data attributes and we're going to say current page and this one as you can see it has been shifted to camel case even though it was written like this in HTML that's because JavaScript does not support um dashes in in the variable names okay so there you go now that we have created that one what we're going to do is basically we're just going to turn it into into an actual number because right so far it's actually a string so I mean let me just show you how that looks like so far current page like this sorry return the current page so we'll return this one right here so now this one right here should have the current page actually stored so let's console log that one current page let's see now I'm just going to erase this right here and I'm going to just add some more here the current page is like this and let's just click here the current page is one of course because the current page is one there you go so now we have that function working correctly but the problem is that this one as you can see it's a string okay so let me show you that and we're going to be doing some calculation with it we're going to be doing more than less than Etc to actually find the actual page that we want because we're I mean we're working with numbers so we want it to be a number and how we do that so let's see the current the type of the variable is so let's just take the check the type of this one right so let's say type of yeah I believe that's the command I'm not sure or is that python I don't remember all right let's see if I click next oh yeah it is actually type of and I can see that the type of current page is string and I don't want it to be a string I want it to be a number so how do I do that so instead of instead of actually returning the current page as assays like that we're going to convert this current page oops current page is going to be equal to current page of course but we're going to parse it in order for it to become an actual an actual number okay so we're going to parse uh sorry parse end like that pass end and now this one right here as you can see the type of far type of the current page this one right here is supposed to be a number now so if I click on next oops um oh yeah because I I said it as a constant so uh you know what I'm just going to return it here instead of actually trying to rename re-define a constant there you go so I'm going to return it as like that there you go um so let's see what happens now I'm going to explain what's happening with the yellow line over there in a moment so if I click here I can see that it's actually a number but the problem is that I mean as you can see I have a yellow line right here and that's an error and the error is basically telling me that power send what it's doing is it's converting a string into an integer but the problem is that I actually need to give it the base of that integer so I mean it can be a hexadecimal number or a binary number Etc so I mean I I have to kind of tell it that I'm going to be working with a base 10 um number so that it doesn't kind of get confused if my number starts with a zero it might interpret it as not in base 10 but it base 6 or something like that I'm not sure how it works but yeah I mean if you're parsing it into guys and you want them to be regular integers like base 10 from 1 to 10 and then 11 you're going to have to add a 10 right here so let's see how that looks now if I click um one moment I get number again but I don't have this error anymore so that's working correctly all right so now we have the current page which is down right there and now pretty much the next step right here is to now once that we have the current page what we want to do is we want to go to the next page so let's use this new um method that we're going to create that's going to be called pause I'm sorry it's going to be gold go to page and it's going to be the current Page Plus One basically there you go and I've already mentioned it or didn't time I actually didn't mention it did I um get my space yeah sorry I forgot that one so actually we needed a method that's going to be go to page like this I'm just going to take obviously the page that you want to go to there you go all right so what we want to do right now is pretty much enable this function go to page I'm going to change the name of this attribute right here I'm going to name it Target page like that so that we don't get [Music] um we don't get it wrong a little bit later uh when dealing with other pages okay so first of all we were gonna want to make sure that the page that we're asking for exists okay because since we're asking for go to page in this other method right here go to page what if for some reason we at some point would have one button that goes to page 10 but we only have three pages so we need to be able to filter that um I mean just some sort of error handling um so if oops so test that page exists there you go so if my all right first of all we have to actually set the maximum page so um constant maximum page will be equal to get Max page like this from this and the actual maximum page we're gonna have to actually Define it because in fact there we have it so we have to actually have this function working in order to use that one so basically all we're going to do right here is go const Max page will be equal oh this is not supposed to be uppercase there you is going to be equal to the form element and the data set from this one and it's going to be Max page like this because remember that we declared that one over here or didn't we now I actually think that we didn't um yeah I know I think that we didn't actually do that so we should do it now data we need to add a data attribute and we're going to name it Max page like this and since we're dealing with three pages we're gonna uh at here the number three um I mean if you were using some other language or some templating language I don't know maybe suppose you're using PHP for this one right you would probably pass in the the variable that you received from the server right here saying the total number of pages so that you will be able to actually enable your your form pagination so there you have it here you have your maximum page and then that's pretty much it I think and then you have to return it just gonna do the same thing as we did with return current page we're gonna return the max page like this and we're gonna turn it into an integer parsing parse into using parse end and using base 10. so there you go so now Max page is supposed to be working right here and we're going to that page so what we're going to want to do right now is let's handle if the page exists Okay so first of all um if my target page is let's say if it's bigger than this if it's bigger than Max page wait um did we actually set the max page all right we should probably set it up here so that way it's easier this Max page equal um this get Max page there you go so that way we don't have to actually bother doing this right here there you go so if this Max page is bigger than this Max page like this um or if my target page is less than one I mean if it goes to zero for some reason or something what we're going to want to do with that is we're going to console an error saying I'm sorry but the page was not found page not found I mean form page not found so that we don't confuse that I'm going to remove the brackets here just to make it a little bit more clean all right uh since I only have one line I can I can remove the brackets I will not be able to do that if I had more than one line because I mean you're supposed to be to do to be able to do this in one single line like this right so if I just put it in a second line it doesn't change anything there you go so now let's actually enable the go to the page go to page like this and to enable that one what we are going to do is we're going to actually first hide every single page and then we're just going to show the page that we actually need to show okay so let me just show it right here so we're going to have to Loop through all of our pages so this Pages which is our property that we defined in our Constructor and we're going to run a very quick 4-H method right here and we're going to say that for each of these Pages what we're going to want to do is first of all we're going to hide it oh sorry we're going to hide it hide page and then if the page is the target page what we're going to want to do is we're going to show the page all right and then what we're going to want to do also inside of this this part is we're going to have to update the data set all right uh update data set because remember that we're getting the I mean the data set Uh current page is pretty much acting as a as a state what what state would be in react for example okay so we will update the data set which would basically means that we're updating the the current page of of our form so that when we run again the get current page we're going to get the actual current page okay so let me show you how that works so first of all we're going to hide this page and this is going to be done pretty much just by using this um High page then we're gonna oops then we're going to say hide this page like that okay um actually you know what I'm going to do I'm going to replace this one right here just to make it clear that this one right here is actually a number okay so I'm going to say page number like that and because this one is an HTML element and this one is supposed to be a number of course this would be way easier if we were using typescript but since we're not using typescript for this tutorial I'm just going to be over explicit with my variable names so this is supposed to be a number remember that we're returning a percent and this one right here is actually a node list of elements that's because it comes from my disk pages right here that I've declared up here it's the list of all elements that have the form page class and so I can actually from this one I can hide it using this method right here and this method is very very simple what I'm going to do is just say this class list oh sorry this actually takes an attribute so it takes page and for this page we're gonna access its class list and let's say that if it contains if it contains the class active we are going to remove that class okay so page dot class list dot remove oops remove active like that there you go so let me just expand this a little bit so page class list contains active so everything that is before these two ampersands is going to be it's going to be the condition so if the cloud and the page contains the class active which means that if it's the page that's actually being shown we're going to remove that class so we're going to hide it and let's just once we're on it let's just code the method for show page as well um so it's going to be actually pretty much the same thing but it's going to be pretty much um the opposite so we're going to take this right here so this also takes a an attribute page um so we're going to access the classlet and here if it doesn't contain class active instead of removing it we're going to add it there you go so now we have the hide and show page and now we can actually use it inside our go to page method right here okay so now we're using it a height page for each page we're actually hiding the page and then if the page is the actual page number what we're going to do is we're going to say that we're going to show it so first let's get the page name the page number of the current page so let's say current constant current page number like that and we're basically just going to do the same thing as we did in get page but just for this particular page we're going to do pass integer and let's just get the date from the let's just get it from the data set of this page and let's parse it on a base of 10 okay now here's a particular problem that we're encountering I'm actually trying to access the data set um for the page element which is this element right here so every single one of this form page um I'm I'm trying to figure out which page they are okay but so far in my HTML um template I don't actually have a anything that tells me which page it is I could try to calculate it but I think it's just easier to just add the data set right here so I'm going to say data page and this one's going to be page number one okay I'm going to do pretty much the same thing for the second one and the same thing for the third one and this one's going to be page number two and this one's going to be page number three there you go so now every single page has a data set um attribute with the page attribute and then and the I mean the value of that page so let's get back here and we're going to say page data set page and that's pretty much just going to return the page um of that current page That We're looping through um so if that current page number is equal to the to the page number that we're targeting we're going to show it okay so let's say if the current page number equals the target page um sorry the page number like this um what we're going to do right here is just as before Ampersand Ampersand and that's this dot show page okay I mean as always remember that we're using this because show page is a method from our class that we're currently in so that's why we are able to use this to access this this uh this method right here so there you go so now that should show the page um let's see what that does so far okay so um so far we're dealing with go to page and where I have actually yeah all right so let's see what that does now if I click on next right here it doesn't do much oh yeah it does all right no it does actually good yeah actually it does but I don't see it because all of my pages look the same so I'm going to change this a little bit okay right here we have the first page that has name last mail and email let's have the second page have an address LSI address two let's just remove this third input and for the last one let's say password let's just say password and password two or whatever I don't remember what I named it here um address address complement and comments other info more info Etc yeah I mean the idea is just put whatever in here that other info there you go I mean this should do it so now if I click on next you should see that it's like it's actually changing the page but if I click again it's going to do it it's not going to do anything because remember that when I click what is actually happening is that I am when I click when it's actually happening is that I am preventing the default and I'm getting the current page and then I'm going to the current Page Plus one but the current page is always one because that has not been changed let me show you that so when I click on let me show you that right here um start working it doesn't seem to be working for some reason um yeah there you go um one second I don't know what's going on why is it not loading yeah all right whatever so if I inspect this element right here as you can see right here the current page is one right here which is the data set element that we've that we created that we defined um on this side right here there you go um you know what let me put that on the bottom like this [Music] um no this is not a react component um there you go so here you have it so we have the data current page data set that we have defined right here um that we have defined right here there you go and we actually want to update it every time we click because when we click right now what's going on here there you go because when we click right now it's actually changing the page but this right here is uh all right there's I don't know why it doesn't like being expected uh it doesn't change this okay so let's just change that I'm just going to take away the inspector because it's not helping at all um so there you go um what we're going to do is pretty much just update the update the current page data set every time we click on it and we're going to do that here in go to page so update data set uh pretty much all that we're going to do is go to this form um take our form then take the data set and then take the current page like this and let's just set it to the Target page sorry no the page number that we're running with right now all right so there you have it page number page number so now every time that we click on this one and the data set from here [Music] this data set right here right here it's going to be updated okay so let's see and that way it's going to be able to actually run through all the pages so if I click next then I click next again it's working um because we're going to the next page the previous button is not working yet because we haven't done anything with it as you can see right here so our go to page method is working so far so we can just reuse it up here in in the previous buttons so we're just going to do pretty much the same thing right here we're going to get the current page for the event listener when we click on the previous buttons and then we're going to go to that page -1 instead of plus one okay so there you go this Bud right here is supposed to be working correctly so far I think all the pagination is pretty much done if I'm not mistaken Let's test it um so I'm going to go click next next previous previous yeah it's working correctly I'm gonna do something pretty quick now I'm just going to show you something I'm gonna add some sort of Animation to when you show up and a page like right here remember in our in our demo this thing all right awesome uh all right my demo stopped working for some reason um all right but we will want to actually have an animation when we click on next right here so let's let's go with that right now um to do that what we're going to want to do is we're going to want to go to Styles right here and inside page right here let's just add an animation element right here and we're going to say that the animation is going to say it's going to be titled show up like that show up it's going to take um how long how long it's going to take 0.5 seconds and let's say it's going to be is is n like this hmm there we go so show up um now let's let's name it more appropriately let's say fade in like that and now we actually have to create our animation so it's pretty much we're pretty much what we're going to do is we're just going to add it on JavaScript on CSS we're going to add keyframes right here frames and the keyframes animation is going to be as we named it before fade in and we're going to say that the zero percent is going to be the opacity at zero and the hundred percent is going to be the opacity at one so that should do it and since it's 0.5 it should be working correctly so let's say next next previous previous it's working pretty good so far so there you go that's already a work in now while the submit button is still submitting but yeah I mean the idea is that you can do anything you want with the submit button um so there you go uh last but not least we need to do something with the progress bar because so far I mean the progress bar is there but it's doing it's not doing anything so let's just track out changes with the progress bar okay so just to just like to make sure everyone's on the same page we have created our initialize button function right here that pretty much what it does is it Loops through all of our next buttons and our previous buttons and it adds events listener to them event listeners to them that make them go to the page to the desired page and then pretty much we have some helpers that just get the current page uh get the maximum page of the of the of the form um go to this page and we have a high page Helper and a short page Helper and then pretty much right now we're just going to update the progress bar whenever we click on one of those so to do that what we're going to do the process is just get the progress bar steps first of all and then we're going to get the current page there you go and then for each one of those um sorry and then for each right here 4-H step what we're going to do is we're going to on color and color all of them and then sorry and then color until current step like that right so let's do that so let's get the progress bar steps first so const all steps we're going to name it in this this variable and it's going to take the form element like this form and let's just query select them all and if I'm not mistaken the class that I gave to every single of one of this page steps was page step like that um let me just check that that's true um page step yeah there you go all right so that seems to be all right and now for now we're supposed to find the current page as well get Uh current page there you go this get current page like that that's the idea of having this methods that you can reuse you can all just reuse them in other methods and it's pretty convenient now for each one of those what we're going to do is we are going to uncover them and we're going to color until the current step okay so let's get to do that so we're going to Loop through all steps let's call this one steps not all step all steps like that and let's say that for each one of this forage um Step let's call it step what we're going to do is pretty much we're going to say that the class list if it contains active it's going to remove active and vice versa if the step class list contains active like that what we're going to do there you go what we're going to do is pretty much just remove the active because remember that we want to uncolder all of them all of them like this and step that class list dot remove active like that there you go so now we haven't colored all of them and now what we're going to want to do is pretty much um color them all if they are um I mean if they're active Okay so right now we're supposed to get the the step page for that one um if I'm not mistaken um yeah I mean we're supposed to get the step for this one actually so we have the steps Let's see we have the steps right here and we actually suppose yeah we need to have some data set right here let's say data step um Step number let's say um let's just call it number number like that and this one's going to be equal to one hmm and we're going to do the same thing for the second one there you go like this oops nope like that this one's going to have a I'm just adding these data sets to be able to actually access it access this through JavaScript so that it's easier there you go so now this right here what we're going to do is we're going to get this the page the number of the current step okay so let's get that one step number like this and we're going to set it to um the current step we're going to access the data set and we're going to access the property that we have just created which is the number like this okay um there you go and we're going all since this returns a string what we're going to do is we're going to parse it again plus end again base of 10 like this there you go and now finally if the step page sorry the step number that we have just created is less or equal to current page to current page what we're going to do is we're going to colorize all of the oh I mean we're going to colorize all of the bubbles these bubbles right here if their step number is equal or or less than the current page okay so there you go um that way if we're in page two it's going to colorize number two and number one for example or if we're in page number three it's going to colorize all of them okay so let's do that right now so step dot class list remember that in order to colorize it we're just adding the active class and we're going to add active like this okay so there you go I mean this function is supposed to be working I mean whenever we call it it's supposed to verify which page we're in um and then on color all of the steps and then color all up until the page that we're in so what we're gonna have to do right now is pretty much just call it at the end of our go to page method so let's do that so after we go to a certain page we're going to update the progress bar to illustrate that page change so let's do that let's just hope update Pro Chris bar like this and right here we're going to say this um update we're going to just going to call this method that we created in a moment ago just save it and let's see if this is working hopefully it's going to work um let's say all right so let's click on next and all right there's a problem going on uh let's see what what the problem is um previous all right so yeah this thing is not not working correctly let's see what's going on um update progress bar update progress bar would have it here let me just check right here head um I'll step this form quiz electoral we're gonna page step like that constant current page you're supposed to get the current page there you go and then for all steps and each of this if it contains the class active there you go and we're going to remove the class active so that's okay and then the const um Step number right here let's just create the step number and we're just parsing the data set number which is if I'm not mistake in this one right here how we save this I think we have all right so this is one two three there you go um what else um if step number oh I I said plus all right yeah I meant less or equal to current page there you go so this is what was messing it all um there you go so if the step number is less or equal to the current page it's going to be illuminated um so let's just refresh hit next next previews previous so now it's working correctly all right so hmm all right that's how you that's how you would over design a form um I mean in case you actually think that this was over design I actually totally agree with you um the thing is that this is not supposed to be like a practical example of what you would do in every single case when you had to do a multi-step form okay this is supposed to be kind of an exercise to show how to work with classes and how to work with internal methods and how to work with with um properties of your class and how to organize your code in classes so that it's containerized but in any case in some cases actually this kind of this software design is actually very useful all right maybe not just for a very small form that you're just going to build once and then you're going to forget about it but if you're actually building something that's big for example let's say that you're doing a page that um has a multi-step formal form and what you want to do is you have to calculate I mean do some calculations depending on what the user step inputs on each of the form Pages let's say I don't know a tax um a tax calculator all right so if they if they use their inputs their their income in the first page and then they they I don't know just just to input their net worth in the second one Etc I don't I mean they're just input different things and then in the end you're going to calculate things I mean this kind of design is actually very useful because it if it's a more sophisticated kind of form you're just going to allow you to actually get it maintained in the long term and to actually be able to be um re-work done by other developers in the future so I hope you found this useful I hope you liked it and and yeah I mean I'll put up a link to this form and the description and if you like this please do drop a like And subscribe so I mean that's free for you and it helps a lot um so yeah hope you liked it and see you next time [Music] [Music]
LxenV0YaX8M,2023-01-16T12:07:00.000000,Javascript Interactive Map with Leaflet EASY (with Marker Clusters & Popups),good morning everyone how is it going today welcome to my channel my name is Alejandro and we're here to talk about web development and a little bit about data science as well because it has become a popular culture already today we're going to be building a JavaScript map and and it's going to be an interactive map and we're going to be building it with vanilla JavaScript which means that we will not be using any Frameworks such as react or angular and we're going to be making it very customizable okay so this is the end result that you see right here as you can see we have several markers right here and you will be able to add as many as you want as long as you have the coordinates every marker you can assign a pop-up to it and every marker can have a different pop-up in this example it's just the same one but every marker can't have a different pop-up we're going to be using a library called leaflet.js which is a free library and we're going to be using openstreetmap as our map provider okay so that's going to be a free map so you won't have to to worry about paying a Google API Etc the map is also pretty customizable as you can see e because here we have a different skin I just chose a watercolor skin but you can choose any different design that you want or just a very sober traditional map style it's also possible okay and last but not least there is also the possibility of adding clusters to your map and this is what we're going to be seeing so when you zoom out if there are many markers that are at the same place we're going to be able to Cluster them in just one icon that shows the amount I mean the number of markers that are in that position and by clicking on it we're going to zoom into the markers okay so as you can see as well this is a div and we're going to be able to just embed it whatever you you want okay since this is a div you can also use it as a full full screen map or you can use it as a very simple embedded map at some point in your in your new website okay so let's get right into it thank you [Music] foreign books because it's pretty much just a front-end project if you're not familiar with code sandbergs I just really recommend it for your front-end project but I'm going to be explaining the differences between code sandbox and your local environment along the way okay so that you can follow either in code sandbox or in your local environment with your machine okay so there we go so let's just take a look at the file folder structure right here so we have our index.html which is the page that in the template that's being loaded here we have our HTML file and we have a div called app okay and then we're importing our index.js here at the bottom um after that if we go see our index.html it's actually replacing the content inside the app element with this right here and this is exactly why we see this right here so what I'm going to do is I'm just going to replace it with hello world how are you and here we have hello world that's being loaded then we're also importing styles.css inside our JavaScript file and styles.css has a font family sunserve and that's all we got okay so it's a very simple folder structure and let's get right into it to start building our our application okay how does that look so there we go as I mentioned before we're going to be using leaflet JS which is a free library and if you feel like it you can also check out their documentation they have a very good and very detailed documentation um but for now let's just code it right ourselves okay um so first of all I'm not going to be using this part right here and right here this one right here I am going to rename it to map okay so this div is going to be map and right here what I'm going to do is I'm going to install leaflet first okay here my dependency list is pretty much the same as doing npm install okay so if I look here for leaflet it's pretty much just the same as doing in npm install leaflet okay so as you can see I am working with the version 1.9.3 but I mean hopefully this will be um you won't have any problems if you're loading a another version okay a newer version so first of all what we're going to do is we're going to import our leaflet Library so what we're going to do is we're going to do import everything as l from the flat there you go and now we can use l as our leaflet element okay so for the first thing we have to do is we have to initialize the map okay and how do we initialize it so we have to create our variable that's going to be a map and the map is going to be an instance of L and we're going to call it oops map like this and right here this this method right here what it does it is it requires you to load to tell it which HTML element is going to be filled with your map okay and the HTML element that we won't filled with our map is the one that we named right here so we're going to pass the ID of this one right here right there okay so the ID of this div is map so what we're going to do is we're going to pass in right here it's going to be map and then just add another method right here that's called set View set view to tell it where we want the map to be centered at the beginning so I'm just going to say it's going to be in London and the coordinates for London and our 51.5 like Arctic Monkeys and negative 0.09 and the second argument that takes is the zoom that we want this to have and we're going to set it to 13 so that we have a City View if you want to know a little bit more about the zoom levels that you have you can just Google leaflet zooms and here you have leaflet Zoom levels basically the higher it is the closer it is to the city and the lower it is the closer it is to the world view okay so I encourage you to test the zoom levels if you want to to try it out for yourself okay so now that we have initialized the map the second thing we have to do is we have to add a map layer to it okay this means that we already have our map but we have to add our map layer um to it and what we're going to do is we're going to call leaflet again and we're going to say tile layer like this and we're going to say which style layer we want to load here here we want to load our map provider okay and the map provider that we're going to be using is openstreetmap um because it's free and so you just have to load it like this right here and then tie layer also takes a second argument which are the parameters that you want to that you want to add to your map okay um and the params uh there are many but I'm just going to set it a maximum zoom level to 19 so that people don't go like very very deep into our zoom and also it's convenient to add an attribution um part to it this attribution part is basically what you see right here there you go um let me just zoom in I cannot zoom in right here so it's basically this pretty this part right here okay so I mean when you use openstreetmap you you kind of have to attribute it to to openstreetmap okay so I'm just going to add this part right here um there you go so my attribution is going to be a copy open street map open street map there you go now you have it and once we have we have already created our layer okay but now we have to actually add it to our map so to do that we are going to use another method that's going to that's called add to and it just takes us an argument the actual map element that we have just created and it is map as we decide as we defined it up here okay so now if I save and I refresh as you can see we have some problems going on right here the map is crazy for some reason and also like um it's like all over the place and we don't seem to see an actual size of the map okay when you see this problem it basically means that you are having problems with your CSS okay so as you can see we have imported the JavaScript part of leaflet but we haven't imported the CSS part of leaflet so what we're going to do to fix this is we're going to go to their tutorials or the docs whatever and we're going to add their CSS okay so include the CSS from leaflet in the set head section of your document um I am going to do it like this but if you are using um uh npm what you can do is just do something like this import leaflet and then just import the CSS from here if I'm not mistaken I don't remember you you might want to check it in your note modules um directory but if I am not mistaken it's something like leaflet test and then leaflet.css if I'm not mistaken but I'm not sure about it um I'm just gonna all right let's try it like this and let's see how it works okay now we have another problem the other problem that we have is that our div I mean leaflet pretty much just fills in our div with the map but it doesn't tell the div what size it has to be it has to be okay so what we are gonna what we're the problem that we see right now is that we don't see anything and that is because our div has a height of zero so what I'm going to do right here is I'm going to set a height to 300 pixels and there you go so now we have our height of 300 pixels and our map is working because apparently this part right here actually worked as you can see if I remove um if I remove leaflet.css this is going to this is going to become crazy okay so this is what you do this I mean just to be to make this clear this right here this line right here only works because I am using leaflet from npm okay this right here calls the leaflet.css that's actually inside node modules note modules leaflet dist leaflet CSS okay so I mean this only works if because I'm using npm if you are not using npm you're going to have to you're going to have to come right here to index.html and add your CSS right here and as you can see it works again okay but since I am using npm I'm not going to add this one right here and I am going to just add it from here there you go so here we have our map seems to be working correctly and we already have a working map in just a few lines we just initialize our map and we added the tile layer uh so that's pretty good um let's see what do we want to do afterwards uh let's add the markers Okay add markers um so to add the markers what we're going to do is we're I mean we're also following just the documentation but what we're going to do to add the markers is pretty much you just set um a new marker you call it an add marker like that and you're going to set it equal to l from leaflet marker and this marker takes several arguments but the first one is basically just its position okay so I'm just going to set it somewhere in London 51.5 and minus 0.08 there you go and then the other argument the I mean that's pretty much all that we need and then once that you have your marker that has been created you just just as you did with the layer you add two map like this and then as you can see if I save this right here and I refresh this page right here my marker for some reason does not have the the icon I suppose because the icon actually comes from this part right here so let's say if I if I use this one does it work for some reason my marker is not loading correctly I'm not sure why um [Music] mm-hmm all right give me a couple of a couple of seconds I'm just going to figure out why this marker is not loading all right so I think I got why it wasn't working actually uh the problem is that we're importing it we're importing leaflet from up here and apparently the icon is only loaded if we imported it from the actual CDN right so the icon is not here but if we import it from here um but I don't know it's just some some kind of strange problem but the this is pretty useful actually because what I'm going to do is I'm going to show you how to load your own icon okay so what we're gonna do is we're going to be using this icon right here for my from Flat icons um so I just loaded flat icon and I just opened whichever icon I wanted I'm going to be using this one and I mean you would usually download it to your to your own file to your own folder and you would load it from there but I'm just like because I'm lazy I'm just going to copy the address from here and I am going to call to paste it right here all right so we're not going to be using this one we're going to stick to npm version like that and now we're going to as you can see we don't have the marker but what we're going to do is we're going to initialize a new marker a new icon okay for this marker I'm going to call it um custom icon and it's going to be a leaflet element I'm going to call you Call leaflet and then you call an icon and this this method creates an icon and it takes several parameters okay so the first one is the icon URL and right here you just paste the URL of your icon as I just copied it I'm just going to paste it right here and now what I'm going to do is I'm going to pass that one right here as um as a parameter for my new marker so right here I'm going to add parameters right here and I'm going to say icon and the icon is going to be custom icon okay like that all right so now our icon is loading as you can see the only problem is that it's huge all right so we probably don't want our icon to be this big so what we are going to do is we're going to add a new um uh parameter here to my icon and I'm going to call it icon size and this one right here takes just pretty much the size of the icon in pixel so I'm going to set it to 38 times 38 so there you go now you have this pretty little icon that's 38 pixels by 38 pixels okay and that's how it works if you want to create your custom icon I'm just going to add it right here my custom icon there you go so now we saw how to add markers uh let's add a couple more all right how about we add three more uh two more um I'm used to two vs code so uh uh all right so there you go I'm going to move this one just a little bit to the side and a little bit um down a little bit up and this one a little bit down so there you go so now you have your three markers right here and and there you go um all right so now you have your markers but what are we going to do right now let's see how about we create a cluster for them okay so right now you can see that we have our map that's working pretty good actually you know what I'm going to show you so that you see it like full screen I'm just going to set this one to 100 viewport height so that way you can see the map all all the way here okay there you go um so there you have it we have our three markers right here and what we're going to do right now is we're going to create a cluster for this okay and now there was another question how do we create this clusters all right because so far if we move too far away it's not working correctly because we're seeing just a bunch of cluster together I mean a bunch of markers together and we don't really see what's in there so we're going to replace this with a div that is going to display the the number of markers that are in that position and then when we click on that div it's going to zoom in and show us all the markers all right so that's how it works and to do this what we're going to do is we're actually going to use a new a new dependency that's actually a plug-in for leaflet and it's called leaflet leaflet marker cluster there you go and you can find it it's on GitHub it's this one right here and as you can see it works pretty good if you want you can follow the instructions right here or let's jump right into the code and I can show you how it works okay um so far um in case you haven't noticed leaflet Works um with layers okay so first we created our map element and then to that element we have added layers okay so first we added we created our tile layer which is the map the map itself that we have added to our map element and we have added it on top of the map element as a layer okay then every marker that we're creating is sort of a layer on top of that on top of that okay so what the cluster plugin does is that it creates a new layer on top of that marker on top of that map and then it's on top of this marker cluster layer that you add your markers and then all the markers that are inside this layer are going to be clustered together when they're closed and then shown separately when they're when they're dispersed okay so let's create this cluster layer okay so to create a cluster layer the first thing that you need to do is install this leaflet Market cluster dependency and to do this you can just do leaflet Mark your cluster I mean as I told you before when I search for dependencies right here it's pretty much as though you were importing them installing them with npm so I just what I made is pretty much equivalent to doing npm install leaflet marker cluster and I'm working with version 1.5.3 and leaflet is 1.9.3 now that I have installed it what I'm going to do is I'm going to import it right here I'm going to down import leaflet leaflet Market cluster there you go and this right here is going to extend this L element right here and it's going to give me access to a new part of it to a new method in this element and it's going to be marker cluster group there you go and basically this this pretty much allows us to create this new layer that is going to be the marker cluster group where we're going to put our markers um so I'm going to create that layer I'm going to call it my custom you know my cluster layer what's equal to that and this one right here actually takes in some arguments um but first of all we're having a problem right here and I want to show you how the why this is not working because you might run into some problems some of these problems here if you're using a npm and a bundler okay so for some reason the cluster plugin does add the marker cluster group function a method to the L element but the problem is that sometimes it doesn't recognize the actual L element from leaflet and it just creates a new one um so to access that new one you would actually have to access it through window.l that market cluster and if as you can see now we don't have an error um I think this is a bug from the plugin and I hope it's fixed soon but another way to look at it is that if you do console log and you check whether window dot l equals l then you're going to see that it actually that it actually I mean at least in my case it prints false which means that window.l and L are not the same thing so yeah I mean if you were having that problem just add a window in front of the L for mask for Mark your cluster group and you will be fine okay all right so let's continue creating our cluster layer this function actually takes in several arguments but the one that we're going to use right here or if we're going to add a function that creates the icon that we're going to see when we have a cluster okay so this phone this argument this parameter is called icon create function there you go and as the name suggests it takes in a function and the function takes in one argument which is cluster okay and this cluster is actually the cluster of the of your markers okay and this function what it does is it has to return your your your div okay so let's see um let's add return l dot div icon which because we're going to create an icon for this and inside this div icon we're going to add some HTML and the HTML is going to be a very simple div okay div and we're going to give it a class so that we can actually modify it later and the class is going to be cluster div like that now let's close our div like this there you go and let's add something inside here and inside here what we're going to do is going to add the cluster dot get child count which basically what it does is it Returns the number of of markers inside that cluster okay so that way what we're going to see right here when we see the cluster we're going to see a div with a class of cluster div and the content of that div is going to be the child count the number of Cl of markers that are inside it okay so that's how this goes uh so we have already created our cluster layer what we're gonna have to do right now is we're going to add this Mark is right here but instead of adding them directly to the map what we're going to do is we're going to add them to our layer to our cluster layer okay so first of all what I'm going to do is I'm going to you know what I'm going to do I'm actually going to take all of this I'm going to add them actually I'm going to create them after the cluster layer down here there you go and I'm not going to add them to the map like this like that there you go there you go and actually I mean this is ridiculous why did we have different names for different L as the same name for different elements so now we have different markers and I'm just going to actually use a is const instead of VAR there you go so now we have our three different markers each of them using our custom icon but we haven't included them in our layer so what we're going to do is we're going to add them on top of our cluster layer and to do that what we're going to do is we're going to call our cluster layer and basically we're just going to say add layer on top of it and we're going to add a layer for and we're going to add each marker as a layer to it so I'm going to add marker one there you go and then if I refresh I should actually see it over there what is going on right here [Applause] my cluster layer add cluster layer at layer my cluster layer what is going on right here Market 2 is assigned console is not working um what is going on right here oh yeah sure actually I mean we have we have successfully added this marker to our cluster layer but the problem is that the layer is not yet added it's not being added yet to our actual map all right so what we're going to want to do in the end after we have added our markers we're going to call our map and we're going to add the layer which is going to be our cluster layer there you go and now there's five if I save this now we have our marker that we have added to the cluster layer and ideally we would want to do the same thing for our marker 2 and our marker 3 and there you have it now we have our three markers working correctly and if we zoom out you can see that we have a div with the number three in there okay so that is pretty convenient we already have a div element which displays the number of items that we have and if we click on it we see the actual three markers over there but I mean of course that is pretty ugly so what we would ideally want to do is actually um like style it so that it actually is fun to see all right I mean I mean this obviously is pretty ugly so remember that we added the cluster Dave class for that one like this not like that like this there you go so what we're going to do is we're just going to restyle this right there so let's add a background color up background color to white why not let's uh let's set its height to 3 REM and it's with oops and it's with oh two three REM two um let's add a border radius to 50 so that we see an actual Circle and let's add a very cute box shadow box shadow of what's uh let's set it to the center zero pixels and four pixels there you go let's see how that looks like there you go uh it's looking pretty good the problem right now is that we're actually seeing it I mean it's displayed I mean it's all it's a little bit not where we want it to be we want it to be actually on top of the cluster and it's I mean only its upper corner is on in the center so what we're going to do to fix this thing right here is pretty much we're going to transform and we're going to translate it and we're going to say minus 50 percent and minus 50 percent there you go and now if we save this it should be there the problem is that our number three is very small over there so what we're going to want to do is we're going to actually Center it I'm just going to use this place on display flex and and Center it like this then what are we going to do let's add a font size of 1.5 REM so that's three and let's set it and it's font weight to bold so that it's a little bit easier to look at it there you go so now we have our number three and it's looking pretty good but remember that we can just like like modify this this the stiff with with our class that we have just added right here okay so I mean that hopefully gives you a lot of freedom to to modify your cluster divs and also remember that you can add as many cluster layers as you wish so that markers can cluster together independently so if you have I don't know some markers for members of of uh of um I don't know of a community or or for events or something and you want them to close to Cluster together and not like in the same cluster you can just add different cluster layers for those and add the markers separately okay now this is very um a little dirty because I mean you would you wouldn't actually do this like in real life you would actually call this into an array and then Loop through the array and then create your markers but that's how it works okay I mean this is just to show you how it works I'm just going to show you pretty quick as well how you add pop-ups to to your to your markers and this is this works pretty much like this to a marker element I mean like here we have our marker number one and to the marker number one we're going to add marker one we're going to add a math we're going to run a method that's called bind popup like that and right here it basically just takes any HTML that you want okay I'm going to say I'm going to add an H3 like this there you go I'm going to say I am a pop-up there we go um and as you can see this right here has created a pop-up in one of this which one is it it's this one okay as you can see this is pretty much entirely customizable as well because I just added whatever HTML right here and it was loaded inside my pop-up and as you can see you can add different pop-ups to different to different two different markers so I am pop-up for marker two there you go and then if I reload then I have my pop-up for marker 2 and this is my pop-up for Market one there you go all right um so now that we have seen how to create our map how to add our cluster groups how to add our pop-ups and how to actually change their icons what we can do now is I'm going to show you how to modify this style of the bag I mean of the actual net okay so so far we're actually just using a very simple tile layer um add markers to Cluster there you go so right now we're actually using a very simple tile layer that comes from from openstreetmap and it's actually very convenient if you want your map to be pretty sober but the idea is that if you want your map to be a little bit more different you can come right here and look for leaflet skins something like that and you will find that something called leaflet provider okay and it basically just allows you to choose many different schemes and some of them are some of them are like paid for some of them are free what I recommend is that you test them and see which ones are which one is free and which one works for you okay um to actually use it what I like to do is I want to go to GitHub right here and here you have the example of how to use this thing okay you can either include it with a script or you can install it with npm which is what I'm going to do myself and to install it you just add Leaf npm install leaflet providers like this one and now I have installed leaflet providers and let import leaflet oops leaflet providers like that there you go and now I can actually I am getting access to a new element in my in my L thing in my like L object and here I can add another tie layer like this one and instead of just opening this one right here I'm gonna be able to add a provider to it like this there you go and inside the provider I can just run whichever whichever map I want okay here you have the example and here you have the diff different Maps actually work differently so I really recommend that you take a look a quick look at this before you choose which skin you want to use I'm just going to use a very simple one which is free but some of them do require an API key okay so this is to include them as you see what I did is style layer provider then you say the name of your map sometimes you require an API key sometimes you don't I am just going to use a free one which is this one's name in watercolor and there you go and I'm just going to add it right here like that same in watercolor which is basically same in watercolor it must be somewhere around here I cannot find it but I mean once you find one that you like you can just check it it's ja WG so you come right here how this download goes all right so Joe G maps in order to use geology Maps you must register once registered Etc so you will get an access token okay so I mean depending on which one you choose you might want to come here to your documentation and check what are the requirements for that actual skin I'm just going to use this free one which is the watercolor one I'm going to paste it over there and the thing is that I have actually created my entire layer but this one right here is going to replace this one right here so what I want to do is I'm going to remove this one from the map right here and I'm just going to add this one instead so add 2 map there you go and if I save now I have my watercolor skin working okay and that's pretty much how it works now you have your cluster now you have your very sophisticated skin and style for your map you have different pop-ups four different icon for different markers you also learned how to change the icon of your markers and yeah I mean that's pretty much how to create maps for this I mean I could go all the way and actually just add um add the like just as I showed you before but I mean I think this is pretty clear all ready and as I mentioned before this is completely customizable you can just tweak pretty much all the parameters that I showed you and just like Center it somewhere else with a different with a different zoom and you can set it to default to Europe or to the United States Etc um there you go what else uh yeah so as I was showing you this actually comes all of it is inside this div which is div ID map so if you want to add this div like if you want to set it to full screen unless I like I did you can just set it to 100 viewport height but if you want to include it just in a section of your website you can just do that as well after all it's just a div and it's all in the JavaScript so I hope you found this this tutorial useful I hope you enjoyed it please subscribe if you want to see more of this kind of videos and like the video of course that helps me a lot for the YouTube algorithm and yeah I hope you have a great day and I'll see you next time [Music] [Music] thank you [Music]
A5r8kslNSF0,2023-01-09T11:29:49.000000,Convert HTML template to WordPress Theme (2023) - Full Course,[Music] thank you good morning everyone how is it going today um today I'm going to be showing you how to convert an HTML template into a WordPress theme okay we're gonna try to do this as quickly I mean in as efficiently as possible but this is going to be more of a walkthrough of all of the process so that you can see all the possible errors that can happen and I mean I'll be doing this like live with you right now so I'm not sure what errors we're going to encounter but the idea is that you will see everything that you can that you would be able to that you could encounter in a real world situation okay um all right so two things before we begin we're going to be using a boilerplate for WordPress that water boilerplate for WordPress is it's a an empty theme that you have that sorry about that an empty theme that you have that you're going to modify in order to adapt it to your new template okay so it's an empty theme and the boilerplate that we're going to be using is this one right here it's called our awesome theme if you would like to know how to build it you can watch my previous video about how to use webpack on on WordPress in which I just basically created the spoilerplate and the good part about this one is that it already has typescript and SAS support and bad little support if I'm not mistaken so you can just start coding on it and it's going to be like completely compatible and you can use SAS and typescript um if you want to know how to build it you can check my video on webpacks 5 and WordPress or if you just want to download the boilerplate you can download it on the link in the description and what else and yeah so you need this boilerplate and of course you need an HTML template that you want to convert into WordPress theme so how do we do that good question um so that's what this is all about um so first of all we're gonna have to use an h10 we're not going to have to have an already HTML template finished and and I don't have one right now so what I'm going to do is I'm going to come right here to html5up.net what this website does is pretty much it just allows you to download free templates or HTML templates and that are completely responsive and that is pretty useful I think so I'm going to be using this one hyperspace and let's see the demo you have the desktop version I mean as you can see this one right here is the front page and you have desktop version you have a tablet version I mean it's yeah I mean this is just all the breakpoints and so it allows you to see that this template is actually um responsive okay so in case you don't know what responsive means is that it's I hit adapts to the size of the of the screen so yeah so let's let's download this one I'm just going to download it and the good part about this website is that it's free and all the some of the templates if I'm not mistaken they do require that you attribute the the I mean the template to the actual person who created the template so yeah don't don't forget to do that if you're going to use this for commercial purposes um all right so now that we have it right here I'm just going to open it and all these files right here is what comes inside of that and as you can see right here we have an index.html which is pretty much the front page that we were looking at before and we also have what else we have right here we also have we also have generic HTML which is the page that we're going to be using for our posts and then for our for our single post and we have an elements that HTML which is kind of the guide that we can use to to style our components so that's pretty convenient too I'm just going to close all the other tabs there you go and there you go so let's go right into our website this is the website that I have and just I'm just going to give you a very quick tour of the boilerplate in case you don't if you in case you haven't used it before and in case you haven't watched the previous video if you have already watched the previous video or you know how this polar plate works you can skip this section of the video so what's your what you can see right here is the front page and you can see it's very clean and empty so there's nothing in it and that's how it works because we have our awesome theme you know what I'm going to show you how to access it from the beginning so to access it what we're going to do I'm running WordPress in a local machine using local by Flywheel the convenient part about local is that you have a sideshow in here you can just open it and it comes with WP WP CLI installed composer PHP in MySQL so that's convenient and right here it opens directly in our WordPress installation so all of these files are the ones that would be in your server so so you know and so what we're going to do is we're going to get into the content we're going to go to themes and here right here you can see that you have all your themes this um this right here are folders and this right here is just an empty index.php that we don't use at all and this right here is my boilerplate okay so if you download the boilerplate from GitHub on the link in the description you're going to get this folder exactly like that so you can just copy it inside here and you can set it up and running and get it up and running um so there we go also what else we got in here um let me show you how this looks um yeah all right so there we go um now I'm just going to open this awesome uh boilerplate let me there you go I'm just going to open this awesome boilerplate in in vs code so there you have it um so this right here is the boilerplate and how it works basically is that we have our source files right here we have SAS and we have typescript and we have all of this I mean of course you're not going to include in queue a SAS file into your WordPress theme so or a typescript because I mean web browsers have no idea of what SAS or typescript is so what you want to do is you're going to you're going to want to compile this into minified versions of SAS and a minified versions of CSS and JavaScript and that is what webpack does and my webpack that we created in the previous videos is down here so all you have to do right now is open the terminal and type npm run watch and that's basically going to take these files and compile them into main CSS and main.man.js and these files are already enqueued into our WordPress okay so there is no need to do anything else so everything you put inside here it's going to be added into your WordPress so that's convenient uh what else are we gonna do um um yeah I guess that's pretty much it so let's get right into it um oh yeah just to show you pretty quick also the scripts and and then the scripts the scripts the scripts are here and so my scripts I created a watch script and that runs webpack and it just pretty much just allows you to keep an eye on the files that you're using up here and if you modify one of this for example let's say that I modify this one to body and body background color to red and I hit save I haven't touched anything but it because I'm running the npm watch this right here already automated and already included in background color red so no need to um there's no need to to to run the compiler it's going to be done automatically okay so that's how the boilerplate works so right now let's get let's get back to including our template into our theme so let's see how that works we have the template right here you know what I'm going to do I'm going to open this in code in vs code as well so I'm going to do code I'm going to copy this here and there we have it so we have our templates up here in case you don't know how to add a front page to a WordPress theme what you want to do is you add a new file then you call it front page dot PHP there you go and in here anything you put in here um I'm just going to say H1 hello world and this right here is going to be is going to be my front page so now that I have saved this if I reload this page it's going to interpret my front page as the front page now my front page file as the front page so there you go so everything we put in here is going to be considered the front page so as you can see all that we have to do is take this file and put it inside there and configure it okay but there's another problem um in WordPress we usually work with a separate header and a footer template in order to there you go in WordPress we usually work with a different header and footer template and what we do is we import those header and footer every time we want to create a new template so that we don't have to repeat ourselves all right so if we didn't do this we would have to add here every time we added we added a new template we would have to be we would have to do something like oh yeah so adult type HTML and then add the nav bar and and all I mean it's it's just a lot of work and it's not useful so what we're going to be doing here is we're going to take the top part of this into a header.php and the footer into a footer.php and we're just going to include them so Footers our footer is already built it's up here and our header is already built it's up here and we're going to do is we're going to import it in here just by you doing this so you do PHP get header and you do the same PHP get footer and this two functions right here they're going to call our files um they're going to call our files footer and header so right now if I add H1 right here hello world now refresh we're going to have our header under footer and as you can see the styles were in included too because my styles are included in my header.php so yeah right now I can modify my header for example header.php and I can say that in here I want it to be I want here to be another H1 and this is inside header dot PHP and then I save this and then I reload this appears right here because we're getting this from the header and if you can see my front page doesn't have that text so it's coming from the header and it's being included on get header same for get footer we can include something on get footer right here I always say H3 this is the Fuller and then if we refresh this appears right here okay so I'm just going to delete this and I'm going to delete this right here too all right so what we want to do is we want to include all those files right all this code right here inside here so let's try to do that um ideally we want we only want the body to be inside it um let's see our footer template we don't have a body tag inside it oh yes we actually do so okay so what we're going to want to do is we're going to get the body tag inside the header too okay so we're going to update our header this right here is going to go into the header pay into the header our header template um this right here is going to go into our footer template and everything in between is going to go into our frontpage.php file okay so let's get let's start with the header so here we have our header this one right here is our boilerplate and this one right here is the the template that we had before so as you can see right here we already have a lot of things inside our head tag and here we have a head tag so let's update this um we want to add a title tag so we copy this here from here to here so now we have a title tag um we have our meta and we Define the Char set this right here pretty much just tells our browser which charts it we're using and we usually use utf-8 but just to make this a little bit more Dynamic we use block info chassette and that basically just does I mean it usually just brings utf-8 but what it does is that if for some reason our theme changes the chart set this is going to be dynamic and it's it Returns the name of the chart set that's stored in the database and it puts it right here so we're going to leave this one as this meta we have viewport detect so everything seems exactly the same we have initial scale One initial scale one we have user scalable no and just to make things completely exactly as they are in in this template we're going to add this one right here um and we're going to replace this one with the one that we have the on the other side what else do we have we have link relationship profile for some reason and we have link style sheet um so we have to link to our Styles CSS as you remember in the file that we downloaded from the template we have our assets and we have our CSS Styles but we don't want them to be like this in our case we want them to be in the way we already have our boilerplate working so we're going to include them using our boilerplate now to do that we're going to be using SAS so that's convenient there we go and we also have some web funds that's going to be kind of a pain probably but let's see how that works um all right so first of all I'm going to leave this title sheets for later okay um so just keep in mind that these two are going to be included later and what else do we have here so the head I guess that's all for the body I mean the the opening tag of the body it's important that you keep it the opening tag of the body it's important that you keep it in the header.php and not inside your template because um I mean pretty much because it's always present and also because um yeah just because it's always present and this right here is pretty important too this is just a PHP function that comes from word from the WordPress framework that substitutes that creates or right that creates the classes for WordPress and it just outputs them in here so what is this doing let's see what this is doing I'm just going to open this my website again I'm let me just get rid of the red color because it kind of it's kind of disturbing um I modified it in main CSS so I'm going to set it to something a little bit more beautiful um let's say well that's not extract exactly beautiful but it's at least it's better on the eyes um so what we're gonna do is I'm gonna show you this right here is the opening body tag and you see we don't have any classes here let's see what's going on um so I'm going to go to elements I'm going to go to my body tag and as you can see we do have some classes here we have home we have blog we have logged in we have admin bar HF wait I'm going to zoom in here there you have it so we have home blog logged in admin bar HF H feed customized support Etc and this classes we did not import them I mean they're not here so where are they so they're being imported by this function right here so it's important that you add this function and so you usually just let it keep it in the header.php so that it's always important so that it's always imported and WordPress is going to import to replace this with any functions that it needs to include so no need to do anything else about that uh we had WP body open now we have ID page class site skip link green letter primary skip content Etc I actually think that we can just let go of all of this let's see how they do on their side they already have like they start already with the section so I'm just going to yeah I'm just going to erase all of this there you go so now we have our header that's looking that's looking very similar to the header from our template that we downloaded let's say if it's still working on here there you go it seems to be working now we only have hello world and but we still have this on our Footers so let's clean up our footer too um our footer is supposed to be something like this let's see if we can get that here um buddy buddy buddy well what we have here okay something important is that our footer has to have all the scripts that we're going to be using so we're going to be using this right here and all of this all the way to here yeah so we're going to be including the footer we're going to be including the script and the End closing tags so let's go to our footer right here footer all right footer and we're going to remove this footer from here we don't need this one um and we're going to add WP footer that's important same just as before this WP footer it works pretty much the same as the Olympiad that oh did I explain to you how would WP head works um all right so just in case I didn't this right here yeah this WP head this is going to replace the I mean calling this function right here it's going to include all the Styles and everything that you want to include in your header that you don't see here but that WordPress does for you so if we see how this works on the front end right here you can see that we have inside our head tag we have what we included we have Myspace by HTML5 up utf-8 as I'm as I was telling you initial scale meta link profile and we also have a title thing right here in my awesome web supply Just another WordPress site so actually we didn't need this one because all of the everything that comes after this one right here is being included by this function right here and this is just like and this comes from the WordPress setting so you don't have to do anything to include all of these things it's all included by WP head okay and later I'm going to show you how to add things to WP head so that it includes them together um what else we got all right so that I guess that's that's it's for the header uh let's let's just go back to the footer uh front page nope uh for their words or footer all right so here's our footer and we want to put all of this in there but we want I mean the wp footer it works just as WP header uh WP head sorry um what it does is basically just import all the scripts that you tell WordPress to include in the footer and it replaces this with all of that um so so so so so this right here should come before be wait yeah this right here should come before the body at the end body tag and we're going to delete this because we don't need them anymore and this looks pretty good to me the problem right here is that we're including scripts that are not uh in our directory so how do we deal with scripts and styles I'm going to show you that in a moment and for the moment I'm just going to comment this out I'm going to do the same in the header in the header remember we need this link Styles right here but we they're not going to work so I'm just going to comment them out all right so I did it um this right here this is not going to work so I'm just going to comment it out these are the styles for the template and and in our footer these are the scripts for our template so we're just going to comment this out right now because it's not going to work because they're not included in our theme so let me just show the EU that footer is working and that the header is working and let's see the front page what it looks right now what it looks like right now so as you can see we only have front footer and header and let's just keep this hello world and if we re refresh this we have hello world still and we have design and Untitled this right here is the footer that we see right here designed by HTML5 Untitled All rights reserved um but we don't have the style for it so that's what we're going to do later in the video but as you can see we already have a footer we already have a header with all this info right here that we wanted to include and so apparently everything's up and ready to include our code inside it so let's get right into it um I'm going to first of all oh by the way yeah don't don't forget that in my header thing in my header dot PHP I opened body and HTML and I close them here right body and HTML so that's that's how it works well let's replace everything that's inside here with everything that's in our template right um I'm going to take just a quick break of five minutes I'm going to show you in a moment how it works all right all right well now we're back and so we're going to put everything that's inside here and here all right and let's see how that looks I'm just going to select the sidebar that's going to be quite important and we're going to select all the way until before the footer because we included the footer in our footer so I'm gonna copy this and paste it right here there you go now you have it right here now if I save this we're in our front page I'm going to bring this here and let's see how that works let's see how that looks um all right seems to be working so we have our hyperspace title we have the description we have the subtitles we have all the content that's here what we do set up some dollar what we do Etc uh what we do yeah I mean we seem to have all the contents so what we're going to do now is we're going to add the Styles first all right um to do that I have to remind you that the styles that we're going to add here are supposed to be this too main.css and no script.css okay for a moment I'm going to stop jetpack because that's not going to be I'm going to show you how to use it in a moment but um for a moment we're going to be using this too so how do we use this too first of all I'm going to uncomment these two lines so we're using acid CSS and Main CSS there's one thing with WordPress that this is not going to work because you have to tell WordPress that you're going to be using you have to give WordPress the actual the actual wait what's going on here [Music] um you have to be to do WordPress to give WordPress the actual full URL of of this right let me show you how this doesn't work just like that okay if we leave it like that and we refresh this uh it's not going to change anything well first of all because we don't have our Styles there but also because if we come here and try to look for that that style sheet that we just imported it's going to be let me see where it's going to be is going to be somewhere around here let's say it's going to be where did I put it by the way I put it under the link profile thingy link profile thing yeah here it is so it's this too and it's not working definitely because here we have a relative path and WordPress does not really like to work with relative paths especially when working with a theme so what we're going to want to do is we're going to have to give it the entire URL or URI for to today's style sheet so first let's add our style sheet here to the assets folder uh all of this I'm just going to delete it for now um and inside assets I'm going to create a CSS CSS directory and inside this CSS I'm going to put main.css all right and main.css is here main.css there you go now my main.css in there it's in there and what else we have a noscript.css.well there you have it so now we have our cssing assets and what we're gonna do right now is we're going to we're going to do to we're going to I mean if we if we save this and we load this it's still not going to work because it won't find it because it's it has a relative um a relative URL so let's make that um let's make that uh complete URL okay so how to find this one to find it we can do a couple things first of all we can do HTTP are we doing are we using https here um wait are we using https I don't think so all right so it's not HTTP so it's my awesome website I forgot an e somewhere around them am I awesome websites are about the the misspell local and then Here Local you uh I mean this is the URL to the PA to the to the CSS file okay so this is going to be my awesome website.local.wp content slash themes and the theme is called right where are we just gonna open this and the theme is called my awesome website if I'm not mistaken or my awesome theme I don't remember how's it called it's called My Awesome theme yeah and the theme is my awesome theme and then assets cssmind.css right that's supposed to work because I mean what we're doing right now is we're just like giving it the entire path all the way to our theme okay so let's see how that works uh it doesn't seem to work working either why is it not working let's see we copy this we come here we paste this and it's actually there so what's going on here um all right what's going on I don't know what's going on I don't know what this is not working let's see if the null script one was the one that had a Lee all the things that were supposed to work content themes to do my awesome theme assets foreign let's see if this is the one that had uh it's not down either I wonder what's going on here uh it's probably the scripts that were supposed to be added hmm how about if I use my awesome how about if I do it like this um did it uh get template directory ERI then I do something like this oh yeah there it is all right so yeah it wasn't working because we didn't add the HTTP um all right so there you go that's what I meant when when I said that we were gonna go through some errors um the thing here is that you're going to want to use get template directory every time that you want to to specify that you're using your current URL because I mean what's going to happen I mean if if I add I mean if I replace this right here to my to https this is going to work too about oh https uh no it's not working either I don't know it's not working out and there must be some kind of type of somewhere um there must be some kind of type or somewhere but well just to let you know here you should use PHP because I mean if you upload this website and you change the domain name at some point this right here is going to remain like hard coded and you don't want to come back to your code and replace the domain name every time you change the domain name so what you do is you ask WordPress for the domain name by saying get template part URI and that way it'll just give you whatever it is the your eye of your theme all right so this right here is going to return your website let's have content things my and the name of your theme and then you can add your relative path inside your theme okay so that's how it works I don't know what's the difference right here um HTTP oh yeah because it's not supposed to be https um so if I do HTTP like this no it works yeah all right so that was the problem I was using HTTP and not https but just remember instead of instead of writing the entire thing just right get template power again template directory URI there we go and we're going to do the same thing for this one right here and don't forget the Slash and there you go so now you have uh now you have already got what's going on here get template directory oh yeah here this is not supposed to be here so now you have your theme and it seems to be working apparently for some reason um and our our links even work as well so that's convenient not bad and there you go so I mean the front page is on its way we have already included our Styles let's do the same thing with our script okay we're already still working on a header okay so any page any template that we create if we just add get header it's going to add all for all of our uh or scripts and all of our Styles let's do the same thing for scripts right now so we're gonna go down here to footer and we're going to try and find this script right here um so there are many of this so we have assets jsg aquarium in JS crawlix scroll ex all right so we have a whole bunch of of JS files here and I suppose that we can find them in here okay so we'd have jQuery mean.js which is this one I'm just going to put them inside assets JS okay JS oops rename it to J s like that and it's not supposed to be inside CSS it's supposed to be inside assets so here we have our CSS then we're going to add our Js and it's supposed to be um we're supposed to have jquery.min.js jquery.me.js so let's put it right here Tech uh what else are we supposed to have scrollix main.js I'm just going to do it like this um um jQuery scroll X Men this one jQuery Skrillex Min js2 for some reason we have two of this oh scroll X and scrolly so it's this two we also have browser main.js which is this one um breakpoints that mean the JS which is this one you tell and Main alright so it's actually all of them and we put them all in here and remember that this right here is not going to work because we're using here relative paths so and we want to use uh you'll want to use the absolute version of the URL and to do this again just as before I'm just going to modify it all oops I'm just going to modify it all at the same time so we're going to add here one second we're gonna add here get template directory year I and then remember to add the slash assets.js aquarium main.js Etc so all of it it's in here it's supposed to find it because we just gave it the URL of our template and then we said to look for ad for assets Js and then your files in here so that seems to work there you go let's save it and let's see if we have any errors in our in our console so here we have a console of course we have many errors for a moment but let's clean this one up a bit and then refresh let's see what that gets um all right so there are a lot of Errors um myosin local WP content themes my awesome theme acids main.css didn't find assets main.css for some reason um my SM website dot local there will be content themes minus and theme acids made it CSS version 6.03 yeah all right so that's something else you're not supposed to all right that comes from webpack um this one right here comes from webpack 2. um I have some website take look look look look look look all right so it's just the images that were not found so I mean apparently so I can as far as I can see this seems to be working all right um let's see who are we all right so the scrolling seems to work seems to be going fine not bad okay we're gonna fix this in a moment that comes from jetpack and images let's get the images working as well and we have the inside the assets we have the weapons but we're not going to use the weapon so more so for the moment we're going to use we're gonna use the images right here and the images if I'm not mistaken how are they referenced the images oh they're inside here okay so CSS doesn't need any images I suppose that our template file does required images so let's see um front page do we have any images yeah it goes on to look to images picked as if pick zero one pick zero two pick zero three so these are the ones that it couldn't find and these are the errors that it was throwing here if you can see we have um big zero two pick zero one and pick zero three not found so we're gonna fix that in a moment um just as before remember um you know what I'm going to do is a search replace right here um so we're going to do image Source equals Tech images every time you want this thing is looking for images what we're going to do is we're going to look for um we're going to replace this with image source and we're also going to say images but now we're going to give it the entire URL and how to give the entire URL you guessed it you give it get template directory directory URI Tech Deck and then slash images and there you have it so now if we click on replace up there you have it get template directory URI and it's looking for image for a folder called images and the pix01 inside that folder so we're gonna have to create that folder here images and let's put our images in there images there you go now you have your images inside your folder and what you're going to want to do now is you're going to save this and let's come back to here and let's see how that's working do we have images and we have images indeed not bad let's see the entire thing this has like all right so it's looking pretty good so far not bad all right and this I I have to if I have to remind you we're running this on WordPress so it's looking pretty good so far what else do we got in here um all right all right all right so next thing I'm going to show you is we're going to see how to we're going to see how to import all of these things because I mean so far we have imported our files on our source file our scripts and our CSS files in in the footer and header just like usual but I'm going to show you how to do it the WordPress way in a moment so um buckle up let's do that all right so what do I mean when I say the WordPress way okay WordPress has a particular way of dealing with dependencies and with scripts and styles in particular okay that means that as you can see right here you have your get footer and get header or functions as I told you before get header calls everything that's in headed out PHP and get footer calls everything that's inside footer.php um and what we want to do is that when we call WP head inside the header we wanted to include our Styles as well not only these styles from WordPress we wanted to include our own Styles too so what we're going to do is we're going to add these two things inside the whippy head that's the WordPress way of creating a theme and as I'll show you in a moment it will allow you to organize your code much more neatly and to configure the dependencies that you need for your CSS and SAS sheets okay and we're going to do the same thing with the footer and in this case as you have seen we have included the scripts in the HTML directly but what we're going to do is we're going to import them the WordPress way inside the wp footer action so that means that when we call this right here it will include all of this by itself and you will not need to include it your um to to type it uh like I mean it's just like again it just allows you to keep it more organized and to keep um to be aware of the dependencies all right good um so that's what we have and right now what we're going to do is hmm I'm going to do there are two things that we can do first of all let's import all of this without webpacking first we're gonna forget about webpack for a moment and what we're going to do is we're going to come right here to functions.php and I'm going to say I'm going to say I'm going to say two seconds I'm gonna say all right I'm going just going to take this off for a moment and I'm going to add function add or let's I'm going to call it custom Scripts and what this function is going to do is it's going to add the scripts and the styles to the action that we mentioned before to WP footer and to WP head so how do we do that for the Styles it's very simple we're going to have to use this function called WP and Q Style and we're going to do that with all of Main and noscript okay I mean we're going to have to use one for each so this function takes uh the first argument that it takes is the name of the of the of the style sheet that we want to add I mean this is whatever you can add whichever name you want to add it's just to recognize it when you're using it and the second argument is the source of the thing what I'm going to do is I'm just going to open this like this so the second argument is the source and to get the source we're going to do the same thing that we did before we're going to say get template um get template a template directory URI and we're going to add here we're going to concatenate the location for our main.css okay and that's going to be assets CSS main.cs says there you go and finally uh this the next argument is the dependencies list and do we need any dependencies if you for example if you needed a bootstrap and you had bootstrap defined before you would write here bootstrap but since we don't need any dependencies for this one we're just going to leave it like that next we're going to have to add the version if there is no version you just have to write false and finally media all I mean I think that's that's enough so this right here is going to include main.css into our into our our head cycle okay into the action this action right here I'm going to do exactly the same thing for no script.css I'm not sure what that one does I'm just going to copy this one and say no script and no script and this one right here is called No script dot CSS again I'm adding the location for this one again no dependencies and false for the version and this right here shooting keyword but so far we're only adding the function if you know how how programming languages work we're just creating the function right here we need to call it so that it actually does something but how it works is we don't just call it like this in WordPress customscripts.ph and like that and that could probably work but that's not the best way to do it what you do in WordPress is you tell WordPress when you want this function to be executed okay so um WordPress works with a cycle um kind of thing which basically means that it does some things first and then then other things Etc and in this cycle there is one um one part of the cycle that's called WP and Q Scripts and that's the part of the cycle when it adds the scripts to and the style sheets to your theme so let me show you how that looks so we're going to add an action to the WordPress cycle and the place in which we want to add this action is going to be WP and Q scripts but there are many many parts of this action list okay you can add it to init and it will just fire whenever you start I mean at the very beginning of your web of your WordPress website when it started to load but right here we're going to add WP and Q scripts if I'm not mistaken let me see if that's right um now we need to find the name of the hook in WP and Q scripts I think that's the name of the hook and it is indeed okay okay so this is the name of the hook and then a second argument is the Callback function that we want to fire at this part at this moment of the action and our uh the function that we want to fire is custom scripts so what we're going to do is we're going to add custom scripts right here and now if we save this and we remove this from here you know what I'm going to show you I'm going to remove the action so so far this will not run it it's just a function for a moment but we're not we I have commented commented out the action so let's go back to the website and and then then let's refresh and you can see that our style sheet is gone of course because we we just commented it out from here but we want to add it inside here so look at this I have not uncommented this I'm actually just going to delete it and I have added it here so I save this and then if I refresh the page I still have the I have the I have the styles again but now they're being loaded inside WP head and that's how you do it in WordPress okay this is the way to be even more organized and to keep your code neat it's very important because many WordPress developers have terrible terrible uh um um I don't know code I don't know why but it's something that happens in WordPress um all right so this is what we do right here and then let's do the same thing for JS right um now for JS instead of using WP and Q style I'm just going to add it inside the inside the same function we're going to use WP and Q rypts and what this one right here does um I'm not sure I can use this um let's see um hello yeah I'm not sure why this is working all right now you know I usually use NQ script okay um this is just like to to show you because we're going to replace this in a moment so same thing between q a script you add the name of your script we're going to start off with great plates dot main.js let me see in which order they have been imported here so we had we this is the order that we want I'm just going to copy this I'm just going to paste it here all right um I'm just going to paste it here there you have it so all right so we're going to import all of this first of all we have to include jQuery jQuery let's just call it jQuery and actually um all right so let's say the source where it is and the source of course it's this one sources this one tag I have to remove this I have to add this and that all right there we go same name source the third argument is the dependencies we don't need any dependencies for this one we don't set a version for it because I mean we could I guess but I guess that's right and then in photo this one's important you need to set this one to True otherwise it will be loaded in WP head and not in WP footer okay so the last argument has to be true if this is a script okay there you go so now we have added the first one I'm going to do the same thing for all of them uh just bear with me I'm going to do this pretty quick oh nope like that um think it's like that yeah all right so the second one is supposed to be the second one is supposed to be jQuery scroll except min.js I'm just going to modify this right here second one's supposed to be jQuery scroll X that mean the JS and I'm going to call it jQuery crawlix and here if you can see we need we do need to add a dependency so it's going to be jQuery okay just to I mean just to keep in just to keep the same order that we had before okay and same thing with the third one which is scroll e Dot main.js and that one we're going to add it here jQuery scrolly that mean the Js okay scrolling between the JS and we're also gonna call it um jQuery okay and also in dependencies we're gonna need jQuery but this time not only jQuery but we're also going to need jQuery scrolling so that it adds scroll eggs before before this one okay so this is going to look for jQuery and jQuery scrollex and it's going to include them before adding this one you know what we we only need jQuery scroll likes because jQuery scrollix already needs jQuery so we're kind of creating like a um a waterfall so it's going to try to import one and it won't fire it will find it it needs I mean if it ever tries to import this one it's gonna say oh I need to import jQuery scrolling first then it's going to try to project very scroll Express and it's going to go and be like oh I need to include jQuery first so that's how it works and then the fourth one is going to be browser.me.js browser.maine.js oh not like that there you go browser.main.js and again right here we're going to our jQuery scrollex as a dependency here um has to be there's a string and this one's going to be called browser and this one right here is going to be break but that mean the Js breakpoints that mean that Js we're going to call it brain break points um what's going on here break points there you go and it's going to be breakpoints not mean the JS and independencies we're going to add this one right here there you go like that like that jQuery scroll eggs oh no this one's going to Independent browser you know jQuery scrollex um wait points DOT main okay I suppose oh yeah no it's all right then util and Main okay we're only missing util in main so let's do the same thing for you till and Main right here till like that util took new till and this one requires break points and name this one's going to be Main dot Js and this one right here is going there's a way faster way of doing this I'm just going to just showing this showing you this very quick so that you kind of have an idea of what's going on so now I can delete all of this and now we should have everything imported uh just remember that in JavaScript of course you need to add um semicolons and at the end of your functions so this is how this works this is going to throw an error otherwise um [Music] and there you go so now this should import all of our Scripts uh I suppose I should I really should have used anq scripts in plural but whatever um I mean it's in the end it's just the same thing um but yeah I mean we have style and scripts there you go and it's always set to true in the last argument so that it will include it in the end so let's see how that works I'm going to remove these things right here and let's see if our smooth scrolling still works okay um all right so our content seems to be working and the scrolling seems to be working too so there you have it um so now our Styles have been imported inside WP head and inside WP footer and that's pretty good that's pretty convenient and that's how you do it in order to for this to be well organized um but there's a better way of doing this even better I'm going to show you that in a moment uh we're going to be doing this um so far as you can see we're using the assets file and we're using directly the main CSS and the main JS and the JS files but we don't want to do this this way we want to be able to import this instant because I mean like what happens if you want to add custom CSS I mean of course you can add a new file here and be like oh this will be my custom.css and then just import this file just as you imported this file right here and add it as a dependency and you'd be you'd be doing something like this and you'd be like oh this is going to be custom it's going to be my custom file and the dependency of course is going to be main because the main is is the is the one from the theme so we wanted one from the theme to be loaded before our custom assets and then right here I can be like oh so background color let's say let's say that we want our H1 H1 to be called okay no column color yellow okay let's see if that works if I refresh here uh this one is working because we have imported custom CSS inside our functions right here but what if you don't want to use CSS what if you want to use SAS um all right so to do that I would recommend that you watch the previous video on how to use webpack in WordPress um but if you don't want to watch all of that you can just learn to use the boilerplate that I and that I already created in that video in this video and that's what we're going to do right now so to add all of this to the boilerplate right here to use SAS and inside sources and for it to be compiled automatically inside assets what we're going to do is we're going to move all of this inside here okay so let's do that first um all right so first of all custom now we're going to delete this thing uh we're not going to be adding this custom thing right here move to trash and of course that means that this one right here custom uh we have absolutely no need for it so there you go and right now what we're gonna want to do is we're going to create all of our files up here and we want to run webpack in order to Minify everything and to put everything inside here in just two files one for JS and one for CSS that way we will only import one one CSS file and one script and that's all that we will have to import it will make our code way more clean and our project way more maintainable and of course it will just be better if you push this to production because webpack allows you to do this automatic to automate all of these processes okay so let's take all of this and put them inside here so CSS is pretty straightforward I suppose um no it's actually not that straightforward uh I'm gonna start with JS actually so what we're going to do first of all is we're going to take all of this files right here and we're going to put them inside the TS Source TS folder and we're going to add a folder inside here we're going to call it default for the default styles of the theme we're going to copy all of these things I mean move them inside default there you go so now of course this is not going to work because none of the styles that are being referenced inside the NQ script files are going to exist actually and that because they have changed um I have moved them to Source TS default but I will have to import this into main.ts how do I import this I can I can do import everything from I'm gonna say default let's say break points um dot main.js let's see if that works I'm not sure it's going to work actually um now you know what I'm gonna do let me let me look at something right here how do how do I import JS files um compiler options all right so this is how to import JS modules into a typescript file so apparently you can do this as I was doing uh let's see if it works put everything as whatever no I'm just going to use this um compiler options allow JS true and I'm going to have to modify my typescript Json file I'm going to add this here um so there you have it allow JS so it was actually set to true for some reason okay so all right and right here I'm going to import great default of course and we're going to say we're going to import bright points first break points.min.js let's see if that works and I'm going to do the same thing for all of them so next I'm going to import browser browser and then jQuery oh no what was the order again I forgot the order um let me see what was the order um so the order was jQuery first okay jQuery then jQuery jQuery Dot scrollex then jQuery dot scroll Lee jquery.com then browser Main hmm browser main then break points that mean the JS then util dot Js and then Main .js main.js all right so that's supposed to work main util breakpoints browser scrolling just colleagues all right so that's supposed to work so right now what we're doing is we are including all of this inside main.ts in order for this to work you might need to enable allow JS in your typescript file so if you have done that it should work we're gonna test it in a moment and finally we're gonna need all these files into our CSS file now this is going to this is going to bring some errors definitely because it's going to use some fonts that we don't have um are we going to we're going to have to clear that up at some point let's see if we have funds here fund family import let's see if we have Imports do you have any Imports yeah we have awesome fun thousand oh we actually only have Phantasm as a font so that's convenient all right um okay so let's do this let's go for main.css and no script and scripts okay so what we're going to do is we're going to do the same thing right here we're going to create a new folder inside scss and we're going to call it um default again and inside default we're going to create two files one's going to be called main which is the name of this one but we're going to call it main.scss now you know what we're going to call it default default.css and the other one we're gonna call it noscript.css scss of course and then just copy all the contents inside here and we're going to paste them here and all the contents inside this one and we're gonna paste them here now why did we have to do this why was this important oh right we're gonna have to of course we're gonna have to import them here um I'm not sure how to import um did it today at import I guess uh did it partials yeah input file name okay yeah that's the way um so yeah it's just exactly the same as what we did with typescript which we're going to use input in SAS and we're going to say that we want to import default because we're giving it the position this the location of this one we're gonna say default okay we're going to do it like that and the second part we're going to add default again and we're going to add no we're going to add no script so there you go now we have both of these that are modularized and we have included them inside the default folder and same here we have included all of this inside the default folder of our typescript and this right here should work I mean if we run this it's going to take everything in here and everything in here and it's going to compile it and put it all of it inside two files and the two files are going to be main.css and Main dot meme.js so everything inside here is going to be one single file and everything inside here is going to be one single file that we can import to Wordpress just like we did before and this is how webpack works that's the magic of bundlers so there's a problem here is that if we have all these files in here they're going to be replaced by our webpack bundle because that's how I have set it up it removes everything that was inside assets and it replaces it with whatever or current compilation outputs okay so to run a webpack I'm going to do npm run watch so that it keeps updating it's obviously not going to work so far because we are of course going to have several uh errors and evidently we do have several errors one of them comes from G4 jQuery scrolly.min cannot resolve to it all right so where is it jQuery scrolling scroll lead it was not ey it was just y so let's come back here to typescript Main and it's not scroll lay it's just scroll e that say if that runs and apparently it actually worked pretty good all right let me see let me just clear this up and let's see if it works again npm run watch uh it's just so beautiful when things work on the first time good all right so we have this and now you can come up here and see that it actually output it has created some files inside here so we have main.css and we have one line that's extremely long that has to server a lot of things in it we have main.css map for some reason it's important um all right but why is main.css so short it's not supposed to be that short I guess um yeah it's not supposed to be that short I don't know what's going on right here um main.main.js all right let's see how that works so what we're gonna do is we're going to go back to functions.php we're going to remove this that we had so far this right here it was to add our custom scripts like usual but the boilerplate already came with this thing right here which all it did was import it was exactly the same thing as we did before but it Imports automatically the bundle that was output by webpack so you have assets main.css main.css and main.js so it Imports the two of them and it puts them on this one actually I need this one just as I told you before the version is false but this one has to be true because it needs to be in the footer because it's the script and let's see how this works um I have a feeling that it's not gonna work and it didn't work apparently of course because for some reason our CSS is not loading so we have default.scss it's not being imported for some reason and here default default why is this one not being imported um let's see uh what happens if we add all of this in here now we have an error we have a couple of Errors if we import it directly like that what are the errors it cannot find CSS loader okay from okay it cannot find source CSS main.css okay so that's this one module build failed error can't result Phantasm yeah of course so the problem is that this file right here is trying to import fantasm and we don't have fantastic so we'll just do remove Phantasm and there's still an error apparently so let's see why that air is happening let's say what's the error right now well that's a lot of things here um um all right what's going on um all right that's even longer than my terminal wants to Output um what's the problem here well that's extremely ugly experts how many default default all right here we have an error main CSS can't resolve images incro.svg right so we have some images inside here yeah that's going to happen at some point it's this one um yeah I mean um yeah if the theme that you have imported has images inside the CSS it's going to throw this error so at some point you will have to either first get rid of all the images that are inside your template and then re-import them using the correct method so let's see if we have more images right here I'm going to look for URL for this to work URL your L and here we have another one um uh all right so this one's I think it's all right this one's right all right so now I think it should work yeah apparently it worked okay clear and let's re-run npm watch and it ran again there you go so now if we come right here to our main.css you can see that it's all it all I mean like this time it actually does have a lot of content so that's what we wanted and this is the one that's oh sorry I I forgot to zoom in again and this is the one that we're going to be using and the one that we have imported in our functions.php as I showed you before which is right here main CSS and main.maine.js which is this one there you go all right so right now if I go back here and refresh it's working again oh it's so nice when things work there you go but the scripts are not working for some reason let's see what's going on because I mean if the scripts were working we would have some smooth scrolling so so the thing right here is that we had a we had a simple problem with the JS okay and I'm going to explain that to you why that hadn't worked before the current version of the website looks like this there you go um so apparently our JS not working and the reason for that is that we were trying to import it let me show you we were trying to import it here where are we here we were trying to import it here using default and then adding our usual inputs here like something like import and then going default Etc right and the problem with that is that when you import something in JavaScript you have to either I mean you have to either export the function that you're importing first or you have to have everything defined in the same file all right and right here we're importing several files that were not um that were not exporting their objects let me show you what I mean in this theme what happens is that everything I mean the main JavaScript file that manages how this works is this one um so we have a function we have a function called break I mean we have a they call a function called breakpoints they call a function called I mean they use jQuery without even defining it first oh look at that they use um they use methods such as crawlix without even defining them either and I mean that's okay because they were using it inside I mean importing it directly into HTML and that's a good thing it just makes the template way more neat and complete but if we want to actually import those JavaScript files into our own Javascript file then we would have to export those functions um because what we're doing here is bundling everything together into one same file and typescript does not understand that we're not exporting an important things and that we're just using things that were never declared okay so that was the problem right here and that's why JavaScript was not working um so all as you can see all of these are dependencies so breakpoints is the one that defines the function breakpoint red points the one that's used here um well here uh jQuery of course is the one that defines jQuery Etc so we have two options right now we can either import all of our JavaScript just like we were importing it a moment ago in in functions.php which is right here and do um and do something like import script and then import every single one of this um or we can just leave them as they are in the HTML and this always comes as a decision it it always comes back to the decision of the developer on the and the way to guide your decision if you want to import it here or in the HTML is what's going to be what's going to make your code more readable okay in this case there are so many things that I actually think that's easier to just leave it in the footer.php like this and let's just uncomment this right here and and just use it like that and then just add just um a comment right here and say um Fame Scripts and then in WP footer we will import our own scripts okay this way we can be sure that these scripts are uploaded before anything that we add ourselves all right so how do we organize this I mean I did this off camera so I'm just going to show you that this right here I mean just a moment ago it was like this assets JS default jQuery Etc now it was assets default um assets TS default jQuery main.js like that and if we do it like this it should work now I suppose um it's not working one minute um oh it's not acid sorry it's source um two minutes one second there we go Source TS and default there you go now if we do this it should work now there you go uh the problem right here is that I really don't want them to be inside typescript right because if you remember from the previous video how our web pack is configured our webpack is configured to take two points of Entry it takes Source TS main TS and Source SAS main SAS okay and I mean that's just to keep it organized but if I mean that basically means that what's inside here is going to become bundled and what's inside here is going to become bundled and we I mean in default write this one right here we're importing it directly on on the HTML template so what I'm going to do right here is I'm going to add a new a new folder right here I'm going to call it JS I'm going to move all the defaults inside there and I mean I clicked on yes for inputs I'm going to delete this one right here and let's see what happened if we see the footer and right now we're using source and we're no longer inside TS we're inside Js JS default and then all of our dependencies and then finally our main GIS okay um so this should work now and now we have separated it from the SAS and typescript directories it just allows us to get it a little bit more organized and let's see how that looks so it's still working our JavaScript is working correctly and we imported it on HTML sometimes it's easier to do it this way sometimes it's easier to import it on functions.php it's I mean it depends on every situation okay so up to you for that one remember that the goal is to make this as maintainable and as readable and as possible all right so there you go with that what else do we have what else can we do now all right so just a moment ago we were having troubles with the SAS file right here because we were trying to import some images and in the end the images were causing us some trouble because they were being added just like uh I mean typescript was looking for them and it was not finding them so we just commented them out what we're going to do right now is we're going to bring them back in so how do we do that let's see where were our images URL uh here is one images infra.svg and fantas and I'm not going to include fantastic anyways um so there we have it it's oh sorry it's not this one it's your l it's this one so it's images intro.svg so it's I don't have it here for some reason let me see where do I have it um images big big well actually don't have intro.svg so all right I guess just gonna leave that one out I suppose CSS images oh here it is intro.svg um all right what I'm going to do is yeah I'm gonna put this one inside success right here images and now since we're using a relative path it should understand I mean this right here we're inside main.sas main.s so it should understand that we're there but actually um you know what I'm gonna do I'm I'm actually going to remodelize this because we had left this inside main.css and it's supposed to be somewhere else we were putting it inside default default there you go that's how we were doing it and this main thing we were supposed to import it like this default default there you go so now let's see how that works did it get imported it was imported correctly there you go oh sorry actually that didn't do anything because I haven't rerun uh webpack so let's see how that works npm run um watch so it compiled let's see our CSS file it's very big so I suppose that everything's working correctly and everything is working correctly actually very good um so now that we have modular modularized our CSS files I mean our SAS files into to default and no script what we want to do is import this image that we just brought in which is actually an SVG and to do that I'm going to go right back to default where we commented out our image and to find it I'm just going to look to for URL images and there you have it it was this one that was having trouble with uh let's see where it's supposed to be shown um to do that I'm just going to look for ID and it's intro but I'm not mistaken yeah intro uh nope let's say intro intro there you have it so this one right here intro it's supposed to have a background SVG let's see how it looks in our template hmm all right so it's supposed to look like that there you go so yeah we don't have that here so let's do that okay how about that and to do that I since we're working on webpack we're going to have to add a relative path right here and the webpack that I that we had configured in the previous video will automatically create an image folder right here and we'll include that one inside it although I'm not sure if I have to include support for SVG but I'm going to check that in a moment let's see so we uncomment this one and instead of I mean did it find it um well apparently it did find it interesting um but you know what I'm going to do here I am going to do it's interesting that it finds it actually because I mean all right let's see what happens if I do this no it doesn't find it all right so yeah so the thing is that I have to assume that even though I'm inside default.sat I have to assume that in I am in main.sas because this one is being imported in main so my relative path in here is going to be relative to main not relative to my default.sas so there you go so just to make things a little bit more readable I'm just going to add Point Dash here and let's see how that works there you have it so we have our SVG background working correctly with webpack that's going to move you oh somewhere right here there you go and so there you go there you go so everything seems to be working correctly what are we going to do now so we added images how about we add a single um the template for our posts so the template for our posts is supposed to look something like generic like this um we'll see how to add the image later uh maybe if we have time but where this is supposed to be like this and this is supposed to be the title of the article and this is supposed to be the content of the article okay so this is going to be the template that's going to load whenever we want to show some content in our file all right so let's see how we can do that um how can we do this um first let's find the template and the files that we downloaded so this one right here is generic.html and this is how it looks as you can see we have the footer so this right here we're not going to be including it because it's already being included in footer.php as we configured it before same for htme HTML head and body and what we want is to include everything that's in between those two things in our template on this side now what's the name of the template that's going to be loaded when we want to create the single article okay or a single post or whatever you want to whatever that it's a single like an article a custom post type Etc uh what you have to do right here is you have to add a new file that's going to be single dot PHP the problem right here is that the boilerplate that we have in that we're using already have a single dot PHP so what we're going to do now is basically just update it let's remove this right here I don't have no idea what this sidebar is and here we have it so we have get header get footer and this right here is going to be like this there you go so now if we save and we try to come right here to my awesome website and try to create a new post let's say and let's say a new a new awesome post home oh some post and we hit publish and we publish and then we go to view the post we have the generic page that the template is being loaded so that's convenient so our generic template is being loaded just to make sure that everything's working correctly I'm going to add an H1 and say this is my custom single template and then if I refresh here I can see that that thing is being loaded so we're actually inside the single template um the problem right now I mean even though we're loading it correctly is that we are loading a hard-coded title and a hard-coded content and this is absolutely not how templates work templates are supposed to work by allowing you to display the content of the article right here and the title of the article right here so what we're going to do is we're going to make this dynamic and it's extremely easy to do that in WordPress what you have to do is just find wherever your title is being printed and replace that with the w with the PHP function called the title okay this function is only going to work if you're actually showing an a post I mean if you're um I mean this function is basically just going to return not going to return but to Echo out the name and the title of your page so this right here if I refresh now you can see that we have the name of our post up here and for the content we can do something very similar we can do um PHP again and we add the content there you go now if I hit refresh I can see that we had no content in here because we hadn't added any but if I hit edit post right here and I say this is my awesome content I hit update and then I go to view the post I go to view the post said I can see that this is my awesome content is being loaded so that was pretty good um now you have a work in template for your single articles that's convenient there is however a quite a small problem with this and it's that we have an avpa that's not working correctly um you know what let's see if we can actually load um yeah I'm going to show you how to load the featured image up here because that's how it was in our template up here so it's supposed to have this image why do we not have an image here let's say um let's inspect this right here where is the image supposed to be it's supposed to be underneath the HR or the separator I'm not sure if they actually use an HR we have images big04 and image fit all right span image fit and I mean I suppose that actually exists in our in our template head image fit span image image 4 but it it's absolutely not finding it because as we had said before this is a hard-coded um relative path and we want a dynamic absolute path we want it to be my URL slash the address I mean the location of my theme and then the location of my image so let's do that um all right so it's all right uh so so so so so where's that supposed to be it's supposed to be here there you go um first of all just to show you how it how it looks I'm going to bring in I'm going to bring in this thing called Lauren pixium and I mean in case you don't know this is extremely good for testing is you use like typing something like this and it's going to return an image so let's just do that just for testing I'm going to and I mean the two arguments that you pass out in the dimensions of your image right so I'm going to say I want something that's um 1400 times 300 sounds pretty good so let's see how that looks and then if I refresh right here we can see that it's still not working because I am actually changing the generic HTML template not my theme all right so wait uh my theme is up here um there you have it if I paste that right here I save and I refresh this right here is going to return a random image from this random image generator API and there you have it so there it is and it seems to be working correctly but I do want to make this image Dynamic and make my user be able to modify it so how do we do that instead of actually just coding a hard-coded image right here we're going to say um I suppose it's got the thumbnail I'm not really sure get thumbnail WordPress I suppose get the post thumbnail and it what it actually does it um I think this one actually Returns the HTML for it but I don't want to return the HTML I want I want the URL just the URL so get the thumbnail URL there you go so that I can use my own template and my own classes and my own everything because other the other function was going to return the entire HTML and I want this to be more much more customizable so in here let's see how this looks it's a get so I might have to Echo it now let's see how this is working uh so I refresh right here it's of course not going to show anything because I need to import a featured image in here let's set a feature image um I'm going to use paxil's image let's use um I don't know something related to to code whatever and let's download this one there you have it I'm going to add it here to my post now let's choose that one set it as featured image update this and let's see the post and there it is so it's actually working correctly it's taking act it's actually taking the styles that we set for it and so it's all right pretty good very good all right now that we have our single uh template working correctly let's make it work for Pages as well because this one is working for posts but what happens if we create a page let's say I test page hello world publish publish and let's view the page and the problem is that our template is not working for this one why does it not work template hierarchy WordPress the thing the problem that's happened and the problem that's the thing that's going on right here is that this is a problem with I mean this has to do with the template directory uh template hierarchy in WordPress right so the thing is that our WordPress installation is trying to load the template for page so it's a it's like oh so we have a static page so we have to look for the page template we don't have the page template we have we try to look to a custom for a custom template we don't have a custom template so it looks for a page slog page ID if so since none of these are being found it looks for a page.php file do we have a page.php file we don't have a page.php file so it looks for singular we created single and actually in this hierarchy only the single post Pages come back to single and the one that brings both together page and single is singular.php so maybe we need to rename this one right here let's rename it and say this is not going to be a single.php this is going to be singular dot PHP now this should make this should make our template also respond to static pages but if you want to separate how static pages and posts look that's where you would create a separate single page b and a page.php right so let's see how that looks um we can save this and we can go back to our theme right here and if I hit refresh now you can see that we're actually loading the template that we were loading before so that's pretty good um all right next thing I want you to do is I want us to um to actually make this menu work because I mean so far it's actually not doing anything so let's do that uh first we're going to have to click on some we're going to have to make these links modifiable by the user and we also want to add a link to this to this thing right here uh that will take us to our home page but so far it's not taking us anywhere so let's do that um first of all um we might want to answer to ask ourselves if we want this to be inside the header.php that might be convenient because it's supposed to be in all the pages let's see how it works in in the template that we downloaded so in the template that we downloaded if we open index.php index.html we don't have that header so it's not going to be in every single page and if we open generic.html there is that thing so what we're going to do is we're going to separate it and we're going to show it dynamically depending on the page okay so let's do that this is a very good moment to show you how template Parts work or components so our boilerplate already has this folder but if you don't have it you can just create it just to be a little bit more organized and we're going to create a new template part or component called navbar navbar.php there you go and inside this one what we're going to do is we're going to bring our nafba here Ctrl X and and we're going to put it right here so there you go so now as you can see this is not um no we're in the temp now as you can see this right here has lost the nav bar because we have separated it into our template Parts folder but what we're going to have to do right now is to import it and that's actually very simple what I'm going to do is going to import it directly from the header.php that's going to make it a little bit more easy and it's right here so what I want to do is I want to add some PHP code and the function to import template Parts in WordPress is very very straightforward it's called get template part and right here you just say the location that you that where your template is and my template is in template parts and then slash and then it is nav bar dot PHP but I'm I suppose you don't really have to add dot PHP for this to work so let's see if that works I refresh and there it is so our navbar is being loaded directly from here so that's pretty good that's convenient um and now we can edit our navbar directly inside here I'm just going to add a link here I'm going to say that it goes to the root and let's if I refresh this I click here it brings me back to the root although as you can see we have a problem the nav bar is being loaded inside our home page and we don't want that because I mean that's I mean that's not how it was in the the template so how do we deal with this because our template our I mean our our nav bar was being loaded from the header and the header is included everywhere so what do we do here is that we can test if we are in the home page with a very simple function a very simple function which name I don't remember is home page probably um is home no is front page yeah is front page and this one right here is going to return a bull uh Boolean Valley true if it's the home page and false if it's not the home page so what I'm going to do is I'm going to test this right here and in case you don't know how ternary operators work they're pretty convenient because they allow you to add if else statements in just a single line so if this is the front page um do nothing let's say and if it's not the home page then add a get template part navbar right so if I save this right now and I go back right here and I refresh let me show you and I refresh this right here this is supposed to not uh appear because we're testing for the front page since this one right here is the front page it's going to return nothing but if it's not the home the home page it's going to return get template part template part snap bar so let's refresh there you go so our template um navbar is gone and now our home page is working correctly and now if we actually look at a post View now this one right here is actually showing so that's that's very good that's convenient and that's how it's supposed to work okay I mean at least according to our template so that's pretty good that's pretty good I would say um now how about we do this we make this menu actually modifiable from the back from the wp admin because so far it's actually hard coded if we come here to our nav bar you can see that the menu is hard coded we have home we have generic we have elements and we really don't want that we want this to be able to I mean if you have used WordPress before you know that you have this nice little control panel for menus and then you can add them right here but the problem right here is that I mean this is absolutely not what's being shown up here um up here up somewhere where is it this is absolutely not what's being shown up here okay so up here we're being shown the hard-coded elements and we want to show this elements here so how do we link these two it's actually very simple and it's built in WordPress you have to you have to add a simple function to your functions.php file so let's find that one here it is and we're going to call it main menu register Main menu and let's call this function register main menu and it's actually very straightforward all that we're going to have to do is this is where is it that we when that would we have to do um give me just a moment while I find a code that works for this one um there you go all right so first of all we have to actually register um this nav menu and it's very the the function that does this is very simple it's register nav menu okay uh there are two separate functions for um I mean there are two types of functions that do the same thing one of them is menus and the other one is menu they both do exactly the same thing but the second one menus takes an array of arguments instead of just one single set of arguments in case you want to imp to register several menus at the same time so let's do this the first argument that we take is the slug that you're going to give your menu this is going to be the the name that's going to um that you will be able to call in order to import that menu somewhere else okay so I'm just going to call it Main menu and then second we're going to say the description of this menu I'm going to call this one main menu what's the name what was the name of our template hyperspace so main main hyperspace main hyperspace menu there you go so now if I save this right here and I have to run this one of course and where do I run it I to run it remember that in WordPress you have to register your functions in a certain part of the WordPress cycle so we're going to add an action to the part of the WordPress cycle in init this means that this function is going to be run at the beginning of the WordPress cycle and I'm just going to in the second parameter and the second argument right here is just the name of the function that we want to run so this is going to register this main menu and now the location of that main menu is being registered and I'm I'm going to be able to see it down here so if I refresh this I now have main hyperspace menu as an available menu to to add these items to so let's let's customize this menu I have home I have a sample page apparently and let's add our test page too so I click add to menu I'm just going to modify this right here test page and there you go so now we hit and save menu and if we go back to here and we hit refresh we're not going to see any changes because we haven't actually even though we have declared the menu and we have added a WordPress menu and tied it to our declared menu I mean how would WordPress how would WordPress know that this right here is what's supposed to be shown up here and that's very simple but we have to add some more a little bit more of uh PHP code up here and we have to do that inside the navbot.php so to do this we're going to get rid of this one and we're going to add our code right here it's very simple all you have to do is to tell WordPress that this right here is the location where your previously defined menu is going to be shown and you can do this several times you can say oh I want my menu to be shown here and then you go to the few to the footer and you'll be like oh yeah so I also want to be shown here so you will do the same thing that I'm doing here but in the footer as well so let's get right into this um the function is called WP nav menu and it takes several arguments in the form of an array so the first one is going to be the theme location um theme location theme location well what this is actually I think it's with an underscore there you go the theme location what this one means is that which registered thing are you going to show and with the one which we're going to show is the one that we created just a moment ago in functions.php this this one right here so the one that we're going to show is this one main hyperspace menu and remember I told you about this log that you had to keep in mind so it's this one that you have to import right here up up um there you go um so we're including the nav theme location main menu so let's see how that looks now now I have commented out the hard-coded one and I have added the main menu uh one with WordPress let's see how that looks it's probably gonna lose some style yep we have missed some Style but we see that the elements are there so how do we fix this style so let's see um inside here we can do inspect and let's see so we're inside a ul and we actually want it to be inside a nav because the previous menu that was working was inside the nav tag so let's see if we can do that um to do that I am going to have to add another argument right here and that argument is going to be it's going to be uh container container and I'm going to say that the container is going to be a nav tag so let's refresh right now and it seems to be working now uh so now let's see how it looks so we have our menu that's being added inside aul and inside a nav but for some reason there is a class that's been added here uh let's and I I'm not sure if that's causing some problems um no it wasn't um but I don't know I don't know why these little lines to the left uh being shown let's see as you can see the links are working right so we have our home page we have our sample page and we have our test page that's because all of that is being done right here and it's being like automatically included through WordPress so we have this we have we have all of this right yeah I don't know what I mean you you can take that one late and take that one out later I'm not going to stop to do that one and this one right here already takes us to the home page which is very good too and yeah um just to let you I mean just to show you something you see that so far we added this href and we just added a slash to say that we want to go to the root of the of the WordPress I mean about the home page but this while this would work in most in most situations it will not work if you're WordPress installation is located inside a subdirectory in your in your website so for example if your WordPress installation is inside my awesome website slash WordPress this right here would would only return to my support my awesome website it would not return to my awesome website slash WordPress so a good thing to do right here is to instead of actually do that which is what you would do in a regular application is to add a PHP function called if I'm not mistaken its homepage probably home URL I think so and let's see how that looks if I refresh if I refresh refresh right here and I click here it's doing nothing um uh did it maybe I have to Echo this one out yeah yeah so there you go um so this one actually just returns it it doesn't Echo it out so I had to Eco it out but the thing is that right now what we're doing is that this right here it goes back to the WordPress database and it asks WordPress for the home page URL and in case it's not the actual root of the domain it will return the actual front page where the WordPress installation is located so yeah it's better to use it this way uh so there you go now we have a working template a working theme we have a working menu with it and actually I think we're pretty much done I mean if we wanted to do a little bit more things we could probably do we could probably include some ACF Fields but I'm going to show that in another video be sure to watch it um to subscribe in order to to get that video in itself when it's out um probably gonna upload it next week but yeah um just to buckle up we have taken this template right here which was just an HTML template with some js and just and CSS and we have transformed it into an actually work in WordPress theme and we had we have added some very cool functionalities that I hope that you will find useful in your um in your job which is that we have added certain functions to register our menu we have added our scripts and styles through the WordPress cycle to make things more neat and organized we have also added our Styles and scripts through a bundler which is webpack in order to make everything faster and in order to only include two um two assets instead of instead of adding one single asset for every single um for every single CSS or or script that we want to include um what else have we done we have configured it to use typescript and SAS but that one that one was more explained in the previous video about webpack and what else we also saw how to use template parts and how to modularize your code to make it more readable and how to show certain templates in case I mean in a conditional statement with the ternary operator what else do we have here and how to use a basic templating system with singular and front page but remember to check my video on templates in order to actually get a more in-depth understanding of how this work of how this works so there you go I think that's pretty much it I hope you found this video interesting and useful and that you will put this to work in your job and that you will write a better code today than you did yesterday so it has been my pleasure to be here with you and I shall tell you that I will see you next time [Music] [Music] [Music]
CmT29pElbt8,2023-01-03T12:37:00.000000,R Programming 101 - Crash Course for beginners,good morning everyone how's it going um today I'm going to be showing you how to use R and rstudio and this is going to be a very very introductory approach introductory approach to R and its capabilities okay we're mainly going to be going through some functions of our some data types and how to handle some basic data just to get your feet wet and like to get you started into what it means to do data analysis with r um if we have time maybe by the end we will be doing some data analysis with an actual data set but just think of this like kind of a crash course of all the functions and all the capabilities basic capabilities that you can have Within These programming languages language okay so there you go let's get right into it [Music] um all right so to start let's see what we got here um so R is a programming language they say programming language it works with um I mean on paper I think it is an object oriented programming language but don't really say that in public is I mean like the objects in R are pretty strange um um yeah I would probably consider it more of a functional programming language but there you go so let's get right into it there are several data types in R there are vectors there are um what else there are data frames there are matrices Etc but um I'm just going to show you for first of all the vectors how they work um so as you can as you probably know date R is made for data analysis and the basic um the most basic data unit that you have is the vector which is just a set of individual pieces of data of the same type okay so let's see how that looks like to create a variable uh wait let me just zoom right here there you go do you see everything I suppose there we go um all right so first of all I'm going to show you what it looks what this is this is our studio there is a web version for it you can use whichever you want I use the desktop version but yeah um you don't hesitate to use the other one um right here you have the console this is the r console you can run pretty much any um any um any are line that you want in here or you can have a script which is up here right here you have the environment which is where you will see all your data I mean yeah the data sets that you have imported the do variables Etc you will see them listed right here and right here you have the plot this is where you will see the plots that you have outputted or output or you you also have a viewer which is pretty useful if you're using a uh I don't know if you're running an applique a shiny app you can actually visualize it right here okay so it's kind of a very complete IDE for our I mean even though I really like code Studio and other IDs I mean for R I don't think there's a better thing than our studio so let's get right into it um to create a variable pretty much like in other languages you can use the equal sign but in r in the ACT actually the most correct way to do this is by using the arrow sign and you can think of it but just by saying telling to yourself that whatever whatever it is on the right is being assigned to the name to the variable name that's on the left okay I mean that's a good way to see it and here let's see we can create a um a vector with the function C which is short for create and right here you have like we have a vector 10 20 30. all right that's a vector of three elements and to run right right here we're inside the or inside the the script file but you can also run it in the console okay but to run the script file what you can do is just select it all and if you're in a Mac you would do command enter and if you're in a win in a Windows machine you would do Ctrl enter but let's see right here now I run it right here you see that I have my my Vector that's in my environment and you can see that it has three elements 10 20 and 30. now something interesting about this is that vectors Can Only Hold one data type so I cannot add right here hello which is a string because that would I mean it will run but do you see right here that this right here is a vector which is a vector of numbers which means that the elements inside it are numbers and since vectors can only take one data type if I add a string all of this will be coerced into Strings okay so let's see how that works I'll just enter right here and now you can see Hello has been added but 10 20 and 30 are no are not numbers anymore they're they're strings okay so that's how this one right here works so that's vectors there you go um secondly let's talk about lists lists are pretty much like vectors the only difference is that you can include several data types inside them and to create them you use you use the function list like this there you go and right here you can actually create you can actually add several data types you can add I mean this one right here will be a will be a number then we have another number then we have a list inside it yeah of course we can add a list inside the list and then let's add another Vector right here two three four there you go and let's see how that one works there we go so now you have a list of five elements and if we output it right here I'm going to run it in the console you can see that I have one two three four five six seven elements in my list one two three four five all right what oh yeah sure no sorry I have one two three four five elements in my list and inside the the fourth element you have another list which is this one right here okay there you go um what else do we what else can we do here all right let me show you the data types that we have right here okay um so as for data types you can have um different kind of values for a variable okay let's say for example The Logical logical one okay logical logical can be either true or false true is written like this and false is written like this and to check the type of a of a variable you can just surround it with the function class like that there you go and then if we run this one like here you can see that the class of this one is logical all right if we say the same about false that would be up sorry logical as well there you go right so that's for class um what else do we get here in one second there we go all right there we go so that's for clad that's that's the class of logical then you also have the class of one second yeah then you also have the class of integer as you can see here we were using numbers and right here we're using numbers as well but integers are not necessarily just numbers without if without um I mean in other languages something like this would be a float and something like this would be an integer okay but in r in order for it to be an integer an integer yeah sorry um you have to add a specifics L to it okay so let's say that if we do if we do class like this of 10 we will get the data type num numeric okay if we want the numeric data type to the an integer an integer what we would have to do is adder and L to it like this there you go so now that one's an integer um what else do we have we have um I mean floats are numeric just like that I mean if I run 10.5 and I ask for it and ask for the type it'll give me numeric it won't give me flow because flow time America just like that okay there it is numeric um what else do we got here all right unless you're a mathematician you might not use this but you also have um complex numbers which are um like constantly I mean just like in same in mathematics you just add an i suffix to it right so if I add let's say two plus three I oh I this one right here is going to evaluate to complex all right there you go complex um so that's it for data types I mean I can show you as well uh what I was showing you is the moment ago that for for the list right here um this one is a list of course and then the other one is a vector um yeah I mean it's a class vector and it's a character a character Vector because as we saw right here it's a vector of characters okay um yeah so there you go um those are the data types now let's see the most important thing um about this is the data frames all right um I'm going to create a data frame pretty quick right here a data frame a good way to define it is probably just to tell yourself that it's a collection of vectors okay vectors that are aligned like that so for example I'm going to I'm going to I'm just going to create a data frame off of several several vectors like this um all right so here we have the let me zoom in a little bit more here we have the patient ID the age diabetes status patient data all right there you go what are we doing right here so we're creating four vectors a patient ID so we're creating four ideas for it we have we are creating also four um variables for H diabetes also type uh type type 1 type 2 Etc this one's a character a vector this one's another character Vector um with the Thai header status and then please note that all of this have the same length you cannot create a data frame if all the vectors that are creating it are not the same length Okay so that is pretty important um so you have your patient data and right here is this one right here is the one that's going to be the data frame to create a data frame as well you just um initialize it with just as you did with a list and a and a vector use you initialize it with this function right here data.frame and then you pass in all the all the vectors that you want inside your data frame so I'm just going to run this right here now you see I have my four my four vectors and also I have my data set right here and it's a data frame indeed if you want to see it a good thing that you can do to see data frames is to run view and then you run your the name then you add the name of your data frame patience oops patient data something important to note I mean I don't love it but do you note that view the keyword I mean for the function of to visualize a data frame or a data set you have to start it with a with a with a cap all right so there you go um and then let's view it and there you have it that's the data frame a data frame you can think of it just like a table but like tables in r or something else so I mean it really just is like a table of information that you can manipulate okay um so there we have it now let's get back to our script and let's do some some stuff with that one um something that you would usually do with the data frame once you import it is to check the types of the columns that you have and to do that you can use you can use the function Str okay so Str and just let's just run patient data inside here and let's see what that one gives us all right so we have that our function has four columns patient ID age diabetes and status and it also gives us the type of functions for each the type of data for each of the columns which patient ID is numeric age is numeric diabetes is character and status is character okay uh all right that's interesting what else do we have right here I'm going to show you as well how you can download uh your own data I mean like right here we just created our data with some handwritten vectors but usually you would like get the data in a CSV file or from an API Etc so I'm going to show you how to open this from an from a CSV file um all right so there are two ways to do this one of them the easiest one is to just I mean first of all you have to have your you have to have your data set for this example I'm just going to be using the ever um ever popular Titanic data set and download it you can just come to kaggle uh Titanic slash data and just download the test one right here um it's a very simple one it has like just 11 columns and I don't know how many observations it has like several I mean enough to make an actual enough to make a good analysis a good exercise so let's just click right here and download there you have it and something that you can do to import it is that you can click right here import data set you click right here and then you choose it like I'm gonna choose it right here from here there you go then you give it to name I'm just going to call it Titanic and I mean you have several options right here that you can toggle but usually it's pretty much the same the most important one is um the separator which I don't see yeah there you have it sometimes CSV files are separated by semicolons instead of instead of Comas but this one is apparently separated by Comas so I'll just keep it like this right I mean you can see um an overview of how your date and data frame will look like because what what you're doing is just converting your CSV into a data frame then we click import and there you have it you have the Titanic data set with all your data in it there you go so now let's do some stuff with this one um there we go now let's do some stuff with this one um another important function that you will find is um one that is to check when oh oh so wait I forgot to mention the other way to down to import the data um as you as you can see right here if you come to history we can see the the function that was actually run by rstudio when we clicked on import data set and you can see that it's this one right here Red Dot CSV and this is pretty much the function that you're going to be using if you're working in a local project and you have your your data set a CSV file inside the same directory you can just do something like Titanic read.csv and then you just write the location to it remember that dot slash means current location and then you just I don't know you can go you can put it inside the data directory and just um Titanic Titanic test dot CSV or whichever is the name of your file that's how you import it right I just imported it with the button right here but this is the most um like professional I mean real way to import it um because it uses like relative paths um all right so let's let's continue with this um so we have the Str patient data to check the the vectors let's do the same thing with the with the Titanic Str Titanic there you go there you have it so we have um so we have the passenger ID which is an integer an integer we have the passenger class which is an integer as well we have their names which are characters sex character H number looks pretty complete looks pretty good uh something interesting that you can do is to see if you have any nans and to do that to do that you can for example see let's see if we have Nan to see if you have Nas you can use the function is Dot N A and then just run your data set right um Titanic for example and then we can even pass in a single column um so let's say that we want to see if we have any NES in passenger class for example and so we have false false false false false all right so this is probably not going to give you a lot of information um so what what you can do um there are several things that you can do right here um what I like to do is to um wrap it in a table table like this this is just going to give you like uh one like a table of all the false entries that you have so let's see so we only have false so there is no any ends in that in that column uh let's see if we run it like this oh in the entire data set apparently we do have 87 true uh any ends all right so we need to find them and see what we're doing I mean we're not going to be doing data cleaning in this video but um yeah um that's the way to see if you have any Nas or Nan's um what else we got right here I mean for a same column you can also use like functions like Max Min things like that right so for Titanic for example we're working with let's say let's say we're working with the H right here so instead of table and instead of n a what we're going to ask is for the maximum so we're going to see the maximum age of um uh the people of the passengers in the Titanic so again um I'm just going to do comment and for this one right here and apparently we have an N A apparently n a is one of the one of the columns where we have um where we have an ANS so to do to check this right here we can just wrap it in n a DOT omit and let's see right here um um our unexpected symbol any.ummit all right I forgot one of this there you go all right uh so it's apparently the oldest passenger was 76 years old um so there you go um Na omit to Omit an A's Max and or main or whatever like let's see who's the youngest one well a newborn newborn apparently and you can run this by column or you can run it on on the entire data set that's pretty convenient pretty useful now all right so that's all for basic Edie like exploring your data set let's I just write it right here exploring your data set there you go and now we're going to check sub setting and how it works um what is subsetting so sub setting basically means just like taking some parts of a certain data object that you have okay but not all of it in order to get just particular information from that part so let's say that you have a vector right here Vector one and I'm going to create a vector um that's going to be one two three four okay so now we have our vector of vector one right here you can see that it's numeric one two three four and what we're going to do is we're going to select some parts of it okay um all right so to select some parts of something be it a vector or a data set I'm just going to be focusing on vectors for now you run it with square braces okay and inside the square braces you just have to tell the positions that you want to be returned okay and the positions you you I mean the positions you select them with a vector as well so I have to create another Vector right here and say which positions I want to keep okay so I can say that I just want the first and second position in the vector number one so that's going to return the first two positions of the vector oh yeah something important um right here that I I don't know if I forgot to mention it before it's pretty bizarre and strange and I don't like it that much because I'm a software developer but R does not count from zero R Counts from one so this one right here would be position number one two three four whereas usually in any other programming language this would be positions zero one two and three so yeah keep that in mind if you're working with r so you have Vector one and we're going to find the position the we're going to subset the first two elements of the vector one and right here let's run this one and it's going to return one and two but why does it return one and two is it because I typed one and two right here no it's because one and two are in the first and second position right here if I change this to five and four or five and six let's say and I run this one right here this one is going to return five and six because those are the elements in the first and second position it has nothing to do with the actual numbers okay it's the position that matters so five and six so yeah we have the vector number one and we have the um we have the two the first two positions now there's another way to get all of this um remember that we're subsetting with with soft setting with with square braces so we can also use Vector number one and then we run the square braces right here and instead of passing a um the positions we can say exactly um we can pass in a vector that's the same length after as the original vector and we say just true true false false I mean like with logical operators right so if I pass in like right here a vector remember it's another and once again a vector I pass through true false true this one right here is going to return true for the first so it's going to return the first element true for the second so it's going to return the second element false for the third is going to so this one's not going to be returned and true for the for the fourth one so the outcome will be 5 6 and 4. let's see how that works there you go five six and four this is very important because this is like the basics for subsetting in actual data frames okay so once you understand how this works you will be able to subset in actual data frames because data frames after all are only vectors aligned one after the other okay so that's why this one right here is important um you can also run [Music] um uh comparison operator so you can say oops Vector one and let's say that any element that's below 4.5 that's lower than 4.5 so what do you think this one's going to return this one's actually going to return another Vector with false true false true true and that my friends if you see it's very very interesting because now you have a vector with logical operators that's exactly the same length as the original vector which means that you can pass it in right here right so let's now get actually get the elements that are that are lowered than 4.5 okay so this right here we can put it inside oh what so what's going on all right so this right here we can I mean right here you would usually take one of this a vector with the same length with logical operators but instead of that we're going to pass in right like this because this one right here returns a vector that's the same length of as Vector one but with logical operators so now we will return all the elements in Vector one that are lower than 4.5 so let's see how that works so we have three and four which are lower than 4.5 so that's a quick tip that you have in order to filter all the elements that are below 4.5 inside of vector 1. um so I'm going to put this right here subsetting there you go so that's for R that's for subsetting vectors in our um what else can I show you oh yeah how to select columns that's pretty important as well so um but that's not about vectors anymore all right one more thing let's suppose you have a vector two and it's defined as first element one well let's say yeah first equals one second equals two and Etc equals three okay these are the keys these are the values if you have worked with python before it I mean you I guess you can see it as a dictionary except that of course you cannot have different types of data inside it so I will just create this Vector number two and now to subset it or just to select a particular element inside it you can just call the key that you're that you want so you have vector number two and in and you just run etc for example and this one right here should return number three so let's see how that one works uh something went wrong um I think that this one has to be a string there you go yeah sorry so this one has to be a string so Vector number two etc etc has the Val and the key of Etc has the value of three so there we go um there we go um I'm just gonna show you pretty quick as well how to subset for lists and then we'll go we'll get into the into matrices and data frames which is the the juice of this um so what was the list that we had created it's called list right here okay so let's see what our list looks like um so we have our five elements and the fourth element has an inner list inside it so what we're going I'm going to show you um stop setting vectors right here I'm just going to create this Command right here and right here subsetting lists all right so we have our list which is list and and we're going to call we're going to call the first element right so let's see what do we get we get this but what is this let's see what is this class of this one which is a list okay so if we use only one bracket it will return a list even if the element that even if the first element is not a list the first element as you can see right here is just a number but if we use just one bright one bracket a single single brackets um this one's going to return a list with that element if we want the actual element we can add double brackets and this one right here will return only the element let's see what this one looks like class of this so this one right here is numeric okay so now there you go so that's subsetting lists um so yeah remember double brackets for the actual element and single brackets for a list with that element okay let's see how that works with element number four which was a list itself right because element number four right here is a list of one two three let's see how that looks like list let's see number four uh oops list there you go so we have this right here what is this a class of this one so apparently it's a list of course because at least with single brackets Returns the list but what is it if I use double brackets like I did just a moment ago well it's still a list because the element inside of this list so yeah I mean if we used only one bracket this one's going to return a list with one list inside it if you want to go even deeper right here but you would probably have to do is to select the first element for example and right here now this one should return the first element of the list that's in the fourth position let's see how that works yeah so the first element is one and it actually returns a list with that element I mean this I hope this is not getting too strange if I add another square brackets right here this one returns just the element Okay so this right here Returns the list of number four out of position number four and inside that list we already have another list so we're dealing with the same kind of rules that we were dealing with with it before another way of thinking about it is inner list and we give this one to list position number four and then inset in your list you can also be asking for the first position which Returns the list or double brackets which Returns the first element in that list okay and this right here is pretty much just the same as doing this right here all right so I hope that was clear for lists [Music] um now I'm going to show you how to do the same thing with matrices okay so to declare a matrix so to declare a Matrix Matrix you can do it like this I'm going to call it a Matrix you create with the function Matrix and then you just say the elements right here I'm just going to say one to nine and I'm going to say that the number of rows is three and let's see how that looks like so now we have our a which is a matrix and let's see what it looks like so we have our Matrix right here and just like as in a data frame and as I'm going to show you how it works in a data frame you can use square brackets to to select information inside it now the element on the left means the row and the element of on the right of the comma means the column okay so if I want the first element of the third of the I mean if I want the First Column and the element on the First Column and the third row that would be one point one comma seven this one's probably going to return seven let's see how it works yeah there you go so that seven um if you want the second element second row uh third column that's going to return eight probably there we go eight so that's how it works okay um now you can also select multiple columns you can do something like a um so that's why it's called sub setting right you just take a subset of of um of the bigger set uh so let's say we can we want to select this small square right here five eight six nine so what we would do right here is we would select the second row all the way to the third row and then for the columns we would select the second row all the way to the third one as well and this one right here is going to return the smaller one like that okay now this is pretty important uh because it kind of Echoes what you're going to be doing with data sets something also pretty interesting is that you can pass the actual numbers that you want in of the columns or the rows as well like right here I selected the range but this right here is actually translate this right this right here it translates to a vector with elements 2 to 3 which is two and three but I could also do something like this um two to three and a vector two and three right and it Returns the same thing and interesting thing about this is that I can just choose another one this one Returns the first one and the third one so right here we have this two three and eight nine two three and eight nine okay so that's subsetting from matrices um now let's get into Data frames which is um kind of the juice of of um R and because that's pretty much what you will be working with if you're using R for data analysis so data frames data frame state to frames what is the data frame a data frame as I mentioned before is the list of vectors data frames a data frame is a list of vectors which are the same length all of them and to select an element inside it sorry you also use square brackets just as you did before okay so just a moment ago we had imported uh Titanic data let's view that one let's just print it actually friend Titanic this one's going to well now it's probably a bit too big but here you have the entire data set for the Titanic okay and right now what we're going to be doing is that's the data set for the Titanic um we're going to select some columns okay let's see how that looks um so right now inside here we have our Titanic data set and we have that we have several columns right here let's say that we have to so we want to select the name column there are several ways of doing this you can use Titanic you I mean what you would usually see is you add the dollar sign and then you have you have to select the name of the column okay so we said that we were going to select the name column which is right this just type name there you have it now it returns all the names of all the passengers in a list okay um sorry um let's say if it's a list or a or a vector it's actually a vector right yeah it's a vector because a column is just a vector as I was telling you before so there you go um so that's that's for to select a a column but you can also do it like this um I think you can do it like this yeah it works as well uh with square brackets and you can also I don't remember if you can use name no I don't think this works no this one doesn't work just square brackets and the dollar sign that would do but something interesting as well is that you can just as with matrices you can say which element you want so let's say we want the third and the third element and the and the name of that element of that one which is in the third position as well so it works pretty much just like a just like a matrix in which if you say Titanic if you say Titanic three comma three this one's going to return the name in that position three comma 3. 3 comma three there you go and just as with matrices you can I like select you can select more than that or like like you can you can select a subset right so let's say that you want all the names for rows three to three to nine so this right here is going to return all the names for all the rows three to nine because remember the element on the left of the comma is the rows and the element on the right is the columns right so this one right here is going to check three to nine and then the third column which is name and now it's going to return all the names from here so that's how it works um what else do we have um oh I mean right now we're only selecting one column but you can also select more than one let's say that you want let's say that you want three two you want not only the name but you want also the you want also the sex so let's just say three to four so this one right here will actually return a data frame with all this with both of them and you can say um you can just create another variable for this one subset and now you can view that subset and let's see what it looks like so it's actually a data frame right here and you have the names and the text right here and you can you can also you you can I mean as us with matrices before you don't really have to select range this one right here just converts and translates to three and four but let's say that you don't want three and four let's say that you want three and five instead of six you want H so you use right right here three and five and this one right here is going to return the age instead of the of the sex right so yeah that's how this one right here works that's how you subset in in date frames um what else can I show you yeah all right I'm going to show you how to select pretty much every single element of a data frame um yeah like like this right so right here we were selecting three to nine and then column number three but what happens if you want all the columns well what have what you want to do is you want to leave the right side just empty and this right here is going to select all the columns right so let's see all columns if you run this one and then you view it remember view is with um um MySQL MySQL uppercase sorry uppercase uh all columns now let's see how that looks like so now you have all columns four rows three to nine uh that's how you subset data frames um what else can we do I mean you can do the same thing but on the other side you can select all the rows I'm just going to show you all rows Titanic and then just select all the rows so you just leave the left side empty and you just select let's say two of these let's say that we want um the name in the class right for all of the columns all of the rows I mean all of the observations so let's say that we want this and we won't uh so it's position two and three so I'd say two and three there you go and let's view all rows and there you have it you have all the rows for just columns b class and name there you go so that's for data frames um we're getting we're getting pretty far in I'm probably gonna end the video soon and let's just finish this with functions and [Music] foreign how do you create functions um to create functions you would use integrate functions the the way to create them you just type the name of the variable first let's say product and then you go equal function then you type in your R your um arguments inside here let's say a b and then you open curly braces and then you then you perform whatever you want to do with the arguments and then you return them to return them let's say that right here we're going to return [Music] oh by the way to return you need you need to wrap it in in parentheses so let's return a a times B so this one right here creates the product function and now if you want to use it you can just go product three and six oh have to run product as well there you go so three times six equals 18. so yeah that's how it works for functions what else can I show you oh yeah sometimes you might be able you might be needing to use anonymous functions like for example you have an L apply function that runs through all of the elements inside your columns inside your all of the rows all of your observations so what you can do is that you can call Titanic up Titanic um and then you say which h oh h does it work yeah age and then right here it'll apply what it does is that it runs through all of your although if your observations and then applies a function to them and saves the result of that function in place I mean if you have worked with other with other programming languages it's pretty much like mapping okay um so age right here and let's say that we want to multiply H by 2 okay I mean you can you can take a product that you can create a function that takes one argument and returns that argument times two or you can use an anonymous function okay I'm going to write this one here anonymous um Anonymous function um so you have Titanic H and what function are we going to apply let's say to add an anonymous function you just type in function then you just type in the name of your argument that you're going to use I'm just going to type in X I'm going to say x times 2. this is the ones that the thing that's going to be returned and this is the argument and this right here if we run it it's going to multiply the edge of every single one of our Titanic uh passengers times two so let's see how that one works um so here we have it uh Kelly James Kelly is 34.5 years old now if we run this one right here let's see what happened uh didn't work for some reason um oh right yeah I think it's yeah I think it doesn't work in place um Titanic H let's see if that one right here works yeah so now if I come right here yeah so it multiplied it by two so yeah this one doesn't work in place you have to actually this one Returns the list I mean the um the vector that with um with the results but you have to actually apply it to your to your to your column right so this right here won't do anything by itself it will just return the the results and then you have to apply the results to your column um but yeah um so right here we went through Anonymous functions and L apply which is pretty important if you want to update all of your elements of all of your observations in a certain column for R very very useful there you go what else do we have all right let's go a bit through loops so let's say that we have names and let's say that we have a vector called Mary um Joseph and Jesus why not so you can Loop through this Vector with the function four okay and this one takes in parenthesis and you take your name in names this one right here is the name that you're going to be using inside the loop and this one right here is the actual set of I mean it can be a vector I think you can iterate through lists as well but I'm not sure let's test that in a minute um so this right here and then we're going to print name let's see how that one works um didn't work for some reason um may be maybe um well it's not working right here um oh yeah sure I need parentheses right here there you go there you go so now we have Mary Joseph and Jesus which are printed right here because name is the one that we use right here we're just looping through the names um I mean it's not an array but it I mean you can think of it that way except for the fact that it all all of it has to be the same data type and then name you use it right here and you can do it whatever you do inside of here with your with your variable you also have a while loop like this you go count while count is less than five and we will just start with a count value of zero so while count is less than five we're going to count equal count plus one and let's just print count there we go so one two three four five so that's while how it works be careful not to get into an infinite Loop because you will break your computer and the universe will explode uh we don't want that to happen so yeah just be careful with that if at some point you do get into an infinite Loop right here you will have a red button called stop and you you just have to press it to save the universe good um what else do we have right here I think that's pretty much it for for [Music] um yeah I'm going to be sure I'm going to be uh I'm doing a continuation of this one where we will actually be working with a big data set like Titanic or Iris and I will show you how to do some basic data analysis with it like very very basic operations over a data frame but yeah um um it's going to be the it's it's the next video in this playlist so be sure to watch it and yeah see you around um well all right so I think that was pretty much all of it for r I hope it was useful I hope it was interesting and right now you should have all that's needed to actually start delving into data analysis with data frames that's what the next video is going to be about and what else yeah I mean sometimes this kind of things this kind of um knowledge it's kind of basic knowledge about a language is what ends up taking you the most time because you just jump in to do like very complicated things like I don't know like like you just don't you just want to jump in to do graphics and stuff like that and plots um but you will very soon be faced with the fact that you don't know how to subset um how to subset a data frame so you won't be able to actually do the plus that you want you will spend like hours and hours uh scrolling through stack Overflow and searching on Google to find the actual way to soft plot your data frame so now hopefully with this knowledge that you have right here you will be able to save all of that time and focus on what you want to do which is data analysis and plotting right and using ggplot uh yeah so in the next video we'll see ggplot um thank you so much for your attention and see you next time alright [Music] thank you [Music]
Ij8SJe_mwpU,2022-12-19T12:07:00.000000,Configure Webpack 5 in Wordpress (2023) with Typescript and SASS,good morning everyone how's it going today um today I'm going to be showing you how to bootstrap or how to Kickstart your WordPress development environment and how to set it up to use um web pack and how to configure it to use typescript inside it and how to add SAS to it so that you have like a very professional um development environment for your for your projects to Kickstart uh so by the end of this video you will probably have like your own um boiler plate for WordPress that you can just like copy and paste and Fork whenever you want to start a new project so um and everything will be configured as you want it to um to create a new website or a new theme right I have to specify that when I work with WordPress I mainly mean that I'm creating custom and personalized themes which basically is like creating the website I don't really work with plugins and things like that I just use WordPress as a CMS all right so that's what we're going to be doing right now um so let's get right into it okay um first of all I'm going to be using uh I'm going I'm going to be doing this on my local machine so I'm not going to be connecting to a server right now and to do this I'm going to be using local if you haven't used local before it's a great way to create your own website uh your WordPress website in your local machine it gives you a PHP environment um a MySQL or Mario DB I don't know um database that's already connected it gives you a shell that you can access to it gives you WP CLI as well that it's already conf configured so you don't have to worry about anything just click a add new site button all right so let's get right into it so the first thing I'm going to do is I'm going to start I'm going to create a new instance here of website here in local going to create a new website there we go and we're going to call it my awesome website there you go let's see if we have some Advanced options my option this is the URL that we're going to be using and we're going to store it right here there we go so continue um what are we using so we're using MySQL 8 we're using engine X and PHP 7.4 that looks good to me if you want to use phph you can just click on custom I'm just going to add like here my name and just a very secure password which is one to Z and it's not a multi side and then just click on outside and there you go that's how fast and easy it is to create oh my password that's how fast and easy it is to create your WordPress site and local um so all right now that we have our local site it's already running so we can just open it like this let's see what it looks like so it looks like this um and as you can see it already has a theme that's running and we of course we want to create our new theme ourselves um so what we're going to do is we're going to use a boiler plate for that and I mean I don't recommend that you actually build the entire uh theme from scratch because it's just a lot work and not I mean like it's not worth it but you can let's use it like this so it's underscores underscores.me and this is the one that I'm going to be using there are many boiler plates um but I just like this one I think it's very simple and and and easy to use so what I'm going to do is I'm going to Fork it into my side theme all right so how do we do this we go right here and we open the side shell this is what I was talking to you about when I told you that that that it comes with a pre-installed shell and right here I hope you can see I'm going to go inside my my WP content U folder so I mean this right here as you can see it's the entire WordPress uh installation the all the website right here and so what we're going to do is we're going to get into WP content uh inside WP content we're going to go to themes and once we're there you can see all the themes that we already have installed what we're going to do is we're going to clone our this underscores um boiler plate okay what this is it's mainly just a regular WordPress WordPress uh theme but it's like a very like clean and empty theme that you can just mod ify to make to turn into your own boiler plate okay so that's what we're going to be doing um so what I'm going to do is I'm going to clone that repository right here and there we go we have it right here it's underscore s my new theme I'm just going to rename it I'm going to call it um my awesome theme and let's open it there we go um so there you have it uh so here we have our theme let me just check my notes to be sure what you have to do right here um T um so I mean um first I'll just explain to you what what's going on right here okay uh so first of all um let me move myself of here so first of all we have like all of our directory structure is pretty similar to what we already have usually um except for the fact that we we also have a woomer CSS and if we see the package.json we can see that it uses SAS although this one right here uses not SAS which is deprecated so we're going to have to be uh removing that and replacing it with a new with a good version um what else do we got right here we have right to left um I mean I'm not coding any right to left website for I don't know in Arabic or I don't know which other right to left languages there are uh so I'm just going to be deleting this um what else do we have right here um we have composer I'm going to be leaving this as is although in in another video I'm going to show you how to configure composer for for WordPress right now we're just going to be focusing on npm and web pack you have all your basic templates 404 archive comments footer uh you have a functions file that's pretty uh I feel that it's pretty clogged I mean pretty I mean too crowded um what else we have we have SAS right here as we're going to using SAS but we're going to be using another plugin to compile it and you have Js right here we're going to be using typescript so let's get right into it um so first of all we're going to have to clean this side and to clean it here we go and to clean it first we're going to have to remove woocommerce because I don't like woocommerce um I mean this is of course we're not removing W Commerce because we don't have woomer we're just removing the the files that interact with woomer and I think it's right here they also have a set of functions that work with W Commerce and I mean I don't know about you but I don't really like using Wordpress for e-commerce websites we're going to be removing the style right to left CSS um te te Tech um we're going to be removing what else can we remove uh we're going to be creating our own read me file later if we have time for that um the screenshot for some reason it's just like an empty thing it's I don't know what it is uh so we're going to add a new screenshot all right how about that so I'm going to go to pexels.com and let's just add like um uh coding like a coding image let's add this one I'll go for that one and let's put it right here there you go so now I'm going to delete screenshot I mean uh in case you don't know screenshot is the image that's going to be shown in your in your in your WP admin all right so now if I save this and if I go to my WP admin right here oh  all right um I mean I usually like to just uh enable one click admin that way I don't have to to to actually connect so open right now now now I'm logged in and here we go here we have an appearance we have themes and there is our theme which is underscores uh let's rename our theme will you um to rename our theme we have to come here to Styles and we just click right here and we change it to my awesome let's say our awesome because it's ours right our awesome theme because we're building it together there you go and I'm just going to remove this um an awesome theme for WordPress and I'm just going to remove all of this um it requires PHP tech tech tech um license text domain I'm just going to leave that one like that take and and uh there you go all right so now if we refresh here we should have like our our awesome theme renamed so there we go um now I'm going to remove jetp as well because I don't like Jet Jet jetpack and what else can we remove all right so let's clean functions.php as well uh to clean functions.php since we're going to be using our own SAS and typescript files I'm going to be removing the inq scripts that they have by default which are right here so I'm just going to be removing this oh just going to going to be removing that um what else what else what else uh so we don't have wo Commerce we don't have jet Peg there you go and so just in case you don't know what's going on right here um this is requiring the PHP files in the folder Inc which is just a way to modularize your files right so what's going on is that in instead of adding all this code to functions.php we're just taking it and putting it into an Inc file and like a separate file as a module and we're just importing it so I mean that's in order to to make things a little bit more readable even though even I mean still I don't really like this boiler plate but whatever uh so we have this and right now what we're going to do is tick tick tick tick tick tick um all right let's just activate the website and see how it looks there you go so now you have your very basic website but you already have your boiler plate which is very clean you you can start building your own website uh your own theme on top of it and I would recommend that you keep this separate uh and just Fork it whenever you have to start a new project uh but still we we're not using typescript or S so let's get right into that um what I'm going to do just to make things easier I'm going to be using Create app create app. def um which is just a very basic um um app that's online and it allows you to create your own web pack configuration and your own package.json oh we're also going to be deleting package.json with I mean we don't need any of this uh let's delete this I guess that's all I'm going to be removing SAS uh because we won't need it but I'm going to going to keep it there for a moment um all right so let's just choose what we want in our project okay um if you wanted to use react I mean you I guess you can add it here but I'm not going to add any Library any main library for this one uh you can also add bootstrap from here if you want I'm not going to be adding bootstrap um but this file I mean this basically what it does is it'll give you the set of files that you need to import to your theme in order to use npm typescript and SAS and whichever other plugins you want to add to it so you can also add a test framework but I'm not going to be adding a test framework even though I mean still if you do want a test I really recommend that you use U Cypress uh with WordPress it's extremely useful um as a transpiler we're going to be using typescript and we're going to make it I mean typescript um comp and we're also going to make it backwards compatible with es5 in case you don't know what Babel is it basically takes all the es6 uh functionality of um of JavaScript and makes it compatible with es5 which is the old version of JavaScript so you can use it in I mean so it basically just makes your JavaScript compatible with very old browsers what else do we have right here uh styling so we're going to add SAS um what else do we have right here are we going to treat images let's add that later for the moment I think this is all that we need um yeah let's add a minii yeah mini CSS so that this what this plugin right here does is that it makes our end version of uh CSS be minified so that I mean it's just all in one line and without spaces or comments it just makes it way more uh concise and and I mean low weight so that your your website is faster so there you go once you have your your files ready you're going to click and Download Project you're going to open it and once you open it you should have this file right here um so you have a disc folder that we're not going to use what we're going to be using is package.json which includes um web pack and all this configuration and we're going to be using TS config.js and weback config.js and these are the ones that we're going to be copying into our project right here so let's do that so first of all I'm going to run package. to copy package.json right here there you go I'm going to copy TS config tojson as well and I'm going to copy web back. config.js and if I'm not mistaken this is pretty much all we need oh we also need Babble lrc there you go um so everything's running smoothly what we're going to want to do right now is we're going to want to oh first of all I'm going to re initialize kit um because remember that this to to get this web this um boiler plate we cloned a GitHub repository from undor s so what we're going to do is I'm I'm just going to remove the git file for that one and I'm going to reinitialize uh git repository there you go so now we're in a new kit and I'm just going to commit it oh just in case you don't know what I did here this basically means get at all but that's just an alas um and let's comment our first comet there you have it so now we have our first comet and everything is in uh what else are we going to do right now we're we just added our new package adjacent so we're going to have to install it oh first of all let's see which version of node I'm running apparently I'm running node version 16 um probably going to want to change that one if you don't know how to use this check out my video and how to use NVM and node version manager it basically just allows you to use different uh versions of node so I'm going to change it to the latest version which is 18 latest stable version which is 18 and it comes with a PM 8 so let's see we have npm version 8 there you go um so once we we're using the latest the latest version I'm just going to npm install everything that's in my package adjacent and let's see how that works this is probably going to take um just a couple minutes but in the meantime I'm going to show you that this right here is creating uh our node modules right here uh I mean it'll appear in a moment and also it's going to allow us to use this scripts right here okay some people like to use gulp instead of weback oh now we have it as I told you node modules some people like to use gulp with especially with WordPress instead of webpack but I just feel web pack is way more straightforward and easy to use and and I just use it with a combination of webpack and npm scripts what npm um scripts are uh it's the ones that allow you to run scripts just by doing npm run and then you click on you you use any of this that you want let's say that we want to use build def um and what that's going to do is this is just an alias for web pack mode development so it basically means that it's going to um it's going to run web pack and bundle our assets okay uh let's see I mean it's probably not going to work because we haven't um all right so interesting thing um web pack um comment not found what's going on right here so what is happening right here is that web pack is a development dependency as you can see it's in dependencies and we're trying to run it uh what is happening when we try to run it when we try to run it um basically npm is looking for a binary which is an executable inside node modules and here we have webpack CLI which is where you should find your your binary and then you open it but it seems to be empty and the reason for that is that we're probably running any devel in a my local environment is set to set to production for some reason so let's see Echo node n and indeed my environment is set to production so if my environment is set to production that means that when I run npm install it's just going to install the the the dependencies which are none and not the development dependencies so what I want to do is I want to change my environment to development oops and right now if I do npm install it should install all my development dependencies uh as well let's see if that works yeah it seems to be working now they're not empty anymore there you go so that's a good point I mean uh when I didn't know this I spent like countless hours try to debug this just to figure out that the problem was that I was using a production environment instead of a development environment so let's wait for it to work and once it's working while it's installing I'm going to give you a tour of our web pack file so what is going on right here um basically we are wait a minute basically what's going on is that we telling it to go look for a file in source index.ts and that basically means that it it has like it's going to look for index.ts in Source um let's see do we have a source directory here we don't so it's probably going to return an error let me just show you how it returns an error um so if we do npm run build Dev as I told you before it's going to run web back in in development mode and let's see how that works um so as we as we were expecting it there is an error because it cannot resolve source index.ts so what we're going to do is we're going to create it um so let's do that let's add Source directory and you know what I'm going to do I'm actually going to create two folders right here I'm going to create one for JS and I'm also going to create one for uh CSS uh I'm going to call it SAS actually and this one I'm going to call it TS there you go so right here I'm going to create a new file called main. CSS because we're going to be using SAS and let's just add you know body background color let's set that one to Red this is going to be our main CSS file I'm just going to um this is just a very simple test and inside TS I'm going to add main.ts right and in here we're going to add a console log hello world and again this is just to test right I mean we're just going to test that our our web pack is working okay so let's come back to our web pack file and let's say let's tell it that let's um let's just update it so that it knows where to look for our source files this right here is what's going to be bundled into our min ifed assets that we're going to include in our WordPress theme so that's how we're going to be using SAS and typescript okay so what we're going to be doing here is we're going to since we have two of this actually what I'm going to do since we have two of this I'm going to add an object right here instead of all instead of this there we go I'm going to add an object right here I'm going to I'm going to call it Main and I'm going to add a couple of things right here first of all we wanted to look for Source TS which is this one right here and we're going to want it to look for main.ts there you go and secondly we want to add another point of entry which is going to be sour scss which is I know it's SAS and it's going to be you know what I'm just going to rename it SC CSS I don't know why I named it has and we're going to name it main. scss there you go so now we have our two main points of Entry which are main.ts and main. scss and right now and now we're going to have to set set up the output where do we want the output to be um I mean I'm just going to run it like this just to show you it's I'm pretty sure it's supposed to be working right now so let's see npn run build death oh config it run successfully it's such a such a pleasure when that happens for the first time um so that basically what it did is it created our directory called disc and it added bundle.js and main.css and as we can see we have body background color red and all of these things for our bundle.js now you might be wondering um mate aren you isn't this supposed to be minified the response to the answer to that is no because we're running on a development environment I mean we're running webpack as in development mode remember the the the command that we run is npn run build Dev which if we come here to package. Jon it me it's running weback mode development but if we want to run web pack in production mode um we can just oh all right we can just change this to prod and this is going to run it in production mode like that so let's do that so it compiled successfully and now if we look again at our file it's minified I mean it's just all in one line and bundle.js it's also all in one line so that seems to be working pretty good um but I'm going to be using Dev um and just to show you uh very quick as well what the script is doing um right now I run build prod and just to show you that that's actually just an alas for this I can actually just run web pack mode production and it's going to do it's not going to do the same thing for some reason um npx web Peg and it run it did exactly the same thing okay because it's running it through npm um so yeah it's just an alas for running web pack and there we go um so now that we have this I'm actually going to modify our web pack file to make it more um ready to use so I don't want it to be called bundle I'm going to be I'm going to call it main. min.js so there you have it and I don't want it to be in a folder called disc I want it to be in a folder called assets so there you have it so that's we changed our output so now we have the output is going to be assets and main. J do uh main.js now if I run this it's not going to work why let's see wa if I run this it's not going to work and the well it apparently did and what happened here assets main main.js all right it apparently worked for some reason um but all right just in case you should be using where where is my ts config here it is you should change this right here [Music] to assets um because this one is the types script file that's going to be dealing with typescript I don't know why it actually worked I I don't know what's happening but uh just to make sure change it right here as well not only on web pack um so there we have it uh I'm going to remove now our disc and I'm going to remove the assets as well just to show you that every time you run it it's going to rerun everything exactly as you as it should and now you can just import it there you have now you can just enq it to Wordpress uh so that's the way to use uh SAS in typescript and just in production what you have to do is just um automate the fact that npm run build prod is automated in your pipeline so that it's actually it builds your assets whenever you want whenever you need it need them to be built this is extremely important because some people do this in local um I mean in their local machine there are some plugins for running SAS and compiling SAS and things like that I mean you can just run and compile it right here but then when you have to run to to move your code to production it's not going to be updated I mean it's just going to upload SAS so that's why you want to have an npm script that bundles your files together so you don't have to do it manually so now every time you you commit it to production it's going to run npm run npm run uh build prod and that's going to uh generate your assets and everything's going to work with SAS and typescript um what else do we have here let's let's pump this one up a little bit more um so there we have it um now right here I can change this to Main main um I can put this right here and say name instead of main that way it's going to it's going to use this this name right here instead I mean it's going to be the same exactly but just just to show you um you know what we're going to do right now we're going to add an image right here and t t t t tck let's say uh where is how do we add images as well to our web pack thingy let's say we want to add an image to our to our CSS file and let's say that we want to import it right here um I'm going to add an image that's going to be background image and I'm going to use I'm going to use te te um I'm going to use remember remember to use uh relative paths to import your images in s i mean in this setting it's going to be completely automated um and now we're going to add it in in in in we're going to add screenshot jpeg right now if we save it and we rerun production uh the build you can see that it created a new image right here and it added it to our assets and if if we see our main. CSS that's minified there is this weird name for the image and that's actually re referring to this image right here which is the screenshot I mean the image that we had imported so it's not actually using the image right here it's using another image in assets um and this is something that you that I mean you could leave it like this but if you have like a ton of images they're all going to be like in the same place as your main. CSS and Main that Main mean.js and you probably not you probably don't want that so what we're going to do is we're going to configure web pack to put your images inside another a new directory inside assets and to do that I'm going to be adding this part right here um t t t let's add styling let's add support for PNG images and let's add svgs as well now you know what I don't like svgs let's just pngs uh so we're just going to copy this part right here which goes all the way till up here and now we're going to paste that one right here and where is it located it's after CSS let's add it right here it's just a new rule for weback and it's going to be using URL loader and it's going to be using it's going to be taking the image. pngs um um now if we already added this one we might need to update I'm not sure but we might need to install something in npm so let's see how our package that Json changed after adding this does it change yeah it does so we have to install URL loader let's do that is it a development dependency yeah so I'm going to add it as a development dependency with capital D and URL loader now we're installing URL loader and we're adding it right here and what we're going to do now is you know what we're not going to be using actually H one thing I wonder if we actually need this one because we can actually do it without it yeah you know what we're going to bring this one right here let's see how it works this is going to add support for all of it not only for all all images and not only pgs so let's take this one out t t t and let's add this right here so it's going to test for pgs JPEG and gifs and we're not going to be naming it using it just like a an image we're just going to call it asset resource and let's add generator let's add a generator and it's going to here right here is where we're going to say where it's uh supposed to to send our images too right um so let's say that we wanted to [Music] all right let's see how this one right here works so far all right um so nothing has changed we we still have our image right here let's rerun it and let's see how that works right so nothing has changed everything's still the same what we're going to want to do right now is T TI tick tick tick TI we're going to put the image inside the the another directory that we want so uh to do that we're going to say we're going to specify a file name for this output and this is very simple you just have to write the file name that you want to add and basically dot slash we're going to say that it's going to be in the same output directory but instead of just being there we're going to add a new directory called IMG for image and let's add it right there but we also don't want it to be like all this weird code names so let's add name right here and let's add the extension afterwards these are just uh web pack um uh codes that you can use to to fill in your your configuration file this one will take the name of the image and this one will take the extension and just add it inside and just add it into the image folder right so let's run it again and let's see how that works and and and what happened oh sorry there now let's add it again let's see how that works there you go H so it created our new image thing and it created our screenshot JPEG and if we see right here it's now imported at screenshot.jpg Ally you didn't have to um like configure your paths to your image and all it was all done smoothly without you ever touching it that's pretty cool I would say and but there is a problem right now and the problem is that we still have this weird file right here inside our assets I mean we can just delete assets and just rerun uh our build but we don't want to do that every time we want to we want to run our uh um we want to build our project so what do we do what we do is we we we're going to add another another param right here to our output we're going to say that we want it clean and we were we're going to set this to true we save and what this is going to do it's going to remove all the previous files that that were not uh generated by the current bundling cycle all right so if I now that I have add my clean setting to through to true I can rerun build prod and as you can see now I only have the files that were bundled in the current cycle and the other weird one that we had there it has just been deleted because we're not using it in our current bundle and as just as I showed you before you can just delete assets and you can just rerun build prod and it's going to go come all back again right here very neatly and very beautiful very very well organized there we go so now that our main. CSS file is here and our main.ts file is here and our assets are up here we don't really need this JS and SAS thing right here I'm just going to show you how to use SAS um um to import your Android organize your files um I mean but you basically just do this let's say that you have your sass right here and you want to add a new file let's call it um my components and inside here you want to add um the specific uh CSS file for a particular component let's say it's um let's say it's the home um the hero oh  all right sorry um rename rename it to hero. scss and now all you have to do is come here and import it um wait I have to remember yeah hero and then just add it as components hero there you go so now this right here is going to import your hero. CSS you know what let's add this to Hero right here and let's change this one to um hero and this right here what's going to do is it's going to now it ran and it included our hero setting right here so here we have our hero and all that that's just a method to modularize your SAS files to make this more organized remember to keep it all in separate um files and separate modules so that it's easier to maintain and to to update in the future what else can we do to make this file amazing and this boiler plate like amazing um there's one more thing you can add a Dev tool um for the source map uh so let's do that um so right now if you're running produ uh if you're running build prod I mean everything in your I mean when you go to inspect your website and you want to see where a part particular CSS line or a particular JS line is in order to debug it it's always going to say that it's in the first line because if you come right here everything is in one line everything is in one line for our minified assets so you don't want to do it like that so you probably want to add a a map to your I mean to this file in order to know where your files are uh I mean in which line the bug was happening so in order to enable this map we're going to have to come right here and add a new def tool and we're going to set this to source source map there you go and right now if we rerun this right here it's going to create our maps for our file so now we know in which line it's uh a certain line a certain bug is happening when you want to inspect on the Chrome developer tools so there you go there you have it what else can we do to make this even more more useful and more neat um how about we add a watcher uh so that every time you save it it's going to be automatically rebundle and to do that what we're going to do is we're going to add a t t t that one we're not going to do it on web.con but we're going to have to add it a new script to our package.json and to do that we're going to check tech tech in here we're going to add a script that's going to call be called watch and what it's going to be it's going to basically [Music] be wait a [Music] second t t t t [Music] um wait a second right here so what we're going to do is we're going to add I don't remember which line it was for it um what's the script that we have to use right so it's this one right here you have watch and just add this right right here web pack progress I mean as usual but you have to add this watch and then you can add the mode production it doesn't matter if you add production because we already have our map so even if it's minified it's going to get tell you where in which line the any line is happening any any line is coming from uh for JS and and and CSS as well so there you have it and now if we do npm run watch it's going to be watch ing our files and every time we modify one of these so let's say we modify our main. CSS and we add a new a new rule for H1 for example let's say that it's going to be uh no not resize but uh font size and let's set it to 4 a.m um and once we save it you can see that it's being reloaded I I haven't touched the terminal myself and I haven't run npm run uh build BR but if we come right here that H1 font size 4 4M it's already there it was uh it was compiled automatically just when I hit save right here so that was The Watcher I hope it was useful so that's how to use SAS and typescript in your theme but there's a problem right now we already have we're already compiling everything but we are not using it yet in our theme so let's go right back to our options uh to our functions.php file and whatever you want I mean obviously if this is going to be your boiler plate you're going to have to organize this a little bit better maybe take all of these things and put them inside another file in ink but I'll let you do that yourselves I mean you can do it as you wish uh as how you feel that it's more organized but I'm just going to add a function that's going to NQ um my awesome scripts and this one right here is going to oh right sure you cannot add dashes to to a function in PHP so right now we are going to double P NQ we're going to inq a style and we're going to inq our main.css and to do that we're going to we're going to we're going to say that scripts uh no style uh we're going to say we're going to give it a source which is going to be get um theme your ey your ey if I remember get theme which was it um no get Styles shed U uh if I'm not mistaken I think that's it and then I'm going to add to it I'm going to say it's inside assets and inside assets is in main. CSS right the dependencies there is no dependencies the version that's an important thing I'm just going to set it to false right now but I'm going to show you a quick little tip for that in a moment so that right here should inq this right here should en our our um wait what's going on right here this right here should NQ our main. CSS thing right here but we should still call it inside an action S no not s add action and we're going to call it dop I think the I think it's in scripts that you have to plug it in not sure let me see where were they um or they you adding it and Q scripts and do in Q script it's not it's not it's this is the name of the h cook all right so this is the one there we have it and now we run the function which is my awesome my awesome scripts and now if I'm not mistaken this right here should should add our main CSS file to our theme so let's go let's take a look into it and let's see if it's working um right now um what is happening here failed resource so it couldn't find it for some reason um themes my CSS for some reason it cannot find it so let's see what's happening right here uh so we're including chck um let's see um Style we're including uh link tick tick tick application my awesome there you have it my awesome that local includes uh themes my awesome there you have it themes my awesome Del content uh for some reason this is not finding its way so yeah this is not finding its way so all right sure because this one is returning style CSS sure yeah sorry that was not the actual function that you have to use it's not get style CD it's get theme your I if I'm not root theme R get P theme I don't remember which it was um how do you do you remember guys how to import a how to inq a theme uh uh Styles sheet let's see where it goes [Music] um where do we import it where do we import it get template directory URI it's not get them U Get template directory URI and then just add the assets let's see how that works already um there we have it so is it working now it seems to be working um so we have our main.css which says that the hero background color is red but we don't have a hero so let's let's just for testing let's modify our source file right here and then modify M CSS and instead of saying that we want the hero to be read we want the whole body of the file to be read um background color let's say red so let's see if that worked there you have it so now you have you have it we're using SAS in here and it's being updated I mean and we can use all the SAS functionalities right we can just add that inside body we want let's say that we want the site title the site title to be color um let's say blue and right now this well that's not already all right so let's not set it to Blue let's set it to Yellow there we have it so now if I refresh and this one right here for some reason it's not turning yellow um all right so let's say that it's it's the there you have it so it's yellow now so we're using SAS right here and it's it's already updating in WordPress so that's how you s and let's just just finally let's just inue our our script script and then we're going to call it script and it's in the same position but it's not main. CSS it's main. main.js and there you go so now our main that me that JS is supposed to be saying hello world so let's reload this and let's see if we see Hello World and there you go so we have hello world that's running from a typescript and we have our background that's changing from a SAS file inside WordPress and all of it is done with web pack that was pretty long I was expecting this to be faster um what else I had one more thing to show you if I'm not mistaken uh main that CSS no I guess that's it oh yeah sure um let me just yeah no I think that was it actually and yeah so right now you have like your entire theme that you can start to customize you can start to create your own templates you can start to create your own um files in your own SAS files your own typescript files and you can use them in your theme and you will be able to use them whenever you want uh just Fork this new boiler plate that you have created that you already use weback with it and when deploying it be sure to run be sure to run inside your your pipeline be sure to run npm run build prodad so that all your files be bundled together um I'm just going to remove this one right here because we're not using these two right and I think that that's pretty much there you have it so I hope you enjoy this I hope this was useful uh will'll be posting uh this repository I mean if you just want to copy the already finished version of this theme I will be uploading it to GitHub and it will be available in the description so be sure to to check that if you don't want to to actually do all of this that I did uh during this last 57 minutes which was more than I expected um and just uh and just copy it if you want um I mean forkit and just use it as your own boiler plate I hope you enjoyed this I hope you learned something new and I will see you next time [Music] [Music] [Music] [Music]
Rdq2oEWg3KU,2022-12-01T10:59:12.000000,Linear Regression in R - Full Project for Beginners,good morning everyone how is it going today my name is Alejandro and welcome to my channel here we talk a little bit about programming and coding in general today we're going to be going through a data science project uh one in which we will see a linear regression and how to apply it in R okay in order to follow this tutorial it's recommended that you already know a little bit what linear regression is and how it works although I will explain it a little bit pretty quick at the beginning if you want to deepen your knowledge in linear regression or just get a quick introduction before actually watching this video I recommend that you check check out my article that I published in medium it's titled a simple explanation of linear regression and then at the end of the article there will be this video explaining pretty much how these concepts are applied in R okay so without further further Ado let's get right into the project and let's create our linear regression model okay so let's go [Music] thank you so let's get started okay um we're going to be doing this in our studio to to manage our project and we're going to be using this data set right here okay I will paste the link in the description so that you can download it and follow along and the idea is that you have an e-commerce customer data set okay um you just have to click on download it and once you download it you're gonna have to unzip it and once it's unzipped you're gonna have to add it to your to your project and how do you do that okay one second um there you go so here I have my folder of my project and I created the date folder and inside the data folder I'm just going to add the unzipped file here right here I'm just going to rename it I'm going to rename it e-commerce e-commerce users there you go so now as you can see we have here our files and here we have e-commerce users inside our data data directory okay and this is the one that we're going to be using so um first of all we're gonna have to create a new R script I'm just going to call it main.r inside our regression tutorial it's right here and now we can start um analyzing our data okay sorry about that just gonna set this in silence mode there you go um so first of all what we're gonna have to do first is import our data okay import data and setup there you go I'm just going to add some divisions right here there we go like that and like that there you go and first of all we're going to import our data to that to do that we just use the read.csv uh command and then we just tell it where our data is located uh since we're working inside a project it's important that we that we use a relative path so this means that it's relative to the current position of my file so which is main R and then I just write data because in the current position was in Main and then we enter data and then inside data we just open Ecommerce that use users I don't know what this file doesn't have a CSV extension but it's a CSV file so I mean it should be all right I'm going to I'm going to run down and let's view it okay so let's view the data there you go so here this is how the data looks like um we have an email column we have an address column we have an avatar apparently which is probably the name of the user average session length we have the time of on the app because I mean these are users that are spending time on an e-commerce application and website okay and we have the time they spent on the website we have the length of the membership that they've had in this e-commerce website and they have the yearly amount spent in that e-commerce platform okay and the idea right here in this project is that we're going to try to predict based on this um variables like the time when they spend on the website the time they spend on the application and the time the average session um in this platforms we're gonna try to predict uh whether or I mean we're going to try to predict how much they are going to spend in the platform okay and to do that of course we're going to be using a linear regression um I'm not of course but this is just what the video is about we could use another model but we're we're going to be using what I'm going to be showing you how to do this with linear regression so let's continue analyzing um like just getting an idea of our data to do that we're going to check the structure of the data and I'm just going to move myself over there so that you can see what's going on here um so here we have that we have an email variable we have 500 observations that means that we have 500 rows each row is called an observation we have one variable which is the email and it's a character variable which means that like just just a string each bar each value is a string then we have the address which is also a string the Avatar which is also a string we have the average session length which is a number um and that's in minutes the time on app that I spend daily I suppose um the time on the website and the length of the membership in months if I'm not mistaken let's check that out do we have do we have an explanation for that um all right let's just suppose that it's an hours um e-commerce linear regression this is a very popular data set anyways that you should be able to find it um all right so dirty head is having data of customers who buys clothes online they off the store offers an in-store selling closing advice sessions customers come to the store have sessions meetings with personal stylists and they go home and Order either on the mobile app the website or on the clothes they spend all right so actually the session means the set the meet the length of the meeting with a personal stylist um it's important that you understand what what each variable actually means that you can actually give an a valuable Insight with this data um then they can go home and Order um either on mobile app or on the website the clothes they actually want okay and we're going to predict how much money they are going to spend in that um in that order and we're going to be trying to predict it with these variables um I don't have the actual nursery rhymes but that sweetens I mean as you can see for the data the time on app is probably in minutes the average session length is also in minutes because they went physically to this place and they spend some time in in place um which is in minutes 34 31 minutes then we have the time the time they spend on the website and the length of the membership in months that I have all right so yearly amount spent in dollars there you go so now we have seen the strength and the structure of the data what we can check right now is the summary of the data let's see so we have the email all right address characters Avatar we have the minimum session length to be 21 the maximum to be 36 so it's around 30 minute sessions for each client we have time on the application the shortest one was eight minutes and the longest one was 15 minutes they do tend to spend a little bit more time on the website apparently with 33 minutes and 40 minutes length of the membership we have some that have had the membership for 0.2 months and others that have had the membership for nearly seven months and the yearly amounts spent okay so there you go now that we have a little bit more of an idea of how our data looks like now we can actually start plotting the data to try to find try to seek correlations and what is um yeah I mean just to try to get get a feel of what the data um how it's correlated and represented Etc okay so we're going to add a new section that's called create plots and search four insights how about that all right so to for the plots we are um going to be using the basic R plotting system and we can also be using our sorry ggplot so I'm just going to add here the library ggplot2 if you don't have dgplot you're going to want to install it and to install it you just run install packages and then you just run ggplot okay okay um all right so first of all let's ask ourselves is there a correlation between the time spent and what on a website and the yearly amount spent um by by each user okay and we can do that with ggplot let's see uh Corey let's find correlation between time on website and yearly amount spend so let's see if there is now to plot um to make a plot in GD plot with with a ggplot we're gonna see we're gonna pass in the data as the first argument and then we're going to say that the x-axis is going to be the time on website uh there you go like that and then the y-axis is going to be the yearly amount spent which is what I have right here there you go just gonna copy paste this so that I don't make mistakes and let's add some let's make it a point uh scatter plot okay so we're going to add a geometric point fill and let's just say add a little bit of color we're just going to say that the color is going to be orange okay um just add a very quick title so that we know what these what this plot is going to represent so this one's going to be time on website against a yearly yearly amount amount spent like that and then let's add some labels as well to to add labels you just do xlab and then you run the function with the name of your label so this is going to be the X label is going to be time on website and the Y label is going to be the yearly yearly amount spent okay this is just a label so let's run down uh we're supposed to be where we have an error apparently um data correlation between area and ggplot could not find function ggplot here because I did not run my library now if I run it I still have an error because while I Y label is not supposed to be with a number case there you go um no there you go so here we have it here we have the curl I mean the Scout plot um um now as you can see there doesn't seem to as you can see there doesn't seem to be much of a correlation between the time they spent on the website and the yearly amount they spend um each I mean the client spends this looks very very scattered and it doesn't look very relevant to our to our study so I mean that's already an Insight let's check for other correlations all right let's see the correlation between the average session length for when the customer went to the store to actually try out the clothes and to take the measurements Etc versus the yearly amount spent so let's add again a ggplot let me just going to copy this one right here I'm just going to paste it down here so it's going to be the data but instead of being X time and website it's going to be session length where is the session length name here it is average session length and Y is going to be the yearly amount spent and here's going to be session length against yearly amount spend time on the website um session length that's going to be my X label and the Y labels is still yearly amount spent okay I'm going to run this and as you can see we have a little bit more of a correlation it's very very thin I mean it's very very small I I don't I mean but you can see that the longer the session they tend to spend a little bit more okay um so I mean it's definitely different to the one that we saw about the time they spent on website this one does look a little bit more correlated so all right so that's already a pretty good Insight um let's see what else what else can we can do how about we do a pair plot of all our variables okay um of all continuous variables um this is important I mean this this is just a basics of data data science and data visualization um if you're going to use a scatter plot both variables have to be continuous I mean they have to be numeric they don't have to be categorical okay in that sense since the session length is a number and the yearly amount spent you can actually plot a number to it but if it was just a categorical variable you would just see a column of points which is I mean it's useful sometimes but like it's not a real scatter plot so there you go what we're going to do right now is we're going to pair plot all the continuous variables together to try to find more correlations to see how this looks like okay the the the function to to code this is Pairs and we're going to pass in the data and instead of passing all of the data we're just going to subset some Columns of the data and to do that we're going to say which which columns we actually want so we're going to just say the we're just going to say the um we're gonna say the average session length of course this one is continuous we're going to pass in as well uh time on app because it's continuous to what else are we going to pass we're gonna pass in time on the website because it's continuous we're gonna pass in length of membership because it's continuous and last but not least we're gonna pass yearly amount spend because that's actually the response variable that we're looking at and that we're trying to predict okay so now that we have passed in the data that we are going to to be analyzing um let's just add some more just a little bit more parameters let's say the color first and I'm going to keep it to Orange because I don't know looks right um PCH let's set that to 16. and the labels yeah let's just add some labels I'm just going to add now you know what uh we can just do without the labels for now but yeah I mean for if you wanted to add some labels you can you can just add a a vector here and just add pretty much the same thing as you were adding up here and do yeah so this one is going to be average session length but instead of like it having a like um like a variable name you can actually name it with a more understandable name without having all the dots in there um I'd I mean just to show you how it works but I'm not going to do it here and let's I'm I am actually going to add a title and the main is going to be a pear blood of all continues variables there you go I know if we run this one we see that we have a pair plot and actually I'm going to zoom in a little bit on this one to actually show you what is going on uh so here we have pretty much the same as we were doing before but for all of the continuous variables so the you can see a little bit more clear how this data set uh behaves so first of all we have they our I mean our response variable we set it at the end so that's pretty convenient because I mean we can see more clearly which variables have a correlation with it okay so let's say we have that the length of membership is actually the most correlated one as you can see the more the long I mean the way this spare plot works is that you have your yearly amount I mean the variable right here is the x-axis and the variable right here is the y-axis okay sorry this one is the x-axis and this is the y-axis because this one this one's right here deck so that means that this one's right here and this one right here is right here and this one's right here okay so X is length of membership and Y is yearly amount spent so here you can see that as the length of membership increases the yearly amount spent increases as well which is kind of logical I guess because I mean the more time you have spent being a member of this um of this store of this community the more time you have had to actually buy things then we have the time spent on website doesn't really seem very correlated so I mean it's here but it doesn't look extremely good I don't know here we have the time on the app the day this one does look a little bit correlated to the yearly amount spent and then last but not least we have the average session length and it does look a little bit correlated too so there we have it now we have a now we have seen um somewhat more somewhat more um now we have more of an idea of what our data set actually looks like and the relationship between different variables okay so that's pretty important uh what we're going to do right now is we're going to wait a second just let me add a new just let me add a new section right here and we're going to do we're going to explore the selected variables okay let's see to to actually let to see what they actually look like themselves without actually looking at the correlations so let's see exploring the selected variables there you go I mean this can be useful if you're going to be using uh different models some models do require link normality some models don't but I mean this is just to see okay the condition for it being a forfeiting a linear regression is that the data has to have a linear relationship I mean that's an assumption um but right now let's just exploded in the selected variables okay so I mean just as a matter of exercise let's see if our variables are normally distributed okay so is the variable normally this tree muted there you go um now to do this we can actually use I mean what I usually what I what I would recommend that you do is just use the basic histogram from R you can do it like this data and then you say length of membership like that this is going to show you a histogram of your length of membership data pretty important you can use a histogram because your data is continuous I mean your variable is continuous if it wasn't continuous you would rather you would use a bar plot instead right so this is the histogram it does look a little bit normally distributed so that that's looking pretty good I'm just going to show you how to do that on ggplot pretty quick so you would do ggplot as well and same just as before you would you would I mean I guess I could have just stored this in a variable but I'm just going to copy it like that um so you can do Gigi plot data and then we're not considering the time on the website we're considering the length of membership and we're not we're not going to have a y variable because we're just measuring just a histogram of one single variable and we're going to do GM histogram there you go like that um and I mean the idea of using ggplot is that you can customize it a little bit more so I'm just going to add a color let's say that it's going to be white um let's say that the fill is going to be orange because just to keep it consistent and actually you can now also I mean you can also do this in in regular R function but you can set a bin width so here as you can see the hour bin is 0.5 if we don't set it I'm not sure to wait to what it will default so it wasn't to 0.5 it was to 0.25 apparently um no I don't know what the bin bin size is right here but I mean you can actually customize it just said bin it's been been with like uh not bit bin bin with and let's set it to 0.5 if we say hit enter then we have a similar histogram to what we had before in our R function just that R is a little bit quicker I mean the base function is a little bit quicker but it's less customizable okay there you go um so it does seem to be normally distributed um so now just pretty quick what we're going to be doing is we're going to be plotting this same variable as well because it's the one that we're going to be choosing for our linear regression model and we're going to be plotting it with a box plot this time all right so instead of using the histogram function we're going to use the box plot function like this one it's the base function from R and we're just going to pass in our variable right uh so let's say length of membership like that let's run it and we have our box plot over there so we can see it actually does look normally distributed and we do have some outliers but they're not very very far away um what else we have let's do the same thing but with ggplot okay um to I mean we're going to be doing pretty much the same thing as we did up here but instead of adding a histogram we're going to be adding a GM box plot like that there you go and how about we add a fill color of orange just to keep things consistent again there you go and I'm pretty sure that's all there we go uh as you can see we have our box plot now and I mean it's horizontal of course because I passed in the variable in the x-axis but if I pass it in the y-axis we see that it actually takes the form of the previous uh plot that I showed you before I'm just going to leave it right here as an horizontal one there you go so now that we have chosen our variable that we're going to be using for our for our linear regression model um we're actually gonna let's just actually fit our linear regression model to our variable and our response variable okay so let me add just a new a new section right here like this there we go like this and here this one's going to be called fitting a linear model there we go first of all I'm just going to attach the data so that whenever I this means that whenever I run a function I just have to type in the name of the variables not not actually mention that they come from this data I mean it just saves me time I suppose so I'm going to create this linear model fit I'm going to store it in a variable called lnfit1 and the function to actually create a linear model is Ln for linear model and it takes um as an argument the first thing that you have to write in here is the response variable that you expect to get so for example we expect to get the the yearly amount spent like that and after that you write a tilde like that one and here you write in the variables or the variable that you expect that that are the predictors okay so right here we have chosen length of membership as our predictor so I'm going to pass it in like that and and there you go so now let's run down uh actually yeah I'm gonna run attach data I'm going to run lmfit like that so now we have lmfit and you can see that we have Alan fit up here it's a list of 12 elements and actually we can start looking at Ellen fit and to see I mean to to our linear model and try to get some insights from it okay so let's just check the summary of it the summary of our lmfit we just wrap wrap it wrap the the variable that you were using to fit it and let's just run down I'm just going to move myself over here and let's see so here we go we can see the function that we called and we actually did call um this one is the response that we expected and this one is the the predictor we have the residuals as well we're going to analyze the residuals in just a moment but let's focus on something else okay remember that right here what we're doing is we're finding not this one here you go we're finding we're trying to find this right here uh nope sorry not down this right here so this is a linear regression with just one predictor the one predictor we have is the X right here and here we have the coefficient of x which is the the weight the weight of of our variable and we also have the the intersect with Y and of course the predictor I mean the intersect is just when y equals zero okay uh so when x equals zero um so there you have it here we have our intercept which is 272 dollars because of course we're talking about the predictor which is in dollars the yearly amount spent and we also have the length of membership um the coefficient of this one is 64. that means that um that means that wait one second um yeah it's 64 that just means that it's uh I mean it's positive and it's a positive relationship with the with the length of membership we also have some more variables right here we have the standard error which is pretty a pretty important measurement we have the T value for the student t-test and you also have the significance of with the P value okay as you might remember from your statistic classes if the p-value is lower than 0.05 that means that we reject the null hypothesis and that also means that this this variable right here is actually significant okay which means that actually the length of membership is significant to our linear model so this seems to be working correctly since we have three stars right here that means that it's very significant here here we have the significance codes three stars means very significant and it goes all the way to zero Stars which is not significant we also have the residual standard error and the multiple r squared and you have statistic so I mean this is how you how this is how you measure your the how well fit your model is um so there you have it that's how we have already fit our model um but how about we actually we actually plotted all right so let's let me show you how it looks when plot I'm just going to plot it pretty quick like this I'm going to go yearly amount there and just add length of membership right here there you go um PLT it's not PLT it's plot like that so there you have it I mean this is pretty much just the same graph that we had just a moment ago okay it's nothing new but I'm just going to add the the linear the regression line that we have just that we have just created and to do that I just use this function apline and I just pass in my linear model which is lmfit one the one I stored right here I'm just going to color it red how about that there you go so here you have this is our regression line as you can see we have our intersection at where was it 272 so here is our intersection and the coefficient of our length of membership is 64. uh and that basically describes this line um so that is how you do a linear regression for one single variable um something that you're going to want to do right now is to analyze the residuals because linear regression assumes that the residuals that you get are going to be normally distributed if they are not normally distributed that means that you're probably there's a problem with your model um so what does it I mean what does it mean that the residuals be normally distributed the residuals are the distance I mean you can just see it as the distance between the points and the there is in the the distance between the points and the regression line okay and there are many different ways to actually test if the residual if the sum of I mean if the distribution of the residuals is normal I'm just going to show you two ways of doing it one of them is with a QQ plot and the other one is the the shape here test shapir will test so let's check that out I'm going to add a new section right here hmm and this one's going to be residuals analysis remember this is pretty important for your linear regression analysis you always you're always going to want to check the residuals so the first thing I'm going to do is I'm going to create a QQ plot if you're not familiar with what a QQ plot is I encourage you to check that out and but I mean I'm just going to explain that pretty quick anyways so you're going to want to pass in the residuals here so residuals and that's the function that you're going to want to use residual assist with is sorry about that residuals and you're going to want to pass in the the model that you just trained which is Ellen fit one there you go and that's basically just created a normal QQ plot for us and what does that mean um so basically QQ plots just take the distribution of your data and they divide it into different quantiles um and then you also have a theoretical quantel which is the normal distribution and then you divide um sorry you also have a theoretical distribution which is the normal distribution and you divide this theoretical distribution into the same amount of quantiles and then you just put all the quantiles for the normal distribution right here and then all the quantiles for the for the for your sample distribution right here and then if all of them are actually like if the normal quantel goes with the I mean you plot it you plot the normal quantel with your sample quantel and if all of them are like one to one then that basically means that your distribution is completely normal okay I guess another way of saying it is just by plotting a histogram of it so we can just say hist of your variable which is going to be the residuals of lm.fit1 and then you can see that it's actually pretty normally distributed I mean it looks like so but I mean this is just a graphical way of seeing it um so that's why we also do the QQ the QQ plot to say if it's I mean to be more sure of it and then on top of that we can actually add a QQ line which is going to plot QQ line like this and we're just passing the residuals to of our lm.fit1 there you go and I'm just going to color it red like that there you go and there there you have it so I mean the QQ the QQ plot for a normal distribution basically means that the more your points are aligned with this no with this line the more your distribution is actually normal okay so this one actually starting to look pretty normal and that's the graphical way of testing if you're just if your residuals are normally distributed um if you want to be even more sure of it you can add another test I mean normal normality analysis is just a topic in and of itself and it could take a long time to actually go through it and just I mean there are very numerous and different kinds of tests and not all of them working with all distributions I mean with all data sets but I mean I'm just showing you a couple here um you can also use a Shapiro test a shapir will test and what this one does is that it basically just tells you if your distribution is normal um as well we've we pass in the residuals of our linear model like this LM fit one there you go we run it and there is a problem because I called it shapiri instead of Shapiro there you go we run it and there we have it so the Shapiro normalized test what it does is that it assumes that the distribution is normal okay that's the h0 and then if we then we just run the Shapiro test and if the p-value is lower than 0.05 that means that we'd reject h0 so we reject normality here the p-value is of course over 0.05 so we cannot reject h0 and the normal ending so we keep we keep the h0 hypothesis and we keep the fact that it's like it's actually normally distributed so that was the normality analysis of the residuals um so they look pretty normal and that means that our model is actually looking pretty good um so what what are we going to do right now we're actually going to evaluate the quality of the model by training it because so far we have actually trained it using the entirety of our data but what we're going to want to do now is we're going to divide our data into a training set and into a day into a testing set it's just I mean of all the 500 observations that we have here we're going to take some random observations train our linear model with those and then we're going to create and when you're we're going to test this model and try to predict the values on some data that the model has not seen you before which is going to be our test data and then we're going to see how well we did okay so let's see that I'm going to just add a new a new section right here I'm going to call it um evaluation evaluation of the of the model there you go and let's just set the seed for one right here and let's just generate row number and let's just create a sample from one to n Row the number of rows in data and 0.8 times the number of rows in the data okay so what are we doing right here uh let me tell you so here what we're doing is basically we're just taking a sample from one and I mean we're giving it a range from one to the number of rows in data so the number of rows in data is 500. so we're taking the sample from 1 to 100 and what we're going to be doing is we're going to be creating we're going to be taking 0.8 I mean 80 of that data and this is what we're going to I mean this sample I mean this is just like the list of rows that we're going to be using there for this one okay and it's going to be random so let's run it right here and here we have it it's a it's just a just an array a list of of 400 elements and and it's random okay so that's what I that's what I was telling you about um now we're going to create our train variable with it and for it we're just going to subset our data with this with this new um oh sorry I missed a comma right here there you go so what we have done right here is that from this samp random sample that we have created we just subset our data so now we have 400 L 400 random elements from data in our train data set okay so there you go and then we're going to do pretty much the same but with the test data set and we're going to call it test and we're just going to call it we're just going to soft set again data but here we're just going to add a negative um before the variable right here so we're just going to take exactly the opposite of this one so let's just run that one and you can see that our test is 20 of the data right here and our training set is four is eight eighty percent of our data right here so we have our training set and our test set all right so let's now what we're going to do is estimate the linear fit with the training set um so we're going to do pretty much the same thing that we did before but instead of using the entire set we're going to be using only the the training set so let's do that so we're going to do LM fit lm.fit and before we just called it one but since we're now just using 80 I'm just going to say 0.8 and let's just add it um just as we did before LM yearly amount spent there you go and then that's going to be our response and our our predictor is going to be length of membership length of membership there you go and I mean I I don't think I have it attached uh yet or I'm yeah I think it it's attached still so this should work oh no no that's actually not gonna work because I have still attached I mean the the one that I have attached is the data and I don't want to work with the entire data I just want to work with the trained data set okay so I rerun this and now LM feed 0.8 is trying to get yearly spent from length of membership with the training data set so it's using only 400 observations to train this this data this this model okay let's take a look at the summary and let's see what we can see from it summary lmfit08 there you go so let's see we have a pretty similar um pretty similar result to the one that we got using the entire data set and that is convenient because I mean we're using pretty much the same kind of data but the thing right now is we're going to try to predict um taking the test data set we're going to take every single value from I mean we're going to try to predict using something like this we're going to take every single value of the length of membership and we're going to try to predict the yearly amount spent and we're going to try to find how far off was our prediction okay so let's do that we're going to predict in the test data sets there we go so what we're going to do is try to predict with this model that we have created to run the prediction in our test data set okay so to do this it's pretty it's actually pretty simple what we're going to do is we're going to just create a new variable that's going to let's call it prediction 0.8 because we're predicting with 80 of the data and we're going to use the function called predict like that there you go and this function takes into arguments the first one is going to be your model and the model is the one that we have just trained so it's lmfit 0.8 remember we created it up here and the second argument is going to be the new data that we're going to be using to actually test it and the new data is to test data of course I mean it's the the remaining 20 data that our model has not yet seen so there you go I'm going to run it like that there you go so there you have our prediction 0.8 um there you have it it's just a list of 100 elements um and so I mean it's basically just what it predicts the let me let me show you what what it actually is so what this thing is doing is it's taking the variable length of membership from our test data set and without looking at the actual predict at the actual year leading yearly amount spent it's trying to predict how much the yearly amount spent it um was for that actual observation so it's doing that for every single observation so that's the reason why we have a hundred a list of 100 things right here because it's the 100 predictions for the yearly observations for the hundred observations in the test data set okay and what we're going to do now is we're basically just going to calculate the difference between what was predicted and what was the actual value okay and to do that I'm just going to store that in a new in a new variable called error error 0.8 and I mean it's basically just a difference so it's a it's prediction I mean this value right here prediction 0.8 minus the actual value so since we have a list it's going to calculate the difference between every element in that list um and this one right here is going to be um tick tick tag test yearly amount spend there you go and now we have our value our variable called error 0.8 and it's just a list of 100 elements um of the I mean the difference between those between the between the actual between the actual value and the prediction there you go and now we can actually calculate some um I mean error the error measurement measure measurements um I'm not going to go over what these actually are but I mean just like uh you can look for an explanation of what these are and the diamond they they're used to actually check the how well your model is behaving okay and how well it's predicting its results um so first I'm just going to show you how to calculate the the root mean Square oops root mean square error I mean it's pretty simple root just going to call it root mean square error like this and I'm going to save it it's pretty just pretty much just defined just to square it of the mean of every part of your air squared there you go um yeah there you go so now we have our our root mean square error that was defined and let's also call let's also create an absolute percentage error there you go and that's that was the map I mean absolute percentage error and this one is basically just defined as the mean of the absolute value of air 0.8 between sorry over test and the yearly amount spent um there we go so now we have our our map and our rmsc and let's just take a look at those and how what this looks like rnse equals Army scene not equals r squared let's also take r squared so it's going to it's going to be equal summary Ln dot fit 0.8 check uh squared um pretty sure this is supposed to work um R2 mode what's going on here um summary lm30.8 r squared there you go um there is a problem with this one apparently and what happened here summary hmm it's gonna oh that's quite uh just let me show you what's going on right here so we have our root mean square error which is 44 and we have our mean absolute percentage here of course it since it's a um uh percentage areas between 0.0 and one um there you go so this is pretty much how to calculate how to evaluate your model I mean there are many different methods but there you go those are just just a few R2 I don't know what's going on with our two length object class and R2 modes null um let's just check this out is there a problem with this function right here oops um all right so there seems to be a problem with Alan Ln fed 0.8 r squared multiple r squared all right so we actually have the values I don't know why it's not working there um [Music] no it's it's actually all right well it's a problem here all right sure because I added this one right here it was not supposed to be here it was supposed to be here there you go so now it should work there you go so now you have R2 um so now we have the three the three measurements in here sorry about that so this one this one right here is the actually the one that's actually um creating the the summary and this one right here we're just subsetting r squared there you go so that was how to evaluate the model but as you can see right now the model is I mean it's all right but it's not amazing uh what I'm going to show you now is how to do pretty much the same thing but with the multiple regression so what we did so far is just like a regular linear regression with just one variable but I mean in the real world there is not just one variable that influences your result so in the real world you're going to be using a multiple regression even for the multiple regression even for the simplest cases because I mean the world is not very simple right um let's attach our data again there you go um and then what we're going to do is we're just going to create a new a new model and we're going to call it lmfit and in in this one again we're going to start with yearly amount spent that's our the first argument again it's going to be the response that we that we expect but after I mean remember that the the second part of this of this formula after the TLD is going to be the predictors okay and instead of just adding one single variable that like we did before we added right here we added pretty much just length of membership as a variable and in this one what we're going to do is we're going to add all of the all of the other numerical variables okay so we're going to add average session length then we add plus um I'm just going to add in the same line um added time on app we're going to add time on a website as well and we're going to add a length of membership there you go so now what this one is doing right here is it's training a linear model but it's going to be a multi-dimensional linear model okay so basically our function is going to look more like this one right here so we will not be working with with a single variable linear model but we'll be working with a several variable in your model and we're just going to try to find which variables are actually relevant to our to our response so let's take a look at that um to do that what we're going to do first is well let's just first of all let's take a look at our summary of I mean just with this simple command we have just already created our linear linear model for owl mode for our multiple regression so let's see how that looks like lmfit um there was a problem with this one summary LM fit tag there you go so let's see what this looks like so we have the formula that I showed you we have the response expected and the predictors over here and here we have the residuals as well I mean you you're going to want to do just as we did before a residual analysis of this one too but here as you can see instead of the single predict single coefficient that we had on a pre on the previous linear model here we have several predictors okay and we have several coefficients so we have for example that the average session length has a coefficient of 25 so it's actually kind of quite important I mean it seems to be quite important we have time on Apple 38 and the length of membership of 61. this one seems to be the most relevant one apparently but we also have more information right here we have the standard error we have the T value and importantly as well we have the P value right here what does the p-value tells us tell us um just as we were mentioning before it tells us that if it's lower than 0.05 we reject the null hypothesis and we actually keep the variable as significant the three stars as I was mentioning before indicates the significance of the variable so three stars is very significant zero stars is not significant and as we can see from this multivariable linear model we see that the time on the website is not a very significant variable even though it has even though I mean even though we included it in our linear model we can drop it and it's not going to it's not going to harm our model um so yeah I mean three of the four variables uh studied seem to have a positive impact in the response variable uh positive I mean because all of these coefficients are positive if one of the coefficients was negative that doesn't mean that it's not um relevant but it means that the correlation is it has an inverse relationship with the with our result variable um there you go and the of course time of website that we're going to be able to drop um I guess I can show you how to yeah let's do pretty much the same thing as we did up here I'm just going to copy paste the part of the evaluation model just to just to go pretty fast but I'm just let's just evaluate this multi multiple regression evaluation of the multiple regression as you can as you will see this one right here is actually way more accurate um so again we're going to set the seat to one and we're going to um we're going to be working with the same train and test data set we're not going to recreate our division but we're going to but what we are going to do is we're going to re-re um uh create our linear model for only the training set are multi-variable linear model for only the training set so I'm going to copy this line right here I'm going to paste it right here there you go so what this one right here is going to be doing I'm going to be calling it 0.8 as well and what this one right here is going to be doing is it's going to be again just creating my linear model but the data that we're going to be using for this one um there you go it's going to be the train data set oops train data set what's going on here trying data so there you go um so I'm just going to run this one and let's see how that looks like so as you can see right now it's pretty much the same as we had before because we're using detain the same kind of data but now what the important part right here is going to be the prediction uh so we're going to use this lm508 to predict the new the new data of the test data set okay um you know what I'm just going to change the name of this variable so that it's easier to see I'm going to call it multi-linear model fit just run it I'm going to call it there we go multi linear model fit there you go and then we're going to predict it here I'm going to be using the multi multi linear model as a predictor and the new data is going to be test just as before and let's see how that worked again just as before we're going to be calculating the error and the error for this one is going to be stored in prediction 0.8 minus the actual value in the yearly amount spent let's run that one and again just let's run the rmsc mape there you go and let's just print that out so there you go so here you have the results for the multiple linear regression I hope I didn't lose you in that one I mean we did exactly the same thing as we did with evaluating the linear model for a single simple regression model but we just did it I mean the only it's pretty much exactly the same just that we we added more variables here as the predictors and as you can see the results are different the the error measurements are much better R2 is almost equal to one and that's pretty good because we're working with the test data set and as you can see before we had we had used a multiple regression um where is it here it is this this were our previous values for for the these were our previous values for the rootman square error and for the mean absolute uh percentage percentage error um and yeah for R2 Square for r squared so as you can see the air from the error right here went from forty two dollars to eight dollars the mean absolute percentage error went from 0.07 to 0.01 and R2 went from I mean r squared went from 0.65 to 0.98 so we have we have um improved our model by a lot and yeah I mean that's pretty much how how you run multiple regressions in our um so yeah I mean defining style that by using a multiple linear model we have created a much more accurate predictor of the response of the variable even though we're using a pretty simple mathematical tool we're actually being able to predict much better and to explain much better the the data by using a multiple regression model so R2 went from 0.65 to 0.92 RSC went from 47 to nine dollars so pretty good all right so there you go that was how to create um just how to create a multiple linear regression and how to add how to train a linear regression model in R hope you found it useful um there you go please like And subscribe if you liked it and I'll see you next time [Music] [Music] foreign [Music]
